Epoch: 1/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.6836 (0.6860) Acc D Real: 69.010%
Loss D Fake: 0.7038 (0.7025) Acc D Fake: 0.000%
Loss D: 1.387
Loss G: 0.6815 (0.6828) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.6795 (0.6839) Acc D Real: 75.035%
Loss D Fake: 0.7064 (0.7038) Acc D Fake: 0.000%
Loss D: 1.386
Loss G: 0.6790 (0.6815) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.6795 (0.6828) Acc D Real: 76.953%
Loss D Fake: 0.7089 (0.7051) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6765 (0.6803) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.6767 (0.6816) Acc D Real: 78.531%
Loss D Fake: 0.7114 (0.7064) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6741 (0.6790) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.6726 (0.6801) Acc D Real: 81.806%
Loss D Fake: 0.7139 (0.7076) Acc D Fake: 0.000%
Loss D: 1.387
Loss G: 0.6717 (0.6778) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.6717 (0.6789) Acc D Real: 83.906%
Loss D Fake: 0.7164 (0.7089) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6693 (0.6766) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.6653 (0.6772) Acc D Real: 85.794%
Loss D Fake: 0.7189 (0.7101) Acc D Fake: 0.000%
Loss D: 1.384
Loss G: 0.6669 (0.6754) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.6615 (0.6754) Acc D Real: 87.367%
Loss D Fake: 0.7215 (0.7114) Acc D Fake: 0.000%
Loss D: 1.383
Loss G: 0.6645 (0.6742) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.6637 (0.6743) Acc D Real: 88.620%
Loss D Fake: 0.7241 (0.7127) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6621 (0.6730) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.6643 (0.6733) Acc D Real: 89.654%
Loss D Fake: 0.7267 (0.7139) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.6597 (0.6718) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.6627 (0.6725) Acc D Real: 90.516%
Loss D Fake: 0.7292 (0.7152) Acc D Fake: 0.000%
Loss D: 1.392
Loss G: 0.6573 (0.6706) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.6583 (0.6714) Acc D Real: 91.246%
Loss D Fake: 0.7318 (0.7165) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6549 (0.6694) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.6540 (0.6701) Acc D Real: 91.871%
Loss D Fake: 0.7343 (0.7178) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6526 (0.6682) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.6518 (0.6689) Acc D Real: 92.413%
Loss D Fake: 0.7369 (0.7190) Acc D Fake: 0.000%
Loss D: 1.389
Loss G: 0.6502 (0.6670) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.6489 (0.6677) Acc D Real: 92.887%
Loss D Fake: 0.7395 (0.7203) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.6478 (0.6658) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.6480 (0.6665) Acc D Real: 93.306%
Loss D Fake: 0.7422 (0.7216) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6453 (0.6646) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.6411 (0.6651) Acc D Real: 93.678%
Loss D Fake: 0.7449 (0.7229) Acc D Fake: 0.000%
Loss D: 1.386
Loss G: 0.6428 (0.6633) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.6423 (0.6639) Acc D Real: 94.010%
Loss D Fake: 0.7478 (0.7242) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6402 (0.6621) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.6404 (0.6627) Acc D Real: 94.310%
Loss D Fake: 0.7507 (0.7255) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.6376 (0.6609) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.6361 (0.6615) Acc D Real: 94.581%
Loss D Fake: 0.7536 (0.7269) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6350 (0.6597) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.6330 (0.6602) Acc D Real: 94.827%
Loss D Fake: 0.7567 (0.7282) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6322 (0.6584) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.6304 (0.6589) Acc D Real: 95.052%
Loss D Fake: 0.7599 (0.7296) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6293 (0.6572) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.6271 (0.6575) Acc D Real: 95.258%
Loss D Fake: 0.7632 (0.7310) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6264 (0.6559) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.6250 (0.6562) Acc D Real: 95.448%
Loss D Fake: 0.7666 (0.7324) Acc D Fake: 0.000%
Loss D: 1.392
Loss G: 0.6235 (0.6546) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.6204 (0.6549) Acc D Real: 95.623%
Loss D Fake: 0.7700 (0.7339) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.6206 (0.6533) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.6178 (0.6535) Acc D Real: 95.785%
Loss D Fake: 0.7735 (0.7353) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.6174 (0.6519) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.6142 (0.6521) Acc D Real: 95.936%
Loss D Fake: 0.7773 (0.7368) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.6142 (0.6506) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.6120 (0.6507) Acc D Real: 96.076%
Loss D Fake: 0.7811 (0.7384) Acc D Fake: 0.000%
Loss D: 1.393
Loss G: 0.6110 (0.6492) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.6094 (0.6493) Acc D Real: 96.207%
Loss D Fake: 0.7849 (0.7399) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.6078 (0.6479) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.6048 (0.6479) Acc D Real: 96.329%
Loss D Fake: 0.7889 (0.7415) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.6044 (0.6465) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.5990 (0.6464) Acc D Real: 96.444%
Loss D Fake: 0.7930 (0.7431) Acc D Fake: 0.000%
Loss D: 1.392
Loss G: 0.6009 (0.6450) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.5943 (0.6448) Acc D Real: 96.551%
Loss D Fake: 0.7973 (0.7447) Acc D Fake: 0.000%
Loss D: 1.392
Loss G: 0.5974 (0.6436) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.5915 (0.6432) Acc D Real: 96.653%
Loss D Fake: 0.8017 (0.7464) Acc D Fake: 0.000%
Loss D: 1.393
Loss G: 0.5938 (0.6421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.5873 (0.6416) Acc D Real: 96.749%
Loss D Fake: 0.8064 (0.7481) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.5899 (0.6406) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.5790 (0.6399) Acc D Real: 96.839%
Loss D Fake: 0.8113 (0.7499) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.5859 (0.6391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.5766 (0.6382) Acc D Real: 96.924%
Loss D Fake: 0.8166 (0.7517) Acc D Fake: 0.000%
Loss D: 1.393
Loss G: 0.5816 (0.6376) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.5715 (0.6364) Acc D Real: 97.005%
Loss D Fake: 0.8223 (0.7535) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.5770 (0.6360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.5619 (0.6345) Acc D Real: 97.082%
Loss D Fake: 0.8286 (0.7555) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.5720 (0.6343) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.5587 (0.6326) Acc D Real: 97.155%
Loss D Fake: 0.8356 (0.7575) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.5664 (0.6326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.5470 (0.6305) Acc D Real: 97.224%
Loss D Fake: 0.8434 (0.7596) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.5602 (0.6309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.5275 (0.6281) Acc D Real: 97.290%
Loss D Fake: 0.8524 (0.7618) Acc D Fake: 0.000%
Loss D: 1.380
Loss G: 0.5533 (0.6290) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.5337 (0.6259) Acc D Real: 97.353%
Loss D Fake: 0.8628 (0.7641) Acc D Fake: 0.000%
Loss D: 1.397
Loss G: 0.5454 (0.6271) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.5080 (0.6232) Acc D Real: 97.414%
Loss D Fake: 0.8749 (0.7666) Acc D Fake: 0.000%
Loss D: 1.383
Loss G: 0.5362 (0.6250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.5145 (0.6208) Acc D Real: 97.471%
Loss D Fake: 0.8894 (0.7694) Acc D Fake: 0.000%
Loss D: 1.404
Loss G: 0.5258 (0.6228) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4730 (0.6176) Acc D Real: 97.526%
Loss D Fake: 0.9064 (0.7724) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.5135 (0.6204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.4377 (0.6137) Acc D Real: 97.579%
Loss D Fake: 0.9277 (0.7757) Acc D Fake: 0.000%
Loss D: 1.365
Loss G: 0.4988 (0.6178) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.4545 (0.6104) Acc D Real: 97.629%
Loss D Fake: 0.9545 (0.7794) Acc D Fake: 0.000%
Loss D: 1.409
Loss G: 0.4827 (0.6150) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.4537 (0.6072) Acc D Real: 97.678%
Loss D Fake: 0.9839 (0.7836) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4666 (0.6120) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4151 (0.6034) Acc D Real: 97.724%
Loss D Fake: 1.0126 (0.7881) Acc D Fake: 0.000%
Loss D: 1.428
Loss G: 0.4546 (0.6088) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3986 (0.5994) Acc D Real: 97.769%
Loss D Fake: 1.0307 (0.7929) Acc D Fake: 0.000%
Loss D: 1.429
Loss G: 0.4478 (0.6057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3840 (0.5952) Acc D Real: 97.811%
Loss D Fake: 1.0388 (0.7976) Acc D Fake: 0.000%
Loss D: 1.423
Loss G: 0.4464 (0.6026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3857 (0.5913) Acc D Real: 97.853%
Loss D Fake: 1.0347 (0.8021) Acc D Fake: 0.000%
Loss D: 1.420
Loss G: 0.4511 (0.5998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.4319 (0.5883) Acc D Real: 97.893%
Loss D Fake: 1.0210 (0.8062) Acc D Fake: 0.000%
Loss D: 1.453
Loss G: 0.4581 (0.5971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3924 (0.5848) Acc D Real: 97.931%
Loss D Fake: 1.0056 (0.8098) Acc D Fake: 0.000%
Loss D: 1.398
Loss G: 0.4662 (0.5948) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3948 (0.5814) Acc D Real: 97.968%
Loss D Fake: 0.9907 (0.8130) Acc D Fake: 0.000%
Loss D: 1.386
Loss G: 0.4728 (0.5926) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3971 (0.5781) Acc D Real: 98.003%
Loss D Fake: 0.9804 (0.8159) Acc D Fake: 0.000%
Loss D: 1.377
Loss G: 0.4774 (0.5906) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.4296 (0.5756) Acc D Real: 98.038%
Loss D Fake: 0.9739 (0.8187) Acc D Fake: 0.000%
Loss D: 1.403
Loss G: 0.4801 (0.5887) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4266 (0.5730) Acc D Real: 98.071%
Loss D Fake: 0.9697 (0.8212) Acc D Fake: 0.000%
Loss D: 1.396
Loss G: 0.4825 (0.5869) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.4742 (0.5714) Acc D Real: 98.103%
Loss D Fake: 0.9655 (0.8236) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4846 (0.5852) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3661 (0.5680) Acc D Real: 98.134%
Loss D Fake: 0.9629 (0.8259) Acc D Fake: 0.000%
Loss D: 1.329
Loss G: 0.4854 (0.5835) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3856 (0.5651) Acc D Real: 98.164%
Loss D Fake: 0.9624 (0.8281) Acc D Fake: 0.000%
Loss D: 1.348
Loss G: 0.4854 (0.5819) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.4303 (0.5629) Acc D Real: 98.194%
Loss D Fake: 0.9628 (0.8303) Acc D Fake: 0.000%
Loss D: 1.393
Loss G: 0.4852 (0.5804) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.4231 (0.5608) Acc D Real: 98.222%
Loss D Fake: 0.9639 (0.8323) Acc D Fake: 0.000%
Loss D: 1.387
Loss G: 0.4838 (0.5789) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3778 (0.5579) Acc D Real: 98.249%
Loss D Fake: 0.9676 (0.8344) Acc D Fake: 0.000%
Loss D: 1.345
Loss G: 0.4814 (0.5774) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3998 (0.5556) Acc D Real: 98.276%
Loss D Fake: 0.9721 (0.8365) Acc D Fake: 0.000%
Loss D: 1.372
Loss G: 0.4796 (0.5759) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.4198 (0.5535) Acc D Real: 98.301%
Loss D Fake: 0.9748 (0.8386) Acc D Fake: 0.000%
Loss D: 1.395
Loss G: 0.4787 (0.5745) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4348 (0.5518) Acc D Real: 98.326%
Loss D Fake: 0.9753 (0.8406) Acc D Fake: 0.000%
Loss D: 1.410
Loss G: 0.4795 (0.5731) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3827 (0.5493) Acc D Real: 98.351%
Loss D Fake: 0.9721 (0.8425) Acc D Fake: 0.000%
Loss D: 1.355
Loss G: 0.4821 (0.5717) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3489 (0.5465) Acc D Real: 98.374%
Loss D Fake: 0.9678 (0.8443) Acc D Fake: 0.000%
Loss D: 1.317
Loss G: 0.4836 (0.5705) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4033 (0.5445) Acc D Real: 98.397%
Loss D Fake: 0.9659 (0.8460) Acc D Fake: 0.000%
Loss D: 1.369
Loss G: 0.4850 (0.5693) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3797 (0.5422) Acc D Real: 98.419%
Loss D Fake: 0.9646 (0.8476) Acc D Fake: 0.000%
Loss D: 1.344
Loss G: 0.4845 (0.5681) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.4079 (0.5403) Acc D Real: 98.441%
Loss D Fake: 0.9667 (0.8493) Acc D Fake: 0.000%
Loss D: 1.375
Loss G: 0.4841 (0.5670) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3603 (0.5379) Acc D Real: 98.462%
Loss D Fake: 0.9660 (0.8508) Acc D Fake: 0.000%
Loss D: 1.326
Loss G: 0.4859 (0.5659) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3903 (0.5359) Acc D Real: 98.483%
Loss D Fake: 0.9612 (0.8523) Acc D Fake: 0.000%
Loss D: 1.351
Loss G: 0.4891 (0.5648) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3699 (0.5337) Acc D Real: 98.503%
Loss D Fake: 0.9555 (0.8537) Acc D Fake: 0.000%
Loss D: 1.325
Loss G: 0.4918 (0.5639) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3785 (0.5317) Acc D Real: 98.522%
Loss D Fake: 0.9510 (0.8549) Acc D Fake: 0.000%
Loss D: 1.330
Loss G: 0.4947 (0.5630) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3997 (0.5300) Acc D Real: 98.541%
Loss D Fake: 0.9461 (0.8561) Acc D Fake: 0.000%
Loss D: 1.346
Loss G: 0.4974 (0.5621) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4227 (0.5287) Acc D Real: 98.559%
Loss D Fake: 0.9416 (0.8572) Acc D Fake: 0.000%
Loss D: 1.364
Loss G: 0.5000 (0.5613) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3914 (0.5270) Acc D Real: 98.577%
Loss D Fake: 0.9392 (0.8582) Acc D Fake: 0.000%
Loss D: 1.331
Loss G: 0.4996 (0.5606) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4126 (0.5255) Acc D Real: 98.595%
Loss D Fake: 0.9415 (0.8592) Acc D Fake: 0.000%
Loss D: 1.354
Loss G: 0.4990 (0.5598) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4222 (0.5243) Acc D Real: 98.612%
Loss D Fake: 0.9433 (0.8603) Acc D Fake: 0.000%
Loss D: 1.366
Loss G: 0.4970 (0.5590) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3728 (0.5225) Acc D Real: 98.629%
Loss D Fake: 0.9475 (0.8613) Acc D Fake: 0.000%
Loss D: 1.320
Loss G: 0.4959 (0.5583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4051 (0.5211) Acc D Real: 98.645%
Loss D Fake: 0.9480 (0.8624) Acc D Fake: 0.000%
Loss D: 1.353
Loss G: 0.4968 (0.5576) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4589 (0.5203) Acc D Real: 98.661%
Loss D Fake: 0.9470 (0.8634) Acc D Fake: 0.000%
Loss D: 1.406
Loss G: 0.4964 (0.5568) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3686 (0.5186) Acc D Real: 98.677%
Loss D Fake: 0.9481 (0.8643) Acc D Fake: 0.000%
Loss D: 1.317
Loss G: 0.4968 (0.5561) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3712 (0.5169) Acc D Real: 98.692%
Loss D Fake: 0.9471 (0.8653) Acc D Fake: 0.000%
Loss D: 1.318
Loss G: 0.4974 (0.5555) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3269 (0.5147) Acc D Real: 98.707%
Loss D Fake: 0.9454 (0.8662) Acc D Fake: 0.000%
Loss D: 1.272
Loss G: 0.4990 (0.5548) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3760 (0.5132) Acc D Real: 98.721%
Loss D Fake: 0.9421 (0.8671) Acc D Fake: 0.000%
Loss D: 1.318
Loss G: 0.5007 (0.5542) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3750 (0.5116) Acc D Real: 98.736%
Loss D Fake: 0.9394 (0.8679) Acc D Fake: 0.000%
Loss D: 1.314
Loss G: 0.5014 (0.5536) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3853 (0.5102) Acc D Real: 98.749%
Loss D Fake: 0.9387 (0.8686) Acc D Fake: 0.000%
Loss D: 1.324
Loss G: 0.5011 (0.5530) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3381 (0.5084) Acc D Real: 98.763%
Loss D Fake: 0.9400 (0.8694) Acc D Fake: 0.000%
Loss D: 1.278
Loss G: 0.4992 (0.5525) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3336 (0.5065) Acc D Real: 98.776%
Loss D Fake: 0.9437 (0.8702) Acc D Fake: 0.000%
Loss D: 1.277
Loss G: 0.4962 (0.5519) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.2952 (0.5042) Acc D Real: 98.789%
Loss D Fake: 0.9485 (0.8710) Acc D Fake: 0.000%
Loss D: 1.244
Loss G: 0.4923 (0.5512) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2983 (0.5021) Acc D Real: 98.802%
Loss D Fake: 0.9545 (0.8719) Acc D Fake: 0.000%
Loss D: 1.253
Loss G: 0.4866 (0.5505) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.2908 (0.4999) Acc D Real: 98.815%
Loss D Fake: 0.9636 (0.8729) Acc D Fake: 0.000%
Loss D: 1.254
Loss G: 0.4789 (0.5498) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.2683 (0.4975) Acc D Real: 98.827%
Loss D Fake: 0.9779 (0.8740) Acc D Fake: 0.000%
Loss D: 1.246
Loss G: 0.4769 (0.5490) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.2185 (0.4946) Acc D Real: 98.839%
Loss D Fake: 0.9711 (0.8749) Acc D Fake: 0.000%
Loss D: 1.190
Loss G: 0.4907 (0.5485) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2246 (0.4919) Acc D Real: 98.850%
Loss D Fake: 0.9395 (0.8756) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.5041 (0.5480) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.2023 (0.4890) Acc D Real: 98.862%
Loss D Fake: 0.9216 (0.8761) Acc D Fake: 0.000%
Loss D: 1.124
Loss G: 0.5130 (0.5477) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.2183 (0.4863) Acc D Real: 98.873%
Loss D Fake: 0.9107 (0.8764) Acc D Fake: 0.000%
Loss D: 1.129
Loss G: 0.5195 (0.5474) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.2282 (0.4838) Acc D Real: 98.884%
Loss D Fake: 0.9031 (0.8767) Acc D Fake: 0.000%
Loss D: 1.131
Loss G: 0.5250 (0.5472) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2061 (0.4811) Acc D Real: 98.895%
Loss D Fake: 0.8963 (0.8769) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.5297 (0.5470) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.2030 (0.4784) Acc D Real: 98.906%
Loss D Fake: 0.8900 (0.8770) Acc D Fake: 0.000%
Loss D: 1.093
Loss G: 0.5339 (0.5469) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.1701 (0.4755) Acc D Real: 98.916%
Loss D Fake: 0.8842 (0.8770) Acc D Fake: 0.000%
Loss D: 1.054
Loss G: 0.5374 (0.5468) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.1931 (0.4728) Acc D Real: 98.926%
Loss D Fake: 0.8790 (0.8771) Acc D Fake: 0.000%
Loss D: 1.072
Loss G: 0.5405 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.1685 (0.4700) Acc D Real: 98.936%
Loss D Fake: 0.8741 (0.8770) Acc D Fake: 0.000%
Loss D: 1.043
Loss G: 0.5430 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.1780 (0.4673) Acc D Real: 98.946%
Loss D Fake: 0.8698 (0.8770) Acc D Fake: 0.000%
Loss D: 1.048
Loss G: 0.5450 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.1694 (0.4645) Acc D Real: 98.956%
Loss D Fake: 0.8664 (0.8769) Acc D Fake: 0.000%
Loss D: 1.036
Loss G: 0.5469 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.1746 (0.4619) Acc D Real: 98.965%
Loss D Fake: 0.8638 (0.8768) Acc D Fake: 0.000%
Loss D: 1.038
Loss G: 0.5486 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.1877 (0.4594) Acc D Real: 98.975%
Loss D Fake: 0.8625 (0.8766) Acc D Fake: 0.000%
Loss D: 1.050
Loss G: 0.5502 (0.5467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.1594 (0.4568) Acc D Real: 98.984%
Loss D Fake: 0.8604 (0.8765) Acc D Fake: 0.000%
Loss D: 1.020
Loss G: 0.5554 (0.5468) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.1644 (0.4542) Acc D Real: 98.992%
Loss D Fake: 0.8511 (0.8763) Acc D Fake: 0.000%
Loss D: 1.015
Loss G: 0.5623 (0.5469) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.1610 (0.4516) Acc D Real: 99.001%
Loss D Fake: 0.8417 (0.8760) Acc D Fake: 0.000%
Loss D: 1.003
Loss G: 0.5681 (0.5471) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.1693 (0.4491) Acc D Real: 99.009%
Loss D Fake: 0.8344 (0.8756) Acc D Fake: 0.000%
Loss D: 1.004
Loss G: 0.5730 (0.5473) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.1803 (0.4468) Acc D Real: 99.017%
Loss D Fake: 0.8281 (0.8752) Acc D Fake: 0.000%
Loss D: 1.008
Loss G: 0.5772 (0.5476) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.1397 (0.4442) Acc D Real: 99.025%
Loss D Fake: 0.8226 (0.8747) Acc D Fake: 0.000%
Loss D: 0.962
Loss G: 0.5813 (0.5479) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.1630 (0.4418) Acc D Real: 99.032%
Loss D Fake: 0.8174 (0.8743) Acc D Fake: 0.000%
Loss D: 0.980
Loss G: 0.5851 (0.5482) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.1453 (0.4393) Acc D Real: 99.039%
Loss D Fake: 0.8127 (0.8737) Acc D Fake: 0.000%
Loss D: 0.958
Loss G: 0.5886 (0.5485) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.1457 (0.4369) Acc D Real: 99.045%
Loss D Fake: 0.8086 (0.8732) Acc D Fake: 0.000%
Loss D: 0.954
Loss G: 0.5917 (0.5489) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.1577 (0.4346) Acc D Real: 99.053%
Loss D Fake: 0.8047 (0.8726) Acc D Fake: 0.000%
Loss D: 0.962
Loss G: 0.5948 (0.5493) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.1545 (0.4323) Acc D Real: 99.059%
Loss D Fake: 0.8012 (0.8720) Acc D Fake: 0.000%
Loss D: 0.956
Loss G: 0.5974 (0.5497) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.1355 (0.4299) Acc D Real: 99.065%
Loss D Fake: 0.7982 (0.8714) Acc D Fake: 0.000%
Loss D: 0.934
Loss G: 0.6001 (0.5501) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.1437 (0.4276) Acc D Real: 99.069%
Loss D Fake: 0.7951 (0.8708) Acc D Fake: 0.000%
Loss D: 0.939
Loss G: 0.6025 (0.5505) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.1522 (0.4254) Acc D Real: 99.075%
Loss D Fake: 0.7922 (0.8702) Acc D Fake: 0.000%
Loss D: 0.944
Loss G: 0.6049 (0.5509) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.1367 (0.4231) Acc D Real: 99.081%
Loss D Fake: 0.7894 (0.8696) Acc D Fake: 0.000%
Loss D: 0.926
Loss G: 0.6074 (0.5514) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.1475 (0.4209) Acc D Real: 99.085%
Loss D Fake: 0.7867 (0.8689) Acc D Fake: 0.000%
Loss D: 0.934
Loss G: 0.6094 (0.5518) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.1517 (0.4188) Acc D Real: 99.087%
Loss D Fake: 0.7848 (0.8682) Acc D Fake: 0.000%
Loss D: 0.936
Loss G: 0.6113 (0.5523) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.1720 (0.4169) Acc D Real: 99.088%
Loss D Fake: 0.7830 (0.8676) Acc D Fake: 0.000%
Loss D: 0.955
Loss G: 0.6131 (0.5528) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.1553 (0.4149) Acc D Real: 99.093%
Loss D Fake: 0.7812 (0.8669) Acc D Fake: 0.000%
Loss D: 0.937
Loss G: 0.6149 (0.5533) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.1254 (0.4127) Acc D Real: 99.096%
Loss D Fake: 0.7799 (0.8663) Acc D Fake: 0.000%
Loss D: 0.905
Loss G: 0.6164 (0.5537) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.1386 (0.4106) Acc D Real: 99.102%
Loss D Fake: 0.7787 (0.8656) Acc D Fake: 0.000%
Loss D: 0.917
Loss G: 0.6185 (0.5542) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.1272 (0.4085) Acc D Real: 99.104%
Loss D Fake: 0.7762 (0.8649) Acc D Fake: 0.000%
Loss D: 0.903
Loss G: 0.6210 (0.5547) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.1424 (0.4065) Acc D Real: 99.106%
Loss D Fake: 0.7736 (0.8642) Acc D Fake: 0.000%
Loss D: 0.916
Loss G: 0.6238 (0.5552) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.1318 (0.4044) Acc D Real: 99.109%
Loss D Fake: 0.7713 (0.8636) Acc D Fake: 0.000%
Loss D: 0.903
Loss G: 0.6264 (0.5558) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.1414 (0.4025) Acc D Real: 99.113%
Loss D Fake: 0.7703 (0.8629) Acc D Fake: 0.000%
Loss D: 0.912
Loss G: 0.6281 (0.5563) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.1791 (0.4009) Acc D Real: 99.115%
Loss D Fake: 0.7795 (0.8623) Acc D Fake: 0.000%
Loss D: 0.959
Loss G: 0.6187 (0.5568) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.1454 (0.3990) Acc D Real: 99.121%
Loss D Fake: 1.5749 (0.8674) Acc D Fake: 0.000%
Loss D: 1.720
Loss G: 0.6206 (0.5572) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.1360 (0.3971) Acc D Real: 99.127%
Loss D Fake: 0.7818 (0.8668) Acc D Fake: 0.000%
Loss D: 0.918
Loss G: 0.6307 (0.5578) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.1362 (0.3953) Acc D Real: 99.127%
Loss D Fake: 0.7695 (0.8661) Acc D Fake: 0.000%
Loss D: 0.906
Loss G: 0.6337 (0.5583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.1425 (0.3935) Acc D Real: 99.126%
Loss D Fake: 0.7669 (0.8654) Acc D Fake: 0.000%
Loss D: 0.909
Loss G: 0.6335 (0.5588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.1240 (0.3916) Acc D Real: 99.127%
Loss D Fake: 0.7684 (0.8647) Acc D Fake: 0.000%
Loss D: 0.892
Loss G: 0.6312 (0.5593) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.1867 (0.3901) Acc D Real: 99.121%
Loss D Fake: 0.7732 (0.8641) Acc D Fake: 0.000%
Loss D: 0.960
Loss G: 0.6269 (0.5598) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.1521 (0.3885) Acc D Real: 99.120%
Loss D Fake: 0.7819 (0.8635) Acc D Fake: 0.000%
Loss D: 0.934
Loss G: 0.6201 (0.5602) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.1968 (0.3872) Acc D Real: 99.107%
Loss D Fake: 0.7974 (0.8631) Acc D Fake: 0.000%
Loss D: 0.994
Loss G: 0.6103 (0.5606) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.1459 (0.3855) Acc D Real: 99.105%
Loss D Fake: 0.8309 (0.8628) Acc D Fake: 0.000%
Loss D: 0.977
Loss G: 0.5979 (0.5608) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.1491 (0.3839) Acc D Real: 99.101%
Loss D Fake: 0.9029 (0.8631) Acc D Fake: 0.000%
Loss D: 1.052
Loss G: 0.5969 (0.5611) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.1870 (0.3826) Acc D Real: 99.098%
Loss D Fake: 0.8286 (0.8629) Acc D Fake: 0.000%
Loss D: 1.016
Loss G: 0.6047 (0.5614) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.2036 (0.3814) Acc D Real: 99.087%
Loss D Fake: 0.8058 (0.8625) Acc D Fake: 0.000%
Loss D: 1.009
Loss G: 0.6095 (0.5617) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.2023 (0.3802) Acc D Real: 99.081%
Loss D Fake: 0.7959 (0.8620) Acc D Fake: 0.000%
Loss D: 0.998
Loss G: 0.6121 (0.5620) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.1637 (0.3787) Acc D Real: 99.073%
Loss D Fake: 0.7909 (0.8616) Acc D Fake: 0.000%
Loss D: 0.955
Loss G: 0.6134 (0.5624) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.2269 (0.3777) Acc D Real: 99.070%
Loss D Fake: 0.7887 (0.8611) Acc D Fake: 0.000%
Loss D: 1.016
Loss G: 0.6133 (0.5627) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.1669 (0.3764) Acc D Real: 99.066%
Loss D Fake: 0.7886 (0.8606) Acc D Fake: 0.000%
Loss D: 0.956
Loss G: 0.6124 (0.5630) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.2496 (0.3755) Acc D Real: 99.056%
Loss D Fake: 0.7896 (0.8602) Acc D Fake: 0.000%
Loss D: 1.039
Loss G: 0.6108 (0.5633) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.1731 (0.3742) Acc D Real: 99.052%
Loss D Fake: 0.7918 (0.8597) Acc D Fake: 0.000%
Loss D: 0.965
Loss G: 0.6088 (0.5636) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.2101 (0.3732) Acc D Real: 99.048%
Loss D Fake: 0.7947 (0.8593) Acc D Fake: 0.000%
Loss D: 1.005
Loss G: 0.6061 (0.5639) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.2150 (0.3722) Acc D Real: 99.046%
Loss D Fake: 0.7989 (0.8589) Acc D Fake: 0.000%
Loss D: 1.014
Loss G: 0.6032 (0.5642) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.1119 (0.3705) Acc D Real: 99.045%
Loss D Fake: 0.8031 (0.8586) Acc D Fake: 0.000%
Loss D: 0.915
Loss G: 0.6005 (0.5644) Acc G: 100.000%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.005 | Generator Loss: 0.585 | Avg: 1.589
TEST [21/180]: Discriminator Loss: 1.029 | Generator Loss: 0.585 | Avg: 1.614
TEST [31/180]: Discriminator Loss: 1.035 | Generator Loss: 0.585 | Avg: 1.620
TRAIN Iteration: [   2/158]
Loss D Real: 0.1485 (0.1985) Acc D Real: 98.854%
Loss D Fake: 0.8117 (0.8095) Acc D Fake: 0.000%
Loss D: 0.960
Loss G: 0.5951 (0.5964) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.2223 (0.2064) Acc D Real: 98.646%
Loss D Fake: 0.8272 (0.8154) Acc D Fake: 0.000%
Loss D: 1.049
Loss G: 0.5721 (0.5883) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.1955 (0.2037) Acc D Real: 98.789%
Loss D Fake: 1.0132 (0.8648) Acc D Fake: 0.000%
Loss D: 1.209
Loss G: 0.5671 (0.5830) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.1768 (0.1983) Acc D Real: 98.760%
Loss D Fake: 0.8503 (0.8619) Acc D Fake: 0.000%
Loss D: 1.027
Loss G: 0.5934 (0.5851) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.1828 (0.1958) Acc D Real: 98.715%
Loss D Fake: 0.8056 (0.8525) Acc D Fake: 0.000%
Loss D: 0.988
Loss G: 0.6064 (0.5887) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.1981 (0.1961) Acc D Real: 98.735%
Loss D Fake: 0.7903 (0.8436) Acc D Fake: 0.000%
Loss D: 0.988
Loss G: 0.6134 (0.5922) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.2291 (0.2002) Acc D Real: 98.763%
Loss D Fake: 0.7822 (0.8360) Acc D Fake: 0.000%
Loss D: 1.011
Loss G: 0.6175 (0.5954) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.1628 (0.1961) Acc D Real: 98.796%
Loss D Fake: 0.7774 (0.8295) Acc D Fake: 0.000%
Loss D: 0.940
Loss G: 0.6202 (0.5981) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.1998 (0.1964) Acc D Real: 98.870%
Loss D Fake: 0.7744 (0.8239) Acc D Fake: 0.000%
Loss D: 0.974
Loss G: 0.6218 (0.6005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.1837 (0.1953) Acc D Real: 98.902%
Loss D Fake: 0.7727 (0.8193) Acc D Fake: 0.000%
Loss D: 0.956
Loss G: 0.6224 (0.6025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.2245 (0.1977) Acc D Real: 98.937%
Loss D Fake: 0.7724 (0.8154) Acc D Fake: 0.000%
Loss D: 0.997
Loss G: 0.6222 (0.6041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.1680 (0.1954) Acc D Real: 98.962%
Loss D Fake: 0.7729 (0.8121) Acc D Fake: 0.000%
Loss D: 0.941
Loss G: 0.6213 (0.6054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.1199 (0.1900) Acc D Real: 98.951%
Loss D Fake: 0.7744 (0.8094) Acc D Fake: 0.000%
Loss D: 0.894
Loss G: 0.6201 (0.6065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.1640 (0.1883) Acc D Real: 98.986%
Loss D Fake: 0.7761 (0.8072) Acc D Fake: 0.000%
Loss D: 0.940
Loss G: 0.6186 (0.6073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.1820 (0.1879) Acc D Real: 98.978%
Loss D Fake: 0.7783 (0.8054) Acc D Fake: 0.000%
Loss D: 0.960
Loss G: 0.6169 (0.6079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.1416 (0.1852) Acc D Real: 98.986%
Loss D Fake: 0.7812 (0.8040) Acc D Fake: 0.000%
Loss D: 0.923
Loss G: 0.6140 (0.6083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.1739 (0.1846) Acc D Real: 99.002%
Loss D Fake: 0.7863 (0.8030) Acc D Fake: 0.000%
Loss D: 0.960
Loss G: 0.6103 (0.6084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.1535 (0.1829) Acc D Real: 98.991%
Loss D Fake: 0.7924 (0.8024) Acc D Fake: 0.000%
Loss D: 0.946
Loss G: 0.6066 (0.6083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.1991 (0.1837) Acc D Real: 99.003%
Loss D Fake: 0.7990 (0.8023) Acc D Fake: 0.000%
Loss D: 0.998
Loss G: 0.6031 (0.6080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.1465 (0.1820) Acc D Real: 99.000%
Loss D Fake: 0.8061 (0.8024) Acc D Fake: 0.000%
Loss D: 0.953
Loss G: 0.6004 (0.6077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.1660 (0.1812) Acc D Real: 99.015%
Loss D Fake: 0.8115 (0.8029) Acc D Fake: 0.000%
Loss D: 0.977
Loss G: 0.5996 (0.6073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.1354 (0.1792) Acc D Real: 99.033%
Loss D Fake: 0.8127 (0.8033) Acc D Fake: 0.000%
Loss D: 0.948
Loss G: 0.6009 (0.6070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.1632 (0.1786) Acc D Real: 99.034%
Loss D Fake: 0.8100 (0.8036) Acc D Fake: 0.000%
Loss D: 0.973
Loss G: 0.6034 (0.6069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.1508 (0.1775) Acc D Real: 99.029%
Loss D Fake: 0.8054 (0.8036) Acc D Fake: 0.000%
Loss D: 0.956
Loss G: 0.6058 (0.6068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.1454 (0.1762) Acc D Real: 99.040%
Loss D Fake: 0.8009 (0.8035) Acc D Fake: 0.000%
Loss D: 0.946
Loss G: 0.6084 (0.6069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.1512 (0.1753) Acc D Real: 99.059%
Loss D Fake: 0.7951 (0.8032) Acc D Fake: 0.000%
Loss D: 0.946
Loss G: 0.6097 (0.6070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.1231 (0.1734) Acc D Real: 99.062%
Loss D Fake: 0.7898 (0.8027) Acc D Fake: 0.000%
Loss D: 0.913
Loss G: 0.6008 (0.6068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.1232 (0.1717) Acc D Real: 99.075%
Loss D Fake: 0.9352 (0.8073) Acc D Fake: 0.000%
Loss D: 1.058
Loss G: 0.6031 (0.6066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.1439 (0.1708) Acc D Real: 99.085%
Loss D Fake: 1.0233 (0.8145) Acc D Fake: 0.000%
Loss D: 1.167
Loss G: 0.5690 (0.6054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.1366 (0.1697) Acc D Real: 99.099%
Loss D Fake: 0.8957 (0.8171) Acc D Fake: 0.000%
Loss D: 1.032
Loss G: 0.5956 (0.6051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.1528 (0.1691) Acc D Real: 99.102%
Loss D Fake: 0.8033 (0.8167) Acc D Fake: 0.000%
Loss D: 0.956
Loss G: 0.6108 (0.6052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.1349 (0.1681) Acc D Real: 99.096%
Loss D Fake: 0.7865 (0.8158) Acc D Fake: 0.000%
Loss D: 0.921
Loss G: 0.6175 (0.6056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.1751 (0.1683) Acc D Real: 99.102%
Loss D Fake: 0.7795 (0.8147) Acc D Fake: 0.000%
Loss D: 0.955
Loss G: 0.6209 (0.6061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.1789 (0.1686) Acc D Real: 99.101%
Loss D Fake: 0.7763 (0.8136) Acc D Fake: 0.000%
Loss D: 0.955
Loss G: 0.6223 (0.6065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.1455 (0.1680) Acc D Real: 99.087%
Loss D Fake: 0.7757 (0.8126) Acc D Fake: 0.000%
Loss D: 0.921
Loss G: 0.6221 (0.6070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.1677 (0.1680) Acc D Real: 99.088%
Loss D Fake: 0.7776 (0.8116) Acc D Fake: 0.000%
Loss D: 0.945
Loss G: 0.6201 (0.6073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.1955 (0.1687) Acc D Real: 99.105%
Loss D Fake: 0.7823 (0.8109) Acc D Fake: 0.000%
Loss D: 0.978
Loss G: 0.6161 (0.6075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.1440 (0.1681) Acc D Real: 99.091%
Loss D Fake: 0.7912 (0.8103) Acc D Fake: 0.000%
Loss D: 0.935
Loss G: 0.6097 (0.6076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.1661 (0.1680) Acc D Real: 99.085%
Loss D Fake: 0.8067 (0.8103) Acc D Fake: 0.000%
Loss D: 0.973
Loss G: 0.5993 (0.6074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.1493 (0.1676) Acc D Real: 99.088%
Loss D Fake: 0.8419 (0.8110) Acc D Fake: 0.000%
Loss D: 0.991
Loss G: 0.5827 (0.6068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.1501 (0.1671) Acc D Real: 99.082%
Loss D Fake: 0.9965 (0.8154) Acc D Fake: 0.000%
Loss D: 1.147
Loss G: 0.5763 (0.6061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.2210 (0.1684) Acc D Real: 99.081%
Loss D Fake: 0.9158 (0.8178) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.5862 (0.6056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.2160 (0.1695) Acc D Real: 99.066%
Loss D Fake: 0.8548 (0.8186) Acc D Fake: 0.000%
Loss D: 1.071
Loss G: 0.5918 (0.6053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.2073 (0.1703) Acc D Real: 99.050%
Loss D Fake: 0.8439 (0.8192) Acc D Fake: 0.000%
Loss D: 1.051
Loss G: 0.5903 (0.6050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.2069 (0.1711) Acc D Real: 99.043%
Loss D Fake: 0.8481 (0.8198) Acc D Fake: 0.000%
Loss D: 1.055
Loss G: 0.5852 (0.6045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.2072 (0.1719) Acc D Real: 99.047%
Loss D Fake: 0.8526 (0.8205) Acc D Fake: 0.000%
Loss D: 1.060
Loss G: 0.5805 (0.6040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.2023 (0.1725) Acc D Real: 99.010%
Loss D Fake: 0.8484 (0.8211) Acc D Fake: 0.000%
Loss D: 1.051
Loss G: 0.5781 (0.6035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3299 (0.1757) Acc D Real: 98.975%
Loss D Fake: 0.8384 (0.8214) Acc D Fake: 0.000%
Loss D: 1.168
Loss G: 0.5808 (0.6030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.2426 (0.1771) Acc D Real: 98.953%
Loss D Fake: 0.8247 (0.8215) Acc D Fake: 0.000%
Loss D: 1.067
Loss G: 0.5878 (0.6027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3100 (0.1797) Acc D Real: 98.910%
Loss D Fake: 0.8111 (0.8213) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.5957 (0.6026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.2634 (0.1813) Acc D Real: 98.875%
Loss D Fake: 0.7998 (0.8209) Acc D Fake: 0.000%
Loss D: 1.063
Loss G: 0.6027 (0.6026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.1828 (0.1813) Acc D Real: 98.867%
Loss D Fake: 0.7906 (0.8203) Acc D Fake: 0.000%
Loss D: 0.973
Loss G: 0.6094 (0.6027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.2495 (0.1826) Acc D Real: 98.837%
Loss D Fake: 0.7825 (0.8196) Acc D Fake: 0.000%
Loss D: 1.032
Loss G: 0.6153 (0.6029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.1775 (0.1825) Acc D Real: 98.812%
Loss D Fake: 0.7756 (0.8188) Acc D Fake: 0.000%
Loss D: 0.953
Loss G: 0.6208 (0.6033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.2100 (0.1830) Acc D Real: 98.779%
Loss D Fake: 0.7693 (0.8179) Acc D Fake: 0.000%
Loss D: 0.979
Loss G: 0.6259 (0.6037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.2188 (0.1836) Acc D Real: 98.747%
Loss D Fake: 0.7636 (0.8170) Acc D Fake: 0.000%
Loss D: 0.982
Loss G: 0.6305 (0.6041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.2132 (0.1841) Acc D Real: 98.722%
Loss D Fake: 0.7585 (0.8160) Acc D Fake: 0.000%
Loss D: 0.972
Loss G: 0.6348 (0.6047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.2241 (0.1848) Acc D Real: 98.693%
Loss D Fake: 0.7542 (0.8149) Acc D Fake: 0.000%
Loss D: 0.978
Loss G: 0.6379 (0.6052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.1813 (0.1847) Acc D Real: 98.672%
Loss D Fake: 0.7511 (0.8139) Acc D Fake: 0.000%
Loss D: 0.932
Loss G: 0.6407 (0.6058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.2026 (0.1850) Acc D Real: 98.658%
Loss D Fake: 0.7481 (0.8128) Acc D Fake: 0.000%
Loss D: 0.951
Loss G: 0.6434 (0.6064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2031 (0.1853) Acc D Real: 98.622%
Loss D Fake: 0.7451 (0.8117) Acc D Fake: 0.000%
Loss D: 0.948
Loss G: 0.6461 (0.6071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2218 (0.1859) Acc D Real: 98.585%
Loss D Fake: 0.7422 (0.8106) Acc D Fake: 0.000%
Loss D: 0.964
Loss G: 0.6489 (0.6077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.1951 (0.1860) Acc D Real: 98.574%
Loss D Fake: 0.7392 (0.8095) Acc D Fake: 0.000%
Loss D: 0.934
Loss G: 0.6515 (0.6084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.1608 (0.1856) Acc D Real: 98.571%
Loss D Fake: 0.7366 (0.8084) Acc D Fake: 0.000%
Loss D: 0.897
Loss G: 0.6539 (0.6091) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.1931 (0.1858) Acc D Real: 98.550%
Loss D Fake: 0.7342 (0.8072) Acc D Fake: 0.000%
Loss D: 0.927
Loss G: 0.6558 (0.6098) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.1922 (0.1859) Acc D Real: 98.532%
Loss D Fake: 0.7326 (0.8061) Acc D Fake: 0.000%
Loss D: 0.925
Loss G: 0.6567 (0.6105) Acc G: 99.950%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.1689 (0.1856) Acc D Real: 98.521%
Loss D Fake: 0.7326 (0.8050) Acc D Fake: 0.049%
Loss D: 0.901
Loss G: 0.6551 (0.6112) Acc G: 99.858%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.2177 (0.1861) Acc D Real: 98.508%
Loss D Fake: 0.7386 (0.8041) Acc D Fake: 0.145%
Loss D: 0.956
Loss G: 0.6425 (0.6116) Acc G: 99.763%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.1395 (0.1854) Acc D Real: 98.508%
Loss D Fake: 0.7863 (0.8038) Acc D Fake: 0.262%
Loss D: 0.926
Loss G: 0.6589 (0.6123) Acc G: 99.624%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.1873 (0.1854) Acc D Real: 98.482%
Loss D Fake: 0.7269 (0.8027) Acc D Fake: 0.376%
Loss D: 0.914
Loss G: 0.6625 (0.6130) Acc G: 99.488%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.1855 (0.1854) Acc D Real: 98.453%
Loss D Fake: 0.7261 (0.8017) Acc D Fake: 0.509%
Loss D: 0.912
Loss G: 0.6627 (0.6137) Acc G: 99.356%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.1677 (0.1852) Acc D Real: 98.433%
Loss D Fake: 0.7259 (0.8006) Acc D Fake: 0.639%
Loss D: 0.894
Loss G: 0.6629 (0.6144) Acc G: 99.205%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2021 (0.1854) Acc D Real: 98.411%
Loss D Fake: 0.7254 (0.7996) Acc D Fake: 0.788%
Loss D: 0.927
Loss G: 0.6636 (0.6151) Acc G: 99.058%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.1717 (0.1852) Acc D Real: 98.390%
Loss D Fake: 0.7245 (0.7986) Acc D Fake: 0.933%
Loss D: 0.896
Loss G: 0.6647 (0.6157) Acc G: 98.915%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.2193 (0.1857) Acc D Real: 98.357%
Loss D Fake: 0.7230 (0.7976) Acc D Fake: 1.075%
Loss D: 0.942
Loss G: 0.6663 (0.6164) Acc G: 98.754%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2061 (0.1859) Acc D Real: 98.319%
Loss D Fake: 0.7211 (0.7966) Acc D Fake: 1.255%
Loss D: 0.927
Loss G: 0.6684 (0.6171) Acc G: 98.575%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.1582 (0.1856) Acc D Real: 98.303%
Loss D Fake: 0.7187 (0.7956) Acc D Fake: 1.432%
Loss D: 0.877
Loss G: 0.6707 (0.6177) Acc G: 98.380%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.2083 (0.1859) Acc D Real: 98.251%
Loss D Fake: 0.7164 (0.7946) Acc D Fake: 1.624%
Loss D: 0.925
Loss G: 0.6730 (0.6184) Acc G: 98.169%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.1723 (0.1857) Acc D Real: 98.225%
Loss D Fake: 0.7143 (0.7936) Acc D Fake: 1.833%
Loss D: 0.887
Loss G: 0.6747 (0.6191) Acc G: 97.941%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.1891 (0.1858) Acc D Real: 98.203%
Loss D Fake: 0.7127 (0.7926) Acc D Fake: 2.058%
Loss D: 0.902
Loss G: 0.6764 (0.6198) Acc G: 97.720%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.1542 (0.1854) Acc D Real: 98.194%
Loss D Fake: 0.7109 (0.7916) Acc D Fake: 2.276%
Loss D: 0.865
Loss G: 0.6782 (0.6206) Acc G: 97.240%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.1749 (0.1852) Acc D Real: 98.168%
Loss D Fake: 0.7090 (0.7906) Acc D Fake: 2.912%
Loss D: 0.884
Loss G: 0.6800 (0.6213) Acc G: 96.570%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.1669 (0.1850) Acc D Real: 98.156%
Loss D Fake: 0.7073 (0.7896) Acc D Fake: 3.591%
Loss D: 0.874
Loss G: 0.6816 (0.6220) Acc G: 95.857%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.1651 (0.1848) Acc D Real: 98.140%
Loss D Fake: 0.7058 (0.7886) Acc D Fake: 4.314%
Loss D: 0.871
Loss G: 0.6829 (0.6227) Acc G: 95.121%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.1590 (0.1845) Acc D Real: 98.128%
Loss D Fake: 0.7047 (0.7877) Acc D Fake: 5.039%
Loss D: 0.864
Loss G: 0.6836 (0.6234) Acc G: 94.365%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.1904 (0.1846) Acc D Real: 98.097%
Loss D Fake: 0.7050 (0.7867) Acc D Fake: 5.670%
Loss D: 0.895
Loss G: 0.6806 (0.6241) Acc G: 93.989%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.1721 (0.1844) Acc D Real: 98.068%
Loss D Fake: 0.7147 (0.7859) Acc D Fake: 5.871%
Loss D: 0.887
Loss G: 0.6679 (0.6246) Acc G: 93.792%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.1535 (0.1841) Acc D Real: 98.061%
Loss D Fake: 0.7378 (0.7854) Acc D Fake: 6.067%
Loss D: 0.891
Loss G: 0.6847 (0.6253) Acc G: 93.188%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.1670 (0.1839) Acc D Real: 98.035%
Loss D Fake: 0.6983 (0.7844) Acc D Fake: 6.833%
Loss D: 0.865
Loss G: 0.6919 (0.6260) Acc G: 92.430%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.2157 (0.1842) Acc D Real: 97.976%
Loss D Fake: 0.6950 (0.7834) Acc D Fake: 7.582%
Loss D: 0.911
Loss G: 0.6940 (0.6267) Acc G: 91.689%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.1518 (0.1839) Acc D Real: 97.961%
Loss D Fake: 0.6934 (0.7824) Acc D Fake: 8.315%
Loss D: 0.845
Loss G: 0.6955 (0.6275) Acc G: 90.964%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.1615 (0.1836) Acc D Real: 97.938%
Loss D Fake: 0.6919 (0.7815) Acc D Fake: 9.032%
Loss D: 0.853
Loss G: 0.6970 (0.6282) Acc G: 90.255%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.1800 (0.1836) Acc D Real: 97.903%
Loss D Fake: 0.6903 (0.7805) Acc D Fake: 9.734%
Loss D: 0.870
Loss G: 0.6987 (0.6290) Acc G: 89.561%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.1690 (0.1834) Acc D Real: 97.877%
Loss D Fake: 0.6886 (0.7795) Acc D Fake: 10.421%
Loss D: 0.858
Loss G: 0.7006 (0.6297) Acc G: 88.881%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.1865 (0.1835) Acc D Real: 97.842%
Loss D Fake: 0.6867 (0.7786) Acc D Fake: 11.094%
Loss D: 0.873
Loss G: 0.7026 (0.6305) Acc G: 88.198%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.1916 (0.1836) Acc D Real: 97.801%
Loss D Fake: 0.6847 (0.7776) Acc D Fake: 11.770%
Loss D: 0.876
Loss G: 0.7046 (0.6313) Acc G: 87.530%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.1315 (0.1830) Acc D Real: 97.794%
Loss D Fake: 0.6828 (0.7766) Acc D Fake: 12.432%
Loss D: 0.814
Loss G: 0.7067 (0.6320) Acc G: 86.874%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.1386 (0.1826) Acc D Real: 97.782%
Loss D Fake: 0.6807 (0.7757) Acc D Fake: 13.081%
Loss D: 0.819
Loss G: 0.7089 (0.6328) Acc G: 86.233%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.2482 (0.1832) Acc D Real: 97.673%
Loss D Fake: 0.6786 (0.7747) Acc D Fake: 13.717%
Loss D: 0.927
Loss G: 0.7111 (0.6336) Acc G: 85.604%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.1914 (0.1833) Acc D Real: 97.629%
Loss D Fake: 0.6766 (0.7737) Acc D Fake: 14.340%
Loss D: 0.868
Loss G: 0.7131 (0.6344) Acc G: 84.987%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.1777 (0.1833) Acc D Real: 97.584%
Loss D Fake: 0.6747 (0.7727) Acc D Fake: 14.967%
Loss D: 0.852
Loss G: 0.7150 (0.6352) Acc G: 84.366%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2078 (0.1835) Acc D Real: 97.520%
Loss D Fake: 0.6732 (0.7718) Acc D Fake: 15.583%
Loss D: 0.881
Loss G: 0.7163 (0.6360) Acc G: 83.758%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.1738 (0.1834) Acc D Real: 97.493%
Loss D Fake: 0.6722 (0.7708) Acc D Fake: 16.186%
Loss D: 0.846
Loss G: 0.7170 (0.6367) Acc G: 83.161%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.1576 (0.1832) Acc D Real: 97.474%
Loss D Fake: 0.6718 (0.7699) Acc D Fake: 16.778%
Loss D: 0.829
Loss G: 0.7173 (0.6375) Acc G: 82.575%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.1450 (0.1828) Acc D Real: 97.453%
Loss D Fake: 0.6718 (0.7689) Acc D Fake: 17.358%
Loss D: 0.817
Loss G: 0.7173 (0.6383) Acc G: 82.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.1494 (0.1825) Acc D Real: 97.450%
Loss D Fake: 0.6718 (0.7680) Acc D Fake: 17.928%
Loss D: 0.821
Loss G: 0.7177 (0.6390) Acc G: 81.436%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.1364 (0.1821) Acc D Real: 97.449%
Loss D Fake: 0.6709 (0.7671) Acc D Fake: 18.488%
Loss D: 0.807
Loss G: 0.7195 (0.6397) Acc G: 80.883%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.1683 (0.1819) Acc D Real: 97.417%
Loss D Fake: 0.6687 (0.7662) Acc D Fake: 19.037%
Loss D: 0.837
Loss G: 0.7220 (0.6405) Acc G: 80.332%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.1354 (0.1815) Acc D Real: 97.407%
Loss D Fake: 0.6660 (0.7653) Acc D Fake: 19.591%
Loss D: 0.801
Loss G: 0.7253 (0.6413) Acc G: 79.783%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.1616 (0.1813) Acc D Real: 97.386%
Loss D Fake: 0.6628 (0.7644) Acc D Fake: 20.135%
Loss D: 0.824
Loss G: 0.7285 (0.6421) Acc G: 79.245%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.1914 (0.1814) Acc D Real: 97.328%
Loss D Fake: 0.6605 (0.7635) Acc D Fake: 20.670%
Loss D: 0.852
Loss G: 0.7300 (0.6428) Acc G: 78.716%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.1805 (0.1814) Acc D Real: 97.293%
Loss D Fake: 0.6603 (0.7626) Acc D Fake: 21.195%
Loss D: 0.841
Loss G: 0.7283 (0.6436) Acc G: 78.196%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.1610 (0.1812) Acc D Real: 97.266%
Loss D Fake: 0.6647 (0.7617) Acc D Fake: 21.696%
Loss D: 0.826
Loss G: 0.7238 (0.6443) Acc G: 77.729%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.1429 (0.1809) Acc D Real: 97.249%
Loss D Fake: 0.6678 (0.7609) Acc D Fake: 22.145%
Loss D: 0.811
Loss G: 0.7302 (0.6450) Acc G: 77.227%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.1758 (0.1809) Acc D Real: 97.209%
Loss D Fake: 0.6558 (0.7600) Acc D Fake: 22.644%
Loss D: 0.832
Loss G: 0.7384 (0.6458) Acc G: 76.734%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.1593 (0.1807) Acc D Real: 97.191%
Loss D Fake: 0.6502 (0.7590) Acc D Fake: 23.134%
Loss D: 0.809
Loss G: 0.7431 (0.6467) Acc G: 76.249%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.1691 (0.1806) Acc D Real: 97.164%
Loss D Fake: 0.6467 (0.7581) Acc D Fake: 23.616%
Loss D: 0.816
Loss G: 0.7465 (0.6475) Acc G: 75.772%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.1413 (0.1802) Acc D Real: 97.152%
Loss D Fake: 0.6439 (0.7571) Acc D Fake: 24.090%
Loss D: 0.785
Loss G: 0.7495 (0.6484) Acc G: 75.304%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.1508 (0.1800) Acc D Real: 97.143%
Loss D Fake: 0.6414 (0.7562) Acc D Fake: 24.556%
Loss D: 0.792
Loss G: 0.7522 (0.6492) Acc G: 74.843%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.1846 (0.1800) Acc D Real: 97.092%
Loss D Fake: 0.6391 (0.7552) Acc D Fake: 25.028%
Loss D: 0.824
Loss G: 0.7548 (0.6501) Acc G: 74.376%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.1561 (0.1798) Acc D Real: 97.072%
Loss D Fake: 0.6370 (0.7542) Acc D Fake: 25.492%
Loss D: 0.793
Loss G: 0.7571 (0.6510) Acc G: 73.916%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.1678 (0.1797) Acc D Real: 97.038%
Loss D Fake: 0.6351 (0.7533) Acc D Fake: 25.949%
Loss D: 0.803
Loss G: 0.7592 (0.6519) Acc G: 73.465%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.1421 (0.1794) Acc D Real: 97.020%
Loss D Fake: 0.6333 (0.7523) Acc D Fake: 26.398%
Loss D: 0.775
Loss G: 0.7614 (0.6528) Acc G: 73.020%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.1694 (0.1794) Acc D Real: 97.001%
Loss D Fake: 0.6315 (0.7513) Acc D Fake: 26.840%
Loss D: 0.801
Loss G: 0.7634 (0.6536) Acc G: 72.583%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.1641 (0.1792) Acc D Real: 96.977%
Loss D Fake: 0.6300 (0.7504) Acc D Fake: 27.275%
Loss D: 0.794
Loss G: 0.7648 (0.6545) Acc G: 72.152%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.1538 (0.1790) Acc D Real: 96.951%
Loss D Fake: 0.6291 (0.7494) Acc D Fake: 27.703%
Loss D: 0.783
Loss G: 0.7657 (0.6554) Acc G: 71.728%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.1938 (0.1792) Acc D Real: 96.890%
Loss D Fake: 0.6284 (0.7485) Acc D Fake: 28.125%
Loss D: 0.822
Loss G: 0.7668 (0.6563) Acc G: 71.311%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.1825 (0.1792) Acc D Real: 96.845%
Loss D Fake: 0.6274 (0.7475) Acc D Fake: 28.540%
Loss D: 0.810
Loss G: 0.7686 (0.6571) Acc G: 70.900%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.1429 (0.1789) Acc D Real: 96.834%
Loss D Fake: 0.6252 (0.7466) Acc D Fake: 28.949%
Loss D: 0.768
Loss G: 0.7723 (0.6580) Acc G: 70.488%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2082 (0.1791) Acc D Real: 96.775%
Loss D Fake: 0.6219 (0.7456) Acc D Fake: 29.364%
Loss D: 0.830
Loss G: 0.7755 (0.6589) Acc G: 70.077%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.1555 (0.1789) Acc D Real: 96.755%
Loss D Fake: 0.6194 (0.7447) Acc D Fake: 29.773%
Loss D: 0.775
Loss G: 0.7785 (0.6598) Acc G: 69.673%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.1816 (0.1790) Acc D Real: 96.721%
Loss D Fake: 0.6171 (0.7437) Acc D Fake: 30.175%
Loss D: 0.799
Loss G: 0.7808 (0.6607) Acc G: 69.274%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.1384 (0.1787) Acc D Real: 96.715%
Loss D Fake: 0.6153 (0.7428) Acc D Fake: 30.572%
Loss D: 0.754
Loss G: 0.7835 (0.6617) Acc G: 68.881%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.1943 (0.1788) Acc D Real: 96.659%
Loss D Fake: 0.6128 (0.7418) Acc D Fake: 30.963%
Loss D: 0.807
Loss G: 0.7865 (0.6626) Acc G: 68.495%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.1542 (0.1786) Acc D Real: 96.638%
Loss D Fake: 0.6104 (0.7408) Acc D Fake: 31.348%
Loss D: 0.765
Loss G: 0.7895 (0.6635) Acc G: 68.114%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.1333 (0.1783) Acc D Real: 96.635%
Loss D Fake: 0.6079 (0.7399) Acc D Fake: 31.727%
Loss D: 0.741
Loss G: 0.7928 (0.6645) Acc G: 67.738%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.1972 (0.1784) Acc D Real: 96.578%
Loss D Fake: 0.6052 (0.7389) Acc D Fake: 32.101%
Loss D: 0.802
Loss G: 0.7960 (0.6654) Acc G: 67.368%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.1596 (0.1783) Acc D Real: 96.560%
Loss D Fake: 0.6028 (0.7379) Acc D Fake: 32.470%
Loss D: 0.762
Loss G: 0.7991 (0.6664) Acc G: 67.003%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.1442 (0.1780) Acc D Real: 96.545%
Loss D Fake: 0.6003 (0.7369) Acc D Fake: 32.833%
Loss D: 0.744
Loss G: 0.8022 (0.6673) Acc G: 66.644%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.1666 (0.1779) Acc D Real: 96.517%
Loss D Fake: 0.5979 (0.7359) Acc D Fake: 33.191%
Loss D: 0.765
Loss G: 0.8052 (0.6683) Acc G: 66.289%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.1714 (0.1779) Acc D Real: 96.480%
Loss D Fake: 0.5956 (0.7349) Acc D Fake: 33.545%
Loss D: 0.767
Loss G: 0.8080 (0.6693) Acc G: 65.940%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.1781 (0.1779) Acc D Real: 96.446%
Loss D Fake: 0.5937 (0.7340) Acc D Fake: 33.893%
Loss D: 0.772
Loss G: 0.8103 (0.6703) Acc G: 65.595%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.1593 (0.1778) Acc D Real: 96.423%
Loss D Fake: 0.5921 (0.7330) Acc D Fake: 34.236%
Loss D: 0.751
Loss G: 0.8124 (0.6713) Acc G: 65.244%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.1373 (0.1775) Acc D Real: 96.414%
Loss D Fake: 0.5917 (0.7320) Acc D Fake: 34.586%
Loss D: 0.729
Loss G: 0.8103 (0.6722) Acc G: 64.897%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.1501 (0.1773) Acc D Real: 96.397%
Loss D Fake: 0.5955 (0.7311) Acc D Fake: 34.932%
Loss D: 0.746
Loss G: 0.8161 (0.6732) Acc G: 64.556%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.1954 (0.1774) Acc D Real: 96.342%
Loss D Fake: 0.5859 (0.7301) Acc D Fake: 35.272%
Loss D: 0.781
Loss G: 0.8219 (0.6742) Acc G: 64.218%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.2118 (0.1777) Acc D Real: 96.280%
Loss D Fake: 0.5829 (0.7291) Acc D Fake: 35.608%
Loss D: 0.795
Loss G: 0.8246 (0.6752) Acc G: 63.886%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.1332 (0.1774) Acc D Real: 96.270%
Loss D Fake: 0.5812 (0.7281) Acc D Fake: 35.940%
Loss D: 0.714
Loss G: 0.8277 (0.6763) Acc G: 63.558%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.1718 (0.1773) Acc D Real: 96.232%
Loss D Fake: 0.5788 (0.7271) Acc D Fake: 36.267%
Loss D: 0.751
Loss G: 0.8304 (0.6773) Acc G: 63.236%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.1710 (0.1773) Acc D Real: 96.206%
Loss D Fake: 0.5774 (0.7261) Acc D Fake: 36.578%
Loss D: 0.748
Loss G: 0.8320 (0.6783) Acc G: 62.928%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.1481 (0.1771) Acc D Real: 96.195%
Loss D Fake: 0.5766 (0.7251) Acc D Fake: 36.886%
Loss D: 0.725
Loss G: 0.8331 (0.6793) Acc G: 62.624%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.1393 (0.1768) Acc D Real: 96.180%
Loss D Fake: 0.5760 (0.7241) Acc D Fake: 37.190%
Loss D: 0.715
Loss G: 0.8343 (0.6804) Acc G: 62.323%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.1781 (0.1769) Acc D Real: 96.146%
Loss D Fake: 0.5752 (0.7232) Acc D Fake: 37.489%
Loss D: 0.753
Loss G: 0.8359 (0.6814) Acc G: 62.027%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.1436 (0.1766) Acc D Real: 96.126%
Loss D Fake: 0.5740 (0.7222) Acc D Fake: 37.785%
Loss D: 0.718
Loss G: 0.8381 (0.6824) Acc G: 61.734%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.1171 (0.1763) Acc D Real: 96.127%
Loss D Fake: 0.5722 (0.7213) Acc D Fake: 38.077%
Loss D: 0.689
Loss G: 0.8411 (0.6834) Acc G: 61.445%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.1369 (0.1760) Acc D Real: 96.124%
Loss D Fake: 0.5701 (0.7203) Acc D Fake: 38.365%
Loss D: 0.707
Loss G: 0.8443 (0.6844) Acc G: 61.160%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.0638 (0.1753) Acc D Real: 96.125%
Loss D Fake: 0.5676 (0.7193) Acc D Fake: 38.392%
Loss D: 0.631
Loss G: 0.8487 (0.6855) Acc G: 61.134%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.632 | Generator Loss: 0.849 | Avg: 1.481
TRAIN Iteration: [   2/158]
Loss D Real: 0.1749 (0.1572) Acc D Real: 92.943%
Loss D Fake: 0.5605 (0.5623) Acc D Fake: 83.333%
Loss D: 0.735
Loss G: 0.8588 (0.8564) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.1694 (0.1613) Acc D Real: 92.448%
Loss D Fake: 0.5580 (0.5609) Acc D Fake: 83.333%
Loss D: 0.727
Loss G: 0.8598 (0.8576) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.1344 (0.1545) Acc D Real: 93.477%
Loss D Fake: 0.5624 (0.5613) Acc D Fake: 83.333%
Loss D: 0.697
Loss G: 0.8693 (0.8605) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.1761 (0.1589) Acc D Real: 93.125%
Loss D Fake: 0.5491 (0.5588) Acc D Fake: 83.333%
Loss D: 0.725
Loss G: 0.8760 (0.8636) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.1277 (0.1537) Acc D Real: 93.420%
Loss D Fake: 0.5456 (0.5566) Acc D Fake: 83.333%
Loss D: 0.673
Loss G: 0.8811 (0.8665) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.0937 (0.1451) Acc D Real: 93.981%
Loss D Fake: 0.5420 (0.5545) Acc D Fake: 83.333%
Loss D: 0.636
Loss G: 0.8869 (0.8694) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.1576 (0.1467) Acc D Real: 93.750%
Loss D Fake: 0.5380 (0.5525) Acc D Fake: 83.333%
Loss D: 0.696
Loss G: 0.8930 (0.8724) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.1342 (0.1453) Acc D Real: 93.848%
Loss D Fake: 0.5339 (0.5504) Acc D Fake: 83.333%
Loss D: 0.668
Loss G: 0.8997 (0.8754) Acc G: 16.667%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.1715 (0.1479) Acc D Real: 93.484%
Loss D Fake: 0.5294 (0.5483) Acc D Fake: 83.432%
Loss D: 0.701
Loss G: 0.9069 (0.8786) Acc G: 16.500%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.1672 (0.1496) Acc D Real: 93.305%
Loss D Fake: 0.5249 (0.5462) Acc D Fake: 83.575%
Loss D: 0.692
Loss G: 0.9141 (0.8818) Acc G: 16.364%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.1648 (0.1509) Acc D Real: 93.134%
Loss D Fake: 0.5202 (0.5440) Acc D Fake: 83.832%
Loss D: 0.685
Loss G: 0.9214 (0.8851) Acc G: 16.111%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.1502 (0.1509) Acc D Real: 93.169%
Loss D Fake: 0.5231 (0.5424) Acc D Fake: 84.050%
Loss D: 0.673
Loss G: 0.9265 (0.8883) Acc G: 15.897%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.1291 (0.1493) Acc D Real: 93.300%
Loss D Fake: 0.5120 (0.5402) Acc D Fake: 84.237%
Loss D: 0.641
Loss G: 0.9356 (0.8917) Acc G: 15.714%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.1350 (0.1483) Acc D Real: 93.420%
Loss D Fake: 0.5075 (0.5381) Acc D Fake: 84.399%
Loss D: 0.642
Loss G: 0.9431 (0.8951) Acc G: 15.556%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.1531 (0.1486) Acc D Real: 93.398%
Loss D Fake: 0.5030 (0.5359) Acc D Fake: 84.541%
Loss D: 0.656
Loss G: 0.9509 (0.8986) Acc G: 15.417%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.0955 (0.1455) Acc D Real: 93.627%
Loss D Fake: 0.4982 (0.5336) Acc D Fake: 84.666%
Loss D: 0.594
Loss G: 0.9600 (0.9022) Acc G: 15.294%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.1867 (0.1478) Acc D Real: 93.472%
Loss D Fake: 0.4928 (0.5314) Acc D Fake: 84.777%
Loss D: 0.679
Loss G: 0.9697 (0.9059) Acc G: 15.185%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.1321 (0.1470) Acc D Real: 93.503%
Loss D Fake: 0.4876 (0.5291) Acc D Fake: 84.877%
Loss D: 0.620
Loss G: 0.9768 (0.9097) Acc G: 15.088%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.1046 (0.1449) Acc D Real: 93.682%
Loss D Fake: 0.4915 (0.5272) Acc D Fake: 84.966%
Loss D: 0.596
Loss G: 0.9867 (0.9135) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.1088 (0.1431) Acc D Real: 93.812%
Loss D Fake: 0.4808 (0.5250) Acc D Fake: 85.047%
Loss D: 0.590
Loss G: 0.9875 (0.9170) Acc G: 14.841%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.2042 (0.1459) Acc D Real: 93.570%
Loss D Fake: 0.4797 (0.5229) Acc D Fake: 85.196%
Loss D: 0.684
Loss G: 0.9892 (0.9203) Acc G: 14.754%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.1619 (0.1466) Acc D Real: 93.512%
Loss D Fake: 0.4790 (0.5210) Acc D Fake: 85.260%
Loss D: 0.641
Loss G: 0.9922 (0.9235) Acc G: 14.692%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.1639 (0.1473) Acc D Real: 93.468%
Loss D Fake: 0.4773 (0.5192) Acc D Fake: 85.319%
Loss D: 0.641
Loss G: 0.9965 (0.9265) Acc G: 14.635%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.1507 (0.1475) Acc D Real: 93.467%
Loss D Fake: 0.4751 (0.5174) Acc D Fake: 85.373%
Loss D: 0.626
Loss G: 1.0015 (0.9295) Acc G: 14.583%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.1821 (0.1488) Acc D Real: 93.299%
Loss D Fake: 0.4726 (0.5157) Acc D Fake: 85.423%
Loss D: 0.655
Loss G: 1.0079 (0.9325) Acc G: 14.535%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.1235 (0.1479) Acc D Real: 93.370%
Loss D Fake: 0.4693 (0.5140) Acc D Fake: 85.469%
Loss D: 0.593
Loss G: 1.0164 (0.9356) Acc G: 14.491%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.1375 (0.1475) Acc D Real: 93.441%
Loss D Fake: 0.4650 (0.5122) Acc D Fake: 85.512%
Loss D: 0.602
Loss G: 1.0266 (0.9389) Acc G: 14.449%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.1275 (0.1468) Acc D Real: 93.502%
Loss D Fake: 0.4600 (0.5104) Acc D Fake: 85.506%
Loss D: 0.587
Loss G: 1.0383 (0.9423) Acc G: 14.468%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.1227 (0.1460) Acc D Real: 93.566%
Loss D Fake: 0.4541 (0.5086) Acc D Fake: 85.490%
Loss D: 0.577
Loss G: 1.0528 (0.9460) Acc G: 14.486%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.1193 (0.1451) Acc D Real: 93.617%
Loss D Fake: 0.4466 (0.5066) Acc D Fake: 85.474%
Loss D: 0.566
Loss G: 1.0717 (0.9500) Acc G: 14.503%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.1501 (0.1453) Acc D Real: 93.626%
Loss D Fake: 0.4367 (0.5044) Acc D Fake: 85.459%
Loss D: 0.587
Loss G: 1.0976 (0.9546) Acc G: 14.518%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.1221 (0.1446) Acc D Real: 93.662%
Loss D Fake: 1.1215 (0.5231) Acc D Fake: 84.877%
Loss D: 1.244
Loss G: 1.0638 (0.9580) Acc G: 14.482%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.1422 (0.1445) Acc D Real: 93.650%
Loss D Fake: 0.4502 (0.5209) Acc D Fake: 84.979%
Loss D: 0.592
Loss G: 1.0373 (0.9603) Acc G: 14.350%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.1784 (0.1455) Acc D Real: 93.551%
Loss D Fake: 0.4567 (0.5191) Acc D Fake: 85.170%
Loss D: 0.635
Loss G: 1.0241 (0.9621) Acc G: 14.179%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.2343 (0.1480) Acc D Real: 93.284%
Loss D Fake: 0.4661 (0.5176) Acc D Fake: 85.396%
Loss D: 0.700
Loss G: 0.9842 (0.9627) Acc G: 13.970%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3174 (0.1525) Acc D Real: 92.815%
Loss D Fake: 0.5065 (0.5173) Acc D Fake: 85.611%
Loss D: 0.824
Loss G: 0.2593 (0.9437) Acc G: 16.025%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.2674 (0.1556) Acc D Real: 92.453%
Loss D Fake: 2.7204 (0.5753) Acc D Fake: 83.490%
Loss D: 2.988
Loss G: 0.1988 (0.9241) Acc G: 18.147%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.2848 (0.1589) Acc D Real: 92.053%
Loss D Fake: 2.8294 (0.6331) Acc D Fake: 81.392%
Loss D: 3.114
Loss G: 0.1835 (0.9051) Acc G: 20.203%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.1891 (0.1596) Acc D Real: 91.885%
Loss D Fake: 2.8489 (0.6885) Acc D Fake: 79.440%
Loss D: 3.038
Loss G: 0.1771 (0.8869) Acc G: 22.031%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.2040 (0.1607) Acc D Real: 91.681%
Loss D Fake: 2.8332 (0.7408) Acc D Fake: 77.665%
Loss D: 3.037
Loss G: 0.1746 (0.8695) Acc G: 23.707%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.1792 (0.1611) Acc D Real: 91.549%
Loss D Fake: 2.7994 (0.7898) Acc D Fake: 76.084%
Loss D: 2.979
Loss G: 0.1741 (0.8530) Acc G: 25.246%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.2735 (0.1638) Acc D Real: 91.223%
Loss D Fake: 2.7554 (0.8355) Acc D Fake: 74.586%
Loss D: 3.029
Loss G: 0.1749 (0.8372) Acc G: 26.713%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.1976 (0.1645) Acc D Real: 91.098%
Loss D Fake: 2.7053 (0.8780) Acc D Fake: 73.156%
Loss D: 2.903
Loss G: 0.1766 (0.8222) Acc G: 28.113%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.1648 (0.1645) Acc D Real: 91.032%
Loss D Fake: 2.6517 (0.9174) Acc D Fake: 71.789%
Loss D: 2.816
Loss G: 0.1790 (0.8079) Acc G: 29.451%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.1978 (0.1653) Acc D Real: 90.879%
Loss D Fake: 2.5961 (0.9539) Acc D Fake: 70.482%
Loss D: 2.794
Loss G: 0.1820 (0.7943) Acc G: 30.696%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.1579 (0.1651) Acc D Real: 90.812%
Loss D Fake: 2.5395 (0.9877) Acc D Fake: 69.266%
Loss D: 2.697
Loss G: 0.1855 (0.7814) Acc G: 31.887%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.1932 (0.1657) Acc D Real: 90.710%
Loss D Fake: 2.4833 (1.0188) Acc D Fake: 68.101%
Loss D: 2.677
Loss G: 0.1888 (0.7690) Acc G: 33.028%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.1988 (0.1664) Acc D Real: 90.553%
Loss D Fake: 2.4294 (1.0476) Acc D Fake: 66.983%
Loss D: 2.628
Loss G: 0.1924 (0.7572) Acc G: 34.123%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.2162 (0.1674) Acc D Real: 90.379%
Loss D Fake: 2.3754 (1.0742) Acc D Fake: 65.910%
Loss D: 2.592
Loss G: 0.1964 (0.7460) Acc G: 35.174%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.2506 (0.1690) Acc D Real: 90.170%
Loss D Fake: 2.3219 (1.0986) Acc D Fake: 64.879%
Loss D: 2.572
Loss G: 0.2007 (0.7353) Acc G: 36.184%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.2104 (0.1698) Acc D Real: 90.034%
Loss D Fake: 2.2695 (1.1211) Acc D Fake: 63.888%
Loss D: 2.480
Loss G: 0.2053 (0.7251) Acc G: 37.154%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.2380 (0.1711) Acc D Real: 89.832%
Loss D Fake: 2.2177 (1.1418) Acc D Fake: 62.934%
Loss D: 2.456
Loss G: 0.2102 (0.7154) Acc G: 38.057%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.1941 (0.1715) Acc D Real: 89.747%
Loss D Fake: 2.1670 (1.1608) Acc D Fake: 62.047%
Loss D: 2.361
Loss G: 0.2153 (0.7062) Acc G: 38.927%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.2356 (0.1727) Acc D Real: 89.541%
Loss D Fake: 2.1175 (1.1782) Acc D Fake: 61.191%
Loss D: 2.353
Loss G: 0.2206 (0.6973) Acc G: 39.764%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.2971 (0.1749) Acc D Real: 89.247%
Loss D Fake: 2.0691 (1.1941) Acc D Fake: 60.366%
Loss D: 2.366
Loss G: 0.2261 (0.6889) Acc G: 40.572%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.2451 (0.1761) Acc D Real: 89.084%
Loss D Fake: 2.0222 (1.2086) Acc D Fake: 59.571%
Loss D: 2.267
Loss G: 0.2316 (0.6809) Acc G: 41.351%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.2571 (0.1775) Acc D Real: 88.892%
Loss D Fake: 1.9769 (1.2219) Acc D Fake: 58.802%
Loss D: 2.234
Loss G: 0.2372 (0.6732) Acc G: 42.104%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3182 (0.1799) Acc D Real: 88.596%
Loss D Fake: 1.9328 (1.2339) Acc D Fake: 58.060%
Loss D: 2.251
Loss G: 0.2429 (0.6660) Acc G: 42.831%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.2544 (0.1811) Acc D Real: 88.438%
Loss D Fake: 1.8899 (1.2449) Acc D Fake: 57.342%
Loss D: 2.144
Loss G: 0.2488 (0.6590) Acc G: 43.506%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.2638 (0.1825) Acc D Real: 88.259%
Loss D Fake: 1.8483 (1.2548) Acc D Fake: 56.675%
Loss D: 2.112
Loss G: 0.2549 (0.6524) Acc G: 44.159%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2530 (0.1836) Acc D Real: 88.129%
Loss D Fake: 1.8072 (1.2637) Acc D Fake: 56.030%
Loss D: 2.060
Loss G: 0.2613 (0.6461) Acc G: 44.791%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2110 (0.1841) Acc D Real: 88.076%
Loss D Fake: 1.7667 (1.2717) Acc D Fake: 55.405%
Loss D: 1.978
Loss G: 0.2680 (0.6401) Acc G: 45.403%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.2178 (0.1846) Acc D Real: 87.987%
Loss D Fake: 1.7275 (1.2788) Acc D Fake: 54.800%
Loss D: 1.945
Loss G: 0.2747 (0.6344) Acc G: 45.995%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.2318 (0.1853) Acc D Real: 87.895%
Loss D Fake: 1.6892 (1.2851) Acc D Fake: 54.213%
Loss D: 1.921
Loss G: 0.2817 (0.6289) Acc G: 46.570%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.2044 (0.1856) Acc D Real: 87.857%
Loss D Fake: 1.6516 (1.2907) Acc D Fake: 53.644%
Loss D: 1.856
Loss G: 0.2889 (0.6238) Acc G: 47.127%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2739 (0.1869) Acc D Real: 87.706%
Loss D Fake: 1.6149 (1.2955) Acc D Fake: 53.092%
Loss D: 1.889
Loss G: 0.2962 (0.6189) Acc G: 47.642%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.2292 (0.1876) Acc D Real: 87.619%
Loss D Fake: 1.5792 (1.2997) Acc D Fake: 52.581%
Loss D: 1.808
Loss G: 0.3037 (0.6143) Acc G: 48.143%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.2762 (0.1888) Acc D Real: 87.483%
Loss D Fake: 1.5444 (1.3032) Acc D Fake: 52.085%
Loss D: 1.821
Loss G: 0.3112 (0.6099) Acc G: 48.628%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.2755 (0.1901) Acc D Real: 87.360%
Loss D Fake: 1.5111 (1.3062) Acc D Fake: 51.603%
Loss D: 1.787
Loss G: 0.3187 (0.6057) Acc G: 49.100%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.2855 (0.1914) Acc D Real: 87.227%
Loss D Fake: 1.4787 (1.3086) Acc D Fake: 51.134%
Loss D: 1.764
Loss G: 0.3262 (0.6018) Acc G: 49.559%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.1952 (0.1915) Acc D Real: 87.228%
Loss D Fake: 1.4473 (1.3105) Acc D Fake: 50.679%
Loss D: 1.642
Loss G: 0.3341 (0.5981) Acc G: 50.005%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.2663 (0.1925) Acc D Real: 87.088%
Loss D Fake: 1.4162 (1.3120) Acc D Fake: 50.235%
Loss D: 1.683
Loss G: 0.3422 (0.5945) Acc G: 50.439%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3016 (0.1940) Acc D Real: 86.954%
Loss D Fake: 1.3857 (1.3130) Acc D Fake: 49.804%
Loss D: 1.687
Loss G: 0.3503 (0.5912) Acc G: 50.861%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.2776 (0.1951) Acc D Real: 86.867%
Loss D Fake: 1.3565 (1.3136) Acc D Fake: 49.385%
Loss D: 1.634
Loss G: 0.3584 (0.5881) Acc G: 51.249%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3445 (0.1971) Acc D Real: 86.673%
Loss D Fake: 1.3281 (1.3138) Acc D Fake: 48.998%
Loss D: 1.673
Loss G: 0.3667 (0.5852) Acc G: 51.628%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.1991 (0.1971) Acc D Real: 86.677%
Loss D Fake: 1.3004 (1.3136) Acc D Fake: 48.621%
Loss D: 1.500
Loss G: 0.3751 (0.5825) Acc G: 51.996%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.2463 (0.1977) Acc D Real: 86.649%
Loss D Fake: 1.2734 (1.3131) Acc D Fake: 48.255%
Loss D: 1.520
Loss G: 0.3835 (0.5799) Acc G: 52.355%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3107 (0.1991) Acc D Real: 86.508%
Loss D Fake: 1.2475 (1.3122) Acc D Fake: 47.897%
Loss D: 1.558
Loss G: 0.3921 (0.5776) Acc G: 52.705%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.2751 (0.2001) Acc D Real: 86.384%
Loss D Fake: 1.2220 (1.3111) Acc D Fake: 47.548%
Loss D: 1.497
Loss G: 0.4010 (0.5754) Acc G: 53.046%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.2744 (0.2010) Acc D Real: 86.320%
Loss D Fake: 1.1967 (1.3097) Acc D Fake: 47.208%
Loss D: 1.471
Loss G: 0.4099 (0.5733) Acc G: 53.379%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.2372 (0.2014) Acc D Real: 86.317%
Loss D Fake: 1.1723 (1.3080) Acc D Fake: 46.876%
Loss D: 1.410
Loss G: 0.4189 (0.5714) Acc G: 53.704%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.2868 (0.2025) Acc D Real: 86.195%
Loss D Fake: 1.1488 (1.3061) Acc D Fake: 46.552%
Loss D: 1.436
Loss G: 0.4279 (0.5697) Acc G: 54.020%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.2744 (0.2033) Acc D Real: 86.127%
Loss D Fake: 1.1259 (1.3040) Acc D Fake: 46.236%
Loss D: 1.400
Loss G: 0.4369 (0.5681) Acc G: 54.310%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3221 (0.2047) Acc D Real: 86.010%
Loss D Fake: 1.1028 (1.3016) Acc D Fake: 45.947%
Loss D: 1.425
Loss G: 0.4476 (0.5667) Acc G: 54.593%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3100 (0.2060) Acc D Real: 85.919%
Loss D Fake: 1.0783 (1.2990) Acc D Fake: 45.665%
Loss D: 1.388
Loss G: 0.4585 (0.5654) Acc G: 54.869%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3149 (0.2072) Acc D Real: 85.817%
Loss D Fake: 1.0554 (1.2962) Acc D Fake: 45.389%
Loss D: 1.370
Loss G: 0.4690 (0.5643) Acc G: 55.138%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3297 (0.2086) Acc D Real: 85.669%
Loss D Fake: 1.0340 (1.2932) Acc D Fake: 45.120%
Loss D: 1.364
Loss G: 0.4788 (0.5634) Acc G: 55.402%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.1511 (0.2080) Acc D Real: 85.724%
Loss D Fake: 1.0137 (1.2901) Acc D Fake: 44.856%
Loss D: 1.165
Loss G: 0.4888 (0.5625) Acc G: 55.641%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.2852 (0.2088) Acc D Real: 85.654%
Loss D Fake: 0.9935 (1.2868) Acc D Fake: 44.617%
Loss D: 1.279
Loss G: 0.4987 (0.5618) Acc G: 55.874%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3566 (0.2104) Acc D Real: 85.568%
Loss D Fake: 0.9746 (1.2833) Acc D Fake: 44.383%
Loss D: 1.331
Loss G: 0.5082 (0.5612) Acc G: 56.103%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3115 (0.2115) Acc D Real: 85.515%
Loss D Fake: 0.9571 (1.2798) Acc D Fake: 44.154%
Loss D: 1.269
Loss G: 0.5173 (0.5608) Acc G: 56.326%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4159 (0.2137) Acc D Real: 85.335%
Loss D Fake: 0.9406 (1.2762) Acc D Fake: 43.930%
Loss D: 1.357
Loss G: 0.5261 (0.5604) Acc G: 56.545%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.2964 (0.2146) Acc D Real: 85.289%
Loss D Fake: 0.9250 (1.2724) Acc D Fake: 43.711%
Loss D: 1.221
Loss G: 0.5349 (0.5601) Acc G: 56.759%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3239 (0.2158) Acc D Real: 85.175%
Loss D Fake: 0.9098 (1.2686) Acc D Fake: 43.497%
Loss D: 1.234
Loss G: 0.5438 (0.5599) Acc G: 56.969%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.2454 (0.2161) Acc D Real: 85.116%
Loss D Fake: 0.8944 (1.2647) Acc D Fake: 43.287%
Loss D: 1.140
Loss G: 0.5531 (0.5599) Acc G: 57.174%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3171 (0.2171) Acc D Real: 85.056%
Loss D Fake: 0.8791 (1.2607) Acc D Fake: 43.081%
Loss D: 1.196
Loss G: 0.5625 (0.5599) Acc G: 57.375%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3879 (0.2189) Acc D Real: 84.914%
Loss D Fake: 0.8645 (1.2567) Acc D Fake: 42.879%
Loss D: 1.252
Loss G: 0.5717 (0.5600) Acc G: 57.572%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2580 (0.2193) Acc D Real: 84.958%
Loss D Fake: 0.8506 (1.2526) Acc D Fake: 42.682%
Loss D: 1.109
Loss G: 0.5806 (0.5602) Acc G: 57.748%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3362 (0.2204) Acc D Real: 84.855%
Loss D Fake: 0.8374 (1.2484) Acc D Fake: 42.505%
Loss D: 1.174
Loss G: 0.5895 (0.5605) Acc G: 57.920%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3231 (0.2214) Acc D Real: 84.804%
Loss D Fake: 0.8245 (1.2442) Acc D Fake: 42.332%
Loss D: 1.148
Loss G: 0.5983 (0.5609) Acc G: 58.089%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3376 (0.2226) Acc D Real: 84.727%
Loss D Fake: 0.8121 (1.2400) Acc D Fake: 42.162%
Loss D: 1.150
Loss G: 0.6071 (0.5613) Acc G: 58.255%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2896 (0.2232) Acc D Real: 84.713%
Loss D Fake: 0.8000 (1.2357) Acc D Fake: 41.995%
Loss D: 1.090
Loss G: 0.6159 (0.5619) Acc G: 58.418%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3729 (0.2247) Acc D Real: 84.672%
Loss D Fake: 0.7885 (1.2314) Acc D Fake: 41.832%
Loss D: 1.161
Loss G: 0.6240 (0.5625) Acc G: 58.577%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3221 (0.2256) Acc D Real: 84.609%
Loss D Fake: 0.7780 (1.2271) Acc D Fake: 41.672%
Loss D: 1.100
Loss G: 0.6321 (0.5631) Acc G: 58.734%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3695 (0.2270) Acc D Real: 84.521%
Loss D Fake: 0.7677 (1.2228) Acc D Fake: 41.514%
Loss D: 1.137
Loss G: 0.6401 (0.5639) Acc G: 58.887%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3300 (0.2279) Acc D Real: 84.470%
Loss D Fake: 0.7578 (1.2184) Acc D Fake: 41.360%
Loss D: 1.088
Loss G: 0.6479 (0.5646) Acc G: 59.038%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4350 (0.2298) Acc D Real: 84.337%
Loss D Fake: 0.7484 (1.2141) Acc D Fake: 41.209%
Loss D: 1.183
Loss G: 0.6553 (0.5655) Acc G: 59.185%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3527 (0.2310) Acc D Real: 84.307%
Loss D Fake: 0.7398 (1.2097) Acc D Fake: 41.060%
Loss D: 1.092
Loss G: 0.6622 (0.5664) Acc G: 59.331%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3654 (0.2322) Acc D Real: 84.229%
Loss D Fake: 0.7316 (1.2054) Acc D Fake: 40.914%
Loss D: 1.097
Loss G: 0.6692 (0.5673) Acc G: 59.473%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.1548 (0.2315) Acc D Real: 84.253%
Loss D Fake: 0.7231 (1.2010) Acc D Fake: 40.770%
Loss D: 0.878
Loss G: 0.6771 (0.5683) Acc G: 59.613%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.2420 (0.2316) Acc D Real: 84.248%
Loss D Fake: 0.7137 (1.1967) Acc D Fake: 40.630%
Loss D: 0.956
Loss G: 0.6856 (0.5693) Acc G: 59.735%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.2587 (0.2318) Acc D Real: 84.268%
Loss D Fake: 0.7042 (1.1923) Acc D Fake: 40.506%
Loss D: 0.963
Loss G: 0.6945 (0.5705) Acc G: 59.856%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3416 (0.2328) Acc D Real: 84.199%
Loss D Fake: 0.6946 (1.1880) Acc D Fake: 40.385%
Loss D: 1.036
Loss G: 0.7033 (0.5716) Acc G: 59.974%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3981 (0.2342) Acc D Real: 84.131%
Loss D Fake: 0.6856 (1.1836) Acc D Fake: 40.265%
Loss D: 1.084
Loss G: 0.7114 (0.5728) Acc G: 60.090%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.2721 (0.2345) Acc D Real: 84.125%
Loss D Fake: 0.6773 (1.1792) Acc D Fake: 40.148%
Loss D: 0.949
Loss G: 0.7196 (0.5741) Acc G: 60.204%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3410 (0.2355) Acc D Real: 84.019%
Loss D Fake: 0.6691 (1.1749) Acc D Fake: 40.432%
Loss D: 1.010
Loss G: 0.7276 (0.5754) Acc G: 59.875%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3368 (0.2363) Acc D Real: 83.896%
Loss D Fake: 0.6612 (1.1705) Acc D Fake: 40.771%
Loss D: 0.998
Loss G: 0.7356 (0.5768) Acc G: 59.509%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3659 (0.2374) Acc D Real: 83.731%
Loss D Fake: 0.6535 (1.1662) Acc D Fake: 41.129%
Loss D: 1.019
Loss G: 0.7435 (0.5782) Acc G: 59.121%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2614 (0.2376) Acc D Real: 83.654%
Loss D Fake: 0.6459 (1.1618) Acc D Fake: 41.508%
Loss D: 0.907
Loss G: 0.7514 (0.5796) Acc G: 58.725%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.4104 (0.2390) Acc D Real: 83.434%
Loss D Fake: 0.6387 (1.1575) Acc D Fake: 41.895%
Loss D: 1.049
Loss G: 0.7589 (0.5811) Acc G: 58.323%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.2625 (0.2392) Acc D Real: 83.354%
Loss D Fake: 0.6319 (1.1532) Acc D Fake: 42.290%
Loss D: 0.894
Loss G: 0.7664 (0.5826) Acc G: 57.926%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3588 (0.2402) Acc D Real: 83.178%
Loss D Fake: 0.6252 (1.1489) Acc D Fake: 42.677%
Loss D: 0.984
Loss G: 0.7735 (0.5842) Acc G: 57.523%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3962 (0.2415) Acc D Real: 82.977%
Loss D Fake: 0.6191 (1.1446) Acc D Fake: 43.072%
Loss D: 1.015
Loss G: 0.7802 (0.5857) Acc G: 57.127%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2482 (0.2415) Acc D Real: 82.917%
Loss D Fake: 0.6132 (1.1404) Acc D Fake: 43.462%
Loss D: 0.861
Loss G: 0.7871 (0.5874) Acc G: 56.710%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4200 (0.2429) Acc D Real: 82.699%
Loss D Fake: 0.6073 (1.1361) Acc D Fake: 43.872%
Loss D: 1.027
Loss G: 0.7936 (0.5890) Acc G: 56.299%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4535 (0.2446) Acc D Real: 82.450%
Loss D Fake: 0.6021 (1.1319) Acc D Fake: 44.274%
Loss D: 1.056
Loss G: 0.7995 (0.5907) Acc G: 55.882%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4049 (0.2458) Acc D Real: 82.249%
Loss D Fake: 0.5972 (1.1278) Acc D Fake: 44.683%
Loss D: 1.002
Loss G: 0.8054 (0.5923) Acc G: 55.472%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4422 (0.2474) Acc D Real: 82.001%
Loss D Fake: 0.5925 (1.1236) Acc D Fake: 45.099%
Loss D: 1.035
Loss G: 0.8106 (0.5940) Acc G: 55.042%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.3291 (0.2480) Acc D Real: 81.887%
Loss D Fake: 0.5884 (1.1195) Acc D Fake: 45.522%
Loss D: 0.917
Loss G: 0.8159 (0.5957) Acc G: 54.618%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3310 (0.2486) Acc D Real: 81.778%
Loss D Fake: 0.5837 (1.1154) Acc D Fake: 45.938%
Loss D: 0.915
Loss G: 0.8223 (0.5975) Acc G: 54.201%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.2730 (0.2488) Acc D Real: 81.716%
Loss D Fake: 0.5783 (1.1113) Acc D Fake: 46.347%
Loss D: 0.851
Loss G: 0.8294 (0.5992) Acc G: 53.791%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3766 (0.2498) Acc D Real: 81.559%
Loss D Fake: 0.5727 (1.1073) Acc D Fake: 46.750%
Loss D: 0.949
Loss G: 0.8366 (0.6010) Acc G: 53.386%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.2798 (0.2500) Acc D Real: 81.497%
Loss D Fake: 0.5670 (1.1033) Acc D Fake: 47.148%
Loss D: 0.847
Loss G: 0.8442 (0.6028) Acc G: 52.988%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4228 (0.2513) Acc D Real: 81.304%
Loss D Fake: 0.5613 (1.0992) Acc D Fake: 47.539%
Loss D: 0.984
Loss G: 0.8516 (0.6047) Acc G: 52.595%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3233 (0.2518) Acc D Real: 81.206%
Loss D Fake: 0.5558 (1.0952) Acc D Fake: 47.925%
Loss D: 0.879
Loss G: 0.8590 (0.6065) Acc G: 52.209%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4140 (0.2530) Acc D Real: 81.022%
Loss D Fake: 0.5505 (1.0913) Acc D Fake: 48.305%
Loss D: 0.965
Loss G: 0.8658 (0.6084) Acc G: 51.827%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3984 (0.2540) Acc D Real: 80.855%
Loss D Fake: 0.5459 (1.0873) Acc D Fake: 48.680%
Loss D: 0.944
Loss G: 0.8720 (0.6103) Acc G: 51.452%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3364 (0.2546) Acc D Real: 80.747%
Loss D Fake: 0.5417 (1.0834) Acc D Fake: 49.049%
Loss D: 0.878
Loss G: 0.8777 (0.6123) Acc G: 51.082%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.2802 (0.2548) Acc D Real: 80.689%
Loss D Fake: 0.5376 (1.0795) Acc D Fake: 49.413%
Loss D: 0.818
Loss G: 0.8836 (0.6142) Acc G: 50.717%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.4281 (0.2560) Acc D Real: 80.512%
Loss D Fake: 0.5336 (1.0756) Acc D Fake: 49.772%
Loss D: 0.962
Loss G: 0.8891 (0.6161) Acc G: 50.357%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.2920 (0.2563) Acc D Real: 80.442%
Loss D Fake: 0.5300 (1.0718) Acc D Fake: 50.125%
Loss D: 0.822
Loss G: 0.8944 (0.6181) Acc G: 50.003%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.2860 (0.2565) Acc D Real: 80.387%
Loss D Fake: 0.5263 (1.0680) Acc D Fake: 50.474%
Loss D: 0.812
Loss G: 0.9000 (0.6201) Acc G: 49.653%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3036 (0.2568) Acc D Real: 80.315%
Loss D Fake: 0.5224 (1.0642) Acc D Fake: 50.818%
Loss D: 0.826
Loss G: 0.9059 (0.6221) Acc G: 49.308%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.3947 (0.2578) Acc D Real: 80.175%
Loss D Fake: 0.5187 (1.0604) Acc D Fake: 51.157%
Loss D: 0.913
Loss G: 0.9109 (0.6240) Acc G: 48.968%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4129 (0.2588) Acc D Real: 80.021%
Loss D Fake: 0.5157 (1.0567) Acc D Fake: 51.492%
Loss D: 0.929
Loss G: 0.9151 (0.6260) Acc G: 48.633%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3468 (0.2594) Acc D Real: 79.918%
Loss D Fake: 0.5132 (1.0530) Acc D Fake: 51.822%
Loss D: 0.860
Loss G: 0.9188 (0.6280) Acc G: 48.302%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3449 (0.2600) Acc D Real: 79.819%
Loss D Fake: 0.5109 (1.0493) Acc D Fake: 52.147%
Loss D: 0.856
Loss G: 0.9224 (0.6300) Acc G: 47.975%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.5126 (0.2617) Acc D Real: 79.598%
Loss D Fake: 0.5088 (1.0457) Acc D Fake: 52.469%
Loss D: 1.021
Loss G: 0.9250 (0.6320) Acc G: 47.653%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3372 (0.2622) Acc D Real: 79.518%
Loss D Fake: 0.5072 (1.0421) Acc D Fake: 52.785%
Loss D: 0.844
Loss G: 0.9279 (0.6340) Acc G: 47.336%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3631 (0.2629) Acc D Real: 79.418%
Loss D Fake: 0.5053 (1.0386) Acc D Fake: 53.098%
Loss D: 0.868
Loss G: 0.9309 (0.6359) Acc G: 47.022%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3715 (0.2636) Acc D Real: 79.311%
Loss D Fake: 0.5034 (1.0350) Acc D Fake: 53.407%
Loss D: 0.875
Loss G: 0.9339 (0.6379) Acc G: 46.713%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4474 (0.2648) Acc D Real: 79.151%
Loss D Fake: 0.5017 (1.0315) Acc D Fake: 53.711%
Loss D: 0.949
Loss G: 0.9360 (0.6398) Acc G: 46.408%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3771 (0.2655) Acc D Real: 79.044%
Loss D Fake: 0.5006 (1.0281) Acc D Fake: 54.012%
Loss D: 0.878
Loss G: 0.9379 (0.6418) Acc G: 46.106%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4584 (0.2668) Acc D Real: 78.887%
Loss D Fake: 0.4995 (1.0247) Acc D Fake: 54.308%
Loss D: 0.958
Loss G: 0.9392 (0.6437) Acc G: 45.809%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.2972 (0.2670) Acc D Real: 78.840%
Loss D Fake: 0.4988 (1.0213) Acc D Fake: 54.601%
Loss D: 0.796
Loss G: 0.9407 (0.6456) Acc G: 45.515%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.2013 (0.2666) Acc D Real: 78.862%
Loss D Fake: 0.4975 (1.0180) Acc D Fake: 54.891%
Loss D: 0.699
Loss G: 0.9434 (0.6475) Acc G: 45.225%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2441 (0.2664) Acc D Real: 78.862%
Loss D Fake: 0.4954 (1.0147) Acc D Fake: 54.917%
Loss D: 0.740
Loss G: 0.9477 (0.6494) Acc G: 45.198%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.550 | Generator Loss: 0.948 | Avg: 1.497
TEST [21/180]: Discriminator Loss: 0.577 | Generator Loss: 0.948 | Avg: 1.524
TEST [31/180]: Discriminator Loss: 0.571 | Generator Loss: 0.948 | Avg: 1.518
TEST [41/180]: Discriminator Loss: 0.563 | Generator Loss: 0.948 | Avg: 1.511
TEST [51/180]: Discriminator Loss: 0.562 | Generator Loss: 0.948 | Avg: 1.510
TEST [61/180]: Discriminator Loss: 0.641 | Generator Loss: 0.948 | Avg: 1.589
TEST [71/180]: Discriminator Loss: 0.639 | Generator Loss: 0.948 | Avg: 1.587
TEST [81/180]: Discriminator Loss: 0.689 | Generator Loss: 0.948 | Avg: 1.637
TEST [91/180]: Discriminator Loss: 0.700 | Generator Loss: 0.948 | Avg: 1.648
TEST [101/180]: Discriminator Loss: 0.761 | Generator Loss: 0.948 | Avg: 1.709
TEST [111/180]: Discriminator Loss: 0.804 | Generator Loss: 0.948 | Avg: 1.752
TEST [121/180]: Discriminator Loss: 0.857 | Generator Loss: 0.948 | Avg: 1.805
TEST [131/180]: Discriminator Loss: 0.884 | Generator Loss: 0.948 | Avg: 1.831
TEST [141/180]: Discriminator Loss: 0.888 | Generator Loss: 0.948 | Avg: 1.836
TEST [151/180]: Discriminator Loss: 0.868 | Generator Loss: 0.948 | Avg: 1.816
TEST [161/180]: Discriminator Loss: 0.849 | Generator Loss: 0.948 | Avg: 1.797
TEST [171/180]: Discriminator Loss: 0.833 | Generator Loss: 0.948 | Avg: 1.781
Epoch: 4/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3656 (0.2891) Acc D Real: 72.109%
Loss D Fake: 0.4892 (0.4908) Acc D Fake: 100.000%
Loss D: 0.855
Loss G: 0.9580 (0.9555) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3455 (0.3079) Acc D Real: 70.347%
Loss D Fake: 0.4864 (0.4894) Acc D Fake: 100.000%
Loss D: 0.832
Loss G: 0.9623 (0.9578) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3183 (0.3105) Acc D Real: 70.286%
Loss D Fake: 0.4840 (0.4880) Acc D Fake: 100.000%
Loss D: 0.802
Loss G: 0.9663 (0.9599) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3827 (0.3249) Acc D Real: 68.781%
Loss D Fake: 0.4817 (0.4868) Acc D Fake: 100.000%
Loss D: 0.864
Loss G: 0.9703 (0.9620) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3079 (0.3221) Acc D Real: 69.123%
Loss D Fake: 0.4793 (0.4855) Acc D Fake: 100.000%
Loss D: 0.787
Loss G: 0.9747 (0.9641) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.2624 (0.3135) Acc D Real: 70.112%
Loss D Fake: 0.4767 (0.4843) Acc D Fake: 100.000%
Loss D: 0.739
Loss G: 0.9794 (0.9663) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.2829 (0.3097) Acc D Real: 70.612%
Loss D Fake: 0.4740 (0.4830) Acc D Fake: 100.000%
Loss D: 0.757
Loss G: 0.9840 (0.9685) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4135 (0.3212) Acc D Real: 69.433%
Loss D Fake: 0.4716 (0.4817) Acc D Fake: 100.000%
Loss D: 0.885
Loss G: 0.9878 (0.9706) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3646 (0.3256) Acc D Real: 69.052%
Loss D Fake: 0.4697 (0.4805) Acc D Fake: 100.000%
Loss D: 0.834
Loss G: 0.9907 (0.9726) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3727 (0.3298) Acc D Real: 68.670%
Loss D Fake: 0.4683 (0.4794) Acc D Fake: 100.000%
Loss D: 0.841
Loss G: 0.9931 (0.9745) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4063 (0.3362) Acc D Real: 68.077%
Loss D Fake: 0.4672 (0.4784) Acc D Fake: 100.000%
Loss D: 0.874
Loss G: 0.9945 (0.9762) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3556 (0.3377) Acc D Real: 68.005%
Loss D Fake: 0.4665 (0.4775) Acc D Fake: 100.000%
Loss D: 0.822
Loss G: 0.9957 (0.9777) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.2830 (0.3338) Acc D Real: 68.408%
Loss D Fake: 0.4658 (0.4766) Acc D Fake: 100.000%
Loss D: 0.749
Loss G: 0.9976 (0.9791) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4211 (0.3396) Acc D Real: 67.833%
Loss D Fake: 0.4647 (0.4759) Acc D Fake: 100.000%
Loss D: 0.886
Loss G: 0.9990 (0.9804) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4171 (0.3445) Acc D Real: 67.370%
Loss D Fake: 0.4641 (0.4751) Acc D Fake: 100.000%
Loss D: 0.881
Loss G: 1.0000 (0.9816) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.2798 (0.3407) Acc D Real: 67.788%
Loss D Fake: 0.4636 (0.4744) Acc D Fake: 100.000%
Loss D: 0.743
Loss G: 1.0014 (0.9828) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3462 (0.3410) Acc D Real: 67.818%
Loss D Fake: 0.4628 (0.4738) Acc D Fake: 100.000%
Loss D: 0.809
Loss G: 1.0026 (0.9839) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3848 (0.3433) Acc D Real: 67.632%
Loss D Fake: 0.4623 (0.4732) Acc D Fake: 100.000%
Loss D: 0.847
Loss G: 1.0034 (0.9849) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3786 (0.3450) Acc D Real: 67.479%
Loss D Fake: 0.4619 (0.4726) Acc D Fake: 100.000%
Loss D: 0.840
Loss G: 1.0040 (0.9859) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.4384 (0.3495) Acc D Real: 67.029%
Loss D Fake: 0.4617 (0.4721) Acc D Fake: 100.000%
Loss D: 0.900
Loss G: 1.0043 (0.9868) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.2331 (0.3442) Acc D Real: 67.562%
Loss D Fake: 0.4614 (0.4716) Acc D Fake: 100.000%
Loss D: 0.694
Loss G: 1.0054 (0.9876) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.2806 (0.3414) Acc D Real: 67.844%
Loss D Fake: 0.4605 (0.4711) Acc D Fake: 100.000%
Loss D: 0.741
Loss G: 1.0072 (0.9885) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.4786 (0.3471) Acc D Real: 67.285%
Loss D Fake: 0.4597 (0.4707) Acc D Fake: 100.000%
Loss D: 0.938
Loss G: 1.0080 (0.9893) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4980 (0.3532) Acc D Real: 66.652%
Loss D Fake: 0.4597 (0.4702) Acc D Fake: 100.000%
Loss D: 0.958
Loss G: 1.0076 (0.9900) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3932 (0.3547) Acc D Real: 66.522%
Loss D Fake: 0.4600 (0.4698) Acc D Fake: 100.000%
Loss D: 0.853
Loss G: 1.0067 (0.9907) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4008 (0.3564) Acc D Real: 66.333%
Loss D Fake: 0.4605 (0.4695) Acc D Fake: 100.000%
Loss D: 0.861
Loss G: 1.0063 (0.9912) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3970 (0.3579) Acc D Real: 66.192%
Loss D Fake: 0.4606 (0.4692) Acc D Fake: 100.000%
Loss D: 0.858
Loss G: 1.0060 (0.9918) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.2879 (0.3555) Acc D Real: 66.467%
Loss D Fake: 0.4607 (0.4689) Acc D Fake: 100.000%
Loss D: 0.749
Loss G: 1.0064 (0.9923) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3110 (0.3540) Acc D Real: 66.660%
Loss D Fake: 0.4604 (0.4686) Acc D Fake: 100.000%
Loss D: 0.771
Loss G: 1.0070 (0.9928) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.2885 (0.3519) Acc D Real: 66.897%
Loss D Fake: 0.4600 (0.4683) Acc D Fake: 100.000%
Loss D: 0.748
Loss G: 1.0083 (0.9933) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3976 (0.3533) Acc D Real: 66.779%
Loss D Fake: 0.4593 (0.4680) Acc D Fake: 100.000%
Loss D: 0.857
Loss G: 1.0092 (0.9938) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.2637 (0.3506) Acc D Real: 67.069%
Loss D Fake: 0.4588 (0.4677) Acc D Fake: 100.000%
Loss D: 0.722
Loss G: 1.0104 (0.9943) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3633 (0.3510) Acc D Real: 67.016%
Loss D Fake: 0.4580 (0.4675) Acc D Fake: 100.000%
Loss D: 0.821
Loss G: 1.0120 (0.9948) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3514 (0.3510) Acc D Real: 67.040%
Loss D Fake: 0.4572 (0.4672) Acc D Fake: 100.000%
Loss D: 0.809
Loss G: 1.0133 (0.9953) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.2504 (0.3482) Acc D Real: 67.338%
Loss D Fake: 0.4565 (0.4669) Acc D Fake: 100.000%
Loss D: 0.707
Loss G: 1.0149 (0.9959) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3108 (0.3472) Acc D Real: 67.459%
Loss D Fake: 0.4555 (0.4666) Acc D Fake: 100.000%
Loss D: 0.766
Loss G: 1.0168 (0.9964) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3262 (0.3466) Acc D Real: 67.537%
Loss D Fake: 0.4546 (0.4662) Acc D Fake: 100.000%
Loss D: 0.781
Loss G: 1.0185 (0.9970) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3954 (0.3479) Acc D Real: 67.425%
Loss D Fake: 0.4538 (0.4659) Acc D Fake: 100.000%
Loss D: 0.849
Loss G: 1.0196 (0.9976) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.2417 (0.3452) Acc D Real: 67.702%
Loss D Fake: 0.4532 (0.4656) Acc D Fake: 100.000%
Loss D: 0.695
Loss G: 1.0211 (0.9982) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4709 (0.3483) Acc D Real: 67.384%
Loss D Fake: 0.4525 (0.4653) Acc D Fake: 100.000%
Loss D: 0.923
Loss G: 1.0220 (0.9987) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.2241 (0.3453) Acc D Real: 67.707%
Loss D Fake: 0.4520 (0.4650) Acc D Fake: 100.000%
Loss D: 0.676
Loss G: 1.0234 (0.9993) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.2642 (0.3434) Acc D Real: 67.902%
Loss D Fake: 0.4511 (0.4646) Acc D Fake: 100.000%
Loss D: 0.715
Loss G: 1.0257 (0.9999) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3473 (0.3435) Acc D Real: 67.920%
Loss D Fake: 0.4499 (0.4643) Acc D Fake: 100.000%
Loss D: 0.797
Loss G: 1.0275 (1.0006) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4106 (0.3450) Acc D Real: 67.786%
Loss D Fake: 0.4492 (0.4640) Acc D Fake: 100.000%
Loss D: 0.860
Loss G: 1.0284 (1.0012) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3899 (0.3460) Acc D Real: 67.714%
Loss D Fake: 0.4489 (0.4637) Acc D Fake: 100.000%
Loss D: 0.839
Loss G: 1.0287 (1.0018) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3195 (0.3454) Acc D Real: 67.765%
Loss D Fake: 0.4487 (0.4633) Acc D Fake: 100.000%
Loss D: 0.768
Loss G: 1.0297 (1.0024) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3172 (0.3448) Acc D Real: 67.841%
Loss D Fake: 0.4481 (0.4630) Acc D Fake: 100.000%
Loss D: 0.765
Loss G: 1.0311 (1.0030) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3064 (0.3441) Acc D Real: 67.946%
Loss D Fake: 0.4474 (0.4627) Acc D Fake: 100.000%
Loss D: 0.754
Loss G: 1.0323 (1.0036) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4224 (0.3456) Acc D Real: 67.775%
Loss D Fake: 0.4468 (0.4624) Acc D Fake: 100.000%
Loss D: 0.869
Loss G: 1.0335 (1.0042) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.2790 (0.3443) Acc D Real: 67.932%
Loss D Fake: 0.4462 (0.4621) Acc D Fake: 100.000%
Loss D: 0.725
Loss G: 1.0348 (1.0048) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3211 (0.3439) Acc D Real: 67.988%
Loss D Fake: 0.4455 (0.4617) Acc D Fake: 100.000%
Loss D: 0.767
Loss G: 1.0363 (1.0054) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4240 (0.3454) Acc D Real: 67.852%
Loss D Fake: 0.4449 (0.4614) Acc D Fake: 100.000%
Loss D: 0.869
Loss G: 1.0371 (1.0060) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3211 (0.3449) Acc D Real: 67.912%
Loss D Fake: 0.4445 (0.4611) Acc D Fake: 100.000%
Loss D: 0.766
Loss G: 1.0378 (1.0066) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3524 (0.3451) Acc D Real: 67.920%
Loss D Fake: 0.4443 (0.4608) Acc D Fake: 100.000%
Loss D: 0.797
Loss G: 1.0382 (1.0071) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3133 (0.3445) Acc D Real: 67.999%
Loss D Fake: 0.4442 (0.4605) Acc D Fake: 100.000%
Loss D: 0.757
Loss G: 1.0383 (1.0077) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3141 (0.3440) Acc D Real: 68.058%
Loss D Fake: 0.4441 (0.4602) Acc D Fake: 100.000%
Loss D: 0.758
Loss G: 1.0387 (1.0082) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3645 (0.3443) Acc D Real: 68.038%
Loss D Fake: 0.4438 (0.4599) Acc D Fake: 100.000%
Loss D: 0.808
Loss G: 1.0390 (1.0088) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3258 (0.3440) Acc D Real: 68.071%
Loss D Fake: 0.4437 (0.4597) Acc D Fake: 100.000%
Loss D: 0.769
Loss G: 1.0397 (1.0093) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.2196 (0.3419) Acc D Real: 68.312%
Loss D Fake: 0.4433 (0.4594) Acc D Fake: 100.000%
Loss D: 0.663
Loss G: 1.0406 (1.0098) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.2428 (0.3403) Acc D Real: 68.490%
Loss D Fake: 0.4427 (0.4591) Acc D Fake: 100.000%
Loss D: 0.685
Loss G: 1.0419 (1.0103) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2707 (0.3392) Acc D Real: 68.625%
Loss D Fake: 0.4421 (0.4588) Acc D Fake: 100.000%
Loss D: 0.713
Loss G: 1.0433 (1.0109) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3436 (0.3393) Acc D Real: 68.618%
Loss D Fake: 0.4414 (0.4586) Acc D Fake: 100.000%
Loss D: 0.785
Loss G: 1.0445 (1.0114) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.2252 (0.3375) Acc D Real: 68.820%
Loss D Fake: 0.4408 (0.4583) Acc D Fake: 100.000%
Loss D: 0.666
Loss G: 1.0459 (1.0120) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.2742 (0.3365) Acc D Real: 68.922%
Loss D Fake: 0.4401 (0.4580) Acc D Fake: 100.000%
Loss D: 0.714
Loss G: 1.0473 (1.0125) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3918 (0.3373) Acc D Real: 68.854%
Loss D Fake: 0.4398 (0.4577) Acc D Fake: 100.000%
Loss D: 0.832
Loss G: 1.0466 (1.0130) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.1998 (0.3353) Acc D Real: 69.083%
Loss D Fake: 0.4407 (0.4575) Acc D Fake: 100.000%
Loss D: 0.641
Loss G: 1.0444 (1.0135) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3382 (0.3353) Acc D Real: 69.107%
Loss D Fake: 0.4420 (0.4572) Acc D Fake: 100.000%
Loss D: 0.780
Loss G: 1.0416 (1.0139) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3543 (0.3356) Acc D Real: 69.101%
Loss D Fake: 0.4436 (0.4571) Acc D Fake: 100.000%
Loss D: 0.798
Loss G: 1.0385 (1.0143) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3306 (0.3355) Acc D Real: 69.132%
Loss D Fake: 0.4451 (0.4569) Acc D Fake: 100.000%
Loss D: 0.776
Loss G: 1.0356 (1.0146) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3494 (0.3357) Acc D Real: 69.135%
Loss D Fake: 0.4465 (0.4567) Acc D Fake: 100.000%
Loss D: 0.796
Loss G: 1.0331 (1.0148) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3644 (0.3361) Acc D Real: 69.105%
Loss D Fake: 0.4479 (0.4566) Acc D Fake: 100.000%
Loss D: 0.812
Loss G: 1.0304 (1.0150) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.4088 (0.3371) Acc D Real: 69.032%
Loss D Fake: 0.4493 (0.4565) Acc D Fake: 100.000%
Loss D: 0.858
Loss G: 1.0276 (1.0152) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2593 (0.3361) Acc D Real: 69.153%
Loss D Fake: 0.4505 (0.4564) Acc D Fake: 100.000%
Loss D: 0.710
Loss G: 1.0260 (1.0154) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.4338 (0.3374) Acc D Real: 69.043%
Loss D Fake: 0.4512 (0.4564) Acc D Fake: 100.000%
Loss D: 0.885
Loss G: 1.0246 (1.0155) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.2642 (0.3364) Acc D Real: 69.137%
Loss D Fake: 0.4519 (0.4563) Acc D Fake: 100.000%
Loss D: 0.716
Loss G: 1.0237 (1.0156) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2994 (0.3359) Acc D Real: 69.182%
Loss D Fake: 0.4523 (0.4563) Acc D Fake: 100.000%
Loss D: 0.752
Loss G: 1.0234 (1.0157) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3274 (0.3358) Acc D Real: 69.199%
Loss D Fake: 0.4524 (0.4562) Acc D Fake: 100.000%
Loss D: 0.780
Loss G: 1.0234 (1.0158) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3695 (0.3362) Acc D Real: 69.176%
Loss D Fake: 0.4525 (0.4562) Acc D Fake: 100.000%
Loss D: 0.822
Loss G: 1.0231 (1.0159) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3739 (0.3367) Acc D Real: 69.153%
Loss D Fake: 0.4528 (0.4561) Acc D Fake: 100.000%
Loss D: 0.827
Loss G: 1.0224 (1.0160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3983 (0.3375) Acc D Real: 69.095%
Loss D Fake: 0.4534 (0.4561) Acc D Fake: 100.000%
Loss D: 0.852
Loss G: 1.0210 (1.0160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.2854 (0.3368) Acc D Real: 69.160%
Loss D Fake: 0.4542 (0.4561) Acc D Fake: 100.000%
Loss D: 0.740
Loss G: 1.0196 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3027 (0.3364) Acc D Real: 69.207%
Loss D Fake: 0.4549 (0.4560) Acc D Fake: 100.000%
Loss D: 0.758
Loss G: 1.0183 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.2945 (0.3359) Acc D Real: 69.273%
Loss D Fake: 0.4556 (0.4560) Acc D Fake: 100.000%
Loss D: 0.750
Loss G: 1.0170 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3216 (0.3358) Acc D Real: 69.292%
Loss D Fake: 0.4563 (0.4560) Acc D Fake: 100.000%
Loss D: 0.778
Loss G: 1.0159 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.2693 (0.3350) Acc D Real: 69.379%
Loss D Fake: 0.4569 (0.4560) Acc D Fake: 100.000%
Loss D: 0.726
Loss G: 1.0150 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3206 (0.3348) Acc D Real: 69.410%
Loss D Fake: 0.4573 (0.4561) Acc D Fake: 100.000%
Loss D: 0.778
Loss G: 1.0140 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.2638 (0.3340) Acc D Real: 69.490%
Loss D Fake: 0.4579 (0.4561) Acc D Fake: 100.000%
Loss D: 0.722
Loss G: 1.0131 (1.0160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3123 (0.3338) Acc D Real: 69.522%
Loss D Fake: 0.4584 (0.4561) Acc D Fake: 100.000%
Loss D: 0.771
Loss G: 1.0123 (1.0160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3195 (0.3336) Acc D Real: 69.542%
Loss D Fake: 0.4588 (0.4561) Acc D Fake: 100.000%
Loss D: 0.778
Loss G: 1.0116 (1.0159) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.2860 (0.3331) Acc D Real: 69.599%
Loss D Fake: 0.4592 (0.4562) Acc D Fake: 100.000%
Loss D: 0.745
Loss G: 1.0109 (1.0159) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3253 (0.3330) Acc D Real: 69.614%
Loss D Fake: 0.4597 (0.4562) Acc D Fake: 100.000%
Loss D: 0.785
Loss G: 1.0100 (1.0158) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3900 (0.3336) Acc D Real: 69.572%
Loss D Fake: 0.4603 (0.4563) Acc D Fake: 100.000%
Loss D: 0.850
Loss G: 1.0084 (1.0157) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.1714 (0.3319) Acc D Real: 69.753%
Loss D Fake: 0.4612 (0.4563) Acc D Fake: 100.000%
Loss D: 0.633
Loss G: 1.0073 (1.0156) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2911 (0.3315) Acc D Real: 69.794%
Loss D Fake: 0.4617 (0.4564) Acc D Fake: 100.000%
Loss D: 0.753
Loss G: 1.0063 (1.0155) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3097 (0.3312) Acc D Real: 69.817%
Loss D Fake: 0.4622 (0.4564) Acc D Fake: 100.000%
Loss D: 0.772
Loss G: 1.0054 (1.0154) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3718 (0.3317) Acc D Real: 69.777%
Loss D Fake: 0.4628 (0.4565) Acc D Fake: 100.000%
Loss D: 0.835
Loss G: 1.0041 (1.0153) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3729 (0.3321) Acc D Real: 69.734%
Loss D Fake: 0.4636 (0.4566) Acc D Fake: 100.000%
Loss D: 0.836
Loss G: 1.0025 (1.0152) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2906 (0.3317) Acc D Real: 69.777%
Loss D Fake: 0.4645 (0.4566) Acc D Fake: 100.000%
Loss D: 0.755
Loss G: 1.0007 (1.0150) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3406 (0.3317) Acc D Real: 69.773%
Loss D Fake: 0.4655 (0.4567) Acc D Fake: 100.000%
Loss D: 0.806
Loss G: 0.9988 (1.0149) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3178 (0.3316) Acc D Real: 69.795%
Loss D Fake: 0.4671 (0.4568) Acc D Fake: 100.000%
Loss D: 0.785
Loss G: 0.9937 (1.0147) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3202 (0.3315) Acc D Real: 69.803%
Loss D Fake: 0.4703 (0.4570) Acc D Fake: 100.000%
Loss D: 0.790
Loss G: 0.9877 (1.0144) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2556 (0.3308) Acc D Real: 69.876%
Loss D Fake: 0.4734 (0.4571) Acc D Fake: 100.000%
Loss D: 0.729
Loss G: 0.9818 (1.0141) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3667 (0.3311) Acc D Real: 69.847%
Loss D Fake: 0.4764 (0.4573) Acc D Fake: 100.000%
Loss D: 0.843
Loss G: 0.9765 (1.0137) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3281 (0.3311) Acc D Real: 69.849%
Loss D Fake: 0.4791 (0.4575) Acc D Fake: 100.000%
Loss D: 0.807
Loss G: 0.9711 (1.0133) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3019 (0.3308) Acc D Real: 69.890%
Loss D Fake: 0.4819 (0.4578) Acc D Fake: 100.000%
Loss D: 0.784
Loss G: 0.9674 (1.0129) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3187 (0.3307) Acc D Real: 69.898%
Loss D Fake: 0.4812 (0.4580) Acc D Fake: 100.000%
Loss D: 0.800
Loss G: 0.9737 (1.0125) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3413 (0.3308) Acc D Real: 69.888%
Loss D Fake: 0.4770 (0.4581) Acc D Fake: 100.000%
Loss D: 0.818
Loss G: 0.9784 (1.0122) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.2777 (0.3303) Acc D Real: 69.946%
Loss D Fake: 0.4757 (0.4583) Acc D Fake: 100.000%
Loss D: 0.753
Loss G: 0.9794 (1.0119) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.2639 (0.3297) Acc D Real: 70.003%
Loss D Fake: 0.4755 (0.4585) Acc D Fake: 100.000%
Loss D: 0.739
Loss G: 0.9795 (1.0116) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.2574 (0.3290) Acc D Real: 70.071%
Loss D Fake: 0.4756 (0.4586) Acc D Fake: 100.000%
Loss D: 0.733
Loss G: 0.9793 (1.0113) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.2538 (0.3284) Acc D Real: 70.143%
Loss D Fake: 0.4757 (0.4588) Acc D Fake: 100.000%
Loss D: 0.730
Loss G: 0.9790 (1.0110) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.1451 (0.3267) Acc D Real: 70.309%
Loss D Fake: 0.4759 (0.4589) Acc D Fake: 100.000%
Loss D: 0.621
Loss G: 0.9789 (1.0108) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3450 (0.3269) Acc D Real: 70.292%
Loss D Fake: 0.4760 (0.4591) Acc D Fake: 100.000%
Loss D: 0.821
Loss G: 0.9787 (1.0105) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3454 (0.3271) Acc D Real: 70.274%
Loss D Fake: 0.4762 (0.4592) Acc D Fake: 100.000%
Loss D: 0.822
Loss G: 0.9784 (1.0102) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3069 (0.3269) Acc D Real: 70.280%
Loss D Fake: 0.4765 (0.4594) Acc D Fake: 100.000%
Loss D: 0.783
Loss G: 0.9775 (1.0099) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.2416 (0.3262) Acc D Real: 70.351%
Loss D Fake: 0.4771 (0.4595) Acc D Fake: 100.000%
Loss D: 0.719
Loss G: 0.9767 (1.0096) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.1904 (0.3250) Acc D Real: 70.467%
Loss D Fake: 0.4776 (0.4597) Acc D Fake: 100.000%
Loss D: 0.668
Loss G: 0.9761 (1.0093) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3718 (0.3254) Acc D Real: 70.418%
Loss D Fake: 0.4780 (0.4598) Acc D Fake: 100.000%
Loss D: 0.850
Loss G: 0.9755 (1.0091) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2591 (0.3249) Acc D Real: 70.468%
Loss D Fake: 0.4784 (0.4600) Acc D Fake: 100.000%
Loss D: 0.738
Loss G: 0.9747 (1.0088) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.2592 (0.3243) Acc D Real: 70.517%
Loss D Fake: 0.4789 (0.4601) Acc D Fake: 100.000%
Loss D: 0.738
Loss G: 0.9740 (1.0085) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4088 (0.3250) Acc D Real: 70.429%
Loss D Fake: 0.4794 (0.4603) Acc D Fake: 100.000%
Loss D: 0.888
Loss G: 0.9732 (1.0082) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.2083 (0.3241) Acc D Real: 70.517%
Loss D Fake: 0.4799 (0.4605) Acc D Fake: 100.000%
Loss D: 0.688
Loss G: 0.9725 (1.0079) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3026 (0.3239) Acc D Real: 70.528%
Loss D Fake: 0.4803 (0.4606) Acc D Fake: 100.000%
Loss D: 0.783
Loss G: 0.9718 (1.0076) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2727 (0.3235) Acc D Real: 70.560%
Loss D Fake: 0.4809 (0.4608) Acc D Fake: 100.000%
Loss D: 0.754
Loss G: 0.9710 (1.0073) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3153 (0.3234) Acc D Real: 70.556%
Loss D Fake: 0.4814 (0.4609) Acc D Fake: 100.000%
Loss D: 0.797
Loss G: 0.9700 (1.0070) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.2311 (0.3227) Acc D Real: 70.620%
Loss D Fake: 0.4821 (0.4611) Acc D Fake: 100.000%
Loss D: 0.713
Loss G: 0.9689 (1.0067) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.1713 (0.3215) Acc D Real: 70.741%
Loss D Fake: 0.4829 (0.4613) Acc D Fake: 100.000%
Loss D: 0.654
Loss G: 0.9672 (1.0064) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.2178 (0.3207) Acc D Real: 70.817%
Loss D Fake: 0.4841 (0.4615) Acc D Fake: 100.000%
Loss D: 0.702
Loss G: 0.9655 (1.0061) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.2648 (0.3203) Acc D Real: 70.850%
Loss D Fake: 0.4851 (0.4616) Acc D Fake: 100.000%
Loss D: 0.750
Loss G: 0.9639 (1.0058) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2535 (0.3198) Acc D Real: 70.892%
Loss D Fake: 0.4861 (0.4618) Acc D Fake: 100.000%
Loss D: 0.740
Loss G: 0.9625 (1.0054) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.2151 (0.3190) Acc D Real: 70.960%
Loss D Fake: 0.4870 (0.4620) Acc D Fake: 100.000%
Loss D: 0.702
Loss G: 0.9612 (1.0051) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3021 (0.3188) Acc D Real: 70.958%
Loss D Fake: 0.4879 (0.4622) Acc D Fake: 100.000%
Loss D: 0.790
Loss G: 0.9600 (1.0048) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.2721 (0.3185) Acc D Real: 70.981%
Loss D Fake: 0.4887 (0.4624) Acc D Fake: 100.000%
Loss D: 0.761
Loss G: 0.9588 (1.0044) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.2150 (0.3177) Acc D Real: 71.046%
Loss D Fake: 0.4896 (0.4626) Acc D Fake: 100.000%
Loss D: 0.705
Loss G: 0.9572 (1.0041) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.2134 (0.3170) Acc D Real: 71.115%
Loss D Fake: 0.4907 (0.4628) Acc D Fake: 100.000%
Loss D: 0.704
Loss G: 0.9556 (1.0037) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.2225 (0.3163) Acc D Real: 71.180%
Loss D Fake: 0.4919 (0.4630) Acc D Fake: 100.000%
Loss D: 0.714
Loss G: 0.9536 (1.0034) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.2265 (0.3156) Acc D Real: 71.235%
Loss D Fake: 0.4935 (0.4632) Acc D Fake: 100.000%
Loss D: 0.720
Loss G: 0.9508 (1.0030) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.2464 (0.3151) Acc D Real: 71.269%
Loss D Fake: 0.4956 (0.4635) Acc D Fake: 100.000%
Loss D: 0.742
Loss G: 0.9478 (1.0026) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.1863 (0.3142) Acc D Real: 71.353%
Loss D Fake: 0.4976 (0.4637) Acc D Fake: 100.000%
Loss D: 0.684
Loss G: 0.9450 (1.0022) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.2022 (0.3134) Acc D Real: 71.428%
Loss D Fake: 0.4998 (0.4640) Acc D Fake: 100.000%
Loss D: 0.702
Loss G: 0.9414 (1.0017) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.2093 (0.3127) Acc D Real: 71.486%
Loss D Fake: 0.5026 (0.4643) Acc D Fake: 100.000%
Loss D: 0.712
Loss G: 0.9373 (1.0013) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.2614 (0.3123) Acc D Real: 71.509%
Loss D Fake: 0.5063 (0.4645) Acc D Fake: 100.000%
Loss D: 0.768
Loss G: 0.9317 (1.0008) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.2776 (0.3121) Acc D Real: 71.519%
Loss D Fake: 0.5121 (0.4649) Acc D Fake: 100.000%
Loss D: 0.790
Loss G: 0.9233 (1.0003) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.2054 (0.3113) Acc D Real: 71.584%
Loss D Fake: 0.5224 (0.4653) Acc D Fake: 99.989%
Loss D: 0.728
Loss G: 0.9107 (0.9996) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.2627 (0.3110) Acc D Real: 71.596%
Loss D Fake: 1.0696 (0.4694) Acc D Fake: 99.844%
Loss D: 1.332
Loss G: 0.9662 (0.9994) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.2443 (0.3105) Acc D Real: 71.626%
Loss D Fake: 0.4747 (0.4695) Acc D Fake: 99.845%
Loss D: 0.719
Loss G: 0.9954 (0.9994) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.2052 (0.3098) Acc D Real: 71.688%
Loss D Fake: 0.4657 (0.4694) Acc D Fake: 99.846%
Loss D: 0.671
Loss G: 0.9861 (0.9993) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.1906 (0.3090) Acc D Real: 71.762%
Loss D Fake: 0.4950 (0.4696) Acc D Fake: 99.847%
Loss D: 0.686
Loss G: 0.9325 (0.9988) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.2897 (0.3089) Acc D Real: 71.763%
Loss D Fake: 0.5154 (0.4699) Acc D Fake: 99.848%
Loss D: 0.805
Loss G: 0.9119 (0.9983) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3390 (0.3091) Acc D Real: 71.720%
Loss D Fake: 0.5254 (0.4703) Acc D Fake: 99.849%
Loss D: 0.864
Loss G: 0.9002 (0.9976) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.2372 (0.3086) Acc D Real: 71.764%
Loss D Fake: 0.5313 (0.4707) Acc D Fake: 99.850%
Loss D: 0.769
Loss G: 0.8935 (0.9969) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3782 (0.3091) Acc D Real: 71.679%
Loss D Fake: 0.5349 (0.4711) Acc D Fake: 99.851%
Loss D: 0.913
Loss G: 0.8891 (0.9962) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3868 (0.3096) Acc D Real: 71.599%
Loss D Fake: 0.5374 (0.4715) Acc D Fake: 99.852%
Loss D: 0.924
Loss G: 0.8860 (0.9955) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.2620 (0.3093) Acc D Real: 71.624%
Loss D Fake: 0.5391 (0.4720) Acc D Fake: 99.853%
Loss D: 0.801
Loss G: 0.8844 (0.9948) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4110 (0.3099) Acc D Real: 71.531%
Loss D Fake: 0.5398 (0.4724) Acc D Fake: 99.854%
Loss D: 0.951
Loss G: 0.8834 (0.9941) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4761 (0.3110) Acc D Real: 71.407%
Loss D Fake: 0.5404 (0.4728) Acc D Fake: 99.855%
Loss D: 1.016
Loss G: 0.8828 (0.9934) Acc G: 0.011%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.4679 (0.3120) Acc D Real: 71.393%
Loss D Fake: 0.5408 (0.4733) Acc D Fake: 99.855%
Loss D: 1.009
Loss G: 0.8820 (0.9927) Acc G: 0.011%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.595 | Generator Loss: 0.882 | Avg: 1.477
TEST [21/180]: Discriminator Loss: 0.653 | Generator Loss: 0.882 | Avg: 1.535
TEST [31/180]: Discriminator Loss: 0.638 | Generator Loss: 0.882 | Avg: 1.520
TEST [41/180]: Discriminator Loss: 0.624 | Generator Loss: 0.882 | Avg: 1.506
TEST [51/180]: Discriminator Loss: 0.621 | Generator Loss: 0.882 | Avg: 1.503
TEST [61/180]: Discriminator Loss: 0.691 | Generator Loss: 0.882 | Avg: 1.573
TEST [71/180]: Discriminator Loss: 0.697 | Generator Loss: 0.882 | Avg: 1.579
TEST [81/180]: Discriminator Loss: 0.754 | Generator Loss: 0.882 | Avg: 1.636
TEST [91/180]: Discriminator Loss: 0.774 | Generator Loss: 0.882 | Avg: 1.656
TEST [101/180]: Discriminator Loss: 0.839 | Generator Loss: 0.882 | Avg: 1.720
TEST [111/180]: Discriminator Loss: 0.879 | Generator Loss: 0.882 | Avg: 1.761
TEST [121/180]: Discriminator Loss: 0.921 | Generator Loss: 0.882 | Avg: 1.802
TEST [131/180]: Discriminator Loss: 0.957 | Generator Loss: 0.882 | Avg: 1.838
TEST [141/180]: Discriminator Loss: 0.966 | Generator Loss: 0.882 | Avg: 1.848
TEST [151/180]: Discriminator Loss: 0.944 | Generator Loss: 0.882 | Avg: 1.826
TEST [161/180]: Discriminator Loss: 0.925 | Generator Loss: 0.882 | Avg: 1.807
TEST [171/180]: Discriminator Loss: 0.907 | Generator Loss: 0.882 | Avg: 1.789
Epoch: 5/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4209 (0.4733) Acc D Real: 50.417%
Loss D Fake: 0.5422 (0.5418) Acc D Fake: 100.000%
Loss D: 0.963
Loss G: 0.8796 (0.8803) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.5121 (0.4862) Acc D Real: 49.306%
Loss D Fake: 0.5432 (0.5423) Acc D Fake: 100.000%
Loss D: 1.055
Loss G: 0.8783 (0.8796) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2773 (0.4340) Acc D Real: 55.404%
Loss D Fake: 0.5438 (0.5427) Acc D Fake: 100.000%
Loss D: 0.821
Loss G: 0.8779 (0.8792) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3461 (0.4164) Acc D Real: 57.250%
Loss D Fake: 0.5437 (0.5429) Acc D Fake: 100.000%
Loss D: 0.890
Loss G: 0.8782 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3493 (0.4052) Acc D Real: 58.411%
Loss D Fake: 0.5433 (0.5429) Acc D Fake: 100.000%
Loss D: 0.893
Loss G: 0.8787 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3799 (0.4016) Acc D Real: 58.698%
Loss D Fake: 0.5428 (0.5429) Acc D Fake: 100.000%
Loss D: 0.923
Loss G: 0.8792 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.5276 (0.4173) Acc D Real: 56.855%
Loss D Fake: 0.5425 (0.5429) Acc D Fake: 100.000%
Loss D: 1.070
Loss G: 0.8793 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3850 (0.4138) Acc D Real: 57.193%
Loss D Fake: 0.5425 (0.5428) Acc D Fake: 100.000%
Loss D: 0.928
Loss G: 0.8790 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4368 (0.4161) Acc D Real: 56.990%
Loss D Fake: 0.5427 (0.5428) Acc D Fake: 100.000%
Loss D: 0.980
Loss G: 0.8788 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3667 (0.4116) Acc D Real: 57.727%
Loss D Fake: 0.5425 (0.5428) Acc D Fake: 100.000%
Loss D: 0.909
Loss G: 0.8792 (0.8790) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4265 (0.4128) Acc D Real: 57.552%
Loss D Fake: 0.5420 (0.5427) Acc D Fake: 100.000%
Loss D: 0.969
Loss G: 0.8800 (0.8791) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3731 (0.4098) Acc D Real: 57.953%
Loss D Fake: 0.5413 (0.5426) Acc D Fake: 100.000%
Loss D: 0.914
Loss G: 0.8808 (0.8792) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4854 (0.4152) Acc D Real: 57.370%
Loss D Fake: 0.5407 (0.5425) Acc D Fake: 100.000%
Loss D: 1.026
Loss G: 0.8817 (0.8794) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4336 (0.4164) Acc D Real: 57.205%
Loss D Fake: 0.5399 (0.5423) Acc D Fake: 100.000%
Loss D: 0.974
Loss G: 0.8826 (0.8796) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4670 (0.4196) Acc D Real: 56.908%
Loss D Fake: 0.5391 (0.5421) Acc D Fake: 100.000%
Loss D: 1.006
Loss G: 0.8837 (0.8799) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.5365 (0.4264) Acc D Real: 56.057%
Loss D Fake: 0.5384 (0.5419) Acc D Fake: 100.000%
Loss D: 1.075
Loss G: 0.8842 (0.8801) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.4192 (0.4260) Acc D Real: 56.134%
Loss D Fake: 0.5380 (0.5417) Acc D Fake: 100.000%
Loss D: 0.957
Loss G: 0.8847 (0.8804) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3251 (0.4207) Acc D Real: 56.790%
Loss D Fake: 0.5375 (0.5414) Acc D Fake: 100.000%
Loss D: 0.863
Loss G: 0.8856 (0.8807) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3798 (0.4187) Acc D Real: 57.036%
Loss D Fake: 0.5366 (0.5412) Acc D Fake: 100.000%
Loss D: 0.916
Loss G: 0.8868 (0.8810) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.5011 (0.4226) Acc D Real: 56.657%
Loss D Fake: 0.5356 (0.5409) Acc D Fake: 100.000%
Loss D: 1.037
Loss G: 0.8882 (0.8813) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.4640 (0.4245) Acc D Real: 56.409%
Loss D Fake: 0.5345 (0.5406) Acc D Fake: 100.000%
Loss D: 0.999
Loss G: 0.8894 (0.8817) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4616 (0.4261) Acc D Real: 56.205%
Loss D Fake: 0.5338 (0.5403) Acc D Fake: 100.000%
Loss D: 0.995
Loss G: 0.8902 (0.8821) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.4328 (0.4264) Acc D Real: 56.189%
Loss D Fake: 0.5332 (0.5400) Acc D Fake: 100.000%
Loss D: 0.966
Loss G: 0.8909 (0.8824) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4440 (0.4271) Acc D Real: 56.177%
Loss D Fake: 0.5327 (0.5398) Acc D Fake: 100.000%
Loss D: 0.977
Loss G: 0.8915 (0.8828) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3770 (0.4252) Acc D Real: 56.372%
Loss D Fake: 0.5322 (0.5395) Acc D Fake: 100.000%
Loss D: 0.909
Loss G: 0.8921 (0.8831) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4422 (0.4258) Acc D Real: 56.283%
Loss D Fake: 0.5317 (0.5392) Acc D Fake: 100.000%
Loss D: 0.974
Loss G: 0.8926 (0.8835) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.5258 (0.4294) Acc D Real: 55.956%
Loss D Fake: 0.5313 (0.5389) Acc D Fake: 100.000%
Loss D: 1.057
Loss G: 0.8932 (0.8838) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3800 (0.4277) Acc D Real: 56.223%
Loss D Fake: 0.5307 (0.5386) Acc D Fake: 100.000%
Loss D: 0.911
Loss G: 0.8942 (0.8842) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3973 (0.4266) Acc D Real: 56.328%
Loss D Fake: 0.5299 (0.5383) Acc D Fake: 100.000%
Loss D: 0.927
Loss G: 0.8952 (0.8846) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.4892 (0.4287) Acc D Real: 56.129%
Loss D Fake: 0.5291 (0.5380) Acc D Fake: 100.000%
Loss D: 1.018
Loss G: 0.8963 (0.8849) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.4685 (0.4299) Acc D Real: 56.009%
Loss D Fake: 0.5284 (0.5377) Acc D Fake: 100.000%
Loss D: 0.997
Loss G: 0.8972 (0.8853) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4733 (0.4312) Acc D Real: 55.870%
Loss D Fake: 0.5278 (0.5374) Acc D Fake: 100.000%
Loss D: 1.001
Loss G: 0.8977 (0.8857) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3632 (0.4292) Acc D Real: 56.115%
Loss D Fake: 0.5274 (0.5371) Acc D Fake: 100.000%
Loss D: 0.891
Loss G: 0.8983 (0.8861) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.4200 (0.4290) Acc D Real: 56.124%
Loss D Fake: 0.5270 (0.5368) Acc D Fake: 100.000%
Loss D: 0.947
Loss G: 0.8987 (0.8864) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.4724 (0.4302) Acc D Real: 56.060%
Loss D Fake: 0.5266 (0.5366) Acc D Fake: 100.000%
Loss D: 0.999
Loss G: 0.8995 (0.8868) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.5007 (0.4321) Acc D Real: 55.892%
Loss D Fake: 0.5259 (0.5363) Acc D Fake: 100.000%
Loss D: 1.027
Loss G: 0.9005 (0.8872) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3939 (0.4311) Acc D Real: 55.999%
Loss D Fake: 0.5251 (0.5360) Acc D Fake: 100.000%
Loss D: 0.919
Loss G: 0.9016 (0.8875) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.4614 (0.4318) Acc D Real: 55.893%
Loss D Fake: 0.5244 (0.5357) Acc D Fake: 100.000%
Loss D: 0.986
Loss G: 0.9024 (0.8879) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3956 (0.4309) Acc D Real: 55.975%
Loss D Fake: 0.5240 (0.5354) Acc D Fake: 100.000%
Loss D: 0.920
Loss G: 0.9029 (0.8883) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3970 (0.4301) Acc D Real: 56.104%
Loss D Fake: 0.5236 (0.5351) Acc D Fake: 100.000%
Loss D: 0.921
Loss G: 0.9036 (0.8887) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.2591 (0.4260) Acc D Real: 56.586%
Loss D Fake: 0.5228 (0.5348) Acc D Fake: 100.000%
Loss D: 0.782
Loss G: 0.9052 (0.8891) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3798 (0.4250) Acc D Real: 56.710%
Loss D Fake: 0.5216 (0.5345) Acc D Fake: 100.000%
Loss D: 0.901
Loss G: 0.9068 (0.8895) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3733 (0.4238) Acc D Real: 56.870%
Loss D Fake: 0.5204 (0.5342) Acc D Fake: 100.000%
Loss D: 0.894
Loss G: 0.9086 (0.8899) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4974 (0.4254) Acc D Real: 56.716%
Loss D Fake: 0.5192 (0.5338) Acc D Fake: 100.000%
Loss D: 1.017
Loss G: 0.9103 (0.8904) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4137 (0.4252) Acc D Real: 56.752%
Loss D Fake: 0.5180 (0.5335) Acc D Fake: 100.000%
Loss D: 0.932
Loss G: 0.9118 (0.8908) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3433 (0.4234) Acc D Real: 56.989%
Loss D Fake: 0.5170 (0.5331) Acc D Fake: 100.000%
Loss D: 0.860
Loss G: 0.9134 (0.8913) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3331 (0.4215) Acc D Real: 57.241%
Loss D Fake: 0.5157 (0.5328) Acc D Fake: 100.000%
Loss D: 0.849
Loss G: 0.9154 (0.8918) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3607 (0.4203) Acc D Real: 57.388%
Loss D Fake: 0.5144 (0.5324) Acc D Fake: 100.000%
Loss D: 0.875
Loss G: 0.9173 (0.8923) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3656 (0.4192) Acc D Real: 57.509%
Loss D Fake: 0.5132 (0.5320) Acc D Fake: 100.000%
Loss D: 0.879
Loss G: 0.9188 (0.8929) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4492 (0.4198) Acc D Real: 57.453%
Loss D Fake: 0.5123 (0.5316) Acc D Fake: 100.000%
Loss D: 0.961
Loss G: 0.9200 (0.8934) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4799 (0.4210) Acc D Real: 57.320%
Loss D Fake: 0.5117 (0.5313) Acc D Fake: 100.000%
Loss D: 0.992
Loss G: 0.9204 (0.8939) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4701 (0.4219) Acc D Real: 57.238%
Loss D Fake: 0.5115 (0.5309) Acc D Fake: 100.000%
Loss D: 0.982
Loss G: 0.9208 (0.8944) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3917 (0.4213) Acc D Real: 57.304%
Loss D Fake: 0.5112 (0.5305) Acc D Fake: 100.000%
Loss D: 0.903
Loss G: 0.9212 (0.8949) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.4096 (0.4211) Acc D Real: 57.356%
Loss D Fake: 0.5108 (0.5302) Acc D Fake: 100.000%
Loss D: 0.920
Loss G: 0.9219 (0.8954) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3150 (0.4192) Acc D Real: 57.600%
Loss D Fake: 0.5101 (0.5298) Acc D Fake: 100.000%
Loss D: 0.825
Loss G: 0.9235 (0.8959) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.4882 (0.4204) Acc D Real: 57.483%
Loss D Fake: 0.5091 (0.5294) Acc D Fake: 100.000%
Loss D: 0.997
Loss G: 0.9246 (0.8964) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.4242 (0.4205) Acc D Real: 57.504%
Loss D Fake: 0.5085 (0.5291) Acc D Fake: 100.000%
Loss D: 0.933
Loss G: 0.9254 (0.8969) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4152 (0.4204) Acc D Real: 57.542%
Loss D Fake: 0.5080 (0.5287) Acc D Fake: 100.000%
Loss D: 0.923
Loss G: 0.9260 (0.8974) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.4906 (0.4216) Acc D Real: 57.451%
Loss D Fake: 0.5076 (0.5284) Acc D Fake: 100.000%
Loss D: 0.998
Loss G: 0.9266 (0.8979) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3394 (0.4202) Acc D Real: 57.628%
Loss D Fake: 0.5071 (0.5280) Acc D Fake: 100.000%
Loss D: 0.847
Loss G: 0.9277 (0.8984) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.4744 (0.4211) Acc D Real: 57.546%
Loss D Fake: 0.5063 (0.5277) Acc D Fake: 100.000%
Loss D: 0.981
Loss G: 0.9288 (0.8989) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3996 (0.4208) Acc D Real: 57.608%
Loss D Fake: 0.5054 (0.5273) Acc D Fake: 100.000%
Loss D: 0.905
Loss G: 0.9304 (0.8994) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.4994 (0.4220) Acc D Real: 57.513%
Loss D Fake: 0.5043 (0.5270) Acc D Fake: 100.000%
Loss D: 1.004
Loss G: 0.9319 (0.8999) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4139 (0.4219) Acc D Real: 57.572%
Loss D Fake: 0.5034 (0.5266) Acc D Fake: 100.000%
Loss D: 0.917
Loss G: 0.9333 (0.9004) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.4261 (0.4219) Acc D Real: 57.570%
Loss D Fake: 0.5026 (0.5262) Acc D Fake: 100.000%
Loss D: 0.929
Loss G: 0.9343 (0.9009) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3583 (0.4210) Acc D Real: 57.704%
Loss D Fake: 0.5020 (0.5259) Acc D Fake: 100.000%
Loss D: 0.860
Loss G: 0.9354 (0.9014) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4104 (0.4208) Acc D Real: 57.755%
Loss D Fake: 0.5012 (0.5255) Acc D Fake: 100.000%
Loss D: 0.912
Loss G: 0.9367 (0.9019) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3326 (0.4195) Acc D Real: 57.917%
Loss D Fake: 0.5002 (0.5251) Acc D Fake: 100.000%
Loss D: 0.833
Loss G: 0.9382 (0.9025) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3718 (0.4189) Acc D Real: 57.999%
Loss D Fake: 0.4992 (0.5248) Acc D Fake: 100.000%
Loss D: 0.871
Loss G: 0.9398 (0.9030) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4641 (0.4195) Acc D Real: 57.939%
Loss D Fake: 0.4983 (0.5244) Acc D Fake: 100.000%
Loss D: 0.962
Loss G: 0.9410 (0.9035) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3884 (0.4191) Acc D Real: 58.002%
Loss D Fake: 0.4976 (0.5240) Acc D Fake: 100.000%
Loss D: 0.886
Loss G: 0.9422 (0.9041) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3873 (0.4186) Acc D Real: 58.057%
Loss D Fake: 0.4968 (0.5237) Acc D Fake: 100.000%
Loss D: 0.884
Loss G: 0.9432 (0.9046) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3309 (0.4174) Acc D Real: 58.207%
Loss D Fake: 0.4961 (0.5233) Acc D Fake: 100.000%
Loss D: 0.827
Loss G: 0.9446 (0.9052) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3724 (0.4168) Acc D Real: 58.310%
Loss D Fake: 0.4951 (0.5229) Acc D Fake: 100.000%
Loss D: 0.868
Loss G: 0.9465 (0.9057) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3684 (0.4162) Acc D Real: 58.405%
Loss D Fake: 0.4938 (0.5225) Acc D Fake: 100.000%
Loss D: 0.862
Loss G: 0.9487 (0.9063) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.5599 (0.4181) Acc D Real: 58.208%
Loss D Fake: 0.4926 (0.5221) Acc D Fake: 100.000%
Loss D: 1.052
Loss G: 0.9499 (0.9068) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.5646 (0.4200) Acc D Real: 58.022%
Loss D Fake: 0.4921 (0.5217) Acc D Fake: 100.000%
Loss D: 1.057
Loss G: 0.9503 (0.9074) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.2909 (0.4183) Acc D Real: 58.215%
Loss D Fake: 0.4919 (0.5214) Acc D Fake: 100.000%
Loss D: 0.783
Loss G: 0.9512 (0.9079) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3445 (0.4174) Acc D Real: 58.342%
Loss D Fake: 0.4911 (0.5210) Acc D Fake: 100.000%
Loss D: 0.836
Loss G: 0.9526 (0.9085) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4089 (0.4173) Acc D Real: 58.376%
Loss D Fake: 0.4902 (0.5206) Acc D Fake: 100.000%
Loss D: 0.899
Loss G: 0.9539 (0.9091) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4761 (0.4180) Acc D Real: 58.314%
Loss D Fake: 0.4896 (0.5202) Acc D Fake: 100.000%
Loss D: 0.966
Loss G: 0.9546 (0.9096) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3777 (0.4175) Acc D Real: 58.384%
Loss D Fake: 0.4892 (0.5199) Acc D Fake: 100.000%
Loss D: 0.867
Loss G: 0.9554 (0.9102) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4023 (0.4173) Acc D Real: 58.408%
Loss D Fake: 0.4887 (0.5195) Acc D Fake: 100.000%
Loss D: 0.891
Loss G: 0.9561 (0.9107) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3972 (0.4171) Acc D Real: 58.456%
Loss D Fake: 0.4882 (0.5191) Acc D Fake: 100.000%
Loss D: 0.885
Loss G: 0.9570 (0.9113) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4332 (0.4173) Acc D Real: 58.442%
Loss D Fake: 0.4877 (0.5188) Acc D Fake: 100.000%
Loss D: 0.921
Loss G: 0.9574 (0.9118) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3750 (0.4168) Acc D Real: 58.505%
Loss D Fake: 0.4876 (0.5184) Acc D Fake: 100.000%
Loss D: 0.863
Loss G: 0.9578 (0.9123) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.5121 (0.4179) Acc D Real: 58.411%
Loss D Fake: 0.4874 (0.5180) Acc D Fake: 100.000%
Loss D: 0.999
Loss G: 0.9580 (0.9128) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.2872 (0.4164) Acc D Real: 58.599%
Loss D Fake: 0.4871 (0.5177) Acc D Fake: 100.000%
Loss D: 0.774
Loss G: 0.9589 (0.9134) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3278 (0.4154) Acc D Real: 58.725%
Loss D Fake: 0.4864 (0.5173) Acc D Fake: 100.000%
Loss D: 0.814
Loss G: 0.9602 (0.9139) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3034 (0.4142) Acc D Real: 58.870%
Loss D Fake: 0.4855 (0.5170) Acc D Fake: 100.000%
Loss D: 0.789
Loss G: 0.9618 (0.9144) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.4648 (0.4148) Acc D Real: 58.836%
Loss D Fake: 0.4846 (0.5166) Acc D Fake: 100.000%
Loss D: 0.949
Loss G: 0.9632 (0.9149) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4444 (0.4151) Acc D Real: 58.823%
Loss D Fake: 0.4839 (0.5163) Acc D Fake: 100.000%
Loss D: 0.928
Loss G: 0.9642 (0.9155) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4022 (0.4149) Acc D Real: 58.843%
Loss D Fake: 0.4833 (0.5159) Acc D Fake: 100.000%
Loss D: 0.886
Loss G: 0.9652 (0.9160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.4665 (0.4155) Acc D Real: 58.792%
Loss D Fake: 0.4828 (0.5156) Acc D Fake: 100.000%
Loss D: 0.949
Loss G: 0.9658 (0.9165) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3566 (0.4149) Acc D Real: 58.877%
Loss D Fake: 0.4825 (0.5152) Acc D Fake: 100.000%
Loss D: 0.839
Loss G: 0.9664 (0.9170) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.4097 (0.4148) Acc D Real: 58.906%
Loss D Fake: 0.4821 (0.5149) Acc D Fake: 100.000%
Loss D: 0.892
Loss G: 0.9669 (0.9176) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3722 (0.4144) Acc D Real: 58.982%
Loss D Fake: 0.4817 (0.5146) Acc D Fake: 100.000%
Loss D: 0.854
Loss G: 0.9678 (0.9181) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.4724 (0.4150) Acc D Real: 58.948%
Loss D Fake: 0.4812 (0.5142) Acc D Fake: 100.000%
Loss D: 0.954
Loss G: 0.9685 (0.9186) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.4497 (0.4153) Acc D Real: 58.923%
Loss D Fake: 0.4809 (0.5139) Acc D Fake: 100.000%
Loss D: 0.931
Loss G: 0.9689 (0.9191) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.5229 (0.4164) Acc D Real: 58.818%
Loss D Fake: 0.4808 (0.5136) Acc D Fake: 100.000%
Loss D: 1.004
Loss G: 0.9685 (0.9196) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4578 (0.4168) Acc D Real: 58.791%
Loss D Fake: 0.4812 (0.5133) Acc D Fake: 100.000%
Loss D: 0.939
Loss G: 0.9677 (0.9200) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2565 (0.4152) Acc D Real: 58.978%
Loss D Fake: 0.4816 (0.5129) Acc D Fake: 100.000%
Loss D: 0.738
Loss G: 0.9675 (0.9205) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.6553 (0.4175) Acc D Real: 58.749%
Loss D Fake: 0.4818 (0.5126) Acc D Fake: 100.000%
Loss D: 1.137
Loss G: 0.9666 (0.9209) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3765 (0.4171) Acc D Real: 58.816%
Loss D Fake: 0.4825 (0.5124) Acc D Fake: 100.000%
Loss D: 0.859
Loss G: 0.9657 (0.9214) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4811 (0.4177) Acc D Real: 58.755%
Loss D Fake: 0.4829 (0.5121) Acc D Fake: 100.000%
Loss D: 0.964
Loss G: 0.9652 (0.9218) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.4527 (0.4181) Acc D Real: 58.738%
Loss D Fake: 0.4831 (0.5118) Acc D Fake: 100.000%
Loss D: 0.936
Loss G: 0.9647 (0.9222) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3152 (0.4171) Acc D Real: 58.859%
Loss D Fake: 0.4833 (0.5115) Acc D Fake: 100.000%
Loss D: 0.798
Loss G: 0.9651 (0.9226) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.5022 (0.4179) Acc D Real: 58.794%
Loss D Fake: 0.4827 (0.5113) Acc D Fake: 100.000%
Loss D: 0.985
Loss G: 0.9668 (0.9230) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4331 (0.4180) Acc D Real: 58.798%
Loss D Fake: 0.4815 (0.5110) Acc D Fake: 100.000%
Loss D: 0.915
Loss G: 0.9687 (0.9234) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.1962 (0.4160) Acc D Real: 59.021%
Loss D Fake: 0.4803 (0.5107) Acc D Fake: 100.000%
Loss D: 0.677
Loss G: 0.9710 (0.9238) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.4595 (0.4164) Acc D Real: 59.000%
Loss D Fake: 0.4789 (0.5105) Acc D Fake: 100.000%
Loss D: 0.938
Loss G: 0.9731 (0.9243) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3866 (0.4162) Acc D Real: 59.047%
Loss D Fake: 0.4778 (0.5102) Acc D Fake: 100.000%
Loss D: 0.864
Loss G: 0.9747 (0.9247) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3926 (0.4160) Acc D Real: 59.083%
Loss D Fake: 0.4769 (0.5099) Acc D Fake: 100.000%
Loss D: 0.870
Loss G: 0.9764 (0.9252) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3745 (0.4156) Acc D Real: 59.136%
Loss D Fake: 0.4758 (0.5096) Acc D Fake: 100.000%
Loss D: 0.850
Loss G: 0.9784 (0.9256) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.4642 (0.4160) Acc D Real: 59.105%
Loss D Fake: 0.4746 (0.5093) Acc D Fake: 100.000%
Loss D: 0.939
Loss G: 0.9804 (0.9261) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.2971 (0.4150) Acc D Real: 59.230%
Loss D Fake: 0.4734 (0.5090) Acc D Fake: 100.000%
Loss D: 0.770
Loss G: 0.9829 (0.9266) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.5379 (0.4160) Acc D Real: 59.134%
Loss D Fake: 0.4720 (0.5087) Acc D Fake: 100.000%
Loss D: 1.010
Loss G: 0.9848 (0.9271) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.4107 (0.4160) Acc D Real: 59.157%
Loss D Fake: 0.4711 (0.5083) Acc D Fake: 100.000%
Loss D: 0.882
Loss G: 0.9864 (0.9276) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.4029 (0.4159) Acc D Real: 59.172%
Loss D Fake: 0.4702 (0.5080) Acc D Fake: 100.000%
Loss D: 0.873
Loss G: 0.9877 (0.9281) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3385 (0.4152) Acc D Real: 59.251%
Loss D Fake: 0.4694 (0.5077) Acc D Fake: 100.000%
Loss D: 0.808
Loss G: 0.9891 (0.9286) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4420 (0.4155) Acc D Real: 59.248%
Loss D Fake: 0.4687 (0.5074) Acc D Fake: 100.000%
Loss D: 0.911
Loss G: 0.9904 (0.9291) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3004 (0.4145) Acc D Real: 59.363%
Loss D Fake: 0.4680 (0.5071) Acc D Fake: 100.000%
Loss D: 0.768
Loss G: 0.9916 (0.9296) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.2933 (0.4136) Acc D Real: 59.480%
Loss D Fake: 0.4672 (0.5067) Acc D Fake: 100.000%
Loss D: 0.760
Loss G: 0.9931 (0.9301) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3788 (0.4133) Acc D Real: 59.521%
Loss D Fake: 0.4664 (0.5064) Acc D Fake: 100.000%
Loss D: 0.845
Loss G: 0.9946 (0.9306) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.5382 (0.4143) Acc D Real: 59.426%
Loss D Fake: 0.4656 (0.5061) Acc D Fake: 100.000%
Loss D: 1.004
Loss G: 0.9954 (0.9312) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4414 (0.4145) Acc D Real: 59.419%
Loss D Fake: 0.4653 (0.5058) Acc D Fake: 100.000%
Loss D: 0.907
Loss G: 0.9959 (0.9317) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.2513 (0.4132) Acc D Real: 59.569%
Loss D Fake: 0.4650 (0.5055) Acc D Fake: 100.000%
Loss D: 0.716
Loss G: 0.9971 (0.9322) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3995 (0.4131) Acc D Real: 59.601%
Loss D Fake: 0.4642 (0.5051) Acc D Fake: 100.000%
Loss D: 0.864
Loss G: 0.9984 (0.9327) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.5013 (0.4138) Acc D Real: 59.538%
Loss D Fake: 0.4636 (0.5048) Acc D Fake: 100.000%
Loss D: 0.965
Loss G: 0.9988 (0.9332) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.4647 (0.4142) Acc D Real: 59.503%
Loss D Fake: 0.4636 (0.5045) Acc D Fake: 100.000%
Loss D: 0.928
Loss G: 0.9989 (0.9337) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3808 (0.4139) Acc D Real: 59.539%
Loss D Fake: 0.4634 (0.5042) Acc D Fake: 100.000%
Loss D: 0.844
Loss G: 0.9995 (0.9342) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.5595 (0.4150) Acc D Real: 59.432%
Loss D Fake: 0.4629 (0.5039) Acc D Fake: 100.000%
Loss D: 1.022
Loss G: 1.0006 (0.9347) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3405 (0.4145) Acc D Real: 59.515%
Loss D Fake: 0.4623 (0.5036) Acc D Fake: 100.000%
Loss D: 0.803
Loss G: 1.0018 (0.9352) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4448 (0.4147) Acc D Real: 59.505%
Loss D Fake: 0.4616 (0.5033) Acc D Fake: 100.000%
Loss D: 0.906
Loss G: 1.0029 (0.9357) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.5326 (0.4155) Acc D Real: 59.427%
Loss D Fake: 0.4611 (0.5029) Acc D Fake: 100.000%
Loss D: 0.994
Loss G: 1.0036 (0.9362) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3963 (0.4154) Acc D Real: 59.455%
Loss D Fake: 0.4608 (0.5026) Acc D Fake: 100.000%
Loss D: 0.857
Loss G: 1.0041 (0.9367) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.2335 (0.4141) Acc D Real: 59.604%
Loss D Fake: 0.4605 (0.5023) Acc D Fake: 100.000%
Loss D: 0.694
Loss G: 1.0051 (0.9372) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3716 (0.4138) Acc D Real: 59.650%
Loss D Fake: 0.4598 (0.5020) Acc D Fake: 100.000%
Loss D: 0.831
Loss G: 1.0065 (0.9377) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3648 (0.4134) Acc D Real: 59.704%
Loss D Fake: 0.4590 (0.5017) Acc D Fake: 100.000%
Loss D: 0.824
Loss G: 1.0080 (0.9382) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3816 (0.4132) Acc D Real: 59.746%
Loss D Fake: 0.4583 (0.5014) Acc D Fake: 100.000%
Loss D: 0.840
Loss G: 1.0089 (0.9387) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4390 (0.4134) Acc D Real: 59.744%
Loss D Fake: 0.4579 (0.5011) Acc D Fake: 100.000%
Loss D: 0.897
Loss G: 1.0096 (0.9392) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4692 (0.4138) Acc D Real: 59.720%
Loss D Fake: 0.4575 (0.5008) Acc D Fake: 100.000%
Loss D: 0.927
Loss G: 1.0103 (0.9397) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.2991 (0.4130) Acc D Real: 59.818%
Loss D Fake: 0.4571 (0.5005) Acc D Fake: 100.000%
Loss D: 0.756
Loss G: 1.0111 (0.9402) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.5042 (0.4136) Acc D Real: 59.761%
Loss D Fake: 0.4568 (0.5002) Acc D Fake: 100.000%
Loss D: 0.961
Loss G: 1.0113 (0.9407) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4265 (0.4137) Acc D Real: 59.773%
Loss D Fake: 0.4568 (0.4999) Acc D Fake: 100.000%
Loss D: 0.883
Loss G: 1.0114 (0.9412) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.4316 (0.4138) Acc D Real: 59.775%
Loss D Fake: 0.4567 (0.4996) Acc D Fake: 100.000%
Loss D: 0.888
Loss G: 1.0115 (0.9416) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3288 (0.4132) Acc D Real: 59.847%
Loss D Fake: 0.4566 (0.4993) Acc D Fake: 100.000%
Loss D: 0.785
Loss G: 1.0119 (0.9421) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3537 (0.4128) Acc D Real: 59.900%
Loss D Fake: 0.4563 (0.4990) Acc D Fake: 100.000%
Loss D: 0.810
Loss G: 1.0125 (0.9426) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.4994 (0.4134) Acc D Real: 59.851%
Loss D Fake: 0.4561 (0.4987) Acc D Fake: 100.000%
Loss D: 0.956
Loss G: 1.0127 (0.9430) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3890 (0.4133) Acc D Real: 59.882%
Loss D Fake: 0.4561 (0.4985) Acc D Fake: 100.000%
Loss D: 0.845
Loss G: 1.0126 (0.9435) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4268 (0.4134) Acc D Real: 59.885%
Loss D Fake: 0.4562 (0.4982) Acc D Fake: 100.000%
Loss D: 0.883
Loss G: 1.0121 (0.9440) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4215 (0.4134) Acc D Real: 59.887%
Loss D Fake: 0.4565 (0.4979) Acc D Fake: 100.000%
Loss D: 0.878
Loss G: 1.0116 (0.9444) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3538 (0.4130) Acc D Real: 59.934%
Loss D Fake: 0.4568 (0.4976) Acc D Fake: 100.000%
Loss D: 0.811
Loss G: 1.0113 (0.9448) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4495 (0.4133) Acc D Real: 59.923%
Loss D Fake: 0.4570 (0.4974) Acc D Fake: 100.000%
Loss D: 0.906
Loss G: 1.0106 (0.9453) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.2873 (0.4124) Acc D Real: 60.017%
Loss D Fake: 0.4573 (0.4971) Acc D Fake: 100.000%
Loss D: 0.745
Loss G: 1.0104 (0.9457) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4211 (0.4125) Acc D Real: 60.017%
Loss D Fake: 0.4572 (0.4969) Acc D Fake: 100.000%
Loss D: 0.878
Loss G: 1.0109 (0.9461) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.3642 (0.4122) Acc D Real: 60.021%
Loss D Fake: 0.4568 (0.4966) Acc D Fake: 100.000%
Loss D: 0.821
Loss G: 1.0122 (0.9465) Acc G: 0.000%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.506 | Generator Loss: 1.012 | Avg: 1.518
TEST [21/180]: Discriminator Loss: 0.556 | Generator Loss: 1.012 | Avg: 1.568
TEST [31/180]: Discriminator Loss: 0.543 | Generator Loss: 1.012 | Avg: 1.555
TEST [41/180]: Discriminator Loss: 0.531 | Generator Loss: 1.012 | Avg: 1.543
TEST [51/180]: Discriminator Loss: 0.528 | Generator Loss: 1.012 | Avg: 1.541
TEST [61/180]: Discriminator Loss: 0.613 | Generator Loss: 1.012 | Avg: 1.625
TEST [71/180]: Discriminator Loss: 0.616 | Generator Loss: 1.012 | Avg: 1.628
TEST [81/180]: Discriminator Loss: 0.675 | Generator Loss: 1.012 | Avg: 1.687
TEST [91/180]: Discriminator Loss: 0.693 | Generator Loss: 1.012 | Avg: 1.706
TEST [101/180]: Discriminator Loss: 0.765 | Generator Loss: 1.012 | Avg: 1.778
TEST [111/180]: Discriminator Loss: 0.809 | Generator Loss: 1.012 | Avg: 1.822
TEST [121/180]: Discriminator Loss: 0.864 | Generator Loss: 1.012 | Avg: 1.876
TEST [131/180]: Discriminator Loss: 0.901 | Generator Loss: 1.012 | Avg: 1.913
TEST [141/180]: Discriminator Loss: 0.909 | Generator Loss: 1.012 | Avg: 1.922
TEST [151/180]: Discriminator Loss: 0.886 | Generator Loss: 1.012 | Avg: 1.898
TEST [161/180]: Discriminator Loss: 0.864 | Generator Loss: 1.012 | Avg: 1.876
TEST [171/180]: Discriminator Loss: 0.844 | Generator Loss: 1.012 | Avg: 1.856
Epoch: 6/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4424 (0.4424) Acc D Real: 58.490%
Loss D Fake: 0.4553 (0.4556) Acc D Fake: 100.000%
Loss D: 0.898
Loss G: 1.0148 (1.0142) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.4752 (0.4533) Acc D Real: 57.153%
Loss D Fake: 0.4547 (0.4553) Acc D Fake: 100.000%
Loss D: 0.930
Loss G: 1.0156 (1.0147) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.4338 (0.4484) Acc D Real: 57.669%
Loss D Fake: 0.4543 (0.4551) Acc D Fake: 100.000%
Loss D: 0.888
Loss G: 1.0164 (1.0151) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3237 (0.4235) Acc D Real: 60.385%
Loss D Fake: 0.4539 (0.4548) Acc D Fake: 100.000%
Loss D: 0.778
Loss G: 1.0172 (1.0155) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.4305 (0.4247) Acc D Real: 60.391%
Loss D Fake: 0.4536 (0.4546) Acc D Fake: 100.000%
Loss D: 0.884
Loss G: 1.0176 (1.0159) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.5462 (0.4420) Acc D Real: 58.862%
Loss D Fake: 0.4535 (0.4545) Acc D Fake: 100.000%
Loss D: 1.000
Loss G: 1.0173 (1.0161) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3948 (0.4361) Acc D Real: 59.460%
Loss D Fake: 0.4538 (0.4544) Acc D Fake: 100.000%
Loss D: 0.849
Loss G: 1.0170 (1.0162) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4516 (0.4378) Acc D Real: 59.363%
Loss D Fake: 0.4540 (0.4543) Acc D Fake: 100.000%
Loss D: 0.906
Loss G: 1.0165 (1.0162) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4056 (0.4346) Acc D Real: 59.740%
Loss D Fake: 0.4543 (0.4543) Acc D Fake: 100.000%
Loss D: 0.860
Loss G: 1.0157 (1.0162) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.4599 (0.4369) Acc D Real: 59.531%
Loss D Fake: 0.4548 (0.4544) Acc D Fake: 100.000%
Loss D: 0.915
Loss G: 1.0145 (1.0160) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4411 (0.4373) Acc D Real: 59.457%
Loss D Fake: 0.4556 (0.4545) Acc D Fake: 100.000%
Loss D: 0.897
Loss G: 1.0132 (1.0158) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3976 (0.4342) Acc D Real: 59.804%
Loss D Fake: 0.4563 (0.4546) Acc D Fake: 100.000%
Loss D: 0.854
Loss G: 1.0120 (1.0155) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.5289 (0.4410) Acc D Real: 59.066%
Loss D Fake: 0.4570 (0.4548) Acc D Fake: 100.000%
Loss D: 0.986
Loss G: 1.0103 (1.0151) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.2628 (0.4291) Acc D Real: 60.323%
Loss D Fake: 0.4579 (0.4550) Acc D Fake: 100.000%
Loss D: 0.721
Loss G: 1.0093 (1.0147) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4228 (0.4287) Acc D Real: 60.312%
Loss D Fake: 0.4582 (0.4552) Acc D Fake: 100.000%
Loss D: 0.881
Loss G: 1.0089 (1.0144) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3948 (0.4267) Acc D Real: 60.527%
Loss D Fake: 0.4584 (0.4554) Acc D Fake: 100.000%
Loss D: 0.853
Loss G: 1.0086 (1.0140) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3552 (0.4227) Acc D Real: 60.859%
Loss D Fake: 0.4586 (0.4556) Acc D Fake: 100.000%
Loss D: 0.814
Loss G: 1.0082 (1.0137) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3995 (0.4215) Acc D Real: 60.962%
Loss D Fake: 0.4588 (0.4557) Acc D Fake: 100.000%
Loss D: 0.858
Loss G: 1.0080 (1.0134) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.4600 (0.4234) Acc D Real: 60.776%
Loss D Fake: 0.4589 (0.4559) Acc D Fake: 100.000%
Loss D: 0.919
Loss G: 1.0077 (1.0131) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3741 (0.4211) Acc D Real: 60.977%
Loss D Fake: 0.4590 (0.4560) Acc D Fake: 100.000%
Loss D: 0.833
Loss G: 1.0078 (1.0129) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3649 (0.4185) Acc D Real: 61.219%
Loss D Fake: 0.4588 (0.4562) Acc D Fake: 100.000%
Loss D: 0.824
Loss G: 1.0084 (1.0127) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3039 (0.4135) Acc D Real: 61.825%
Loss D Fake: 0.4584 (0.4563) Acc D Fake: 100.000%
Loss D: 0.762
Loss G: 1.0095 (1.0125) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3839 (0.4123) Acc D Real: 61.940%
Loss D Fake: 0.4578 (0.4563) Acc D Fake: 100.000%
Loss D: 0.842
Loss G: 1.0106 (1.0124) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.5001 (0.4158) Acc D Real: 61.577%
Loss D Fake: 0.4572 (0.4564) Acc D Fake: 100.000%
Loss D: 0.957
Loss G: 1.0113 (1.0124) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3954 (0.4150) Acc D Real: 61.679%
Loss D Fake: 0.4570 (0.4564) Acc D Fake: 100.000%
Loss D: 0.852
Loss G: 1.0116 (1.0124) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4146 (0.4150) Acc D Real: 61.651%
Loss D Fake: 0.4568 (0.4564) Acc D Fake: 100.000%
Loss D: 0.871
Loss G: 1.0119 (1.0123) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4532 (0.4164) Acc D Real: 61.483%
Loss D Fake: 0.4567 (0.4564) Acc D Fake: 100.000%
Loss D: 0.910
Loss G: 1.0122 (1.0123) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.2720 (0.4114) Acc D Real: 62.010%
Loss D Fake: 0.4565 (0.4564) Acc D Fake: 100.000%
Loss D: 0.729
Loss G: 1.0126 (1.0123) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3799 (0.4104) Acc D Real: 62.087%
Loss D Fake: 0.4563 (0.4564) Acc D Fake: 100.000%
Loss D: 0.836
Loss G: 1.0132 (1.0124) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.2719 (0.4059) Acc D Real: 62.544%
Loss D Fake: 0.4559 (0.4564) Acc D Fake: 100.000%
Loss D: 0.728
Loss G: 1.0141 (1.0124) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.5178 (0.4094) Acc D Real: 62.215%
Loss D Fake: 0.4554 (0.4564) Acc D Fake: 100.000%
Loss D: 0.973
Loss G: 1.0147 (1.0125) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4679 (0.4112) Acc D Real: 62.025%
Loss D Fake: 0.4552 (0.4563) Acc D Fake: 100.000%
Loss D: 0.923
Loss G: 1.0150 (1.0126) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.1279 (0.4028) Acc D Real: 62.917%
Loss D Fake: 0.4549 (0.4563) Acc D Fake: 100.000%
Loss D: 0.583
Loss G: 1.0161 (1.0127) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3065 (0.4001) Acc D Real: 63.205%
Loss D Fake: 0.4542 (0.4562) Acc D Fake: 100.000%
Loss D: 0.761
Loss G: 1.0176 (1.0128) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.5642 (0.4046) Acc D Real: 62.713%
Loss D Fake: 0.4535 (0.4562) Acc D Fake: 100.000%
Loss D: 1.018
Loss G: 1.0185 (1.0130) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3912 (0.4043) Acc D Real: 62.739%
Loss D Fake: 0.4531 (0.4561) Acc D Fake: 100.000%
Loss D: 0.844
Loss G: 1.0194 (1.0132) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3663 (0.4033) Acc D Real: 62.834%
Loss D Fake: 0.4525 (0.4560) Acc D Fake: 100.000%
Loss D: 0.819
Loss G: 1.0206 (1.0134) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.5170 (0.4062) Acc D Real: 62.519%
Loss D Fake: 0.4520 (0.4559) Acc D Fake: 100.000%
Loss D: 0.969
Loss G: 1.0212 (1.0136) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3739 (0.4054) Acc D Real: 62.617%
Loss D Fake: 0.4517 (0.4558) Acc D Fake: 100.000%
Loss D: 0.826
Loss G: 1.0218 (1.0138) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4581 (0.4067) Acc D Real: 62.497%
Loss D Fake: 0.4515 (0.4557) Acc D Fake: 100.000%
Loss D: 0.910
Loss G: 1.0222 (1.0140) Acc G: 0.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4059 (0.4066) Acc D Real: 62.521%
Loss D Fake: 0.4513 (0.4556) Acc D Fake: 100.000%
Loss D: 0.857
Loss G: 1.0227 (1.0142) Acc G: 0.040%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.4479 (0.4076) Acc D Real: 62.402%
Loss D Fake: 0.4509 (0.4555) Acc D Fake: 99.961%
Loss D: 0.899
Loss G: 1.0237 (1.0144) Acc G: 0.078%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3377 (0.4060) Acc D Real: 62.577%
Loss D Fake: 0.4502 (0.4553) Acc D Fake: 99.924%
Loss D: 0.788
Loss G: 1.0256 (1.0146) Acc G: 0.114%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4346 (0.4067) Acc D Real: 62.477%
Loss D Fake: 0.4490 (0.4552) Acc D Fake: 99.889%
Loss D: 0.884
Loss G: 1.0287 (1.0150) Acc G: 0.148%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4855 (0.4084) Acc D Real: 62.275%
Loss D Fake: 0.4471 (0.4550) Acc D Fake: 99.819%
Loss D: 0.933
Loss G: 1.0325 (1.0153) Acc G: 0.217%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.4528 (0.4093) Acc D Real: 62.160%
Loss D Fake: 0.4451 (0.4548) Acc D Fake: 99.752%
Loss D: 0.898
Loss G: 1.0362 (1.0158) Acc G: 0.284%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.4487 (0.4101) Acc D Real: 62.067%
Loss D Fake: 0.4433 (0.4546) Acc D Fake: 99.688%
Loss D: 0.892
Loss G: 1.0388 (1.0163) Acc G: 0.347%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.4840 (0.4116) Acc D Real: 61.880%
Loss D Fake: 0.4424 (0.4543) Acc D Fake: 99.626%
Loss D: 0.926
Loss G: 1.0398 (1.0167) Acc G: 0.408%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3388 (0.4102) Acc D Real: 62.033%
Loss D Fake: 0.4421 (0.4541) Acc D Fake: 99.567%
Loss D: 0.781
Loss G: 1.0402 (1.0172) Acc G: 0.467%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4001 (0.4100) Acc D Real: 62.042%
Loss D Fake: 0.4421 (0.4538) Acc D Fake: 99.510%
Loss D: 0.842
Loss G: 1.0402 (1.0177) Acc G: 0.523%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4325 (0.4104) Acc D Real: 61.988%
Loss D Fake: 0.4422 (0.4536) Acc D Fake: 99.455%
Loss D: 0.875
Loss G: 1.0399 (1.0181) Acc G: 0.577%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4908 (0.4119) Acc D Real: 61.825%
Loss D Fake: 0.4424 (0.4534) Acc D Fake: 99.403%
Loss D: 0.933
Loss G: 1.0395 (1.0185) Acc G: 0.629%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.4044 (0.4118) Acc D Real: 61.851%
Loss D Fake: 0.4427 (0.4532) Acc D Fake: 99.352%
Loss D: 0.847
Loss G: 1.0390 (1.0189) Acc G: 0.679%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.5489 (0.4143) Acc D Real: 61.573%
Loss D Fake: 0.4430 (0.4530) Acc D Fake: 99.303%
Loss D: 0.992
Loss G: 1.0382 (1.0192) Acc G: 0.727%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.4687 (0.4153) Acc D Real: 61.485%
Loss D Fake: 0.4434 (0.4528) Acc D Fake: 99.256%
Loss D: 0.912
Loss G: 1.0373 (1.0196) Acc G: 0.774%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.4751 (0.4163) Acc D Real: 61.385%
Loss D Fake: 0.4440 (0.4527) Acc D Fake: 99.211%
Loss D: 0.919
Loss G: 1.0364 (1.0198) Acc G: 0.819%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.4506 (0.4169) Acc D Real: 61.302%
Loss D Fake: 0.4445 (0.4526) Acc D Fake: 99.167%
Loss D: 0.895
Loss G: 1.0354 (1.0201) Acc G: 0.862%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4161 (0.4169) Acc D Real: 61.299%
Loss D Fake: 0.4450 (0.4524) Acc D Fake: 99.124%
Loss D: 0.861
Loss G: 1.0345 (1.0204) Acc G: 0.904%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.2479 (0.4141) Acc D Real: 61.573%
Loss D Fake: 0.4455 (0.4523) Acc D Fake: 99.083%
Loss D: 0.693
Loss G: 1.0338 (1.0206) Acc G: 0.944%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3707 (0.4134) Acc D Real: 61.650%
Loss D Fake: 0.4458 (0.4522) Acc D Fake: 99.044%
Loss D: 0.817
Loss G: 1.0331 (1.0208) Acc G: 0.984%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3330 (0.4121) Acc D Real: 61.773%
Loss D Fake: 0.4462 (0.4521) Acc D Fake: 99.005%
Loss D: 0.779
Loss G: 1.0325 (1.0210) Acc G: 1.022%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2218 (0.4090) Acc D Real: 62.101%
Loss D Fake: 0.4465 (0.4520) Acc D Fake: 98.968%
Loss D: 0.668
Loss G: 1.0321 (1.0212) Acc G: 1.058%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3454 (0.4080) Acc D Real: 62.198%
Loss D Fake: 0.4467 (0.4519) Acc D Fake: 98.932%
Loss D: 0.792
Loss G: 1.0318 (1.0213) Acc G: 1.094%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3845 (0.4077) Acc D Real: 62.221%
Loss D Fake: 0.4469 (0.4519) Acc D Fake: 98.897%
Loss D: 0.831
Loss G: 1.0313 (1.0215) Acc G: 1.128%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3686 (0.4071) Acc D Real: 62.277%
Loss D Fake: 0.4472 (0.4518) Acc D Fake: 98.864%
Loss D: 0.816
Loss G: 1.0308 (1.0216) Acc G: 1.162%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.4810 (0.4082) Acc D Real: 62.138%
Loss D Fake: 0.4475 (0.4517) Acc D Fake: 98.831%
Loss D: 0.929
Loss G: 1.0302 (1.0217) Acc G: 1.194%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3755 (0.4077) Acc D Real: 62.174%
Loss D Fake: 0.4479 (0.4517) Acc D Fake: 98.799%
Loss D: 0.823
Loss G: 1.0295 (1.0219) Acc G: 1.225%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.4693 (0.4086) Acc D Real: 62.062%
Loss D Fake: 0.4483 (0.4516) Acc D Fake: 98.768%
Loss D: 0.918
Loss G: 1.0287 (1.0220) Acc G: 1.256%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3408 (0.4076) Acc D Real: 62.150%
Loss D Fake: 0.4488 (0.4516) Acc D Fake: 98.738%
Loss D: 0.790
Loss G: 1.0280 (1.0220) Acc G: 1.286%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4139 (0.4077) Acc D Real: 62.128%
Loss D Fake: 0.4492 (0.4515) Acc D Fake: 98.709%
Loss D: 0.863
Loss G: 1.0272 (1.0221) Acc G: 1.315%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.4772 (0.4087) Acc D Real: 61.976%
Loss D Fake: 0.4497 (0.4515) Acc D Fake: 98.681%
Loss D: 0.927
Loss G: 1.0263 (1.0222) Acc G: 1.343%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3508 (0.4079) Acc D Real: 62.040%
Loss D Fake: 0.4502 (0.4515) Acc D Fake: 98.630%
Loss D: 0.801
Loss G: 1.0254 (1.0222) Acc G: 1.393%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3603 (0.4073) Acc D Real: 62.088%
Loss D Fake: 0.4507 (0.4515) Acc D Fake: 98.581%
Loss D: 0.811
Loss G: 1.0246 (1.0223) Acc G: 1.441%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.4021 (0.4072) Acc D Real: 62.071%
Loss D Fake: 0.4511 (0.4515) Acc D Fake: 98.533%
Loss D: 0.853
Loss G: 1.0238 (1.0223) Acc G: 1.489%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3712 (0.4067) Acc D Real: 62.111%
Loss D Fake: 0.4516 (0.4515) Acc D Fake: 98.487%
Loss D: 0.823
Loss G: 1.0230 (1.0223) Acc G: 1.535%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2694 (0.4049) Acc D Real: 62.282%
Loss D Fake: 0.4520 (0.4515) Acc D Fake: 98.442%
Loss D: 0.721
Loss G: 1.0223 (1.0223) Acc G: 1.580%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.4234 (0.4052) Acc D Real: 62.230%
Loss D Fake: 0.4524 (0.4515) Acc D Fake: 98.397%
Loss D: 0.876
Loss G: 1.0215 (1.0223) Acc G: 1.624%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3620 (0.4046) Acc D Real: 62.269%
Loss D Fake: 0.4528 (0.4515) Acc D Fake: 98.354%
Loss D: 0.815
Loss G: 1.0209 (1.0223) Acc G: 1.667%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4404 (0.4051) Acc D Real: 62.164%
Loss D Fake: 0.4532 (0.4515) Acc D Fake: 98.312%
Loss D: 0.894
Loss G: 1.0201 (1.0222) Acc G: 1.708%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3435 (0.4043) Acc D Real: 62.204%
Loss D Fake: 0.4536 (0.4516) Acc D Fake: 98.272%
Loss D: 0.797
Loss G: 1.0194 (1.0222) Acc G: 1.749%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3437 (0.4036) Acc D Real: 62.276%
Loss D Fake: 0.4540 (0.4516) Acc D Fake: 98.232%
Loss D: 0.798
Loss G: 1.0188 (1.0221) Acc G: 1.789%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3448 (0.4029) Acc D Real: 62.327%
Loss D Fake: 0.4544 (0.4516) Acc D Fake: 98.193%
Loss D: 0.799
Loss G: 1.0183 (1.0221) Acc G: 1.827%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3041 (0.4017) Acc D Real: 62.414%
Loss D Fake: 0.4546 (0.4517) Acc D Fake: 98.155%
Loss D: 0.759
Loss G: 1.0179 (1.0221) Acc G: 1.865%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4044 (0.4017) Acc D Real: 62.377%
Loss D Fake: 0.4548 (0.4517) Acc D Fake: 98.118%
Loss D: 0.859
Loss G: 1.0177 (1.0220) Acc G: 1.902%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3165 (0.4007) Acc D Real: 62.452%
Loss D Fake: 0.4550 (0.4517) Acc D Fake: 98.081%
Loss D: 0.771
Loss G: 1.0174 (1.0219) Acc G: 1.938%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3497 (0.4001) Acc D Real: 62.489%
Loss D Fake: 0.4551 (0.4518) Acc D Fake: 98.046%
Loss D: 0.805
Loss G: 1.0172 (1.0219) Acc G: 1.973%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3662 (0.3998) Acc D Real: 62.507%
Loss D Fake: 0.4553 (0.4518) Acc D Fake: 98.011%
Loss D: 0.821
Loss G: 1.0170 (1.0218) Acc G: 2.008%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4186 (0.4000) Acc D Real: 62.451%
Loss D Fake: 0.4554 (0.4519) Acc D Fake: 97.978%
Loss D: 0.874
Loss G: 1.0166 (1.0218) Acc G: 2.041%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.2225 (0.3980) Acc D Real: 62.643%
Loss D Fake: 0.4557 (0.4519) Acc D Fake: 97.944%
Loss D: 0.678
Loss G: 1.0162 (1.0217) Acc G: 2.074%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.2580 (0.3965) Acc D Real: 62.774%
Loss D Fake: 0.4559 (0.4519) Acc D Fake: 97.912%
Loss D: 0.714
Loss G: 1.0161 (1.0217) Acc G: 2.106%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.5183 (0.3978) Acc D Real: 62.543%
Loss D Fake: 0.4560 (0.4520) Acc D Fake: 97.880%
Loss D: 0.974
Loss G: 1.0155 (1.0216) Acc G: 2.138%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4147 (0.3980) Acc D Real: 62.498%
Loss D Fake: 0.4565 (0.4520) Acc D Fake: 97.849%
Loss D: 0.871
Loss G: 1.0147 (1.0215) Acc G: 2.168%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.2245 (0.3961) Acc D Real: 62.698%
Loss D Fake: 0.4569 (0.4521) Acc D Fake: 97.819%
Loss D: 0.681
Loss G: 1.0143 (1.0214) Acc G: 2.199%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3669 (0.3958) Acc D Real: 62.711%
Loss D Fake: 0.4571 (0.4521) Acc D Fake: 97.789%
Loss D: 0.824
Loss G: 1.0139 (1.0214) Acc G: 2.228%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.2687 (0.3945) Acc D Real: 62.841%
Loss D Fake: 0.4573 (0.4522) Acc D Fake: 97.760%
Loss D: 0.726
Loss G: 1.0138 (1.0213) Acc G: 2.257%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.5208 (0.3958) Acc D Real: 62.649%
Loss D Fake: 0.4574 (0.4522) Acc D Fake: 97.732%
Loss D: 0.978
Loss G: 1.0134 (1.0212) Acc G: 2.285%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3530 (0.3953) Acc D Real: 62.658%
Loss D Fake: 0.4577 (0.4523) Acc D Fake: 97.704%
Loss D: 0.811
Loss G: 1.0130 (1.0211) Acc G: 2.313%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3136 (0.3945) Acc D Real: 62.721%
Loss D Fake: 0.4579 (0.4524) Acc D Fake: 97.677%
Loss D: 0.771
Loss G: 1.0128 (1.0210) Acc G: 2.340%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3554 (0.3941) Acc D Real: 62.742%
Loss D Fake: 0.4580 (0.4524) Acc D Fake: 97.650%
Loss D: 0.813
Loss G: 1.0126 (1.0209) Acc G: 2.367%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3736 (0.3939) Acc D Real: 62.748%
Loss D Fake: 0.4582 (0.4525) Acc D Fake: 97.624%
Loss D: 0.832
Loss G: 1.0123 (1.0209) Acc G: 2.393%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4293 (0.3943) Acc D Real: 62.689%
Loss D Fake: 0.4585 (0.4525) Acc D Fake: 97.598%
Loss D: 0.888
Loss G: 1.0115 (1.0208) Acc G: 2.418%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.4232 (0.3946) Acc D Real: 62.645%
Loss D Fake: 0.4590 (0.4526) Acc D Fake: 97.573%
Loss D: 0.882
Loss G: 1.0107 (1.0207) Acc G: 2.443%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3843 (0.3945) Acc D Real: 62.641%
Loss D Fake: 0.4594 (0.4527) Acc D Fake: 97.548%
Loss D: 0.844
Loss G: 1.0100 (1.0206) Acc G: 2.468%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3815 (0.3943) Acc D Real: 62.628%
Loss D Fake: 0.4598 (0.4527) Acc D Fake: 97.524%
Loss D: 0.841
Loss G: 1.0093 (1.0205) Acc G: 2.492%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3947 (0.3943) Acc D Real: 62.629%
Loss D Fake: 0.4603 (0.4528) Acc D Fake: 97.500%
Loss D: 0.855
Loss G: 1.0083 (1.0203) Acc G: 2.516%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3807 (0.3942) Acc D Real: 62.742%
Loss D Fake: 0.4610 (0.4529) Acc D Fake: 97.477%
Loss D: 0.842
Loss G: 1.0071 (1.0202) Acc G: 2.539%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3202 (0.3935) Acc D Real: 62.872%
Loss D Fake: 0.4617 (0.4530) Acc D Fake: 97.454%
Loss D: 0.782
Loss G: 1.0059 (1.0201) Acc G: 2.562%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3915 (0.3935) Acc D Real: 62.970%
Loss D Fake: 0.4624 (0.4530) Acc D Fake: 97.431%
Loss D: 0.854
Loss G: 1.0045 (1.0199) Acc G: 2.591%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3721 (0.3933) Acc D Real: 63.028%
Loss D Fake: 0.4639 (0.4531) Acc D Fake: 97.394%
Loss D: 0.836
Loss G: 0.9981 (1.0197) Acc G: 2.628%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.4477 (0.3938) Acc D Real: 63.063%
Loss D Fake: 0.4707 (0.4533) Acc D Fake: 97.357%
Loss D: 0.918
Loss G: 0.9826 (1.0194) Acc G: 2.664%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3957 (0.3938) Acc D Real: 63.107%
Loss D Fake: 0.4824 (0.4536) Acc D Fake: 97.321%
Loss D: 0.878
Loss G: 0.9778 (1.0190) Acc G: 2.700%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3479 (0.3934) Acc D Real: 63.253%
Loss D Fake: 0.4754 (0.4538) Acc D Fake: 97.286%
Loss D: 0.823
Loss G: 0.9922 (1.0188) Acc G: 2.735%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3796 (0.3933) Acc D Real: 63.374%
Loss D Fake: 0.4670 (0.4539) Acc D Fake: 97.251%
Loss D: 0.847
Loss G: 1.0003 (1.0186) Acc G: 2.770%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.4295 (0.3936) Acc D Real: 63.393%
Loss D Fake: 0.4643 (0.4540) Acc D Fake: 97.217%
Loss D: 0.894
Loss G: 1.0034 (1.0185) Acc G: 2.803%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3144 (0.3929) Acc D Real: 63.524%
Loss D Fake: 0.4632 (0.4540) Acc D Fake: 97.184%
Loss D: 0.778
Loss G: 1.0048 (1.0184) Acc G: 2.837%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.4128 (0.3931) Acc D Real: 63.555%
Loss D Fake: 0.4627 (0.4541) Acc D Fake: 97.151%
Loss D: 0.875
Loss G: 1.0054 (1.0183) Acc G: 2.869%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4745 (0.3938) Acc D Real: 63.524%
Loss D Fake: 0.4625 (0.4542) Acc D Fake: 97.119%
Loss D: 0.937
Loss G: 1.0056 (1.0182) Acc G: 2.902%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3490 (0.3934) Acc D Real: 63.609%
Loss D Fake: 0.4625 (0.4543) Acc D Fake: 97.087%
Loss D: 0.812
Loss G: 1.0056 (1.0181) Acc G: 2.933%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2247 (0.3920) Acc D Real: 63.819%
Loss D Fake: 0.4626 (0.4543) Acc D Fake: 97.056%
Loss D: 0.687
Loss G: 1.0057 (1.0180) Acc G: 2.964%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.2774 (0.3911) Acc D Real: 63.954%
Loss D Fake: 0.4626 (0.4544) Acc D Fake: 97.025%
Loss D: 0.740
Loss G: 1.0057 (1.0179) Acc G: 2.995%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4049 (0.3912) Acc D Real: 63.995%
Loss D Fake: 0.4627 (0.4545) Acc D Fake: 96.995%
Loss D: 0.868
Loss G: 1.0056 (1.0178) Acc G: 3.025%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4271 (0.3915) Acc D Real: 63.983%
Loss D Fake: 0.4628 (0.4545) Acc D Fake: 96.965%
Loss D: 0.890
Loss G: 1.0054 (1.0177) Acc G: 3.055%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3056 (0.3908) Acc D Real: 64.086%
Loss D Fake: 0.4630 (0.4546) Acc D Fake: 96.935%
Loss D: 0.769
Loss G: 1.0050 (1.0176) Acc G: 3.084%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3390 (0.3904) Acc D Real: 64.183%
Loss D Fake: 0.4632 (0.4547) Acc D Fake: 96.907%
Loss D: 0.802
Loss G: 1.0047 (1.0175) Acc G: 3.112%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4288 (0.3907) Acc D Real: 64.195%
Loss D Fake: 0.4635 (0.4547) Acc D Fake: 96.878%
Loss D: 0.892
Loss G: 1.0042 (1.0174) Acc G: 3.141%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3952 (0.3907) Acc D Real: 64.220%
Loss D Fake: 0.4638 (0.4548) Acc D Fake: 96.850%
Loss D: 0.859
Loss G: 1.0037 (1.0172) Acc G: 3.168%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3459 (0.3903) Acc D Real: 64.312%
Loss D Fake: 0.4642 (0.4549) Acc D Fake: 96.823%
Loss D: 0.810
Loss G: 1.0031 (1.0171) Acc G: 3.196%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4903 (0.3911) Acc D Real: 64.276%
Loss D Fake: 0.4646 (0.4550) Acc D Fake: 96.796%
Loss D: 0.955
Loss G: 1.0023 (1.0170) Acc G: 3.223%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4500 (0.3916) Acc D Real: 64.224%
Loss D Fake: 0.4651 (0.4550) Acc D Fake: 96.769%
Loss D: 0.915
Loss G: 1.0014 (1.0169) Acc G: 3.249%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3272 (0.3911) Acc D Real: 64.319%
Loss D Fake: 0.4656 (0.4551) Acc D Fake: 96.743%
Loss D: 0.793
Loss G: 1.0006 (1.0168) Acc G: 3.275%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4261 (0.3913) Acc D Real: 64.356%
Loss D Fake: 0.4662 (0.4552) Acc D Fake: 96.717%
Loss D: 0.892
Loss G: 0.9997 (1.0166) Acc G: 3.301%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3141 (0.3908) Acc D Real: 64.451%
Loss D Fake: 0.4667 (0.4553) Acc D Fake: 96.692%
Loss D: 0.781
Loss G: 0.9988 (1.0165) Acc G: 3.326%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3663 (0.3906) Acc D Real: 64.524%
Loss D Fake: 0.4672 (0.4554) Acc D Fake: 96.667%
Loss D: 0.834
Loss G: 0.9980 (1.0164) Acc G: 3.351%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.2467 (0.3895) Acc D Real: 64.689%
Loss D Fake: 0.4677 (0.4555) Acc D Fake: 96.642%
Loss D: 0.714
Loss G: 0.9974 (1.0162) Acc G: 3.376%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3412 (0.3892) Acc D Real: 64.785%
Loss D Fake: 0.4681 (0.4556) Acc D Fake: 96.618%
Loss D: 0.809
Loss G: 0.9968 (1.0161) Acc G: 3.400%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.2666 (0.3883) Acc D Real: 64.880%
Loss D Fake: 0.4684 (0.4557) Acc D Fake: 96.594%
Loss D: 0.735
Loss G: 0.9963 (1.0159) Acc G: 3.424%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3291 (0.3878) Acc D Real: 64.959%
Loss D Fake: 0.4687 (0.4557) Acc D Fake: 96.570%
Loss D: 0.798
Loss G: 0.9959 (1.0158) Acc G: 3.447%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3825 (0.3878) Acc D Real: 65.011%
Loss D Fake: 0.4690 (0.4558) Acc D Fake: 96.547%
Loss D: 0.852
Loss G: 0.9954 (1.0157) Acc G: 3.470%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3233 (0.3873) Acc D Real: 65.092%
Loss D Fake: 0.4694 (0.4559) Acc D Fake: 96.524%
Loss D: 0.793
Loss G: 0.9950 (1.0155) Acc G: 3.493%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3457 (0.3870) Acc D Real: 65.189%
Loss D Fake: 0.4697 (0.4560) Acc D Fake: 96.489%
Loss D: 0.815
Loss G: 0.9945 (1.0154) Acc G: 3.528%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.2032 (0.3857) Acc D Real: 65.358%
Loss D Fake: 0.4700 (0.4561) Acc D Fake: 96.455%
Loss D: 0.673
Loss G: 0.9941 (1.0152) Acc G: 3.561%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3647 (0.3856) Acc D Real: 65.404%
Loss D Fake: 0.4703 (0.4562) Acc D Fake: 96.422%
Loss D: 0.835
Loss G: 0.9937 (1.0151) Acc G: 3.595%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3469 (0.3853) Acc D Real: 65.484%
Loss D Fake: 0.4706 (0.4563) Acc D Fake: 96.389%
Loss D: 0.818
Loss G: 0.9932 (1.0149) Acc G: 3.628%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.2109 (0.3841) Acc D Real: 65.613%
Loss D Fake: 0.4710 (0.4564) Acc D Fake: 96.356%
Loss D: 0.682
Loss G: 0.9927 (1.0148) Acc G: 3.660%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.3188 (0.3837) Acc D Real: 65.665%
Loss D Fake: 0.4713 (0.4565) Acc D Fake: 96.324%
Loss D: 0.790
Loss G: 0.9923 (1.0146) Acc G: 3.692%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.2926 (0.3831) Acc D Real: 65.738%
Loss D Fake: 0.4716 (0.4566) Acc D Fake: 96.293%
Loss D: 0.764
Loss G: 0.9920 (1.0144) Acc G: 3.724%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.2165 (0.3819) Acc D Real: 65.872%
Loss D Fake: 0.4718 (0.4567) Acc D Fake: 96.261%
Loss D: 0.688
Loss G: 0.9917 (1.0143) Acc G: 3.755%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.2811 (0.3813) Acc D Real: 65.980%
Loss D Fake: 0.4720 (0.4568) Acc D Fake: 96.230%
Loss D: 0.753
Loss G: 0.9915 (1.0141) Acc G: 3.786%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3131 (0.3808) Acc D Real: 66.070%
Loss D Fake: 0.4723 (0.4569) Acc D Fake: 96.200%
Loss D: 0.785
Loss G: 0.9912 (1.0140) Acc G: 3.816%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3487 (0.3806) Acc D Real: 66.127%
Loss D Fake: 0.4726 (0.4571) Acc D Fake: 96.170%
Loss D: 0.821
Loss G: 0.9907 (1.0138) Acc G: 3.846%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3652 (0.3805) Acc D Real: 66.172%
Loss D Fake: 0.4730 (0.4572) Acc D Fake: 96.140%
Loss D: 0.838
Loss G: 0.9901 (1.0137) Acc G: 3.875%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.2748 (0.3798) Acc D Real: 66.254%
Loss D Fake: 0.4734 (0.4573) Acc D Fake: 96.111%
Loss D: 0.748
Loss G: 0.9895 (1.0135) Acc G: 3.905%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.2890 (0.3792) Acc D Real: 66.338%
Loss D Fake: 0.4739 (0.4574) Acc D Fake: 96.082%
Loss D: 0.763
Loss G: 0.9889 (1.0134) Acc G: 3.933%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4018 (0.3794) Acc D Real: 66.343%
Loss D Fake: 0.4743 (0.4575) Acc D Fake: 96.054%
Loss D: 0.876
Loss G: 0.9882 (1.0132) Acc G: 3.962%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.3253 (0.3790) Acc D Real: 66.418%
Loss D Fake: 0.4749 (0.4576) Acc D Fake: 96.026%
Loss D: 0.800
Loss G: 0.9873 (1.0130) Acc G: 3.990%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.2746 (0.3783) Acc D Real: 66.501%
Loss D Fake: 0.4756 (0.4577) Acc D Fake: 95.998%
Loss D: 0.750
Loss G: 0.9863 (1.0129) Acc G: 4.017%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2599 (0.3776) Acc D Real: 66.516%
Loss D Fake: 0.4763 (0.4578) Acc D Fake: 95.995%
Loss D: 0.736
Loss G: 0.9853 (1.0127) Acc G: 4.020%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.521 | Generator Loss: 0.984 | Avg: 1.505
TEST [21/180]: Discriminator Loss: 0.556 | Generator Loss: 0.984 | Avg: 1.540
TEST [31/180]: Discriminator Loss: 0.548 | Generator Loss: 0.984 | Avg: 1.532
TEST [41/180]: Discriminator Loss: 0.538 | Generator Loss: 0.984 | Avg: 1.523
TEST [51/180]: Discriminator Loss: 0.537 | Generator Loss: 0.984 | Avg: 1.521
TEST [61/180]: Discriminator Loss: 0.597 | Generator Loss: 0.984 | Avg: 1.581
TEST [71/180]: Discriminator Loss: 0.600 | Generator Loss: 0.984 | Avg: 1.584
TEST [81/180]: Discriminator Loss: 0.655 | Generator Loss: 0.984 | Avg: 1.639
TEST [91/180]: Discriminator Loss: 0.670 | Generator Loss: 0.984 | Avg: 1.654
TEST [101/180]: Discriminator Loss: 0.726 | Generator Loss: 0.984 | Avg: 1.710
TEST [111/180]: Discriminator Loss: 0.764 | Generator Loss: 0.984 | Avg: 1.748
TEST [121/180]: Discriminator Loss: 0.794 | Generator Loss: 0.984 | Avg: 1.778
TEST [131/180]: Discriminator Loss: 0.824 | Generator Loss: 0.984 | Avg: 1.809
TEST [141/180]: Discriminator Loss: 0.829 | Generator Loss: 0.984 | Avg: 1.814
TEST [151/180]: Discriminator Loss: 0.811 | Generator Loss: 0.984 | Avg: 1.796
TEST [161/180]: Discriminator Loss: 0.795 | Generator Loss: 0.984 | Avg: 1.779
TEST [171/180]: Discriminator Loss: 0.780 | Generator Loss: 0.984 | Avg: 1.764
Epoch: 7/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3742 (0.3410) Acc D Real: 74.036%
Loss D Fake: 0.4778 (0.4774) Acc D Fake: 90.990%
Loss D: 0.852
Loss G: 0.9831 (0.9837) Acc G: 9.141%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.2703 (0.3174) Acc D Real: 76.562%
Loss D Fake: 0.4786 (0.4778) Acc D Fake: 90.660%
Loss D: 0.749
Loss G: 0.9818 (0.9831) Acc G: 9.427%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2033 (0.2889) Acc D Real: 79.245%
Loss D Fake: 0.4795 (0.4782) Acc D Fake: 90.495%
Loss D: 0.683
Loss G: 0.9806 (0.9824) Acc G: 9.570%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3895 (0.3090) Acc D Real: 77.073%
Loss D Fake: 0.4805 (0.4787) Acc D Fake: 90.396%
Loss D: 0.870
Loss G: 0.9791 (0.9818) Acc G: 9.656%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3328 (0.3130) Acc D Real: 76.372%
Loss D Fake: 0.4817 (0.4792) Acc D Fake: 90.330%
Loss D: 0.814
Loss G: 0.9768 (0.9809) Acc G: 9.714%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.2464 (0.3035) Acc D Real: 77.574%
Loss D Fake: 0.4834 (0.4798) Acc D Fake: 90.283%
Loss D: 0.730
Loss G: 0.9741 (0.9800) Acc G: 9.754%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.2479 (0.2965) Acc D Real: 78.158%
Loss D Fake: 0.4853 (0.4805) Acc D Fake: 90.247%
Loss D: 0.733
Loss G: 0.9713 (0.9789) Acc G: 9.785%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3058 (0.2976) Acc D Real: 78.177%
Loss D Fake: 0.4872 (0.4812) Acc D Fake: 90.220%
Loss D: 0.793
Loss G: 0.9684 (0.9777) Acc G: 9.809%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3135 (0.2991) Acc D Real: 78.167%
Loss D Fake: 0.4893 (0.4820) Acc D Fake: 90.198%
Loss D: 0.803
Loss G: 0.9651 (0.9764) Acc G: 9.828%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3770 (0.3062) Acc D Real: 77.727%
Loss D Fake: 0.4917 (0.4829) Acc D Fake: 90.028%
Loss D: 0.869
Loss G: 0.9613 (0.9751) Acc G: 9.995%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.3824 (0.3126) Acc D Real: 77.005%
Loss D Fake: 0.4945 (0.4839) Acc D Fake: 89.887%
Loss D: 0.877
Loss G: 0.9570 (0.9736) Acc G: 10.135%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4144 (0.3204) Acc D Real: 75.974%
Loss D Fake: 0.4977 (0.4849) Acc D Fake: 89.768%
Loss D: 0.912
Loss G: 0.9522 (0.9719) Acc G: 10.252%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.2261 (0.3137) Acc D Real: 76.626%
Loss D Fake: 0.5016 (0.4861) Acc D Fake: 89.665%
Loss D: 0.728
Loss G: 0.9465 (0.9701) Acc G: 10.353%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3154 (0.3138) Acc D Real: 76.705%
Loss D Fake: 0.5063 (0.4875) Acc D Fake: 89.517%
Loss D: 0.822
Loss G: 0.9396 (0.9681) Acc G: 10.528%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4160 (0.3202) Acc D Real: 76.146%
Loss D Fake: 0.5126 (0.4890) Acc D Fake: 89.339%
Loss D: 0.929
Loss G: 0.9299 (0.9657) Acc G: 10.703%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.2582 (0.3165) Acc D Real: 76.688%
Loss D Fake: 0.5217 (0.4910) Acc D Fake: 89.182%
Loss D: 0.780
Loss G: 0.9163 (0.9628) Acc G: 10.861%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3180 (0.3166) Acc D Real: 76.704%
Loss D Fake: 0.5361 (0.4935) Acc D Fake: 88.950%
Loss D: 0.854
Loss G: 0.8950 (0.9590) Acc G: 11.091%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3352 (0.3176) Acc D Real: 76.414%
Loss D Fake: 0.5613 (0.4970) Acc D Fake: 88.566%
Loss D: 0.896
Loss G: 0.8589 (0.9537) Acc G: 11.472%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.2217 (0.3128) Acc D Real: 76.852%
Loss D Fake: 0.6103 (0.5027) Acc D Fake: 87.549%
Loss D: 0.832
Loss G: 0.7948 (0.9458) Acc G: 12.482%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.2679 (0.3107) Acc D Real: 77.054%
Loss D Fake: 4.8658 (0.7105) Acc D Fake: 83.380%
Loss D: 5.134
Loss G: 0.2296 (0.9117) Acc G: 16.649%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3178 (0.3110) Acc D Real: 77.043%
Loss D Fake: 5.5871 (0.9321) Acc D Fake: 79.590%
Loss D: 5.905
Loss G: 0.1703 (0.8780) Acc G: 20.438%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.2611 (0.3088) Acc D Real: 77.409%
Loss D Fake: 5.8057 (1.1440) Acc D Fake: 76.130%
Loss D: 6.067
Loss G: 0.1500 (0.8463) Acc G: 23.897%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3664 (0.3112) Acc D Real: 77.101%
Loss D Fake: 5.8920 (1.3419) Acc D Fake: 72.958%
Loss D: 6.258
Loss G: 0.1389 (0.8169) Acc G: 27.068%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3215 (0.3116) Acc D Real: 76.975%
Loss D Fake: 5.9159 (1.5248) Acc D Fake: 70.040%
Loss D: 6.237
Loss G: 0.1318 (0.7895) Acc G: 29.985%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.2411 (0.3089) Acc D Real: 77.192%
Loss D Fake: 5.9042 (1.6933) Acc D Fake: 67.346%
Loss D: 6.145
Loss G: 0.1270 (0.7640) Acc G: 32.678%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4254 (0.3132) Acc D Real: 76.757%
Loss D Fake: 5.8703 (1.8480) Acc D Fake: 64.851%
Loss D: 6.296
Loss G: 0.1235 (0.7403) Acc G: 35.172%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3232 (0.3136) Acc D Real: 76.745%
Loss D Fake: 5.8221 (1.9899) Acc D Fake: 62.535%
Loss D: 6.145
Loss G: 0.1208 (0.7181) Acc G: 37.487%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3408 (0.3145) Acc D Real: 76.613%
Loss D Fake: 5.7642 (2.1200) Acc D Fake: 60.379%
Loss D: 6.105
Loss G: 0.1188 (0.6975) Acc G: 39.643%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.2313 (0.3117) Acc D Real: 76.788%
Loss D Fake: 5.6995 (2.2394) Acc D Fake: 58.366%
Loss D: 5.931
Loss G: 0.1173 (0.6781) Acc G: 41.655%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.2352 (0.3093) Acc D Real: 77.088%
Loss D Fake: 5.6300 (2.3487) Acc D Fake: 56.484%
Loss D: 5.865
Loss G: 0.1161 (0.6600) Acc G: 43.537%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3239 (0.3097) Acc D Real: 77.030%
Loss D Fake: 5.5571 (2.4490) Acc D Fake: 54.718%
Loss D: 5.881
Loss G: 0.1151 (0.6430) Acc G: 45.301%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.2869 (0.3090) Acc D Real: 77.208%
Loss D Fake: 5.4818 (2.5409) Acc D Fake: 53.060%
Loss D: 5.769
Loss G: 0.1144 (0.6270) Acc G: 46.959%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3634 (0.3106) Acc D Real: 77.132%
Loss D Fake: 5.4049 (2.6251) Acc D Fake: 51.500%
Loss D: 5.768
Loss G: 0.1138 (0.6119) Acc G: 48.519%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.2262 (0.3082) Acc D Real: 77.388%
Loss D Fake: 5.3269 (2.7023) Acc D Fake: 50.028%
Loss D: 5.553
Loss G: 0.1134 (0.5976) Acc G: 49.990%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3294 (0.3088) Acc D Real: 77.367%
Loss D Fake: 5.2480 (2.7730) Acc D Fake: 48.639%
Loss D: 5.577
Loss G: 0.1131 (0.5842) Acc G: 51.379%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3527 (0.3100) Acc D Real: 77.242%
Loss D Fake: 5.1686 (2.8378) Acc D Fake: 47.324%
Loss D: 5.521
Loss G: 0.1129 (0.5714) Acc G: 52.693%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3260 (0.3104) Acc D Real: 77.233%
Loss D Fake: 5.0889 (2.8970) Acc D Fake: 46.079%
Loss D: 5.415
Loss G: 0.1128 (0.5594) Acc G: 53.938%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.2560 (0.3090) Acc D Real: 77.408%
Loss D Fake: 5.0093 (2.9512) Acc D Fake: 44.897%
Loss D: 5.265
Loss G: 0.1127 (0.5479) Acc G: 55.119%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3462 (0.3100) Acc D Real: 77.279%
Loss D Fake: 4.9297 (3.0007) Acc D Fake: 43.775%
Loss D: 5.276
Loss G: 0.1127 (0.5370) Acc G: 56.241%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3151 (0.3101) Acc D Real: 77.353%
Loss D Fake: 4.8505 (3.0458) Acc D Fake: 42.707%
Loss D: 5.166
Loss G: 0.1128 (0.5267) Acc G: 57.308%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3922 (0.3120) Acc D Real: 77.176%
Loss D Fake: 4.7720 (3.0869) Acc D Fake: 41.690%
Loss D: 5.164
Loss G: 0.1129 (0.5168) Acc G: 58.325%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.2676 (0.3110) Acc D Real: 77.350%
Loss D Fake: 4.6943 (3.1243) Acc D Fake: 40.721%
Loss D: 4.962
Loss G: 0.1131 (0.5074) Acc G: 59.294%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3237 (0.3113) Acc D Real: 77.430%
Loss D Fake: 4.6176 (3.1582) Acc D Fake: 39.795%
Loss D: 4.941
Loss G: 0.1133 (0.4985) Acc G: 60.219%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.2178 (0.3092) Acc D Real: 77.625%
Loss D Fake: 4.5421 (3.1889) Acc D Fake: 38.911%
Loss D: 4.760
Loss G: 0.1136 (0.4899) Acc G: 61.103%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.2461 (0.3078) Acc D Real: 77.741%
Loss D Fake: 4.4675 (3.2167) Acc D Fake: 38.065%
Loss D: 4.714
Loss G: 0.1139 (0.4817) Acc G: 61.949%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.2735 (0.3071) Acc D Real: 77.930%
Loss D Fake: 4.3942 (3.2418) Acc D Fake: 37.255%
Loss D: 4.668
Loss G: 0.1142 (0.4739) Acc G: 62.758%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3072 (0.3071) Acc D Real: 77.859%
Loss D Fake: 4.3223 (3.2643) Acc D Fake: 36.479%
Loss D: 4.629
Loss G: 0.1146 (0.4664) Acc G: 63.534%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3278 (0.3075) Acc D Real: 77.883%
Loss D Fake: 4.2515 (3.2844) Acc D Fake: 35.734%
Loss D: 4.579
Loss G: 0.1150 (0.4593) Acc G: 64.278%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4068 (0.3095) Acc D Real: 77.802%
Loss D Fake: 4.1821 (3.3024) Acc D Fake: 35.020%
Loss D: 4.589
Loss G: 0.1154 (0.4524) Acc G: 64.993%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.2734 (0.3088) Acc D Real: 77.925%
Loss D Fake: 4.1140 (3.3183) Acc D Fake: 34.333%
Loss D: 4.387
Loss G: 0.1159 (0.4458) Acc G: 65.679%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3471 (0.3095) Acc D Real: 77.887%
Loss D Fake: 4.0470 (3.3323) Acc D Fake: 33.673%
Loss D: 4.394
Loss G: 0.1165 (0.4395) Acc G: 66.339%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.2773 (0.3089) Acc D Real: 77.975%
Loss D Fake: 3.9812 (3.3446) Acc D Fake: 33.038%
Loss D: 4.258
Loss G: 0.1170 (0.4334) Acc G: 66.974%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.2568 (0.3080) Acc D Real: 78.143%
Loss D Fake: 3.9164 (3.3552) Acc D Fake: 32.426%
Loss D: 4.173
Loss G: 0.1176 (0.4275) Acc G: 67.586%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3190 (0.3082) Acc D Real: 78.095%
Loss D Fake: 3.8527 (3.3642) Acc D Fake: 31.836%
Loss D: 4.172
Loss G: 0.1183 (0.4219) Acc G: 68.175%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3791 (0.3094) Acc D Real: 78.078%
Loss D Fake: 3.7899 (3.3718) Acc D Fake: 31.268%
Loss D: 4.169
Loss G: 0.1190 (0.4165) Acc G: 68.743%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.2850 (0.3090) Acc D Real: 78.166%
Loss D Fake: 3.7283 (3.3781) Acc D Fake: 30.719%
Loss D: 4.013
Loss G: 0.1198 (0.4113) Acc G: 69.292%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3303 (0.3094) Acc D Real: 78.240%
Loss D Fake: 3.6676 (3.3831) Acc D Fake: 30.189%
Loss D: 3.998
Loss G: 0.1205 (0.4063) Acc G: 69.821%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.2467 (0.3083) Acc D Real: 78.358%
Loss D Fake: 3.6080 (3.3869) Acc D Fake: 29.678%
Loss D: 3.855
Loss G: 0.1214 (0.4015) Acc G: 70.305%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3430 (0.3089) Acc D Real: 78.436%
Loss D Fake: 3.5492 (3.3896) Acc D Fake: 29.211%
Loss D: 3.892
Loss G: 0.1222 (0.3968) Acc G: 70.772%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3245 (0.3092) Acc D Real: 78.356%
Loss D Fake: 3.4912 (3.3912) Acc D Fake: 28.759%
Loss D: 3.816
Loss G: 0.1232 (0.3923) Acc G: 71.224%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2633 (0.3084) Acc D Real: 78.495%
Loss D Fake: 3.4340 (3.3919) Acc D Fake: 28.322%
Loss D: 3.697
Loss G: 0.1242 (0.3880) Acc G: 71.661%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2896 (0.3081) Acc D Real: 78.589%
Loss D Fake: 3.3777 (3.3917) Acc D Fake: 27.899%
Loss D: 3.667
Loss G: 0.1252 (0.3838) Acc G: 72.084%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.2524 (0.3072) Acc D Real: 78.709%
Loss D Fake: 3.3221 (3.3906) Acc D Fake: 27.489%
Loss D: 3.575
Loss G: 0.1263 (0.3798) Acc G: 72.494%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3798 (0.3084) Acc D Real: 78.639%
Loss D Fake: 3.2673 (3.3887) Acc D Fake: 27.092%
Loss D: 3.647
Loss G: 0.1275 (0.3759) Acc G: 72.892%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.2480 (0.3074) Acc D Real: 78.716%
Loss D Fake: 3.2132 (3.3861) Acc D Fake: 26.707%
Loss D: 3.461
Loss G: 0.1287 (0.3722) Acc G: 73.277%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2342 (0.3064) Acc D Real: 78.812%
Loss D Fake: 3.1598 (3.3827) Acc D Fake: 26.333%
Loss D: 3.394
Loss G: 0.1301 (0.3686) Acc G: 73.651%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3295 (0.3067) Acc D Real: 78.858%
Loss D Fake: 3.1070 (3.3786) Acc D Fake: 25.970%
Loss D: 3.436
Loss G: 0.1315 (0.3651) Acc G: 74.014%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3032 (0.3066) Acc D Real: 78.817%
Loss D Fake: 3.0551 (3.3739) Acc D Fake: 25.618%
Loss D: 3.358
Loss G: 0.1329 (0.3617) Acc G: 74.367%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3426 (0.3072) Acc D Real: 78.826%
Loss D Fake: 3.0039 (3.3687) Acc D Fake: 25.276%
Loss D: 3.346
Loss G: 0.1345 (0.3585) Acc G: 74.709%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3392 (0.3076) Acc D Real: 78.869%
Loss D Fake: 2.9535 (3.3628) Acc D Fake: 24.944%
Loss D: 3.293
Loss G: 0.1361 (0.3553) Acc G: 75.042%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3241 (0.3078) Acc D Real: 78.877%
Loss D Fake: 2.9039 (3.3564) Acc D Fake: 24.620%
Loss D: 3.228
Loss G: 0.1378 (0.3523) Acc G: 75.365%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.2917 (0.3076) Acc D Real: 78.901%
Loss D Fake: 2.8550 (3.3496) Acc D Fake: 24.306%
Loss D: 3.147
Loss G: 0.1396 (0.3494) Acc G: 75.657%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3691 (0.3084) Acc D Real: 78.765%
Loss D Fake: 2.8069 (3.3422) Acc D Fake: 24.022%
Loss D: 3.176
Loss G: 0.1414 (0.3466) Acc G: 75.941%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3941 (0.3096) Acc D Real: 78.689%
Loss D Fake: 2.7593 (3.3345) Acc D Fake: 23.747%
Loss D: 3.153
Loss G: 0.1434 (0.3439) Acc G: 76.217%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.2889 (0.3093) Acc D Real: 78.732%
Loss D Fake: 2.7126 (3.3263) Acc D Fake: 23.478%
Loss D: 3.002
Loss G: 0.1455 (0.3413) Acc G: 76.486%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2935 (0.3091) Acc D Real: 78.825%
Loss D Fake: 2.6666 (3.3177) Acc D Fake: 23.216%
Loss D: 2.960
Loss G: 0.1476 (0.3387) Acc G: 76.749%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3111 (0.3091) Acc D Real: 78.858%
Loss D Fake: 2.6214 (3.3088) Acc D Fake: 22.961%
Loss D: 2.932
Loss G: 0.1499 (0.3363) Acc G: 77.004%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3057 (0.3091) Acc D Real: 78.905%
Loss D Fake: 2.5770 (3.2995) Acc D Fake: 22.713%
Loss D: 2.883
Loss G: 0.1523 (0.3340) Acc G: 77.253%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3213 (0.3092) Acc D Real: 78.954%
Loss D Fake: 2.5333 (3.2899) Acc D Fake: 22.471%
Loss D: 2.855
Loss G: 0.1547 (0.3318) Acc G: 77.495%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3468 (0.3097) Acc D Real: 78.946%
Loss D Fake: 2.4903 (3.2801) Acc D Fake: 22.234%
Loss D: 2.837
Loss G: 0.1573 (0.3296) Acc G: 77.732%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.2754 (0.3093) Acc D Real: 79.025%
Loss D Fake: 2.4480 (3.2699) Acc D Fake: 22.004%
Loss D: 2.723
Loss G: 0.1599 (0.3275) Acc G: 77.963%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3017 (0.3092) Acc D Real: 79.110%
Loss D Fake: 2.4065 (3.2595) Acc D Fake: 21.779%
Loss D: 2.708
Loss G: 0.1627 (0.3255) Acc G: 78.188%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3530 (0.3097) Acc D Real: 79.084%
Loss D Fake: 2.3657 (3.2489) Acc D Fake: 21.579%
Loss D: 2.719
Loss G: 0.1656 (0.3236) Acc G: 78.389%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3317 (0.3100) Acc D Real: 79.133%
Loss D Fake: 2.3255 (3.2380) Acc D Fake: 21.384%
Loss D: 2.657
Loss G: 0.1686 (0.3218) Acc G: 78.584%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3640 (0.3106) Acc D Real: 79.139%
Loss D Fake: 2.2860 (3.2269) Acc D Fake: 21.194%
Loss D: 2.650
Loss G: 0.1717 (0.3201) Acc G: 78.775%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3520 (0.3111) Acc D Real: 79.125%
Loss D Fake: 2.2471 (3.2157) Acc D Fake: 21.008%
Loss D: 2.599
Loss G: 0.1749 (0.3184) Acc G: 78.961%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4386 (0.3125) Acc D Real: 78.986%
Loss D Fake: 2.2088 (3.2042) Acc D Fake: 20.826%
Loss D: 2.647
Loss G: 0.1783 (0.3168) Acc G: 79.144%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3226 (0.3126) Acc D Real: 79.029%
Loss D Fake: 2.1710 (3.1926) Acc D Fake: 20.648%
Loss D: 2.494
Loss G: 0.1817 (0.3153) Acc G: 79.322%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3601 (0.3132) Acc D Real: 79.040%
Loss D Fake: 2.1339 (3.1809) Acc D Fake: 20.474%
Loss D: 2.494
Loss G: 0.1853 (0.3138) Acc G: 79.496%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4093 (0.3142) Acc D Real: 78.977%
Loss D Fake: 2.0975 (3.1690) Acc D Fake: 20.304%
Loss D: 2.507
Loss G: 0.1890 (0.3125) Acc G: 79.666%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3098 (0.3142) Acc D Real: 79.057%
Loss D Fake: 2.0617 (3.1569) Acc D Fake: 20.138%
Loss D: 2.371
Loss G: 0.1928 (0.3112) Acc G: 79.833%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3177 (0.3142) Acc D Real: 79.075%
Loss D Fake: 2.0267 (3.1448) Acc D Fake: 19.975%
Loss D: 2.344
Loss G: 0.1967 (0.3099) Acc G: 79.996%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3515 (0.3146) Acc D Real: 79.091%
Loss D Fake: 1.9924 (3.1325) Acc D Fake: 19.815%
Loss D: 2.344
Loss G: 0.2008 (0.3088) Acc G: 80.156%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3579 (0.3151) Acc D Real: 79.131%
Loss D Fake: 1.9587 (3.1202) Acc D Fake: 19.660%
Loss D: 2.317
Loss G: 0.2049 (0.3077) Acc G: 80.312%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3327 (0.3153) Acc D Real: 79.158%
Loss D Fake: 1.9257 (3.1077) Acc D Fake: 19.507%
Loss D: 2.258
Loss G: 0.2092 (0.3067) Acc G: 80.465%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.4079 (0.3162) Acc D Real: 79.115%
Loss D Fake: 1.8934 (3.0952) Acc D Fake: 19.370%
Loss D: 2.301
Loss G: 0.2135 (0.3057) Acc G: 80.598%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3637 (0.3167) Acc D Real: 79.144%
Loss D Fake: 1.8617 (3.0826) Acc D Fake: 19.240%
Loss D: 2.225
Loss G: 0.2180 (0.3048) Acc G: 80.728%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3413 (0.3169) Acc D Real: 79.192%
Loss D Fake: 1.8307 (3.0700) Acc D Fake: 19.113%
Loss D: 2.172
Loss G: 0.2226 (0.3040) Acc G: 80.855%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3734 (0.3175) Acc D Real: 79.236%
Loss D Fake: 1.8004 (3.0573) Acc D Fake: 18.989%
Loss D: 2.174
Loss G: 0.2273 (0.3032) Acc G: 80.980%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4040 (0.3184) Acc D Real: 79.169%
Loss D Fake: 1.7706 (3.0445) Acc D Fake: 18.867%
Loss D: 2.175
Loss G: 0.2321 (0.3025) Acc G: 81.102%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3835 (0.3190) Acc D Real: 79.160%
Loss D Fake: 1.7415 (3.0318) Acc D Fake: 18.747%
Loss D: 2.125
Loss G: 0.2370 (0.3019) Acc G: 81.222%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.4537 (0.3203) Acc D Real: 79.144%
Loss D Fake: 1.7128 (3.0189) Acc D Fake: 18.630%
Loss D: 2.167
Loss G: 0.2420 (0.3013) Acc G: 81.340%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3362 (0.3205) Acc D Real: 79.204%
Loss D Fake: 1.6846 (3.0061) Acc D Fake: 18.515%
Loss D: 2.021
Loss G: 0.2471 (0.3008) Acc G: 81.455%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3857 (0.3211) Acc D Real: 79.250%
Loss D Fake: 1.6572 (2.9933) Acc D Fake: 18.402%
Loss D: 2.043
Loss G: 0.2523 (0.3003) Acc G: 81.568%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3739 (0.3216) Acc D Real: 79.303%
Loss D Fake: 1.6305 (2.9804) Acc D Fake: 18.291%
Loss D: 2.004
Loss G: 0.2576 (0.2999) Acc G: 81.679%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3600 (0.3219) Acc D Real: 79.354%
Loss D Fake: 1.6045 (2.9676) Acc D Fake: 18.182%
Loss D: 1.964
Loss G: 0.2630 (0.2996) Acc G: 81.788%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4027 (0.3227) Acc D Real: 79.338%
Loss D Fake: 1.5791 (2.9547) Acc D Fake: 18.076%
Loss D: 1.982
Loss G: 0.2684 (0.2993) Acc G: 81.895%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.4564 (0.3239) Acc D Real: 79.232%
Loss D Fake: 1.5544 (2.9419) Acc D Fake: 17.971%
Loss D: 2.011
Loss G: 0.2739 (0.2990) Acc G: 82.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3897 (0.3245) Acc D Real: 79.253%
Loss D Fake: 1.5301 (2.9290) Acc D Fake: 17.868%
Loss D: 1.920
Loss G: 0.2795 (0.2989) Acc G: 82.103%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3986 (0.3252) Acc D Real: 79.280%
Loss D Fake: 1.5065 (2.9162) Acc D Fake: 17.767%
Loss D: 1.905
Loss G: 0.2851 (0.2987) Acc G: 82.204%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3995 (0.3258) Acc D Real: 79.286%
Loss D Fake: 1.4836 (2.9034) Acc D Fake: 17.668%
Loss D: 1.883
Loss G: 0.2907 (0.2987) Acc G: 82.303%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.4131 (0.3266) Acc D Real: 79.306%
Loss D Fake: 1.4614 (2.8907) Acc D Fake: 17.571%
Loss D: 1.874
Loss G: 0.2964 (0.2986) Acc G: 82.401%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.4137 (0.3274) Acc D Real: 79.305%
Loss D Fake: 1.4397 (2.8779) Acc D Fake: 17.475%
Loss D: 1.853
Loss G: 0.3021 (0.2987) Acc G: 82.497%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.4169 (0.3282) Acc D Real: 79.300%
Loss D Fake: 1.4186 (2.8652) Acc D Fake: 17.381%
Loss D: 1.836
Loss G: 0.3079 (0.2987) Acc G: 82.591%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.4283 (0.3290) Acc D Real: 79.282%
Loss D Fake: 1.3982 (2.8526) Acc D Fake: 17.289%
Loss D: 1.826
Loss G: 0.3137 (0.2989) Acc G: 82.684%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.4320 (0.3299) Acc D Real: 79.271%
Loss D Fake: 1.3783 (2.8400) Acc D Fake: 17.198%
Loss D: 1.810
Loss G: 0.3194 (0.2991) Acc G: 82.775%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4138 (0.3306) Acc D Real: 79.297%
Loss D Fake: 1.3590 (2.8274) Acc D Fake: 17.109%
Loss D: 1.773
Loss G: 0.3252 (0.2993) Acc G: 82.864%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3793 (0.3310) Acc D Real: 79.368%
Loss D Fake: 1.3404 (2.8149) Acc D Fake: 17.021%
Loss D: 1.720
Loss G: 0.3309 (0.2995) Acc G: 82.952%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.4306 (0.3318) Acc D Real: 79.405%
Loss D Fake: 1.3226 (2.8025) Acc D Fake: 16.935%
Loss D: 1.753
Loss G: 0.3366 (0.2998) Acc G: 83.039%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.4419 (0.3328) Acc D Real: 79.401%
Loss D Fake: 1.3050 (2.7901) Acc D Fake: 16.850%
Loss D: 1.747
Loss G: 0.3424 (0.3002) Acc G: 83.124%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4154 (0.3334) Acc D Real: 79.409%
Loss D Fake: 1.2880 (2.7778) Acc D Fake: 16.767%
Loss D: 1.703
Loss G: 0.3480 (0.3006) Acc G: 83.207%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4554 (0.3344) Acc D Real: 79.387%
Loss D Fake: 1.2718 (2.7656) Acc D Fake: 16.684%
Loss D: 1.727
Loss G: 0.3536 (0.3010) Acc G: 83.290%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.4138 (0.3351) Acc D Real: 79.444%
Loss D Fake: 1.2560 (2.7534) Acc D Fake: 16.604%
Loss D: 1.670
Loss G: 0.3592 (0.3015) Acc G: 83.371%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.4384 (0.3359) Acc D Real: 79.457%
Loss D Fake: 1.2407 (2.7413) Acc D Fake: 16.524%
Loss D: 1.679
Loss G: 0.3648 (0.3020) Acc G: 83.450%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4343 (0.3367) Acc D Real: 79.496%
Loss D Fake: 1.2258 (2.7293) Acc D Fake: 16.446%
Loss D: 1.660
Loss G: 0.3704 (0.3025) Acc G: 83.529%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4164 (0.3373) Acc D Real: 79.548%
Loss D Fake: 1.2113 (2.7173) Acc D Fake: 16.369%
Loss D: 1.628
Loss G: 0.3758 (0.3031) Acc G: 83.606%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4531 (0.3382) Acc D Real: 79.567%
Loss D Fake: 1.1974 (2.7054) Acc D Fake: 16.293%
Loss D: 1.651
Loss G: 0.3813 (0.3037) Acc G: 83.682%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4834 (0.3393) Acc D Real: 79.523%
Loss D Fake: 1.1836 (2.6936) Acc D Fake: 16.219%
Loss D: 1.667
Loss G: 0.3869 (0.3044) Acc G: 83.757%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4827 (0.3404) Acc D Real: 79.485%
Loss D Fake: 1.1701 (2.6819) Acc D Fake: 16.145%
Loss D: 1.653
Loss G: 0.3925 (0.3051) Acc G: 83.831%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.4469 (0.3412) Acc D Real: 79.513%
Loss D Fake: 1.1568 (2.6703) Acc D Fake: 16.073%
Loss D: 1.604
Loss G: 0.3981 (0.3058) Acc G: 83.903%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4707 (0.3422) Acc D Real: 79.512%
Loss D Fake: 1.1438 (2.6587) Acc D Fake: 16.001%
Loss D: 1.615
Loss G: 0.4038 (0.3065) Acc G: 83.975%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.4433 (0.3430) Acc D Real: 79.547%
Loss D Fake: 1.1311 (2.6472) Acc D Fake: 15.931%
Loss D: 1.574
Loss G: 0.4091 (0.3073) Acc G: 84.045%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4844 (0.3440) Acc D Real: 79.522%
Loss D Fake: 1.1195 (2.6358) Acc D Fake: 15.862%
Loss D: 1.604
Loss G: 0.4143 (0.3081) Acc G: 84.114%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4761 (0.3450) Acc D Real: 79.519%
Loss D Fake: 1.1083 (2.6245) Acc D Fake: 15.794%
Loss D: 1.584
Loss G: 0.4194 (0.3089) Acc G: 84.182%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4806 (0.3460) Acc D Real: 79.512%
Loss D Fake: 1.0976 (2.6133) Acc D Fake: 15.727%
Loss D: 1.578
Loss G: 0.4244 (0.3097) Acc G: 84.250%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4693 (0.3469) Acc D Real: 79.527%
Loss D Fake: 1.0873 (2.6022) Acc D Fake: 15.661%
Loss D: 1.557
Loss G: 0.4292 (0.3106) Acc G: 84.316%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4836 (0.3479) Acc D Real: 79.523%
Loss D Fake: 1.0773 (2.5911) Acc D Fake: 15.596%
Loss D: 1.561
Loss G: 0.4341 (0.3115) Acc G: 84.381%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.4885 (0.3489) Acc D Real: 79.515%
Loss D Fake: 1.0674 (2.5801) Acc D Fake: 15.531%
Loss D: 1.556
Loss G: 0.4390 (0.3124) Acc G: 84.446%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.4884 (0.3499) Acc D Real: 79.514%
Loss D Fake: 1.0578 (2.5693) Acc D Fake: 15.468%
Loss D: 1.546
Loss G: 0.4438 (0.3134) Acc G: 84.509%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.4827 (0.3509) Acc D Real: 79.526%
Loss D Fake: 1.0486 (2.5585) Acc D Fake: 15.406%
Loss D: 1.531
Loss G: 0.4483 (0.3143) Acc G: 84.572%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4974 (0.3519) Acc D Real: 79.514%
Loss D Fake: 1.0399 (2.5478) Acc D Fake: 15.344%
Loss D: 1.537
Loss G: 0.4529 (0.3153) Acc G: 84.634%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4660 (0.3527) Acc D Real: 79.552%
Loss D Fake: 1.0313 (2.5372) Acc D Fake: 15.283%
Loss D: 1.497
Loss G: 0.4574 (0.3163) Acc G: 84.694%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.4749 (0.3535) Acc D Real: 79.580%
Loss D Fake: 1.0229 (2.5267) Acc D Fake: 15.224%
Loss D: 1.498
Loss G: 0.4620 (0.3173) Acc G: 84.754%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.5107 (0.3546) Acc D Real: 79.564%
Loss D Fake: 1.0147 (2.5162) Acc D Fake: 15.165%
Loss D: 1.525
Loss G: 0.4664 (0.3183) Acc G: 84.814%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.5111 (0.3557) Acc D Real: 79.541%
Loss D Fake: 1.0067 (2.5059) Acc D Fake: 15.106%
Loss D: 1.518
Loss G: 0.4708 (0.3194) Acc G: 84.872%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.5048 (0.3567) Acc D Real: 79.537%
Loss D Fake: 0.9989 (2.4956) Acc D Fake: 15.049%
Loss D: 1.504
Loss G: 0.4752 (0.3204) Acc G: 84.929%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.4945 (0.3576) Acc D Real: 79.552%
Loss D Fake: 0.9914 (2.4855) Acc D Fake: 14.992%
Loss D: 1.486
Loss G: 0.4794 (0.3215) Acc G: 84.986%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.4880 (0.3585) Acc D Real: 79.572%
Loss D Fake: 0.9842 (2.4754) Acc D Fake: 14.936%
Loss D: 1.472
Loss G: 0.4835 (0.3226) Acc G: 85.042%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.4676 (0.3592) Acc D Real: 79.612%
Loss D Fake: 0.9771 (2.4654) Acc D Fake: 14.881%
Loss D: 1.445
Loss G: 0.4877 (0.3237) Acc G: 85.098%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.5250 (0.3603) Acc D Real: 79.581%
Loss D Fake: 0.9700 (2.4555) Acc D Fake: 14.827%
Loss D: 1.495
Loss G: 0.4920 (0.3248) Acc G: 85.152%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.5367 (0.3615) Acc D Real: 79.516%
Loss D Fake: 0.9627 (2.4457) Acc D Fake: 14.773%
Loss D: 1.499
Loss G: 0.4965 (0.3259) Acc G: 85.206%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4857 (0.3623) Acc D Real: 79.541%
Loss D Fake: 0.9552 (2.4360) Acc D Fake: 14.720%
Loss D: 1.441
Loss G: 0.5011 (0.3271) Acc G: 85.259%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4825 (0.3631) Acc D Real: 79.573%
Loss D Fake: 0.9478 (2.4263) Acc D Fake: 14.668%
Loss D: 1.430
Loss G: 0.5056 (0.3283) Acc G: 85.311%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4949 (0.3639) Acc D Real: 79.623%
Loss D Fake: 0.9409 (2.4167) Acc D Fake: 14.616%
Loss D: 1.436
Loss G: 0.5097 (0.3294) Acc G: 85.363%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4693 (0.3646) Acc D Real: 79.674%
Loss D Fake: 0.9347 (2.4072) Acc D Fake: 14.565%
Loss D: 1.404
Loss G: 0.5135 (0.3306) Acc G: 85.414%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4987 (0.3655) Acc D Real: 79.740%
Loss D Fake: 0.9290 (2.3978) Acc D Fake: 14.515%
Loss D: 1.428
Loss G: 0.5169 (0.3318) Acc G: 85.465%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.5354 (0.3665) Acc D Real: 79.743%
Loss D Fake: 0.9246 (2.3885) Acc D Fake: 14.510%
Loss D: 1.460
Loss G: 0.5192 (0.3330) Acc G: 85.469%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.430 | Generator Loss: 0.519 | Avg: 1.949
TEST [21/180]: Discriminator Loss: 1.457 | Generator Loss: 0.519 | Avg: 1.976
TEST [31/180]: Discriminator Loss: 1.450 | Generator Loss: 0.519 | Avg: 1.969
TEST [41/180]: Discriminator Loss: 1.442 | Generator Loss: 0.519 | Avg: 1.961
TEST [51/180]: Discriminator Loss: 1.442 | Generator Loss: 0.519 | Avg: 1.961
TEST [61/180]: Discriminator Loss: 1.431 | Generator Loss: 0.519 | Avg: 1.950
TEST [71/180]: Discriminator Loss: 1.440 | Generator Loss: 0.519 | Avg: 1.959
TEST [81/180]: Discriminator Loss: 1.438 | Generator Loss: 0.519 | Avg: 1.957
TEST [91/180]: Discriminator Loss: 1.444 | Generator Loss: 0.519 | Avg: 1.963
TEST [101/180]: Discriminator Loss: 1.441 | Generator Loss: 0.519 | Avg: 1.960
TEST [111/180]: Discriminator Loss: 1.437 | Generator Loss: 0.519 | Avg: 1.956
TEST [121/180]: Discriminator Loss: 1.425 | Generator Loss: 0.519 | Avg: 1.944
TEST [131/180]: Discriminator Loss: 1.426 | Generator Loss: 0.519 | Avg: 1.945
TEST [141/180]: Discriminator Loss: 1.430 | Generator Loss: 0.519 | Avg: 1.949
TEST [151/180]: Discriminator Loss: 1.433 | Generator Loss: 0.519 | Avg: 1.952
TEST [161/180]: Discriminator Loss: 1.434 | Generator Loss: 0.519 | Avg: 1.953
TEST [171/180]: Discriminator Loss: 1.434 | Generator Loss: 0.519 | Avg: 1.953
Epoch: 8/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4958 (0.5029) Acc D Real: 82.682%
Loss D Fake: 0.9178 (0.9196) Acc D Fake: 6.667%
Loss D: 1.414
Loss G: 0.5238 (0.5226) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.5056 (0.5038) Acc D Real: 83.663%
Loss D Fake: 0.9141 (0.9178) Acc D Fake: 6.667%
Loss D: 1.420
Loss G: 0.5262 (0.5238) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.5144 (0.5064) Acc D Real: 84.505%
Loss D Fake: 0.9107 (0.9160) Acc D Fake: 6.667%
Loss D: 1.425
Loss G: 0.5282 (0.5249) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.5174 (0.5086) Acc D Real: 84.562%
Loss D Fake: 0.9080 (0.9144) Acc D Fake: 6.667%
Loss D: 1.425
Loss G: 0.5299 (0.5259) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.5340 (0.5128) Acc D Real: 83.438%
Loss D Fake: 0.9054 (0.9129) Acc D Fake: 6.667%
Loss D: 1.439
Loss G: 0.5317 (0.5269) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.4994 (0.5109) Acc D Real: 83.824%
Loss D Fake: 0.9027 (0.9114) Acc D Fake: 6.667%
Loss D: 1.402
Loss G: 0.5335 (0.5278) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.5159 (0.5115) Acc D Real: 83.405%
Loss D Fake: 0.9000 (0.9100) Acc D Fake: 6.667%
Loss D: 1.416
Loss G: 0.5355 (0.5288) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.5371 (0.5144) Acc D Real: 82.888%
Loss D Fake: 0.8971 (0.9086) Acc D Fake: 6.667%
Loss D: 1.434
Loss G: 0.5374 (0.5297) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.5261 (0.5156) Acc D Real: 82.807%
Loss D Fake: 0.8944 (0.9072) Acc D Fake: 6.667%
Loss D: 1.420
Loss G: 0.5392 (0.5307) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.5243 (0.5163) Acc D Real: 82.566%
Loss D Fake: 0.8918 (0.9058) Acc D Fake: 6.667%
Loss D: 1.416
Loss G: 0.5410 (0.5316) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.5055 (0.5154) Acc D Real: 82.326%
Loss D Fake: 0.8889 (0.9044) Acc D Fake: 6.667%
Loss D: 1.394
Loss G: 0.5433 (0.5326) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.5070 (0.5148) Acc D Real: 82.007%
Loss D Fake: 0.8853 (0.9029) Acc D Fake: 6.667%
Loss D: 1.392
Loss G: 0.5460 (0.5336) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4886 (0.5129) Acc D Real: 82.165%
Loss D Fake: 0.8812 (0.9014) Acc D Fake: 6.667%
Loss D: 1.370
Loss G: 0.5490 (0.5347) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.5095 (0.5127) Acc D Real: 82.257%
Loss D Fake: 0.8770 (0.8997) Acc D Fake: 6.667%
Loss D: 1.387
Loss G: 0.5518 (0.5359) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.5083 (0.5124) Acc D Real: 82.116%
Loss D Fake: 0.8730 (0.8981) Acc D Fake: 6.667%
Loss D: 1.381
Loss G: 0.5549 (0.5371) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.5248 (0.5131) Acc D Real: 82.037%
Loss D Fake: 0.8689 (0.8963) Acc D Fake: 6.667%
Loss D: 1.394
Loss G: 0.5577 (0.5383) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.5038 (0.5126) Acc D Real: 82.219%
Loss D Fake: 0.8650 (0.8946) Acc D Fake: 6.667%
Loss D: 1.369
Loss G: 0.5605 (0.5395) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.5328 (0.5137) Acc D Real: 81.804%
Loss D Fake: 0.8612 (0.8928) Acc D Fake: 6.667%
Loss D: 1.394
Loss G: 0.5634 (0.5408) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.5347 (0.5147) Acc D Real: 81.714%
Loss D Fake: 0.8573 (0.8911) Acc D Fake: 6.667%
Loss D: 1.392
Loss G: 0.5661 (0.5420) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.5343 (0.5157) Acc D Real: 81.845%
Loss D Fake: 0.8539 (0.8893) Acc D Fake: 6.667%
Loss D: 1.388
Loss G: 0.5683 (0.5433) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.5086 (0.5153) Acc D Real: 81.856%
Loss D Fake: 0.8511 (0.8876) Acc D Fake: 6.667%
Loss D: 1.360
Loss G: 0.5705 (0.5445) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.5339 (0.5162) Acc D Real: 81.927%
Loss D Fake: 0.8483 (0.8859) Acc D Fake: 6.667%
Loss D: 1.382
Loss G: 0.5724 (0.5457) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.5209 (0.5163) Acc D Real: 81.858%
Loss D Fake: 0.8458 (0.8842) Acc D Fake: 6.667%
Loss D: 1.367
Loss G: 0.5744 (0.5469) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.5234 (0.5166) Acc D Real: 82.096%
Loss D Fake: 0.8434 (0.8826) Acc D Fake: 6.667%
Loss D: 1.367
Loss G: 0.5759 (0.5481) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.5264 (0.5170) Acc D Real: 82.488%
Loss D Fake: 0.8418 (0.8810) Acc D Fake: 6.667%
Loss D: 1.368
Loss G: 0.5767 (0.5492) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.5118 (0.5168) Acc D Real: 82.296%
Loss D Fake: 0.8408 (0.8795) Acc D Fake: 6.667%
Loss D: 1.353
Loss G: 0.5779 (0.5503) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.5690 (0.5187) Acc D Real: 81.955%
Loss D Fake: 0.8390 (0.8780) Acc D Fake: 6.667%
Loss D: 1.408
Loss G: 0.5793 (0.5513) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.5572 (0.5200) Acc D Real: 81.909%
Loss D Fake: 0.8372 (0.8766) Acc D Fake: 6.667%
Loss D: 1.394
Loss G: 0.5804 (0.5523) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.5184 (0.5200) Acc D Real: 81.892%
Loss D Fake: 0.8358 (0.8753) Acc D Fake: 6.667%
Loss D: 1.354
Loss G: 0.5816 (0.5533) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.5283 (0.5202) Acc D Real: 81.976%
Loss D Fake: 0.8343 (0.8740) Acc D Fake: 6.667%
Loss D: 1.363
Loss G: 0.5826 (0.5542) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.5238 (0.5203) Acc D Real: 82.077%
Loss D Fake: 0.8330 (0.8727) Acc D Fake: 6.667%
Loss D: 1.357
Loss G: 0.5835 (0.5551) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4693 (0.5188) Acc D Real: 82.303%
Loss D Fake: 0.8319 (0.8714) Acc D Fake: 6.667%
Loss D: 1.301
Loss G: 0.5845 (0.5560) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.5326 (0.5192) Acc D Real: 82.587%
Loss D Fake: 0.8307 (0.8702) Acc D Fake: 6.667%
Loss D: 1.363
Loss G: 0.5849 (0.5569) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.5440 (0.5199) Acc D Real: 82.506%
Loss D Fake: 0.8304 (0.8691) Acc D Fake: 6.667%
Loss D: 1.374
Loss G: 0.5852 (0.5577) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.4593 (0.5182) Acc D Real: 82.577%
Loss D Fake: 0.8297 (0.8680) Acc D Fake: 6.667%
Loss D: 1.289
Loss G: 0.5861 (0.5585) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.4690 (0.5169) Acc D Real: 82.672%
Loss D Fake: 0.8281 (0.8669) Acc D Fake: 6.667%
Loss D: 1.297
Loss G: 0.5877 (0.5593) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.5020 (0.5165) Acc D Real: 82.797%
Loss D Fake: 0.8260 (0.8659) Acc D Fake: 6.667%
Loss D: 1.328
Loss G: 0.5892 (0.5601) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.4961 (0.5160) Acc D Real: 82.985%
Loss D Fake: 0.8242 (0.8648) Acc D Fake: 6.667%
Loss D: 1.320
Loss G: 0.5904 (0.5608) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.5503 (0.5168) Acc D Real: 82.999%
Loss D Fake: 0.8229 (0.8637) Acc D Fake: 6.667%
Loss D: 1.373
Loss G: 0.5912 (0.5616) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.5102 (0.5167) Acc D Real: 82.942%
Loss D Fake: 0.8219 (0.8627) Acc D Fake: 6.667%
Loss D: 1.332
Loss G: 0.5922 (0.5623) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4951 (0.5162) Acc D Real: 83.047%
Loss D Fake: 0.8205 (0.8617) Acc D Fake: 6.667%
Loss D: 1.316
Loss G: 0.5933 (0.5631) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.5174 (0.5162) Acc D Real: 83.161%
Loss D Fake: 0.8193 (0.8607) Acc D Fake: 6.667%
Loss D: 1.337
Loss G: 0.5941 (0.5638) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.5368 (0.5167) Acc D Real: 83.252%
Loss D Fake: 0.8185 (0.8598) Acc D Fake: 6.667%
Loss D: 1.355
Loss G: 0.5944 (0.5645) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.5028 (0.5163) Acc D Real: 83.229%
Loss D Fake: 0.8180 (0.8588) Acc D Fake: 6.667%
Loss D: 1.321
Loss G: 0.5950 (0.5652) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4950 (0.5159) Acc D Real: 83.293%
Loss D Fake: 0.8171 (0.8579) Acc D Fake: 6.667%
Loss D: 1.312
Loss G: 0.5958 (0.5658) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.5235 (0.5160) Acc D Real: 83.317%
Loss D Fake: 0.8161 (0.8570) Acc D Fake: 6.667%
Loss D: 1.340
Loss G: 0.5965 (0.5665) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.5445 (0.5166) Acc D Real: 83.403%
Loss D Fake: 0.8154 (0.8562) Acc D Fake: 6.667%
Loss D: 1.360
Loss G: 0.5967 (0.5671) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.5269 (0.5168) Acc D Real: 83.440%
Loss D Fake: 0.8154 (0.8553) Acc D Fake: 6.667%
Loss D: 1.342
Loss G: 0.5966 (0.5677) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4793 (0.5161) Acc D Real: 83.477%
Loss D Fake: 0.8153 (0.8545) Acc D Fake: 6.667%
Loss D: 1.295
Loss G: 0.5969 (0.5683) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.5041 (0.5159) Acc D Real: 83.599%
Loss D Fake: 0.8148 (0.8538) Acc D Fake: 6.667%
Loss D: 1.319
Loss G: 0.5972 (0.5689) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.5050 (0.5157) Acc D Real: 83.662%
Loss D Fake: 0.8145 (0.8530) Acc D Fake: 6.667%
Loss D: 1.320
Loss G: 0.5974 (0.5694) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.5153 (0.5156) Acc D Real: 83.648%
Loss D Fake: 0.8141 (0.8523) Acc D Fake: 6.667%
Loss D: 1.329
Loss G: 0.5978 (0.5700) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.5489 (0.5163) Acc D Real: 83.597%
Loss D Fake: 0.8136 (0.8516) Acc D Fake: 6.667%
Loss D: 1.362
Loss G: 0.5981 (0.5705) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.4893 (0.5158) Acc D Real: 83.680%
Loss D Fake: 0.8132 (0.8509) Acc D Fake: 6.667%
Loss D: 1.303
Loss G: 0.5984 (0.5710) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.4667 (0.5149) Acc D Real: 83.787%
Loss D Fake: 0.8127 (0.8502) Acc D Fake: 6.667%
Loss D: 1.279
Loss G: 0.5989 (0.5715) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.5330 (0.5152) Acc D Real: 83.912%
Loss D Fake: 0.8122 (0.8495) Acc D Fake: 6.667%
Loss D: 1.345
Loss G: 0.5989 (0.5720) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.5350 (0.5156) Acc D Real: 83.878%
Loss D Fake: 0.8124 (0.8489) Acc D Fake: 6.667%
Loss D: 1.347
Loss G: 0.5987 (0.5724) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.5008 (0.5153) Acc D Real: 83.955%
Loss D Fake: 0.8126 (0.8483) Acc D Fake: 6.667%
Loss D: 1.313
Loss G: 0.5985 (0.5729) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.4575 (0.5143) Acc D Real: 84.022%
Loss D Fake: 0.8126 (0.8477) Acc D Fake: 6.667%
Loss D: 1.270
Loss G: 0.5988 (0.5733) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.4951 (0.5140) Acc D Real: 84.097%
Loss D Fake: 0.8121 (0.8471) Acc D Fake: 6.667%
Loss D: 1.307
Loss G: 0.5991 (0.5737) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.5327 (0.5143) Acc D Real: 84.127%
Loss D Fake: 0.8118 (0.8465) Acc D Fake: 6.667%
Loss D: 1.344
Loss G: 0.5991 (0.5741) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.4841 (0.5138) Acc D Real: 84.238%
Loss D Fake: 0.8119 (0.8460) Acc D Fake: 6.667%
Loss D: 1.296
Loss G: 0.5990 (0.5745) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.4613 (0.5130) Acc D Real: 84.351%
Loss D Fake: 0.8119 (0.8454) Acc D Fake: 6.667%
Loss D: 1.273
Loss G: 0.5990 (0.5749) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4800 (0.5125) Acc D Real: 84.405%
Loss D Fake: 0.8117 (0.8449) Acc D Fake: 6.667%
Loss D: 1.292
Loss G: 0.5993 (0.5753) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.5025 (0.5124) Acc D Real: 84.408%
Loss D Fake: 0.8112 (0.8444) Acc D Fake: 6.667%
Loss D: 1.314
Loss G: 0.5997 (0.5756) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.4839 (0.5119) Acc D Real: 84.537%
Loss D Fake: 0.8108 (0.8439) Acc D Fake: 6.667%
Loss D: 1.295
Loss G: 0.5999 (0.5760) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4740 (0.5114) Acc D Real: 84.611%
Loss D Fake: 0.8105 (0.8434) Acc D Fake: 6.667%
Loss D: 1.284
Loss G: 0.6002 (0.5764) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.4482 (0.5105) Acc D Real: 84.682%
Loss D Fake: 0.8099 (0.8429) Acc D Fake: 6.667%
Loss D: 1.258
Loss G: 0.6008 (0.5767) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4844 (0.5101) Acc D Real: 84.648%
Loss D Fake: 0.8088 (0.8424) Acc D Fake: 6.667%
Loss D: 1.293
Loss G: 0.6019 (0.5771) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.5279 (0.5103) Acc D Real: 84.711%
Loss D Fake: 0.8076 (0.8419) Acc D Fake: 6.667%
Loss D: 1.336
Loss G: 0.6025 (0.5774) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.4841 (0.5100) Acc D Real: 84.795%
Loss D Fake: 0.8071 (0.8415) Acc D Fake: 6.667%
Loss D: 1.291
Loss G: 0.6029 (0.5778) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.4906 (0.5097) Acc D Real: 84.871%
Loss D Fake: 0.8067 (0.8410) Acc D Fake: 6.667%
Loss D: 1.297
Loss G: 0.6030 (0.5781) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.4816 (0.5093) Acc D Real: 84.988%
Loss D Fake: 0.8067 (0.8405) Acc D Fake: 6.667%
Loss D: 1.288
Loss G: 0.6029 (0.5785) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.4660 (0.5088) Acc D Real: 85.060%
Loss D Fake: 0.8068 (0.8401) Acc D Fake: 6.667%
Loss D: 1.273
Loss G: 0.6029 (0.5788) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4843 (0.5084) Acc D Real: 85.036%
Loss D Fake: 0.8065 (0.8396) Acc D Fake: 6.667%
Loss D: 1.291
Loss G: 0.6034 (0.5791) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.5580 (0.5091) Acc D Real: 84.948%
Loss D Fake: 0.8058 (0.8392) Acc D Fake: 6.667%
Loss D: 1.364
Loss G: 0.6038 (0.5794) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.4852 (0.5088) Acc D Real: 85.015%
Loss D Fake: 0.8055 (0.8388) Acc D Fake: 6.667%
Loss D: 1.291
Loss G: 0.6040 (0.5798) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4833 (0.5084) Acc D Real: 85.067%
Loss D Fake: 0.8052 (0.8383) Acc D Fake: 6.667%
Loss D: 1.289
Loss G: 0.6042 (0.5801) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4808 (0.5081) Acc D Real: 85.124%
Loss D Fake: 0.8049 (0.8379) Acc D Fake: 6.667%
Loss D: 1.286
Loss G: 0.6044 (0.5804) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4303 (0.5071) Acc D Real: 85.199%
Loss D Fake: 0.8044 (0.8375) Acc D Fake: 6.667%
Loss D: 1.235
Loss G: 0.6050 (0.5807) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4913 (0.5070) Acc D Real: 85.248%
Loss D Fake: 0.8036 (0.8371) Acc D Fake: 6.667%
Loss D: 1.295
Loss G: 0.6056 (0.5810) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.4666 (0.5065) Acc D Real: 85.297%
Loss D Fake: 0.8028 (0.8367) Acc D Fake: 6.667%
Loss D: 1.269
Loss G: 0.6063 (0.5813) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4367 (0.5056) Acc D Real: 85.368%
Loss D Fake: 0.8019 (0.8363) Acc D Fake: 6.667%
Loss D: 1.239
Loss G: 0.6072 (0.5816) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4789 (0.5053) Acc D Real: 85.394%
Loss D Fake: 0.8006 (0.8358) Acc D Fake: 6.667%
Loss D: 1.279
Loss G: 0.6082 (0.5819) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4658 (0.5049) Acc D Real: 85.399%
Loss D Fake: 0.7992 (0.8354) Acc D Fake: 6.667%
Loss D: 1.265
Loss G: 0.6096 (0.5822) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.4658 (0.5044) Acc D Real: 85.457%
Loss D Fake: 0.7975 (0.8350) Acc D Fake: 6.667%
Loss D: 1.263
Loss G: 0.6110 (0.5826) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4851 (0.5042) Acc D Real: 85.509%
Loss D Fake: 0.7959 (0.8345) Acc D Fake: 6.667%
Loss D: 1.281
Loss G: 0.6122 (0.5829) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4928 (0.5041) Acc D Real: 85.546%
Loss D Fake: 0.7947 (0.8341) Acc D Fake: 6.667%
Loss D: 1.287
Loss G: 0.6130 (0.5832) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4603 (0.5036) Acc D Real: 85.580%
Loss D Fake: 0.7937 (0.8336) Acc D Fake: 6.667%
Loss D: 1.254
Loss G: 0.6139 (0.5836) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4635 (0.5031) Acc D Real: 85.610%
Loss D Fake: 0.7924 (0.8332) Acc D Fake: 6.667%
Loss D: 1.256
Loss G: 0.6151 (0.5839) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.4856 (0.5029) Acc D Real: 85.688%
Loss D Fake: 0.7912 (0.8327) Acc D Fake: 6.667%
Loss D: 1.277
Loss G: 0.6158 (0.5843) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.5073 (0.5030) Acc D Real: 85.720%
Loss D Fake: 0.7905 (0.8323) Acc D Fake: 6.667%
Loss D: 1.298
Loss G: 0.6161 (0.5846) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4738 (0.5027) Acc D Real: 85.750%
Loss D Fake: 0.7902 (0.8318) Acc D Fake: 6.667%
Loss D: 1.264
Loss G: 0.6164 (0.5849) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.4349 (0.5020) Acc D Real: 85.747%
Loss D Fake: 0.7896 (0.8314) Acc D Fake: 6.667%
Loss D: 1.224
Loss G: 0.6174 (0.5853) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4840 (0.5018) Acc D Real: 85.782%
Loss D Fake: 0.7882 (0.8309) Acc D Fake: 6.667%
Loss D: 1.272
Loss G: 0.6184 (0.5856) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.4950 (0.5017) Acc D Real: 85.827%
Loss D Fake: 0.7873 (0.8305) Acc D Fake: 6.667%
Loss D: 1.282
Loss G: 0.6189 (0.5860) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.4589 (0.5013) Acc D Real: 85.891%
Loss D Fake: 0.7868 (0.8300) Acc D Fake: 6.667%
Loss D: 1.246
Loss G: 0.6194 (0.5863) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.5362 (0.5016) Acc D Real: 85.897%
Loss D Fake: 0.7864 (0.8296) Acc D Fake: 6.667%
Loss D: 1.323
Loss G: 0.6193 (0.5867) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.4113 (0.5007) Acc D Real: 85.954%
Loss D Fake: 0.7864 (0.8292) Acc D Fake: 6.667%
Loss D: 1.198
Loss G: 0.6197 (0.5870) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4491 (0.5002) Acc D Real: 86.029%
Loss D Fake: 0.7857 (0.8287) Acc D Fake: 6.667%
Loss D: 1.235
Loss G: 0.6203 (0.5873) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4707 (0.4999) Acc D Real: 86.071%
Loss D Fake: 0.7850 (0.8283) Acc D Fake: 6.667%
Loss D: 1.256
Loss G: 0.6208 (0.5876) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.4868 (0.4998) Acc D Real: 86.088%
Loss D Fake: 0.7845 (0.8279) Acc D Fake: 6.667%
Loss D: 1.271
Loss G: 0.6212 (0.5880) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.4528 (0.4993) Acc D Real: 86.127%
Loss D Fake: 0.7839 (0.8275) Acc D Fake: 6.667%
Loss D: 1.237
Loss G: 0.6218 (0.5883) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.4490 (0.4989) Acc D Real: 86.195%
Loss D Fake: 0.7831 (0.8270) Acc D Fake: 6.667%
Loss D: 1.232
Loss G: 0.6225 (0.5886) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4906 (0.4988) Acc D Real: 86.222%
Loss D Fake: 0.7824 (0.8266) Acc D Fake: 6.667%
Loss D: 1.273
Loss G: 0.6229 (0.5889) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.5259 (0.4990) Acc D Real: 86.249%
Loss D Fake: 0.7822 (0.8262) Acc D Fake: 6.667%
Loss D: 1.308
Loss G: 0.6227 (0.5893) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4870 (0.4989) Acc D Real: 86.305%
Loss D Fake: 0.7827 (0.8258) Acc D Fake: 6.667%
Loss D: 1.270
Loss G: 0.6221 (0.5896) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.4044 (0.4981) Acc D Real: 86.347%
Loss D Fake: 0.7831 (0.8254) Acc D Fake: 6.667%
Loss D: 1.188
Loss G: 0.6221 (0.5899) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4633 (0.4977) Acc D Real: 86.405%
Loss D Fake: 0.7829 (0.8250) Acc D Fake: 6.667%
Loss D: 1.246
Loss G: 0.6222 (0.5902) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.4328 (0.4972) Acc D Real: 86.397%
Loss D Fake: 0.7825 (0.8246) Acc D Fake: 6.667%
Loss D: 1.215
Loss G: 0.6229 (0.5904) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.4712 (0.4969) Acc D Real: 86.435%
Loss D Fake: 0.7815 (0.8243) Acc D Fake: 6.667%
Loss D: 1.253
Loss G: 0.6237 (0.5907) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.4058 (0.4961) Acc D Real: 86.488%
Loss D Fake: 0.7804 (0.8239) Acc D Fake: 6.667%
Loss D: 1.186
Loss G: 0.6249 (0.5910) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.4633 (0.4958) Acc D Real: 86.512%
Loss D Fake: 0.7789 (0.8235) Acc D Fake: 6.667%
Loss D: 1.242
Loss G: 0.6261 (0.5914) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3753 (0.4948) Acc D Real: 86.529%
Loss D Fake: 0.7772 (0.8231) Acc D Fake: 6.667%
Loss D: 1.152
Loss G: 0.6281 (0.5917) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.4846 (0.4947) Acc D Real: 86.541%
Loss D Fake: 0.7747 (0.8226) Acc D Fake: 6.667%
Loss D: 1.259
Loss G: 0.6300 (0.5920) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.4375 (0.4942) Acc D Real: 86.583%
Loss D Fake: 0.7726 (0.8222) Acc D Fake: 6.667%
Loss D: 1.210
Loss G: 0.6318 (0.5923) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4568 (0.4939) Acc D Real: 86.599%
Loss D Fake: 0.7706 (0.8218) Acc D Fake: 6.667%
Loss D: 1.227
Loss G: 0.6335 (0.5927) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.4497 (0.4935) Acc D Real: 86.643%
Loss D Fake: 0.7687 (0.8213) Acc D Fake: 6.667%
Loss D: 1.218
Loss G: 0.6351 (0.5930) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.4613 (0.4933) Acc D Real: 86.673%
Loss D Fake: 0.7670 (0.8209) Acc D Fake: 6.667%
Loss D: 1.228
Loss G: 0.6364 (0.5934) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.4475 (0.4929) Acc D Real: 86.730%
Loss D Fake: 0.7657 (0.8204) Acc D Fake: 6.667%
Loss D: 1.213
Loss G: 0.6374 (0.5938) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4399 (0.4924) Acc D Real: 86.765%
Loss D Fake: 0.7645 (0.8200) Acc D Fake: 6.667%
Loss D: 1.204
Loss G: 0.6386 (0.5941) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4625 (0.4922) Acc D Real: 86.821%
Loss D Fake: 0.7633 (0.8195) Acc D Fake: 6.667%
Loss D: 1.226
Loss G: 0.6394 (0.5945) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.4493 (0.4918) Acc D Real: 86.876%
Loss D Fake: 0.7625 (0.8190) Acc D Fake: 6.667%
Loss D: 1.212
Loss G: 0.6399 (0.5949) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3911 (0.4910) Acc D Real: 86.912%
Loss D Fake: 0.7617 (0.8186) Acc D Fake: 6.667%
Loss D: 1.153
Loss G: 0.6410 (0.5952) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4838 (0.4910) Acc D Real: 86.951%
Loss D Fake: 0.7604 (0.8181) Acc D Fake: 6.667%
Loss D: 1.244
Loss G: 0.6418 (0.5956) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4971 (0.4910) Acc D Real: 86.975%
Loss D Fake: 0.7598 (0.8177) Acc D Fake: 6.667%
Loss D: 1.257
Loss G: 0.6421 (0.5960) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4646 (0.4908) Acc D Real: 86.992%
Loss D Fake: 0.7596 (0.8172) Acc D Fake: 6.667%
Loss D: 1.224
Loss G: 0.6424 (0.5963) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4614 (0.4906) Acc D Real: 87.034%
Loss D Fake: 0.7593 (0.8168) Acc D Fake: 6.667%
Loss D: 1.221
Loss G: 0.6425 (0.5967) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4815 (0.4905) Acc D Real: 87.080%
Loss D Fake: 0.7594 (0.8163) Acc D Fake: 6.667%
Loss D: 1.241
Loss G: 0.6420 (0.5970) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.4540 (0.4903) Acc D Real: 87.094%
Loss D Fake: 0.7599 (0.8159) Acc D Fake: 6.667%
Loss D: 1.214
Loss G: 0.6418 (0.5974) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.5036 (0.4904) Acc D Real: 87.138%
Loss D Fake: 0.7603 (0.8155) Acc D Fake: 6.667%
Loss D: 1.264
Loss G: 0.6410 (0.5977) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.5013 (0.4904) Acc D Real: 87.150%
Loss D Fake: 0.7613 (0.8151) Acc D Fake: 6.667%
Loss D: 1.263
Loss G: 0.6399 (0.5980) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4166 (0.4899) Acc D Real: 87.207%
Loss D Fake: 0.7625 (0.8147) Acc D Fake: 6.667%
Loss D: 1.179
Loss G: 0.6391 (0.5983) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4706 (0.4897) Acc D Real: 87.231%
Loss D Fake: 0.7633 (0.8143) Acc D Fake: 6.667%
Loss D: 1.234
Loss G: 0.6383 (0.5986) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4616 (0.4895) Acc D Real: 87.235%
Loss D Fake: 0.7640 (0.8139) Acc D Fake: 6.667%
Loss D: 1.226
Loss G: 0.6378 (0.5989) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4611 (0.4893) Acc D Real: 87.255%
Loss D Fake: 0.7644 (0.8136) Acc D Fake: 6.667%
Loss D: 1.225
Loss G: 0.6375 (0.5992) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4237 (0.4888) Acc D Real: 87.295%
Loss D Fake: 0.7645 (0.8132) Acc D Fake: 6.667%
Loss D: 1.188
Loss G: 0.6376 (0.5995) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.4364 (0.4885) Acc D Real: 87.315%
Loss D Fake: 0.7642 (0.8129) Acc D Fake: 6.667%
Loss D: 1.201
Loss G: 0.6380 (0.5998) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.5076 (0.4886) Acc D Real: 87.337%
Loss D Fake: 0.7639 (0.8125) Acc D Fake: 6.667%
Loss D: 1.271
Loss G: 0.6378 (0.6000) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.4452 (0.4883) Acc D Real: 87.359%
Loss D Fake: 0.7642 (0.8122) Acc D Fake: 6.667%
Loss D: 1.209
Loss G: 0.6376 (0.6003) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.5307 (0.4886) Acc D Real: 87.393%
Loss D Fake: 0.7647 (0.8118) Acc D Fake: 6.667%
Loss D: 1.295
Loss G: 0.6365 (0.6006) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4836 (0.4886) Acc D Real: 87.410%
Loss D Fake: 0.7663 (0.8115) Acc D Fake: 6.667%
Loss D: 1.250
Loss G: 0.6350 (0.6008) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.4845 (0.4885) Acc D Real: 87.438%
Loss D Fake: 0.7680 (0.8112) Acc D Fake: 6.667%
Loss D: 1.252
Loss G: 0.6333 (0.6010) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4379 (0.4882) Acc D Real: 87.461%
Loss D Fake: 0.7698 (0.8109) Acc D Fake: 6.667%
Loss D: 1.208
Loss G: 0.6320 (0.6012) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4079 (0.4876) Acc D Real: 87.503%
Loss D Fake: 0.7709 (0.8106) Acc D Fake: 6.667%
Loss D: 1.179
Loss G: 0.6313 (0.6014) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.4624 (0.4875) Acc D Real: 87.538%
Loss D Fake: 0.7715 (0.8104) Acc D Fake: 6.667%
Loss D: 1.234
Loss G: 0.6306 (0.6016) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.5170 (0.4877) Acc D Real: 87.564%
Loss D Fake: 0.7726 (0.8101) Acc D Fake: 6.667%
Loss D: 1.290
Loss G: 0.6292 (0.6018) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.5060 (0.4878) Acc D Real: 87.574%
Loss D Fake: 0.7745 (0.8099) Acc D Fake: 6.667%
Loss D: 1.280
Loss G: 0.6273 (0.6020) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.4358 (0.4874) Acc D Real: 87.597%
Loss D Fake: 0.7766 (0.8097) Acc D Fake: 6.667%
Loss D: 1.212
Loss G: 0.6257 (0.6022) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.4367 (0.4871) Acc D Real: 87.630%
Loss D Fake: 0.7781 (0.8095) Acc D Fake: 6.667%
Loss D: 1.215
Loss G: 0.6244 (0.6023) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4133 (0.4866) Acc D Real: 87.639%
Loss D Fake: 0.7792 (0.8093) Acc D Fake: 6.667%
Loss D: 1.192
Loss G: 0.6239 (0.6024) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4949 (0.4867) Acc D Real: 87.669%
Loss D Fake: 0.7797 (0.8091) Acc D Fake: 6.667%
Loss D: 1.275
Loss G: 0.6230 (0.6026) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4040 (0.4861) Acc D Real: 87.692%
Loss D Fake: 0.7807 (0.8089) Acc D Fake: 6.667%
Loss D: 1.185
Loss G: 0.6226 (0.6027) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4519 (0.4859) Acc D Real: 87.705%
Loss D Fake: 0.7809 (0.8087) Acc D Fake: 6.667%
Loss D: 1.233
Loss G: 0.6225 (0.6028) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4346 (0.4856) Acc D Real: 87.745%
Loss D Fake: 0.7809 (0.8085) Acc D Fake: 6.667%
Loss D: 1.216
Loss G: 0.6224 (0.6030) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4878 (0.4856) Acc D Real: 87.777%
Loss D Fake: 0.7813 (0.8083) Acc D Fake: 6.667%
Loss D: 1.269
Loss G: 0.6215 (0.6031) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.4614 (0.4854) Acc D Real: 87.782%
Loss D Fake: 0.7827 (0.8082) Acc D Fake: 6.667%
Loss D: 1.244
Loss G: 0.6199 (0.6032) Acc G: 93.333%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.374 | Generator Loss: 0.620 | Avg: 1.994
TEST [21/180]: Discriminator Loss: 1.356 | Generator Loss: 0.620 | Avg: 1.976
TEST [31/180]: Discriminator Loss: 1.361 | Generator Loss: 0.620 | Avg: 1.980
TEST [41/180]: Discriminator Loss: 1.364 | Generator Loss: 0.620 | Avg: 1.984
TRAIN Iteration: [   2/158]
Loss D Real: 0.4031 (0.4085) Acc D Real: 90.260%
Loss D Fake: 0.7851 (0.7848) Acc D Fake: 6.667%
Loss D: 1.188
Loss G: 0.6186 (0.6187) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.4381 (0.4183) Acc D Real: 91.076%
Loss D Fake: 0.7852 (0.7849) Acc D Fake: 6.667%
Loss D: 1.223
Loss G: 0.6184 (0.6186) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.4191 (0.4185) Acc D Real: 91.016%
Loss D Fake: 0.7852 (0.7850) Acc D Fake: 6.667%
Loss D: 1.204
Loss G: 0.6186 (0.6186) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4022 (0.4153) Acc D Real: 91.510%
Loss D Fake: 0.7846 (0.7849) Acc D Fake: 6.667%
Loss D: 1.187
Loss G: 0.6192 (0.6187) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.4186 (0.4158) Acc D Real: 91.918%
Loss D Fake: 0.7838 (0.7847) Acc D Fake: 6.667%
Loss D: 1.202
Loss G: 0.6199 (0.6189) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.4688 (0.4234) Acc D Real: 91.153%
Loss D Fake: 0.7830 (0.7845) Acc D Fake: 6.667%
Loss D: 1.252
Loss G: 0.6206 (0.6192) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3392 (0.4129) Acc D Real: 91.823%
Loss D Fake: 0.7819 (0.7841) Acc D Fake: 6.667%
Loss D: 1.121
Loss G: 0.6221 (0.6195) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3386 (0.4046) Acc D Real: 92.193%
Loss D Fake: 0.7795 (0.7836) Acc D Fake: 6.667%
Loss D: 1.118
Loss G: 0.6247 (0.6201) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4533 (0.4095) Acc D Real: 92.198%
Loss D Fake: 0.7764 (0.7829) Acc D Fake: 6.667%
Loss D: 1.230
Loss G: 0.6269 (0.6208) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.4152 (0.4100) Acc D Real: 92.230%
Loss D Fake: 0.7742 (0.7821) Acc D Fake: 6.667%
Loss D: 1.189
Loss G: 0.6287 (0.6215) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4300 (0.4117) Acc D Real: 92.287%
Loss D Fake: 0.7724 (0.7813) Acc D Fake: 6.667%
Loss D: 1.202
Loss G: 0.6300 (0.6222) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3993 (0.4107) Acc D Real: 92.464%
Loss D Fake: 0.7712 (0.7805) Acc D Fake: 6.667%
Loss D: 1.171
Loss G: 0.6309 (0.6229) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4369 (0.4126) Acc D Real: 92.452%
Loss D Fake: 0.7704 (0.7798) Acc D Fake: 6.667%
Loss D: 1.207
Loss G: 0.6314 (0.6235) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4135 (0.4126) Acc D Real: 92.451%
Loss D Fake: 0.7698 (0.7791) Acc D Fake: 6.667%
Loss D: 1.183
Loss G: 0.6319 (0.6240) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3983 (0.4117) Acc D Real: 92.500%
Loss D Fake: 0.7690 (0.7785) Acc D Fake: 6.667%
Loss D: 1.167
Loss G: 0.6332 (0.6246) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.4378 (0.4133) Acc D Real: 92.546%
Loss D Fake: 0.7672 (0.7778) Acc D Fake: 6.667%
Loss D: 1.205
Loss G: 0.6349 (0.6252) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.4316 (0.4143) Acc D Real: 92.474%
Loss D Fake: 0.7653 (0.7771) Acc D Fake: 6.667%
Loss D: 1.197
Loss G: 0.6369 (0.6259) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.4047 (0.4138) Acc D Real: 92.519%
Loss D Fake: 0.7626 (0.7764) Acc D Fake: 6.667%
Loss D: 1.167
Loss G: 0.6400 (0.6266) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.4247 (0.4143) Acc D Real: 92.240%
Loss D Fake: 0.7585 (0.7755) Acc D Fake: 6.667%
Loss D: 1.183
Loss G: 0.6447 (0.6275) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.4624 (0.4166) Acc D Real: 92.205%
Loss D Fake: 0.7536 (0.7744) Acc D Fake: 6.667%
Loss D: 1.216
Loss G: 0.6483 (0.6285) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.4231 (0.4169) Acc D Real: 92.299%
Loss D Fake: 0.7502 (0.7733) Acc D Fake: 6.667%
Loss D: 1.173
Loss G: 0.6516 (0.6296) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4278 (0.4174) Acc D Real: 92.235%
Loss D Fake: 0.7466 (0.7722) Acc D Fake: 6.667%
Loss D: 1.174
Loss G: 0.6553 (0.6307) Acc G: 91.667%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.4516 (0.4188) Acc D Real: 92.159%
Loss D Fake: 0.7430 (0.7710) Acc D Fake: 8.403%
Loss D: 1.195
Loss G: 0.6579 (0.6318) Acc G: 89.653%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4465 (0.4199) Acc D Real: 92.079%
Loss D Fake: 0.7414 (0.7698) Acc D Fake: 10.267%
Loss D: 1.188
Loss G: 0.6583 (0.6329) Acc G: 87.733%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.4084 (0.4195) Acc D Real: 91.905%
Loss D Fake: 0.7414 (0.7687) Acc D Fake: 12.051%
Loss D: 1.150
Loss G: 0.6604 (0.6339) Acc G: 85.769%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4448 (0.4204) Acc D Real: 91.821%
Loss D Fake: 0.7377 (0.7675) Acc D Fake: 14.012%
Loss D: 1.183
Loss G: 0.6643 (0.6351) Acc G: 83.765%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3895 (0.4193) Acc D Real: 91.743%
Loss D Fake: 0.7336 (0.7663) Acc D Fake: 15.952%
Loss D: 1.123
Loss G: 0.6680 (0.6362) Acc G: 81.845%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3765 (0.4178) Acc D Real: 91.722%
Loss D Fake: 0.7300 (0.7651) Acc D Fake: 17.816%
Loss D: 1.107
Loss G: 0.6712 (0.6374) Acc G: 80.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3934 (0.4170) Acc D Real: 91.774%
Loss D Fake: 0.7267 (0.7638) Acc D Fake: 19.611%
Loss D: 1.120
Loss G: 0.6744 (0.6387) Acc G: 78.222%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3753 (0.4157) Acc D Real: 91.725%
Loss D Fake: 0.7235 (0.7625) Acc D Fake: 21.344%
Loss D: 1.099
Loss G: 0.6773 (0.6399) Acc G: 76.559%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3834 (0.4147) Acc D Real: 91.662%
Loss D Fake: 0.7206 (0.7612) Acc D Fake: 22.969%
Loss D: 1.104
Loss G: 0.6805 (0.6412) Acc G: 74.948%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4192 (0.4148) Acc D Real: 91.512%
Loss D Fake: 0.7176 (0.7599) Acc D Fake: 24.545%
Loss D: 1.137
Loss G: 0.6828 (0.6424) Acc G: 73.434%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3826 (0.4139) Acc D Real: 91.441%
Loss D Fake: 0.7158 (0.7586) Acc D Fake: 26.029%
Loss D: 1.098
Loss G: 0.6848 (0.6437) Acc G: 72.010%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.4232 (0.4141) Acc D Real: 91.321%
Loss D Fake: 0.7147 (0.7573) Acc D Fake: 27.429%
Loss D: 1.138
Loss G: 0.6841 (0.6448) Acc G: 70.667%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3478 (0.4123) Acc D Real: 91.412%
Loss D Fake: 0.7163 (0.7562) Acc D Fake: 28.750%
Loss D: 1.064
Loss G: 0.6860 (0.6460) Acc G: 69.398%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3709 (0.4112) Acc D Real: 91.341%
Loss D Fake: 0.7111 (0.7550) Acc D Fake: 30.000%
Loss D: 1.082
Loss G: 0.6921 (0.6472) Acc G: 68.153%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3650 (0.4099) Acc D Real: 91.327%
Loss D Fake: 0.7047 (0.7536) Acc D Fake: 31.228%
Loss D: 1.070
Loss G: 0.6976 (0.6486) Acc G: 66.974%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.4003 (0.4097) Acc D Real: 91.178%
Loss D Fake: 0.7008 (0.7523) Acc D Fake: 32.436%
Loss D: 1.101
Loss G: 0.7002 (0.6499) Acc G: 65.812%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.4042 (0.4096) Acc D Real: 91.128%
Loss D Fake: 0.6992 (0.7510) Acc D Fake: 33.583%
Loss D: 1.103
Loss G: 0.7014 (0.6512) Acc G: 64.708%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4093 (0.4095) Acc D Real: 91.014%
Loss D Fake: 0.6987 (0.7497) Acc D Fake: 34.675%
Loss D: 1.108
Loss G: 0.7019 (0.6524) Acc G: 63.659%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3360 (0.4078) Acc D Real: 91.026%
Loss D Fake: 0.6976 (0.7484) Acc D Fake: 35.714%
Loss D: 1.034
Loss G: 0.7052 (0.6537) Acc G: 62.659%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.4696 (0.4092) Acc D Real: 90.742%
Loss D Fake: 0.6938 (0.7472) Acc D Fake: 36.705%
Loss D: 1.163
Loss G: 0.7071 (0.6549) Acc G: 61.705%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3455 (0.4078) Acc D Real: 90.627%
Loss D Fake: 0.6931 (0.7459) Acc D Fake: 37.652%
Loss D: 1.039
Loss G: 0.7080 (0.6561) Acc G: 60.795%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3567 (0.4067) Acc D Real: 90.499%
Loss D Fake: 0.6940 (0.7448) Acc D Fake: 38.556%
Loss D: 1.051
Loss G: 0.7005 (0.6571) Acc G: 59.926%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3691 (0.4058) Acc D Real: 90.437%
Loss D Fake: 0.8413 (0.7469) Acc D Fake: 38.188%
Loss D: 1.210
Loss G: 0.7070 (0.6582) Acc G: 59.058%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3778 (0.4052) Acc D Real: 90.376%
Loss D Fake: 0.7184 (0.7463) Acc D Fake: 38.617%
Loss D: 1.096
Loss G: 0.6852 (0.6588) Acc G: 58.582%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3543 (0.4042) Acc D Real: 90.237%
Loss D Fake: 0.7056 (0.7454) Acc D Fake: 39.236%
Loss D: 1.060
Loss G: 0.7301 (0.6603) Acc G: 57.743%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3858 (0.4038) Acc D Real: 90.134%
Loss D Fake: 0.6571 (0.7436) Acc D Fake: 40.102%
Loss D: 1.043
Loss G: 0.7548 (0.6622) Acc G: 56.905%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3812 (0.4034) Acc D Real: 89.857%
Loss D Fake: 0.6464 (0.7417) Acc D Fake: 40.969%
Loss D: 1.028
Loss G: 0.7626 (0.6642) Acc G: 56.070%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4985 (0.4052) Acc D Real: 89.304%
Loss D Fake: 0.6420 (0.7397) Acc D Fake: 41.832%
Loss D: 1.140
Loss G: 0.7653 (0.6662) Acc G: 55.265%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4918 (0.4069) Acc D Real: 88.736%
Loss D Fake: 0.6411 (0.7378) Acc D Fake: 42.662%
Loss D: 1.133
Loss G: 0.7650 (0.6681) Acc G: 54.490%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3621 (0.4060) Acc D Real: 88.520%
Loss D Fake: 0.6417 (0.7360) Acc D Fake: 43.461%
Loss D: 1.004
Loss G: 0.7642 (0.6699) Acc G: 53.745%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.5193 (0.4081) Acc D Real: 87.914%
Loss D Fake: 0.6431 (0.7343) Acc D Fake: 44.230%
Loss D: 1.162
Loss G: 0.7603 (0.6716) Acc G: 53.028%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3693 (0.4074) Acc D Real: 87.719%
Loss D Fake: 0.6471 (0.7327) Acc D Fake: 44.972%
Loss D: 1.016
Loss G: 0.7553 (0.6731) Acc G: 52.336%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3967 (0.4072) Acc D Real: 87.504%
Loss D Fake: 0.6516 (0.7313) Acc D Fake: 45.686%
Loss D: 1.048
Loss G: 0.7487 (0.6744) Acc G: 51.669%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3088 (0.4055) Acc D Real: 87.475%
Loss D Fake: 0.6584 (0.7300) Acc D Fake: 46.376%
Loss D: 0.967
Loss G: 0.7384 (0.6756) Acc G: 51.026%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3678 (0.4049) Acc D Real: 87.322%
Loss D Fake: 0.6687 (0.7289) Acc D Fake: 47.042%
Loss D: 1.036
Loss G: 0.7261 (0.6764) Acc G: 50.405%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3858 (0.4045) Acc D Real: 87.180%
Loss D Fake: 0.6806 (0.7281) Acc D Fake: 47.657%
Loss D: 1.066
Loss G: 0.7117 (0.6770) Acc G: 49.833%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3750 (0.4040) Acc D Real: 87.072%
Loss D Fake: 0.6951 (0.7276) Acc D Fake: 48.252%
Loss D: 1.070
Loss G: 0.6970 (0.6774) Acc G: 49.280%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3207 (0.4027) Acc D Real: 87.007%
Loss D Fake: 0.7081 (0.7272) Acc D Fake: 48.827%
Loss D: 1.029
Loss G: 0.6991 (0.6777) Acc G: 48.746%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3586 (0.4020) Acc D Real: 86.936%
Loss D Fake: 0.6952 (0.7267) Acc D Fake: 49.383%
Loss D: 1.054
Loss G: 0.7165 (0.6783) Acc G: 48.228%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3053 (0.4004) Acc D Real: 87.030%
Loss D Fake: 0.6755 (0.7259) Acc D Fake: 49.922%
Loss D: 0.981
Loss G: 0.7342 (0.6792) Acc G: 47.701%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3151 (0.3991) Acc D Real: 87.060%
Loss D Fake: 0.6603 (0.7249) Acc D Fake: 50.470%
Loss D: 0.975
Loss G: 0.7506 (0.6803) Acc G: 47.190%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3948 (0.3990) Acc D Real: 86.935%
Loss D Fake: 0.6480 (0.7237) Acc D Fake: 51.002%
Loss D: 1.043
Loss G: 0.7618 (0.6816) Acc G: 46.695%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.4419 (0.3997) Acc D Real: 86.701%
Loss D Fake: 0.6407 (0.7224) Acc D Fake: 51.517%
Loss D: 1.083
Loss G: 0.7693 (0.6829) Acc G: 46.214%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3123 (0.3984) Acc D Real: 86.699%
Loss D Fake: 0.6347 (0.7211) Acc D Fake: 52.016%
Loss D: 0.947
Loss G: 0.7778 (0.6843) Acc G: 45.749%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3889 (0.3982) Acc D Real: 86.620%
Loss D Fake: 0.6471 (0.7200) Acc D Fake: 52.502%
Loss D: 1.036
Loss G: 0.4741 (0.6813) Acc G: 46.252%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3913 (0.3981) Acc D Real: 86.470%
Loss D Fake: 1.1128 (0.7257) Acc D Fake: 51.861%
Loss D: 1.504
Loss G: 0.4189 (0.6774) Acc G: 46.910%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.2888 (0.3966) Acc D Real: 86.516%
Loss D Fake: 1.1566 (0.7319) Acc D Fake: 51.240%
Loss D: 1.445
Loss G: 0.4052 (0.6736) Acc G: 47.550%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3330 (0.3957) Acc D Real: 86.545%
Loss D Fake: 1.1668 (0.7380) Acc D Fake: 50.635%
Loss D: 1.500
Loss G: 0.4026 (0.6697) Acc G: 48.171%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3182 (0.3946) Acc D Real: 86.611%
Loss D Fake: 1.1588 (0.7439) Acc D Fake: 50.048%
Loss D: 1.477
Loss G: 0.4073 (0.6661) Acc G: 48.775%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3384 (0.3938) Acc D Real: 86.654%
Loss D Fake: 1.1365 (0.7492) Acc D Fake: 49.476%
Loss D: 1.475
Loss G: 0.4181 (0.6627) Acc G: 49.363%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2861 (0.3924) Acc D Real: 86.765%
Loss D Fake: 1.1030 (0.7540) Acc D Fake: 48.920%
Loss D: 1.389
Loss G: 0.4340 (0.6596) Acc G: 49.935%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3123 (0.3913) Acc D Real: 86.838%
Loss D Fake: 1.0621 (0.7581) Acc D Fake: 48.379%
Loss D: 1.374
Loss G: 0.4537 (0.6569) Acc G: 50.491%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3218 (0.3904) Acc D Real: 86.913%
Loss D Fake: 1.0183 (0.7615) Acc D Fake: 47.852%
Loss D: 1.340
Loss G: 0.4759 (0.6545) Acc G: 51.033%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3485 (0.3899) Acc D Real: 86.974%
Loss D Fake: 0.9748 (0.7643) Acc D Fake: 47.339%
Loss D: 1.323
Loss G: 0.4995 (0.6525) Acc G: 51.560%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3304 (0.3891) Acc D Real: 87.055%
Loss D Fake: 0.9320 (0.7665) Acc D Fake: 46.839%
Loss D: 1.262
Loss G: 0.5264 (0.6509) Acc G: 52.075%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4053 (0.3893) Acc D Real: 87.154%
Loss D Fake: 0.8863 (0.7680) Acc D Fake: 46.352%
Loss D: 1.292
Loss G: 0.5585 (0.6497) Acc G: 52.576%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3957 (0.3894) Acc D Real: 87.204%
Loss D Fake: 0.8358 (0.7688) Acc D Fake: 45.876%
Loss D: 1.231
Loss G: 0.5905 (0.6489) Acc G: 53.064%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3864 (0.3893) Acc D Real: 87.274%
Loss D Fake: 0.8009 (0.7692) Acc D Fake: 45.413%
Loss D: 1.187
Loss G: 0.6097 (0.6485) Acc G: 53.500%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4006 (0.3895) Acc D Real: 87.271%
Loss D Fake: 0.7821 (0.7694) Acc D Fake: 45.042%
Loss D: 1.183
Loss G: 0.6228 (0.6481) Acc G: 53.864%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.4296 (0.3900) Acc D Real: 87.208%
Loss D Fake: 0.7686 (0.7694) Acc D Fake: 44.700%
Loss D: 1.198
Loss G: 0.6331 (0.6480) Acc G: 54.199%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3537 (0.3895) Acc D Real: 87.212%
Loss D Fake: 0.7577 (0.7692) Acc D Fake: 44.406%
Loss D: 1.111
Loss G: 0.6425 (0.6479) Acc G: 54.486%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3376 (0.3889) Acc D Real: 87.240%
Loss D Fake: 0.7475 (0.7690) Acc D Fake: 44.156%
Loss D: 1.085
Loss G: 0.6514 (0.6479) Acc G: 54.727%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3526 (0.3885) Acc D Real: 87.266%
Loss D Fake: 0.7382 (0.7686) Acc D Fake: 43.953%
Loss D: 1.091
Loss G: 0.6598 (0.6481) Acc G: 54.924%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.4109 (0.3888) Acc D Real: 87.228%
Loss D Fake: 0.7297 (0.7682) Acc D Fake: 43.793%
Loss D: 1.141
Loss G: 0.6673 (0.6483) Acc G: 55.078%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4275 (0.3892) Acc D Real: 87.156%
Loss D Fake: 0.7225 (0.7677) Acc D Fake: 43.674%
Loss D: 1.150
Loss G: 0.6735 (0.6486) Acc G: 55.172%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4556 (0.3899) Acc D Real: 87.096%
Loss D Fake: 0.7168 (0.7671) Acc D Fake: 43.595%
Loss D: 1.172
Loss G: 0.6785 (0.6489) Acc G: 55.226%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4886 (0.3910) Acc D Real: 86.930%
Loss D Fake: 0.7125 (0.7665) Acc D Fake: 43.573%
Loss D: 1.201
Loss G: 0.6820 (0.6493) Acc G: 55.242%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4457 (0.3916) Acc D Real: 86.846%
Loss D Fake: 0.7098 (0.7659) Acc D Fake: 43.589%
Loss D: 1.156
Loss G: 0.6839 (0.6497) Acc G: 55.221%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.4502 (0.3923) Acc D Real: 86.785%
Loss D Fake: 0.7087 (0.7652) Acc D Fake: 43.623%
Loss D: 1.159
Loss G: 0.6845 (0.6501) Acc G: 55.183%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3951 (0.3923) Acc D Real: 86.750%
Loss D Fake: 0.7084 (0.7646) Acc D Fake: 43.655%
Loss D: 1.104
Loss G: 0.6848 (0.6504) Acc G: 55.145%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3858 (0.3922) Acc D Real: 86.735%
Loss D Fake: 0.7085 (0.7640) Acc D Fake: 43.697%
Loss D: 1.094
Loss G: 0.6843 (0.6508) Acc G: 55.108%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.4391 (0.3927) Acc D Real: 86.637%
Loss D Fake: 0.7096 (0.7635) Acc D Fake: 43.729%
Loss D: 1.149
Loss G: 0.6832 (0.6511) Acc G: 55.072%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4679 (0.3935) Acc D Real: 86.540%
Loss D Fake: 0.7112 (0.7629) Acc D Fake: 43.759%
Loss D: 1.179
Loss G: 0.6825 (0.6515) Acc G: 55.019%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3616 (0.3932) Acc D Real: 86.512%
Loss D Fake: 0.7108 (0.7624) Acc D Fake: 43.824%
Loss D: 1.072
Loss G: 0.6855 (0.6518) Acc G: 54.933%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.4291 (0.3935) Acc D Real: 86.482%
Loss D Fake: 0.7059 (0.7618) Acc D Fake: 43.938%
Loss D: 1.135
Loss G: 0.6917 (0.6522) Acc G: 54.763%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3736 (0.3933) Acc D Real: 86.388%
Loss D Fake: 0.6978 (0.7611) Acc D Fake: 44.167%
Loss D: 1.071
Loss G: 0.7020 (0.6527) Acc G: 54.412%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.4697 (0.3941) Acc D Real: 86.330%
Loss D Fake: 0.6875 (0.7604) Acc D Fake: 44.592%
Loss D: 1.157
Loss G: 0.7110 (0.6533) Acc G: 54.002%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3627 (0.3938) Acc D Real: 86.280%
Loss D Fake: 0.6791 (0.7596) Acc D Fake: 45.009%
Loss D: 1.042
Loss G: 0.7205 (0.6540) Acc G: 53.599%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4173 (0.3940) Acc D Real: 86.262%
Loss D Fake: 0.6707 (0.7587) Acc D Fake: 45.417%
Loss D: 1.088
Loss G: 0.7271 (0.6547) Acc G: 53.204%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3327 (0.3934) Acc D Real: 86.289%
Loss D Fake: 0.6699 (0.7579) Acc D Fake: 45.818%
Loss D: 1.003
Loss G: 0.7304 (0.6554) Acc G: 52.817%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3949 (0.3934) Acc D Real: 86.287%
Loss D Fake: 0.6630 (0.7570) Acc D Fake: 46.210%
Loss D: 1.058
Loss G: 0.7347 (0.6562) Acc G: 52.437%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3472 (0.3930) Acc D Real: 86.309%
Loss D Fake: 0.6608 (0.7560) Acc D Fake: 46.596%
Loss D: 1.008
Loss G: 0.7372 (0.6569) Acc G: 52.065%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4047 (0.3931) Acc D Real: 86.261%
Loss D Fake: 0.6590 (0.7551) Acc D Fake: 46.974%
Loss D: 1.064
Loss G: 0.7385 (0.6577) Acc G: 51.700%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.4225 (0.3934) Acc D Real: 86.173%
Loss D Fake: 0.6582 (0.7542) Acc D Fake: 47.345%
Loss D: 1.081
Loss G: 0.7408 (0.6585) Acc G: 51.341%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3465 (0.3930) Acc D Real: 86.208%
Loss D Fake: 0.6557 (0.7533) Acc D Fake: 47.709%
Loss D: 1.002
Loss G: 0.7439 (0.6593) Acc G: 50.989%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.4135 (0.3931) Acc D Real: 86.139%
Loss D Fake: 0.6526 (0.7524) Acc D Fake: 48.066%
Loss D: 1.066
Loss G: 0.7486 (0.6601) Acc G: 50.644%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4169 (0.3934) Acc D Real: 86.057%
Loss D Fake: 0.6481 (0.7514) Acc D Fake: 48.417%
Loss D: 1.065
Loss G: 0.7525 (0.6609) Acc G: 50.304%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3656 (0.3931) Acc D Real: 86.065%
Loss D Fake: 0.6458 (0.7505) Acc D Fake: 48.762%
Loss D: 1.011
Loss G: 0.7543 (0.6618) Acc G: 49.971%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3857 (0.3930) Acc D Real: 86.019%
Loss D Fake: 0.6446 (0.7495) Acc D Fake: 49.100%
Loss D: 1.030
Loss G: 0.7545 (0.6626) Acc G: 49.644%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3595 (0.3928) Acc D Real: 85.973%
Loss D Fake: 0.6464 (0.7486) Acc D Fake: 49.433%
Loss D: 1.006
Loss G: 0.7559 (0.6634) Acc G: 49.323%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3684 (0.3925) Acc D Real: 85.937%
Loss D Fake: 0.6422 (0.7477) Acc D Fake: 49.759%
Loss D: 1.011
Loss G: 0.7587 (0.6643) Acc G: 49.007%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3508 (0.3922) Acc D Real: 85.901%
Loss D Fake: 0.6425 (0.7468) Acc D Fake: 50.080%
Loss D: 0.993
Loss G: 0.7480 (0.6650) Acc G: 48.697%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3068 (0.3914) Acc D Real: 85.904%
Loss D Fake: 0.7061 (0.7464) Acc D Fake: 50.194%
Loss D: 1.013
Loss G: 0.7698 (0.6659) Acc G: 48.392%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3676 (0.3912) Acc D Real: 85.822%
Loss D Fake: 0.6421 (0.7455) Acc D Fake: 50.506%
Loss D: 1.010
Loss G: 0.7871 (0.6669) Acc G: 48.093%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3520 (0.3909) Acc D Real: 85.757%
Loss D Fake: 0.6129 (0.7444) Acc D Fake: 50.813%
Loss D: 0.965
Loss G: 0.7967 (0.6680) Acc G: 47.784%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3349 (0.3904) Acc D Real: 85.709%
Loss D Fake: 0.6093 (0.7433) Acc D Fake: 51.128%
Loss D: 0.944
Loss G: 0.8015 (0.6692) Acc G: 47.480%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3405 (0.3900) Acc D Real: 85.647%
Loss D Fake: 0.6051 (0.7421) Acc D Fake: 51.438%
Loss D: 0.946
Loss G: 0.8077 (0.6703) Acc G: 47.182%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.2938 (0.3892) Acc D Real: 85.648%
Loss D Fake: 0.5996 (0.7409) Acc D Fake: 51.743%
Loss D: 0.893
Loss G: 0.8157 (0.6715) Acc G: 46.888%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3593 (0.3890) Acc D Real: 85.587%
Loss D Fake: 0.5938 (0.7397) Acc D Fake: 52.043%
Loss D: 0.953
Loss G: 0.8223 (0.6728) Acc G: 46.600%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3449 (0.3886) Acc D Real: 85.528%
Loss D Fake: 0.5897 (0.7385) Acc D Fake: 52.338%
Loss D: 0.935
Loss G: 0.8268 (0.6740) Acc G: 46.316%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3388 (0.3882) Acc D Real: 85.465%
Loss D Fake: 0.5863 (0.7373) Acc D Fake: 52.628%
Loss D: 0.925
Loss G: 0.8330 (0.6753) Acc G: 46.036%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2995 (0.3875) Acc D Real: 85.435%
Loss D Fake: 0.5817 (0.7361) Acc D Fake: 52.914%
Loss D: 0.881
Loss G: 0.8387 (0.6766) Acc G: 45.761%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3638 (0.3873) Acc D Real: 85.381%
Loss D Fake: 0.5786 (0.7348) Acc D Fake: 53.195%
Loss D: 0.942
Loss G: 0.8411 (0.6779) Acc G: 45.491%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.2794 (0.3865) Acc D Real: 85.374%
Loss D Fake: 0.5770 (0.7336) Acc D Fake: 53.472%
Loss D: 0.856
Loss G: 0.8455 (0.6792) Acc G: 45.224%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3750 (0.3864) Acc D Real: 85.298%
Loss D Fake: 0.5737 (0.7323) Acc D Fake: 53.744%
Loss D: 0.949
Loss G: 0.8492 (0.6806) Acc G: 44.962%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3794 (0.3863) Acc D Real: 85.211%
Loss D Fake: 0.5728 (0.7311) Acc D Fake: 54.012%
Loss D: 0.952
Loss G: 0.8476 (0.6818) Acc G: 44.704%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.3716 (0.3862) Acc D Real: 85.151%
Loss D Fake: 0.5769 (0.7299) Acc D Fake: 54.276%
Loss D: 0.948
Loss G: 0.8417 (0.6831) Acc G: 44.450%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2621 (0.3853) Acc D Real: 85.145%
Loss D Fake: 0.5775 (0.7287) Acc D Fake: 54.536%
Loss D: 0.840
Loss G: 0.8555 (0.6844) Acc G: 44.200%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3208 (0.3848) Acc D Real: 85.107%
Loss D Fake: 0.5617 (0.7275) Acc D Fake: 54.792%
Loss D: 0.883
Loss G: 0.8738 (0.6858) Acc G: 43.953%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.2919 (0.3841) Acc D Real: 85.099%
Loss D Fake: 0.5511 (0.7261) Acc D Fake: 55.044%
Loss D: 0.843
Loss G: 0.8873 (0.6873) Acc G: 43.710%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3534 (0.3839) Acc D Real: 85.010%
Loss D Fake: 0.5434 (0.7248) Acc D Fake: 55.293%
Loss D: 0.897
Loss G: 0.8978 (0.6889) Acc G: 43.471%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4057 (0.3840) Acc D Real: 84.900%
Loss D Fake: 0.5380 (0.7234) Acc D Fake: 55.537%
Loss D: 0.944
Loss G: 0.9038 (0.6905) Acc G: 43.236%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3494 (0.3838) Acc D Real: 84.829%
Loss D Fake: 0.5351 (0.7220) Acc D Fake: 55.779%
Loss D: 0.885
Loss G: 0.9083 (0.6921) Acc G: 43.004%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.2670 (0.3829) Acc D Real: 84.824%
Loss D Fake: 0.5326 (0.7206) Acc D Fake: 56.016%
Loss D: 0.800
Loss G: 0.9121 (0.6937) Acc G: 42.775%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3781 (0.3829) Acc D Real: 84.735%
Loss D Fake: 0.5306 (0.7192) Acc D Fake: 56.250%
Loss D: 0.909
Loss G: 0.9145 (0.6953) Acc G: 42.549%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3463 (0.3826) Acc D Real: 84.674%
Loss D Fake: 0.5293 (0.7179) Acc D Fake: 56.481%
Loss D: 0.876
Loss G: 0.9171 (0.6969) Acc G: 42.327%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3396 (0.3823) Acc D Real: 84.615%
Loss D Fake: 0.5277 (0.7165) Acc D Fake: 56.709%
Loss D: 0.867
Loss G: 0.9193 (0.6985) Acc G: 42.108%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3063 (0.3818) Acc D Real: 84.580%
Loss D Fake: 0.5266 (0.7152) Acc D Fake: 56.933%
Loss D: 0.833
Loss G: 0.9212 (0.7001) Acc G: 41.892%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.2520 (0.3808) Acc D Real: 84.595%
Loss D Fake: 0.5255 (0.7138) Acc D Fake: 57.154%
Loss D: 0.777
Loss G: 0.9232 (0.7016) Acc G: 41.680%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3453 (0.3806) Acc D Real: 84.540%
Loss D Fake: 0.5243 (0.7125) Acc D Fake: 57.372%
Loss D: 0.870
Loss G: 0.9255 (0.7032) Acc G: 41.470%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.4166 (0.3808) Acc D Real: 84.421%
Loss D Fake: 0.5243 (0.7112) Acc D Fake: 57.587%
Loss D: 0.941
Loss G: 0.9206 (0.7047) Acc G: 41.263%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.3695 (0.3808) Acc D Real: 84.349%
Loss D Fake: 0.5312 (0.7100) Acc D Fake: 57.799%
Loss D: 0.901
Loss G: 0.9088 (0.7061) Acc G: 41.059%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.3611 (0.3806) Acc D Real: 84.281%
Loss D Fake: 0.5447 (0.7088) Acc D Fake: 58.008%
Loss D: 0.906
Loss G: 0.9118 (0.7075) Acc G: 40.857%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.4042 (0.3808) Acc D Real: 84.172%
Loss D Fake: 0.5286 (0.7076) Acc D Fake: 58.215%
Loss D: 0.933
Loss G: 0.9230 (0.7090) Acc G: 40.659%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.4076 (0.3810) Acc D Real: 84.068%
Loss D Fake: 0.5249 (0.7064) Acc D Fake: 58.418%
Loss D: 0.932
Loss G: 0.9228 (0.7104) Acc G: 40.463%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.4233 (0.3813) Acc D Real: 83.945%
Loss D Fake: 0.5263 (0.7052) Acc D Fake: 58.619%
Loss D: 0.950
Loss G: 0.9201 (0.7119) Acc G: 40.270%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.2947 (0.3807) Acc D Real: 83.936%
Loss D Fake: 0.5272 (0.7040) Acc D Fake: 58.817%
Loss D: 0.822
Loss G: 0.9207 (0.7132) Acc G: 40.079%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.2943 (0.3801) Acc D Real: 83.916%
Loss D Fake: 0.5264 (0.7028) Acc D Fake: 59.012%
Loss D: 0.821
Loss G: 0.9244 (0.7146) Acc G: 39.891%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.2909 (0.3795) Acc D Real: 83.899%
Loss D Fake: 0.5233 (0.7016) Acc D Fake: 59.216%
Loss D: 0.814
Loss G: 0.9307 (0.7161) Acc G: 39.694%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3306 (0.3792) Acc D Real: 83.857%
Loss D Fake: 0.5199 (0.7004) Acc D Fake: 59.418%
Loss D: 0.850
Loss G: 0.9359 (0.7175) Acc G: 39.500%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3517 (0.3790) Acc D Real: 83.789%
Loss D Fake: 0.5177 (0.6992) Acc D Fake: 59.616%
Loss D: 0.869
Loss G: 0.9415 (0.7190) Acc G: 39.308%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.2808 (0.3784) Acc D Real: 83.772%
Loss D Fake: 0.5128 (0.6980) Acc D Fake: 59.812%
Loss D: 0.794
Loss G: 0.9530 (0.7205) Acc G: 39.119%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.3481 (0.3782) Acc D Real: 83.704%
Loss D Fake: 0.5059 (0.6968) Acc D Fake: 60.006%
Loss D: 0.854
Loss G: 0.9623 (0.7220) Acc G: 38.933%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.3414 (0.3780) Acc D Real: 83.655%
Loss D Fake: 0.5018 (0.6956) Acc D Fake: 60.197%
Loss D: 0.843
Loss G: 0.9677 (0.7236) Acc G: 38.748%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.5217 (0.3789) Acc D Real: 83.639%
Loss D Fake: 0.5153 (0.6944) Acc D Fake: 60.215%
Loss D: 1.037
Loss G: 0.9333 (0.7249) Acc G: 38.731%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.144 | Generator Loss: 0.931 | Avg: 2.075
TRAIN Iteration: [   2/158]
Loss D Real: 0.4066 (0.3858) Acc D Real: 69.505%
Loss D Fake: 0.5019 (0.5122) Acc D Fake: 90.000%
Loss D: 0.909
Loss G: 0.9563 (0.9650) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3511 (0.3743) Acc D Real: 70.955%
Loss D Fake: 0.5153 (0.5132) Acc D Fake: 90.000%
Loss D: 0.866
Loss G: 0.9540 (0.9613) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2639 (0.3467) Acc D Real: 74.479%
Loss D Fake: 0.5050 (0.5112) Acc D Fake: 90.000%
Loss D: 0.769
Loss G: 0.9738 (0.9644) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4445 (0.3662) Acc D Real: 72.750%
Loss D Fake: 0.4961 (0.5082) Acc D Fake: 90.000%
Loss D: 0.941
Loss G: 0.9790 (0.9674) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.2741 (0.3509) Acc D Real: 74.731%
Loss D Fake: 0.4951 (0.5060) Acc D Fake: 90.000%
Loss D: 0.769
Loss G: 0.9839 (0.9701) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3709 (0.3537) Acc D Real: 74.598%
Loss D Fake: 0.4921 (0.5040) Acc D Fake: 90.000%
Loss D: 0.863
Loss G: 0.9888 (0.9728) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3171 (0.3492) Acc D Real: 75.228%
Loss D Fake: 0.4898 (0.5022) Acc D Fake: 90.000%
Loss D: 0.807
Loss G: 0.9940 (0.9754) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3671 (0.3512) Acc D Real: 74.925%
Loss D Fake: 0.4871 (0.5005) Acc D Fake: 90.000%
Loss D: 0.854
Loss G: 0.9989 (0.9780) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3338 (0.3494) Acc D Real: 75.031%
Loss D Fake: 0.4871 (0.4992) Acc D Fake: 90.000%
Loss D: 0.821
Loss G: 0.9907 (0.9793) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3030 (0.3452) Acc D Real: 75.559%
Loss D Fake: 0.4949 (0.4988) Acc D Fake: 90.000%
Loss D: 0.798
Loss G: 0.9797 (0.9793) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.2862 (0.3403) Acc D Real: 76.029%
Loss D Fake: 0.4999 (0.4989) Acc D Fake: 90.000%
Loss D: 0.786
Loss G: 0.9835 (0.9797) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.2988 (0.3371) Acc D Real: 76.462%
Loss D Fake: 0.4922 (0.4984) Acc D Fake: 89.872%
Loss D: 0.791
Loss G: 0.9994 (0.9812) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3546 (0.3383) Acc D Real: 76.261%
Loss D Fake: 0.4846 (0.4974) Acc D Fake: 89.762%
Loss D: 0.839
Loss G: 1.0055 (0.9829) Acc G: 10.119%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3016 (0.3359) Acc D Real: 76.479%
Loss D Fake: 0.4857 (0.4966) Acc D Fake: 89.667%
Loss D: 0.787
Loss G: 0.9920 (0.9835) Acc G: 10.222%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3707 (0.3381) Acc D Real: 76.201%
Loss D Fake: 0.5165 (0.4979) Acc D Fake: 89.583%
Loss D: 0.887
Loss G: 1.0134 (0.9854) Acc G: 10.312%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3345 (0.3379) Acc D Real: 76.241%
Loss D Fake: 0.4987 (0.4979) Acc D Fake: 89.510%
Loss D: 0.833
Loss G: 0.9741 (0.9847) Acc G: 10.392%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.4154 (0.3422) Acc D Real: 75.660%
Loss D Fake: 0.4917 (0.4976) Acc D Fake: 89.444%
Loss D: 0.907
Loss G: 1.0445 (0.9881) Acc G: 10.463%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.2770 (0.3387) Acc D Real: 76.028%
Loss D Fake: 0.4595 (0.4956) Acc D Fake: 89.298%
Loss D: 0.736
Loss G: 1.0542 (0.9916) Acc G: 10.614%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.4116 (0.3424) Acc D Real: 75.573%
Loss D Fake: 0.4606 (0.4938) Acc D Fake: 89.167%
Loss D: 0.872
Loss G: 1.0495 (0.9944) Acc G: 10.750%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.4019 (0.3452) Acc D Real: 75.312%
Loss D Fake: 0.4647 (0.4924) Acc D Fake: 89.048%
Loss D: 0.867
Loss G: 1.0365 (0.9964) Acc G: 10.873%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.4180 (0.3485) Acc D Real: 74.934%
Loss D Fake: 0.4741 (0.4916) Acc D Fake: 88.939%
Loss D: 0.892
Loss G: 1.0169 (0.9974) Acc G: 10.985%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3515 (0.3487) Acc D Real: 74.880%
Loss D Fake: 0.4893 (0.4915) Acc D Fake: 88.841%
Loss D: 0.841
Loss G: 0.9990 (0.9975) Acc G: 11.087%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.2168 (0.3432) Acc D Real: 75.510%
Loss D Fake: 0.4937 (0.4916) Acc D Fake: 88.750%
Loss D: 0.711
Loss G: 1.0206 (0.9984) Acc G: 11.181%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.2833 (0.3408) Acc D Real: 75.744%
Loss D Fake: 0.4752 (0.4909) Acc D Fake: 88.667%
Loss D: 0.758
Loss G: 1.0322 (0.9998) Acc G: 11.267%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3157 (0.3398) Acc D Real: 75.921%
Loss D Fake: 0.4724 (0.4902) Acc D Fake: 88.590%
Loss D: 0.788
Loss G: 1.0382 (1.0012) Acc G: 11.346%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4523 (0.3440) Acc D Real: 75.459%
Loss D Fake: 0.4684 (0.4894) Acc D Fake: 88.519%
Loss D: 0.921
Loss G: 1.0477 (1.0030) Acc G: 11.420%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3227 (0.3432) Acc D Real: 75.502%
Loss D Fake: 0.4636 (0.4885) Acc D Fake: 88.512%
Loss D: 0.786
Loss G: 1.0497 (1.0046) Acc G: 11.429%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3477 (0.3434) Acc D Real: 75.424%
Loss D Fake: 0.4695 (0.4878) Acc D Fake: 88.506%
Loss D: 0.817
Loss G: 0.9951 (1.0043) Acc G: 11.437%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3701 (0.3443) Acc D Real: 75.292%
Loss D Fake: 1.5329 (0.5227) Acc D Fake: 86.444%
Loss D: 1.903
Loss G: 0.4612 (0.9862) Acc G: 13.167%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3360 (0.3440) Acc D Real: 75.247%
Loss D Fake: 1.3235 (0.5485) Acc D Fake: 84.839%
Loss D: 1.659
Loss G: 0.8414 (0.9815) Acc G: 13.118%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3819 (0.3452) Acc D Real: 75.003%
Loss D Fake: 0.5797 (0.5495) Acc D Fake: 84.948%
Loss D: 0.962
Loss G: 0.8374 (0.9770) Acc G: 13.073%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.5612 (0.3517) Acc D Real: 74.145%
Loss D Fake: 0.5741 (0.5502) Acc D Fake: 85.051%
Loss D: 1.135
Loss G: 0.8447 (0.9730) Acc G: 13.030%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.5163 (0.3566) Acc D Real: 73.511%
Loss D Fake: 0.5693 (0.5508) Acc D Fake: 85.147%
Loss D: 1.086
Loss G: 0.8495 (0.9694) Acc G: 12.990%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.5403 (0.3618) Acc D Real: 72.817%
Loss D Fake: 0.5669 (0.5512) Acc D Fake: 85.284%
Loss D: 1.107
Loss G: 0.8513 (0.9660) Acc G: 12.905%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.4761 (0.3650) Acc D Real: 72.352%
Loss D Fake: 0.5665 (0.5517) Acc D Fake: 85.415%
Loss D: 1.043
Loss G: 0.8509 (0.9628) Acc G: 12.824%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.5092 (0.3689) Acc D Real: 71.857%
Loss D Fake: 0.5673 (0.5521) Acc D Fake: 85.539%
Loss D: 1.076
Loss G: 0.8488 (0.9597) Acc G: 12.748%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.5921 (0.3748) Acc D Real: 71.073%
Loss D Fake: 0.5695 (0.5525) Acc D Fake: 85.657%
Loss D: 1.162
Loss G: 0.8442 (0.9567) Acc G: 12.763%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.5186 (0.3784) Acc D Real: 70.576%
Loss D Fake: 0.5734 (0.5531) Acc D Fake: 85.682%
Loss D: 1.092
Loss G: 0.8381 (0.9537) Acc G: 12.778%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.5125 (0.3818) Acc D Real: 70.064%
Loss D Fake: 0.5782 (0.5537) Acc D Fake: 85.707%
Loss D: 1.091
Loss G: 0.8310 (0.9506) Acc G: 12.792%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.5083 (0.3849) Acc D Real: 69.605%
Loss D Fake: 0.5835 (0.5544) Acc D Fake: 85.730%
Loss D: 1.092
Loss G: 0.8234 (0.9475) Acc G: 12.805%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3914 (0.3850) Acc D Real: 69.475%
Loss D Fake: 0.5890 (0.5553) Acc D Fake: 85.753%
Loss D: 0.980
Loss G: 0.8166 (0.9444) Acc G: 12.817%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.4759 (0.3872) Acc D Real: 69.110%
Loss D Fake: 0.5940 (0.5562) Acc D Fake: 85.774%
Loss D: 1.070
Loss G: 0.8096 (0.9412) Acc G: 12.829%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.4764 (0.3892) Acc D Real: 68.780%
Loss D Fake: 0.5993 (0.5571) Acc D Fake: 85.794%
Loss D: 1.076
Loss G: 0.8026 (0.9381) Acc G: 12.841%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4739 (0.3911) Acc D Real: 68.443%
Loss D Fake: 0.6047 (0.5582) Acc D Fake: 85.814%
Loss D: 1.079
Loss G: 0.7956 (0.9349) Acc G: 12.852%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.5212 (0.3939) Acc D Real: 68.014%
Loss D Fake: 0.6102 (0.5593) Acc D Fake: 85.832%
Loss D: 1.131
Loss G: 0.7885 (0.9317) Acc G: 12.862%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.5027 (0.3962) Acc D Real: 67.588%
Loss D Fake: 0.6161 (0.5605) Acc D Fake: 85.814%
Loss D: 1.119
Loss G: 0.7807 (0.9285) Acc G: 12.908%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.4998 (0.3984) Acc D Real: 67.207%
Loss D Fake: 0.6224 (0.5618) Acc D Fake: 85.798%
Loss D: 1.122
Loss G: 0.7728 (0.9253) Acc G: 12.986%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3704 (0.3978) Acc D Real: 67.190%
Loss D Fake: 0.6286 (0.5632) Acc D Fake: 85.747%
Loss D: 0.999
Loss G: 0.7663 (0.9220) Acc G: 13.061%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.5127 (0.4001) Acc D Real: 66.771%
Loss D Fake: 0.6338 (0.5646) Acc D Fake: 85.699%
Loss D: 1.146
Loss G: 0.7596 (0.9188) Acc G: 13.133%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4763 (0.4016) Acc D Real: 66.458%
Loss D Fake: 0.6395 (0.5661) Acc D Fake: 85.653%
Loss D: 1.116
Loss G: 0.7528 (0.9155) Acc G: 13.203%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4237 (0.4020) Acc D Real: 66.320%
Loss D Fake: 0.6452 (0.5676) Acc D Fake: 85.608%
Loss D: 1.069
Loss G: 0.7467 (0.9123) Acc G: 13.269%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4032 (0.4020) Acc D Real: 66.207%
Loss D Fake: 0.6502 (0.5691) Acc D Fake: 85.565%
Loss D: 1.053
Loss G: 0.7413 (0.9091) Acc G: 13.333%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3755 (0.4015) Acc D Real: 66.160%
Loss D Fake: 0.6545 (0.5707) Acc D Fake: 85.524%
Loss D: 1.030
Loss G: 0.7369 (0.9059) Acc G: 13.395%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.4148 (0.4018) Acc D Real: 66.012%
Loss D Fake: 0.6581 (0.5723) Acc D Fake: 85.484%
Loss D: 1.073
Loss G: 0.7330 (0.9027) Acc G: 13.455%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3990 (0.4017) Acc D Real: 65.907%
Loss D Fake: 0.6615 (0.5739) Acc D Fake: 85.445%
Loss D: 1.060
Loss G: 0.7294 (0.8996) Acc G: 13.512%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3920 (0.4016) Acc D Real: 65.809%
Loss D Fake: 0.6644 (0.5755) Acc D Fake: 85.408%
Loss D: 1.056
Loss G: 0.7264 (0.8966) Acc G: 13.567%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.4372 (0.4022) Acc D Real: 65.611%
Loss D Fake: 0.6672 (0.5771) Acc D Fake: 85.373%
Loss D: 1.104
Loss G: 0.7233 (0.8936) Acc G: 13.621%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4285 (0.4026) Acc D Real: 65.443%
Loss D Fake: 0.6701 (0.5786) Acc D Fake: 85.338%
Loss D: 1.099
Loss G: 0.7201 (0.8907) Acc G: 13.672%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3854 (0.4023) Acc D Real: 65.379%
Loss D Fake: 0.6729 (0.5802) Acc D Fake: 85.305%
Loss D: 1.058
Loss G: 0.7172 (0.8878) Acc G: 13.722%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3056 (0.4008) Acc D Real: 65.518%
Loss D Fake: 0.6751 (0.5818) Acc D Fake: 85.272%
Loss D: 0.981
Loss G: 0.7159 (0.8850) Acc G: 13.770%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.4467 (0.4015) Acc D Real: 65.386%
Loss D Fake: 0.6761 (0.5833) Acc D Fake: 85.241%
Loss D: 1.123
Loss G: 0.7145 (0.8822) Acc G: 13.817%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.4570 (0.4024) Acc D Real: 65.198%
Loss D Fake: 0.6777 (0.5848) Acc D Fake: 85.211%
Loss D: 1.135
Loss G: 0.7122 (0.8795) Acc G: 13.862%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3263 (0.4012) Acc D Real: 65.306%
Loss D Fake: 0.6797 (0.5863) Acc D Fake: 85.181%
Loss D: 1.006
Loss G: 0.7107 (0.8769) Acc G: 13.906%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4251 (0.4016) Acc D Real: 65.225%
Loss D Fake: 0.6810 (0.5877) Acc D Fake: 85.127%
Loss D: 1.106
Loss G: 0.7092 (0.8743) Acc G: 13.974%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3242 (0.4004) Acc D Real: 65.321%
Loss D Fake: 0.6823 (0.5892) Acc D Fake: 85.075%
Loss D: 1.006
Loss G: 0.7084 (0.8718) Acc G: 14.040%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3410 (0.3995) Acc D Real: 65.483%
Loss D Fake: 0.6826 (0.5906) Acc D Fake: 85.024%
Loss D: 1.024
Loss G: 0.7084 (0.8693) Acc G: 14.104%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4357 (0.4000) Acc D Real: 65.427%
Loss D Fake: 0.6826 (0.5919) Acc D Fake: 84.975%
Loss D: 1.118
Loss G: 0.7080 (0.8670) Acc G: 14.167%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3413 (0.3992) Acc D Real: 65.515%
Loss D Fake: 0.6830 (0.5932) Acc D Fake: 84.927%
Loss D: 1.024
Loss G: 0.7080 (0.8647) Acc G: 14.227%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4323 (0.3996) Acc D Real: 65.478%
Loss D Fake: 0.6831 (0.5945) Acc D Fake: 84.880%
Loss D: 1.115
Loss G: 0.7075 (0.8624) Acc G: 14.286%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3903 (0.3995) Acc D Real: 65.484%
Loss D Fake: 0.6838 (0.5958) Acc D Fake: 84.835%
Loss D: 1.074
Loss G: 0.7067 (0.8602) Acc G: 14.343%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3608 (0.3990) Acc D Real: 65.549%
Loss D Fake: 0.6845 (0.5970) Acc D Fake: 84.791%
Loss D: 1.045
Loss G: 0.7061 (0.8581) Acc G: 14.398%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3337 (0.3981) Acc D Real: 65.659%
Loss D Fake: 0.6847 (0.5982) Acc D Fake: 84.748%
Loss D: 1.018
Loss G: 0.7064 (0.8560) Acc G: 14.452%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.4480 (0.3988) Acc D Real: 65.612%
Loss D Fake: 0.6846 (0.5994) Acc D Fake: 84.707%
Loss D: 1.133
Loss G: 0.7059 (0.8540) Acc G: 14.505%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3742 (0.3984) Acc D Real: 65.688%
Loss D Fake: 0.6852 (0.6005) Acc D Fake: 84.666%
Loss D: 1.059
Loss G: 0.7054 (0.8520) Acc G: 14.556%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3916 (0.3983) Acc D Real: 65.656%
Loss D Fake: 0.6857 (0.6016) Acc D Fake: 84.627%
Loss D: 1.077
Loss G: 0.7048 (0.8501) Acc G: 14.605%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3571 (0.3978) Acc D Real: 65.724%
Loss D Fake: 0.6862 (0.6027) Acc D Fake: 84.588%
Loss D: 1.043
Loss G: 0.7045 (0.8482) Acc G: 14.654%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3593 (0.3973) Acc D Real: 65.783%
Loss D Fake: 0.6863 (0.6038) Acc D Fake: 84.551%
Loss D: 1.046
Loss G: 0.7046 (0.8463) Acc G: 14.701%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3647 (0.3969) Acc D Real: 65.906%
Loss D Fake: 0.6861 (0.6049) Acc D Fake: 84.514%
Loss D: 1.051
Loss G: 0.7049 (0.8445) Acc G: 14.747%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3200 (0.3959) Acc D Real: 66.050%
Loss D Fake: 0.6856 (0.6059) Acc D Fake: 84.479%
Loss D: 1.006
Loss G: 0.7057 (0.8428) Acc G: 14.792%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4395 (0.3965) Acc D Real: 65.990%
Loss D Fake: 0.6848 (0.6068) Acc D Fake: 84.444%
Loss D: 1.124
Loss G: 0.7061 (0.8411) Acc G: 14.835%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4822 (0.3975) Acc D Real: 65.966%
Loss D Fake: 0.6851 (0.6078) Acc D Fake: 84.410%
Loss D: 1.167
Loss G: 0.7051 (0.8395) Acc G: 14.878%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.4120 (0.3977) Acc D Real: 65.997%
Loss D Fake: 0.6864 (0.6087) Acc D Fake: 84.377%
Loss D: 1.098
Loss G: 0.7036 (0.8378) Acc G: 14.920%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3502 (0.3971) Acc D Real: 66.096%
Loss D Fake: 0.6878 (0.6097) Acc D Fake: 84.345%
Loss D: 1.038
Loss G: 0.7024 (0.8362) Acc G: 14.977%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3629 (0.3967) Acc D Real: 66.176%
Loss D Fake: 0.6887 (0.6106) Acc D Fake: 84.294%
Loss D: 1.052
Loss G: 0.7017 (0.8346) Acc G: 15.036%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4690 (0.3976) Acc D Real: 66.126%
Loss D Fake: 0.6895 (0.6115) Acc D Fake: 84.244%
Loss D: 1.159
Loss G: 0.7003 (0.8331) Acc G: 15.094%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3993 (0.3976) Acc D Real: 66.162%
Loss D Fake: 0.6911 (0.6124) Acc D Fake: 84.195%
Loss D: 1.090
Loss G: 0.6987 (0.8315) Acc G: 15.150%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4700 (0.3984) Acc D Real: 66.161%
Loss D Fake: 0.6929 (0.6134) Acc D Fake: 84.147%
Loss D: 1.163
Loss G: 0.6964 (0.8300) Acc G: 15.205%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4107 (0.3986) Acc D Real: 66.222%
Loss D Fake: 0.6954 (0.6143) Acc D Fake: 84.101%
Loss D: 1.106
Loss G: 0.6939 (0.8285) Acc G: 15.259%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3361 (0.3979) Acc D Real: 66.339%
Loss D Fake: 0.6975 (0.6152) Acc D Fake: 84.055%
Loss D: 1.034
Loss G: 0.6924 (0.8269) Acc G: 15.312%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4095 (0.3980) Acc D Real: 66.304%
Loss D Fake: 0.6988 (0.6161) Acc D Fake: 84.010%
Loss D: 1.108
Loss G: 0.6910 (0.8254) Acc G: 15.363%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3838 (0.3978) Acc D Real: 66.402%
Loss D Fake: 0.7001 (0.6170) Acc D Fake: 83.967%
Loss D: 1.084
Loss G: 0.6897 (0.8240) Acc G: 15.414%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4224 (0.3981) Acc D Real: 66.495%
Loss D Fake: 0.7014 (0.6179) Acc D Fake: 83.924%
Loss D: 1.124
Loss G: 0.6882 (0.8225) Acc G: 15.463%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4242 (0.3984) Acc D Real: 66.565%
Loss D Fake: 0.7032 (0.6189) Acc D Fake: 83.882%
Loss D: 1.127
Loss G: 0.6863 (0.8211) Acc G: 15.511%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3953 (0.3983) Acc D Real: 66.692%
Loss D Fake: 0.7051 (0.6198) Acc D Fake: 83.842%
Loss D: 1.100
Loss G: 0.6846 (0.8196) Acc G: 15.559%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4033 (0.3984) Acc D Real: 66.763%
Loss D Fake: 0.7066 (0.6207) Acc D Fake: 83.792%
Loss D: 1.110
Loss G: 0.6831 (0.8182) Acc G: 15.619%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3491 (0.3979) Acc D Real: 66.909%
Loss D Fake: 0.7080 (0.6216) Acc D Fake: 83.736%
Loss D: 1.057
Loss G: 0.6822 (0.8168) Acc G: 15.681%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.4761 (0.3987) Acc D Real: 66.951%
Loss D Fake: 0.7090 (0.6225) Acc D Fake: 83.681%
Loss D: 1.185
Loss G: 0.6805 (0.8154) Acc G: 15.742%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3876 (0.3986) Acc D Real: 67.049%
Loss D Fake: 0.7109 (0.6233) Acc D Fake: 83.627%
Loss D: 1.098
Loss G: 0.6789 (0.8140) Acc G: 15.802%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3878 (0.3985) Acc D Real: 67.193%
Loss D Fake: 0.7122 (0.6242) Acc D Fake: 83.191%
Loss D: 1.100
Loss G: 0.6778 (0.8127) Acc G: 16.170%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4209 (0.3987) Acc D Real: 67.223%
Loss D Fake: 0.7133 (0.6251) Acc D Fake: 82.631%
Loss D: 1.134
Loss G: 0.6766 (0.8113) Acc G: 16.736%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.2983 (0.3977) Acc D Real: 67.399%
Loss D Fake: 0.7142 (0.6260) Acc D Fake: 82.034%
Loss D: 1.013
Loss G: 0.6765 (0.8100) Acc G: 17.291%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3169 (0.3969) Acc D Real: 67.566%
Loss D Fake: 0.7137 (0.6268) Acc D Fake: 81.496%
Loss D: 1.031
Loss G: 0.6776 (0.8087) Acc G: 17.703%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.4124 (0.3971) Acc D Real: 67.683%
Loss D Fake: 0.7125 (0.6277) Acc D Fake: 81.065%
Loss D: 1.125
Loss G: 0.6784 (0.8075) Acc G: 17.741%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3940 (0.3970) Acc D Real: 67.818%
Loss D Fake: 0.7119 (0.6285) Acc D Fake: 81.039%
Loss D: 1.106
Loss G: 0.6788 (0.8062) Acc G: 17.778%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3635 (0.3967) Acc D Real: 67.954%
Loss D Fake: 0.7115 (0.6293) Acc D Fake: 81.014%
Loss D: 1.075
Loss G: 0.6794 (0.8050) Acc G: 17.815%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.4025 (0.3968) Acc D Real: 68.033%
Loss D Fake: 0.7110 (0.6300) Acc D Fake: 80.989%
Loss D: 1.113
Loss G: 0.6797 (0.8039) Acc G: 17.851%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3430 (0.3963) Acc D Real: 68.150%
Loss D Fake: 0.7106 (0.6308) Acc D Fake: 80.964%
Loss D: 1.054
Loss G: 0.6803 (0.8027) Acc G: 17.886%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.4168 (0.3965) Acc D Real: 68.242%
Loss D Fake: 0.7100 (0.6315) Acc D Fake: 80.940%
Loss D: 1.127
Loss G: 0.6807 (0.8016) Acc G: 17.921%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3413 (0.3960) Acc D Real: 68.335%
Loss D Fake: 0.7096 (0.6322) Acc D Fake: 80.916%
Loss D: 1.051
Loss G: 0.6813 (0.8005) Acc G: 17.955%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3869 (0.3959) Acc D Real: 68.387%
Loss D Fake: 0.7088 (0.6329) Acc D Fake: 80.893%
Loss D: 1.096
Loss G: 0.6821 (0.7994) Acc G: 17.988%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3253 (0.3953) Acc D Real: 68.535%
Loss D Fake: 0.7079 (0.6336) Acc D Fake: 80.870%
Loss D: 1.033
Loss G: 0.6834 (0.7984) Acc G: 18.021%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3984 (0.3953) Acc D Real: 68.591%
Loss D Fake: 0.7065 (0.6342) Acc D Fake: 80.848%
Loss D: 1.105
Loss G: 0.6846 (0.7974) Acc G: 18.054%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.2597 (0.3941) Acc D Real: 68.750%
Loss D Fake: 0.7049 (0.6348) Acc D Fake: 80.826%
Loss D: 0.965
Loss G: 0.6871 (0.7964) Acc G: 18.085%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.2620 (0.3929) Acc D Real: 68.875%
Loss D Fake: 0.7017 (0.6354) Acc D Fake: 80.804%
Loss D: 0.964
Loss G: 0.6910 (0.7955) Acc G: 18.116%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.4029 (0.3930) Acc D Real: 68.883%
Loss D Fake: 0.6979 (0.6359) Acc D Fake: 80.783%
Loss D: 1.101
Loss G: 0.6943 (0.7946) Acc G: 18.147%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3470 (0.3926) Acc D Real: 68.974%
Loss D Fake: 0.6949 (0.6364) Acc D Fake: 80.762%
Loss D: 1.042
Loss G: 0.6973 (0.7938) Acc G: 18.163%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3841 (0.3926) Acc D Real: 69.031%
Loss D Fake: 0.6922 (0.6369) Acc D Fake: 80.755%
Loss D: 1.076
Loss G: 0.6997 (0.7930) Acc G: 18.178%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.4338 (0.3929) Acc D Real: 69.003%
Loss D Fake: 0.6903 (0.6374) Acc D Fake: 80.749%
Loss D: 1.124
Loss G: 0.7011 (0.7922) Acc G: 18.194%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.4005 (0.3930) Acc D Real: 69.005%
Loss D Fake: 0.6893 (0.6378) Acc D Fake: 80.743%
Loss D: 1.090
Loss G: 0.7020 (0.7915) Acc G: 18.209%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3984 (0.3930) Acc D Real: 68.982%
Loss D Fake: 0.6887 (0.6382) Acc D Fake: 80.736%
Loss D: 1.087
Loss G: 0.7024 (0.7908) Acc G: 18.224%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4217 (0.3933) Acc D Real: 68.965%
Loss D Fake: 0.6886 (0.6386) Acc D Fake: 80.730%
Loss D: 1.110
Loss G: 0.7021 (0.7900) Acc G: 18.238%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4767 (0.3939) Acc D Real: 68.877%
Loss D Fake: 0.6894 (0.6390) Acc D Fake: 80.725%
Loss D: 1.166
Loss G: 0.7006 (0.7893) Acc G: 18.252%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3716 (0.3938) Acc D Real: 68.881%
Loss D Fake: 0.6910 (0.6395) Acc D Fake: 80.719%
Loss D: 1.063
Loss G: 0.6993 (0.7886) Acc G: 18.267%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.4532 (0.3942) Acc D Real: 68.820%
Loss D Fake: 0.6924 (0.6399) Acc D Fake: 80.713%
Loss D: 1.146
Loss G: 0.6974 (0.7878) Acc G: 18.280%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3692 (0.3940) Acc D Real: 68.922%
Loss D Fake: 0.6942 (0.6403) Acc D Fake: 80.707%
Loss D: 1.063
Loss G: 0.6958 (0.7871) Acc G: 18.294%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4306 (0.3943) Acc D Real: 68.905%
Loss D Fake: 0.6957 (0.6408) Acc D Fake: 80.702%
Loss D: 1.126
Loss G: 0.6941 (0.7864) Acc G: 18.317%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3304 (0.3938) Acc D Real: 68.968%
Loss D Fake: 0.6972 (0.6412) Acc D Fake: 80.683%
Loss D: 1.028
Loss G: 0.6931 (0.7857) Acc G: 18.343%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3860 (0.3938) Acc D Real: 69.034%
Loss D Fake: 0.6979 (0.6416) Acc D Fake: 80.665%
Loss D: 1.084
Loss G: 0.6924 (0.7849) Acc G: 18.368%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4505 (0.3942) Acc D Real: 69.038%
Loss D Fake: 0.6988 (0.6421) Acc D Fake: 80.647%
Loss D: 1.149
Loss G: 0.6912 (0.7842) Acc G: 18.394%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.4501 (0.3946) Acc D Real: 69.044%
Loss D Fake: 0.7003 (0.6425) Acc D Fake: 80.629%
Loss D: 1.150
Loss G: 0.6894 (0.7835) Acc G: 18.419%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3636 (0.3944) Acc D Real: 69.137%
Loss D Fake: 0.7021 (0.6430) Acc D Fake: 80.612%
Loss D: 1.066
Loss G: 0.6879 (0.7828) Acc G: 18.443%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3861 (0.3943) Acc D Real: 69.178%
Loss D Fake: 0.7034 (0.6434) Acc D Fake: 80.595%
Loss D: 1.089
Loss G: 0.6867 (0.7820) Acc G: 18.468%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3849 (0.3942) Acc D Real: 69.230%
Loss D Fake: 0.7044 (0.6439) Acc D Fake: 80.578%
Loss D: 1.089
Loss G: 0.6858 (0.7813) Acc G: 18.492%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3346 (0.3938) Acc D Real: 69.311%
Loss D Fake: 0.7051 (0.6443) Acc D Fake: 80.561%
Loss D: 1.040
Loss G: 0.6856 (0.7806) Acc G: 18.515%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3728 (0.3937) Acc D Real: 69.334%
Loss D Fake: 0.7050 (0.6448) Acc D Fake: 80.545%
Loss D: 1.078
Loss G: 0.6858 (0.7799) Acc G: 18.538%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3658 (0.3935) Acc D Real: 69.418%
Loss D Fake: 0.7047 (0.6452) Acc D Fake: 80.529%
Loss D: 1.071
Loss G: 0.6862 (0.7792) Acc G: 18.561%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4432 (0.3938) Acc D Real: 69.426%
Loss D Fake: 0.7046 (0.6457) Acc D Fake: 80.513%
Loss D: 1.148
Loss G: 0.6859 (0.7786) Acc G: 18.584%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.2908 (0.3931) Acc D Real: 69.522%
Loss D Fake: 0.7046 (0.6461) Acc D Fake: 80.497%
Loss D: 0.995
Loss G: 0.6866 (0.7779) Acc G: 18.606%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3316 (0.3926) Acc D Real: 69.556%
Loss D Fake: 0.7034 (0.6465) Acc D Fake: 80.482%
Loss D: 1.035
Loss G: 0.6882 (0.7773) Acc G: 18.628%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.4230 (0.3928) Acc D Real: 69.562%
Loss D Fake: 0.7020 (0.6469) Acc D Fake: 80.467%
Loss D: 1.125
Loss G: 0.6892 (0.7766) Acc G: 18.649%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.3822 (0.3928) Acc D Real: 69.580%
Loss D Fake: 0.7013 (0.6473) Acc D Fake: 80.452%
Loss D: 1.084
Loss G: 0.6898 (0.7760) Acc G: 18.670%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3664 (0.3926) Acc D Real: 69.628%
Loss D Fake: 0.7007 (0.6476) Acc D Fake: 80.437%
Loss D: 1.067
Loss G: 0.6904 (0.7754) Acc G: 18.691%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3048 (0.3920) Acc D Real: 69.718%
Loss D Fake: 0.6999 (0.6480) Acc D Fake: 80.422%
Loss D: 1.005
Loss G: 0.6917 (0.7748) Acc G: 18.700%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4160 (0.3921) Acc D Real: 69.704%
Loss D Fake: 0.6985 (0.6483) Acc D Fake: 80.419%
Loss D: 1.115
Loss G: 0.6927 (0.7743) Acc G: 18.709%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4356 (0.3924) Acc D Real: 69.714%
Loss D Fake: 0.6981 (0.6487) Acc D Fake: 80.416%
Loss D: 1.134
Loss G: 0.6925 (0.7737) Acc G: 18.718%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3107 (0.3919) Acc D Real: 69.802%
Loss D Fake: 0.6982 (0.6490) Acc D Fake: 80.413%
Loss D: 1.009
Loss G: 0.6930 (0.7732) Acc G: 18.727%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3636 (0.3917) Acc D Real: 69.885%
Loss D Fake: 0.6975 (0.6494) Acc D Fake: 80.411%
Loss D: 1.061
Loss G: 0.6937 (0.7726) Acc G: 18.736%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.2806 (0.3909) Acc D Real: 69.960%
Loss D Fake: 0.6964 (0.6497) Acc D Fake: 80.408%
Loss D: 0.977
Loss G: 0.6955 (0.7721) Acc G: 18.744%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.4776 (0.3915) Acc D Real: 69.887%
Loss D Fake: 0.6949 (0.6500) Acc D Fake: 80.405%
Loss D: 1.172
Loss G: 0.6960 (0.7716) Acc G: 18.752%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3739 (0.3914) Acc D Real: 69.934%
Loss D Fake: 0.6949 (0.6503) Acc D Fake: 80.403%
Loss D: 1.069
Loss G: 0.6961 (0.7711) Acc G: 18.761%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3648 (0.3912) Acc D Real: 69.990%
Loss D Fake: 0.6947 (0.6506) Acc D Fake: 80.400%
Loss D: 1.060
Loss G: 0.6964 (0.7706) Acc G: 18.769%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3537 (0.3910) Acc D Real: 70.012%
Loss D Fake: 0.6943 (0.6508) Acc D Fake: 80.397%
Loss D: 1.048
Loss G: 0.6970 (0.7701) Acc G: 18.777%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4557 (0.3914) Acc D Real: 69.953%
Loss D Fake: 0.6939 (0.6511) Acc D Fake: 80.395%
Loss D: 1.150
Loss G: 0.6969 (0.7697) Acc G: 18.785%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3135 (0.3909) Acc D Real: 69.999%
Loss D Fake: 0.6941 (0.6514) Acc D Fake: 80.392%
Loss D: 1.008
Loss G: 0.6972 (0.7692) Acc G: 18.793%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4310 (0.3912) Acc D Real: 69.947%
Loss D Fake: 0.6938 (0.6517) Acc D Fake: 80.390%
Loss D: 1.125
Loss G: 0.6971 (0.7687) Acc G: 18.800%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4192 (0.3913) Acc D Real: 69.935%
Loss D Fake: 0.6942 (0.6519) Acc D Fake: 80.387%
Loss D: 1.113
Loss G: 0.6963 (0.7683) Acc G: 18.808%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.4938 (0.3920) Acc D Real: 69.927%
Loss D Fake: 0.6955 (0.6522) Acc D Fake: 80.387%
Loss D: 1.189
Loss G: 0.6941 (0.7678) Acc G: 18.809%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.346 | Generator Loss: 0.694 | Avg: 2.040
TEST [21/180]: Discriminator Loss: 1.267 | Generator Loss: 0.694 | Avg: 1.961
TEST [31/180]: Discriminator Loss: 1.290 | Generator Loss: 0.694 | Avg: 1.984
TEST [41/180]: Discriminator Loss: 1.304 | Generator Loss: 0.694 | Avg: 1.998
TEST [51/180]: Discriminator Loss: 1.308 | Generator Loss: 0.694 | Avg: 2.002
TEST [61/180]: Discriminator Loss: 1.263 | Generator Loss: 0.694 | Avg: 1.957
TEST [71/180]: Discriminator Loss: 1.244 | Generator Loss: 0.694 | Avg: 1.938
TEST [81/180]: Discriminator Loss: 1.206 | Generator Loss: 0.694 | Avg: 1.900
TEST [91/180]: Discriminator Loss: 1.185 | Generator Loss: 0.694 | Avg: 1.879
TEST [101/180]: Discriminator Loss: 1.145 | Generator Loss: 0.694 | Avg: 1.839
TEST [111/180]: Discriminator Loss: 1.116 | Generator Loss: 0.694 | Avg: 1.810
TEST [121/180]: Discriminator Loss: 1.087 | Generator Loss: 0.694 | Avg: 1.781
TEST [131/180]: Discriminator Loss: 1.064 | Generator Loss: 0.694 | Avg: 1.758
TEST [141/180]: Discriminator Loss: 1.047 | Generator Loss: 0.694 | Avg: 1.741
TEST [151/180]: Discriminator Loss: 1.063 | Generator Loss: 0.694 | Avg: 1.757
TEST [161/180]: Discriminator Loss: 1.079 | Generator Loss: 0.694 | Avg: 1.773
TEST [171/180]: Discriminator Loss: 1.092 | Generator Loss: 0.694 | Avg: 1.786
Epoch: 11/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3544 (0.3931) Acc D Real: 71.771%
Loss D Fake: 0.7008 (0.6995) Acc D Fake: 79.167%
Loss D: 1.055
Loss G: 0.6892 (0.6902) Acc G: 20.833%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.2935 (0.3599) Acc D Real: 74.705%
Loss D Fake: 0.7021 (0.7004) Acc D Fake: 78.889%
Loss D: 0.996
Loss G: 0.6887 (0.6897) Acc G: 21.111%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3881 (0.3669) Acc D Real: 73.958%
Loss D Fake: 0.7021 (0.7008) Acc D Fake: 78.750%
Loss D: 1.090
Loss G: 0.6887 (0.6894) Acc G: 21.250%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3713 (0.3678) Acc D Real: 73.708%
Loss D Fake: 0.7022 (0.7011) Acc D Fake: 78.667%
Loss D: 1.073
Loss G: 0.6887 (0.6893) Acc G: 21.333%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.4085 (0.3746) Acc D Real: 73.550%
Loss D Fake: 0.7022 (0.7013) Acc D Fake: 78.333%
Loss D: 1.111
Loss G: 0.6885 (0.6892) Acc G: 21.667%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3820 (0.3757) Acc D Real: 73.021%
Loss D Fake: 0.7024 (0.7014) Acc D Fake: 78.095%
Loss D: 1.084
Loss G: 0.6885 (0.6891) Acc G: 21.905%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3597 (0.3737) Acc D Real: 73.939%
Loss D Fake: 0.7023 (0.7015) Acc D Fake: 77.917%
Loss D: 1.062
Loss G: 0.6886 (0.6890) Acc G: 22.083%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3624 (0.3724) Acc D Real: 74.057%
Loss D Fake: 0.7021 (0.7016) Acc D Fake: 77.778%
Loss D: 1.065
Loss G: 0.6890 (0.6890) Acc G: 22.222%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4050 (0.3757) Acc D Real: 73.932%
Loss D Fake: 0.7018 (0.7016) Acc D Fake: 77.667%
Loss D: 1.107
Loss G: 0.6891 (0.6890) Acc G: 22.333%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3820 (0.3762) Acc D Real: 73.887%
Loss D Fake: 0.7017 (0.7016) Acc D Fake: 77.576%
Loss D: 1.084
Loss G: 0.6892 (0.6890) Acc G: 22.287%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4086 (0.3789) Acc D Real: 73.303%
Loss D Fake: 0.7018 (0.7016) Acc D Fake: 77.500%
Loss D: 1.110
Loss G: 0.6889 (0.6890) Acc G: 22.374%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4490 (0.3843) Acc D Real: 72.696%
Loss D Fake: 0.7024 (0.7017) Acc D Fake: 77.436%
Loss D: 1.151
Loss G: 0.6878 (0.6889) Acc G: 22.448%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3446 (0.3815) Acc D Real: 72.857%
Loss D Fake: 0.7035 (0.7018) Acc D Fake: 77.381%
Loss D: 1.048
Loss G: 0.6871 (0.6888) Acc G: 22.511%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3920 (0.3822) Acc D Real: 72.688%
Loss D Fake: 0.7041 (0.7020) Acc D Fake: 77.333%
Loss D: 1.096
Loss G: 0.6864 (0.6886) Acc G: 22.566%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4389 (0.3857) Acc D Real: 72.490%
Loss D Fake: 0.7051 (0.7022) Acc D Fake: 77.292%
Loss D: 1.144
Loss G: 0.6850 (0.6884) Acc G: 22.614%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.2769 (0.3793) Acc D Real: 73.560%
Loss D Fake: 0.7061 (0.7024) Acc D Fake: 77.255%
Loss D: 0.983
Loss G: 0.6850 (0.6882) Acc G: 22.656%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3622 (0.3784) Acc D Real: 73.507%
Loss D Fake: 0.7057 (0.7026) Acc D Fake: 77.222%
Loss D: 1.068
Loss G: 0.6855 (0.6881) Acc G: 22.694%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3424 (0.3765) Acc D Real: 73.799%
Loss D Fake: 0.7050 (0.7027) Acc D Fake: 77.193%
Loss D: 1.047
Loss G: 0.6865 (0.6880) Acc G: 22.728%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3682 (0.3761) Acc D Real: 73.833%
Loss D Fake: 0.7039 (0.7028) Acc D Fake: 77.167%
Loss D: 1.072
Loss G: 0.6875 (0.6880) Acc G: 22.758%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3532 (0.3750) Acc D Real: 73.874%
Loss D Fake: 0.7027 (0.7028) Acc D Fake: 77.143%
Loss D: 1.056
Loss G: 0.6889 (0.6880) Acc G: 22.706%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3704 (0.3748) Acc D Real: 73.726%
Loss D Fake: 0.7013 (0.7027) Acc D Fake: 77.197%
Loss D: 1.072
Loss G: 0.6903 (0.6881) Acc G: 22.659%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4535 (0.3782) Acc D Real: 73.727%
Loss D Fake: 0.7003 (0.7026) Acc D Fake: 77.246%
Loss D: 1.154
Loss G: 0.6907 (0.6882) Acc G: 22.615%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3128 (0.3755) Acc D Real: 73.976%
Loss D Fake: 0.7000 (0.7025) Acc D Fake: 77.292%
Loss D: 1.013
Loss G: 0.6915 (0.6884) Acc G: 22.576%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3756 (0.3755) Acc D Real: 74.069%
Loss D Fake: 0.6990 (0.7023) Acc D Fake: 77.333%
Loss D: 1.075
Loss G: 0.6926 (0.6885) Acc G: 22.540%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3247 (0.3735) Acc D Real: 74.259%
Loss D Fake: 0.6976 (0.7022) Acc D Fake: 77.372%
Loss D: 1.022
Loss G: 0.6943 (0.6887) Acc G: 22.506%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3409 (0.3723) Acc D Real: 74.419%
Loss D Fake: 0.6958 (0.7019) Acc D Fake: 77.407%
Loss D: 1.037
Loss G: 0.6962 (0.6890) Acc G: 22.475%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3570 (0.3718) Acc D Real: 74.423%
Loss D Fake: 0.6940 (0.7016) Acc D Fake: 77.440%
Loss D: 1.051
Loss G: 0.6982 (0.6894) Acc G: 22.446%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3486 (0.3710) Acc D Real: 74.551%
Loss D Fake: 0.6920 (0.7013) Acc D Fake: 77.471%
Loss D: 1.041
Loss G: 0.7002 (0.6897) Acc G: 22.419%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3846 (0.3714) Acc D Real: 74.460%
Loss D Fake: 0.6902 (0.7009) Acc D Fake: 77.500%
Loss D: 1.075
Loss G: 0.7018 (0.6901) Acc G: 22.394%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.4077 (0.3726) Acc D Real: 74.309%
Loss D Fake: 0.6891 (0.7006) Acc D Fake: 77.527%
Loss D: 1.097
Loss G: 0.7025 (0.6905) Acc G: 22.371%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3546 (0.3720) Acc D Real: 74.251%
Loss D Fake: 0.6886 (0.7002) Acc D Fake: 77.552%
Loss D: 1.043
Loss G: 0.7032 (0.6909) Acc G: 22.349%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4519 (0.3745) Acc D Real: 73.857%
Loss D Fake: 0.6881 (0.6998) Acc D Fake: 77.576%
Loss D: 1.140
Loss G: 0.7029 (0.6913) Acc G: 22.328%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3643 (0.3742) Acc D Real: 73.822%
Loss D Fake: 0.6887 (0.6995) Acc D Fake: 77.598%
Loss D: 1.053
Loss G: 0.7025 (0.6916) Acc G: 22.309%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3774 (0.3743) Acc D Real: 73.677%
Loss D Fake: 0.6890 (0.6992) Acc D Fake: 77.619%
Loss D: 1.066
Loss G: 0.7023 (0.6919) Acc G: 22.290%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3835 (0.3745) Acc D Real: 73.488%
Loss D Fake: 0.6892 (0.6989) Acc D Fake: 77.639%
Loss D: 1.073
Loss G: 0.7021 (0.6922) Acc G: 22.273%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.4223 (0.3758) Acc D Real: 73.177%
Loss D Fake: 0.6894 (0.6987) Acc D Fake: 77.658%
Loss D: 1.112
Loss G: 0.7016 (0.6925) Acc G: 22.256%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3651 (0.3755) Acc D Real: 73.209%
Loss D Fake: 0.6900 (0.6984) Acc D Fake: 77.675%
Loss D: 1.055
Loss G: 0.7011 (0.6927) Acc G: 22.241%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3861 (0.3758) Acc D Real: 73.094%
Loss D Fake: 0.6904 (0.6982) Acc D Fake: 77.692%
Loss D: 1.076
Loss G: 0.7008 (0.6929) Acc G: 22.226%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3326 (0.3747) Acc D Real: 73.185%
Loss D Fake: 0.6905 (0.6980) Acc D Fake: 77.708%
Loss D: 1.023
Loss G: 0.7010 (0.6931) Acc G: 22.212%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3579 (0.3743) Acc D Real: 73.121%
Loss D Fake: 0.6900 (0.6978) Acc D Fake: 77.724%
Loss D: 1.048
Loss G: 0.7017 (0.6933) Acc G: 22.199%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3473 (0.3737) Acc D Real: 73.065%
Loss D Fake: 0.6892 (0.6976) Acc D Fake: 77.738%
Loss D: 1.037
Loss G: 0.7027 (0.6935) Acc G: 22.186%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.2688 (0.3712) Acc D Real: 73.289%
Loss D Fake: 0.6877 (0.6974) Acc D Fake: 77.752%
Loss D: 0.956
Loss G: 0.7052 (0.6938) Acc G: 22.174%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3633 (0.3710) Acc D Real: 73.258%
Loss D Fake: 0.6849 (0.6971) Acc D Fake: 77.765%
Loss D: 1.048
Loss G: 0.7080 (0.6941) Acc G: 22.163%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4473 (0.3727) Acc D Real: 73.080%
Loss D Fake: 0.6828 (0.6968) Acc D Fake: 77.778%
Loss D: 1.130
Loss G: 0.7095 (0.6945) Acc G: 22.152%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4384 (0.3742) Acc D Real: 72.806%
Loss D Fake: 0.6820 (0.6965) Acc D Fake: 77.790%
Loss D: 1.120
Loss G: 0.7096 (0.6948) Acc G: 22.141%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3725 (0.3741) Acc D Real: 72.708%
Loss D Fake: 0.6822 (0.6962) Acc D Fake: 77.801%
Loss D: 1.055
Loss G: 0.7094 (0.6951) Acc G: 22.131%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3451 (0.3735) Acc D Real: 72.696%
Loss D Fake: 0.6823 (0.6959) Acc D Fake: 77.812%
Loss D: 1.027
Loss G: 0.7097 (0.6954) Acc G: 22.121%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3367 (0.3728) Acc D Real: 72.705%
Loss D Fake: 0.6818 (0.6956) Acc D Fake: 77.823%
Loss D: 1.018
Loss G: 0.7105 (0.6957) Acc G: 22.078%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4007 (0.3733) Acc D Real: 72.539%
Loss D Fake: 0.6810 (0.6953) Acc D Fake: 77.867%
Loss D: 1.082
Loss G: 0.7111 (0.6960) Acc G: 22.036%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3963 (0.3738) Acc D Real: 72.379%
Loss D Fake: 0.6808 (0.6950) Acc D Fake: 77.908%
Loss D: 1.077
Loss G: 0.7110 (0.6963) Acc G: 21.997%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3432 (0.3732) Acc D Real: 72.397%
Loss D Fake: 0.6808 (0.6947) Acc D Fake: 77.949%
Loss D: 1.024
Loss G: 0.7112 (0.6966) Acc G: 21.958%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3802 (0.3733) Acc D Real: 72.191%
Loss D Fake: 0.6805 (0.6945) Acc D Fake: 77.987%
Loss D: 1.061
Loss G: 0.7114 (0.6969) Acc G: 21.921%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3970 (0.3738) Acc D Real: 72.121%
Loss D Fake: 0.6805 (0.6942) Acc D Fake: 78.025%
Loss D: 1.078
Loss G: 0.7112 (0.6971) Acc G: 21.886%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.4326 (0.3748) Acc D Real: 72.010%
Loss D Fake: 0.6811 (0.6940) Acc D Fake: 78.061%
Loss D: 1.114
Loss G: 0.7101 (0.6974) Acc G: 21.851%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3166 (0.3738) Acc D Real: 72.064%
Loss D Fake: 0.6819 (0.6938) Acc D Fake: 78.095%
Loss D: 0.999
Loss G: 0.7099 (0.6976) Acc G: 21.818%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.4003 (0.3743) Acc D Real: 71.974%
Loss D Fake: 0.6820 (0.6936) Acc D Fake: 78.129%
Loss D: 1.082
Loss G: 0.7096 (0.6978) Acc G: 21.786%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.4472 (0.3755) Acc D Real: 71.787%
Loss D Fake: 0.6826 (0.6934) Acc D Fake: 78.132%
Loss D: 1.130
Loss G: 0.7084 (0.6980) Acc G: 21.784%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3466 (0.3750) Acc D Real: 71.763%
Loss D Fake: 0.6839 (0.6932) Acc D Fake: 78.136%
Loss D: 1.030
Loss G: 0.7075 (0.6982) Acc G: 21.782%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3407 (0.3745) Acc D Real: 71.805%
Loss D Fake: 0.6843 (0.6931) Acc D Fake: 78.139%
Loss D: 1.025
Loss G: 0.7074 (0.6983) Acc G: 21.780%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3108 (0.3734) Acc D Real: 71.849%
Loss D Fake: 0.6840 (0.6929) Acc D Fake: 78.142%
Loss D: 0.995
Loss G: 0.7082 (0.6985) Acc G: 21.779%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3742 (0.3734) Acc D Real: 71.794%
Loss D Fake: 0.6831 (0.6928) Acc D Fake: 78.145%
Loss D: 1.057
Loss G: 0.7090 (0.6986) Acc G: 21.750%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3658 (0.3733) Acc D Real: 71.724%
Loss D Fake: 0.6824 (0.6926) Acc D Fake: 78.175%
Loss D: 1.048
Loss G: 0.7098 (0.6988) Acc G: 21.722%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3578 (0.3731) Acc D Real: 71.737%
Loss D Fake: 0.6817 (0.6924) Acc D Fake: 78.203%
Loss D: 1.040
Loss G: 0.7102 (0.6990) Acc G: 21.695%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4114 (0.3736) Acc D Real: 71.640%
Loss D Fake: 0.6817 (0.6923) Acc D Fake: 78.231%
Loss D: 1.093
Loss G: 0.7099 (0.6992) Acc G: 21.673%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.2748 (0.3722) Acc D Real: 71.766%
Loss D Fake: 0.6817 (0.6921) Acc D Fake: 78.232%
Loss D: 0.957
Loss G: 0.7108 (0.6993) Acc G: 21.673%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3604 (0.3720) Acc D Real: 71.810%
Loss D Fake: 0.6806 (0.6919) Acc D Fake: 78.234%
Loss D: 1.041
Loss G: 0.7120 (0.6995) Acc G: 21.673%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3103 (0.3711) Acc D Real: 71.902%
Loss D Fake: 0.6792 (0.6917) Acc D Fake: 78.235%
Loss D: 0.990
Loss G: 0.7138 (0.6997) Acc G: 21.697%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3527 (0.3708) Acc D Real: 71.880%
Loss D Fake: 0.6775 (0.6915) Acc D Fake: 78.213%
Loss D: 1.030
Loss G: 0.7155 (0.7000) Acc G: 21.721%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.2995 (0.3698) Acc D Real: 71.971%
Loss D Fake: 0.6759 (0.6913) Acc D Fake: 78.190%
Loss D: 0.975
Loss G: 0.7177 (0.7002) Acc G: 21.744%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3658 (0.3697) Acc D Real: 71.923%
Loss D Fake: 0.6737 (0.6911) Acc D Fake: 78.169%
Loss D: 1.040
Loss G: 0.7199 (0.7005) Acc G: 21.766%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.4097 (0.3703) Acc D Real: 71.759%
Loss D Fake: 0.6722 (0.6908) Acc D Fake: 78.148%
Loss D: 1.082
Loss G: 0.7210 (0.7008) Acc G: 21.788%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3150 (0.3695) Acc D Real: 71.790%
Loss D Fake: 0.6712 (0.6905) Acc D Fake: 78.128%
Loss D: 0.986
Loss G: 0.7224 (0.7011) Acc G: 21.809%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3432 (0.3692) Acc D Real: 71.772%
Loss D Fake: 0.6698 (0.6902) Acc D Fake: 78.108%
Loss D: 1.013
Loss G: 0.7241 (0.7014) Acc G: 21.830%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3821 (0.3693) Acc D Real: 71.713%
Loss D Fake: 0.6690 (0.6900) Acc D Fake: 78.089%
Loss D: 1.051
Loss G: 0.7233 (0.7017) Acc G: 21.850%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4192 (0.3700) Acc D Real: 71.580%
Loss D Fake: 0.6710 (0.6897) Acc D Fake: 78.070%
Loss D: 1.090
Loss G: 0.7209 (0.7019) Acc G: 21.870%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3337 (0.3695) Acc D Real: 71.581%
Loss D Fake: 0.6733 (0.6895) Acc D Fake: 78.052%
Loss D: 1.007
Loss G: 0.7188 (0.7022) Acc G: 21.889%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3185 (0.3689) Acc D Real: 71.579%
Loss D Fake: 0.6749 (0.6893) Acc D Fake: 78.034%
Loss D: 0.993
Loss G: 0.7177 (0.7024) Acc G: 21.907%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.2742 (0.3677) Acc D Real: 71.644%
Loss D Fake: 0.6755 (0.6891) Acc D Fake: 78.017%
Loss D: 0.950
Loss G: 0.7180 (0.7026) Acc G: 21.925%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4196 (0.3683) Acc D Real: 71.521%
Loss D Fake: 0.6753 (0.6890) Acc D Fake: 78.000%
Loss D: 1.095
Loss G: 0.7178 (0.7027) Acc G: 21.943%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.2870 (0.3673) Acc D Real: 71.584%
Loss D Fake: 0.6754 (0.6888) Acc D Fake: 77.984%
Loss D: 0.962
Loss G: 0.7184 (0.7029) Acc G: 21.960%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3009 (0.3665) Acc D Real: 71.638%
Loss D Fake: 0.6744 (0.6886) Acc D Fake: 77.967%
Loss D: 0.975
Loss G: 0.7200 (0.7031) Acc G: 21.977%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.2588 (0.3652) Acc D Real: 71.724%
Loss D Fake: 0.6724 (0.6884) Acc D Fake: 77.952%
Loss D: 0.931
Loss G: 0.7230 (0.7034) Acc G: 21.993%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.2997 (0.3644) Acc D Real: 71.752%
Loss D Fake: 0.6693 (0.6882) Acc D Fake: 77.937%
Loss D: 0.969
Loss G: 0.7267 (0.7037) Acc G: 22.009%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.2676 (0.3633) Acc D Real: 71.829%
Loss D Fake: 0.6658 (0.6879) Acc D Fake: 77.922%
Loss D: 0.933
Loss G: 0.7311 (0.7040) Acc G: 22.025%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.2806 (0.3623) Acc D Real: 71.870%
Loss D Fake: 0.6616 (0.6876) Acc D Fake: 77.907%
Loss D: 0.942
Loss G: 0.7361 (0.7044) Acc G: 22.040%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.2652 (0.3612) Acc D Real: 71.955%
Loss D Fake: 0.6572 (0.6873) Acc D Fake: 77.893%
Loss D: 0.922
Loss G: 0.7412 (0.7048) Acc G: 22.055%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3724 (0.3613) Acc D Real: 71.867%
Loss D Fake: 0.6530 (0.6869) Acc D Fake: 77.879%
Loss D: 1.025
Loss G: 0.7455 (0.7052) Acc G: 22.069%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3149 (0.3608) Acc D Real: 71.883%
Loss D Fake: 0.6496 (0.6865) Acc D Fake: 77.865%
Loss D: 0.965
Loss G: 0.7495 (0.7057) Acc G: 22.083%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3602 (0.3608) Acc D Real: 71.833%
Loss D Fake: 0.6465 (0.6860) Acc D Fake: 77.852%
Loss D: 1.007
Loss G: 0.7527 (0.7063) Acc G: 22.097%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3433 (0.3606) Acc D Real: 71.802%
Loss D Fake: 0.6440 (0.6856) Acc D Fake: 77.839%
Loss D: 0.987
Loss G: 0.7554 (0.7068) Acc G: 22.111%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.2694 (0.3596) Acc D Real: 71.851%
Loss D Fake: 0.6417 (0.6851) Acc D Fake: 77.826%
Loss D: 0.911
Loss G: 0.7587 (0.7074) Acc G: 22.124%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.2970 (0.3590) Acc D Real: 71.876%
Loss D Fake: 0.6387 (0.6846) Acc D Fake: 77.814%
Loss D: 0.936
Loss G: 0.7624 (0.7080) Acc G: 22.137%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3104 (0.3584) Acc D Real: 71.869%
Loss D Fake: 0.6356 (0.6841) Acc D Fake: 77.801%
Loss D: 0.946
Loss G: 0.7661 (0.7086) Acc G: 22.150%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3273 (0.3581) Acc D Real: 71.865%
Loss D Fake: 0.6327 (0.6835) Acc D Fake: 77.789%
Loss D: 0.960
Loss G: 0.7695 (0.7092) Acc G: 22.162%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4643 (0.3592) Acc D Real: 71.673%
Loss D Fake: 0.6305 (0.6830) Acc D Fake: 77.778%
Loss D: 1.095
Loss G: 0.7708 (0.7099) Acc G: 22.174%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.2920 (0.3585) Acc D Real: 71.691%
Loss D Fake: 0.6299 (0.6824) Acc D Fake: 77.766%
Loss D: 0.922
Loss G: 0.7721 (0.7105) Acc G: 22.186%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.2495 (0.3574) Acc D Real: 71.801%
Loss D Fake: 0.6283 (0.6819) Acc D Fake: 77.755%
Loss D: 0.878
Loss G: 0.7748 (0.7112) Acc G: 22.198%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3244 (0.3571) Acc D Real: 71.802%
Loss D Fake: 0.6259 (0.6813) Acc D Fake: 77.744%
Loss D: 0.950
Loss G: 0.7776 (0.7118) Acc G: 22.210%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3542 (0.3570) Acc D Real: 71.770%
Loss D Fake: 0.6239 (0.6807) Acc D Fake: 77.733%
Loss D: 0.978
Loss G: 0.7798 (0.7125) Acc G: 22.221%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.2983 (0.3565) Acc D Real: 71.796%
Loss D Fake: 0.6223 (0.6802) Acc D Fake: 77.723%
Loss D: 0.921
Loss G: 0.7821 (0.7132) Acc G: 22.232%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.2789 (0.3557) Acc D Real: 71.835%
Loss D Fake: 0.6203 (0.6796) Acc D Fake: 77.712%
Loss D: 0.899
Loss G: 0.7850 (0.7139) Acc G: 22.243%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3219 (0.3554) Acc D Real: 71.831%
Loss D Fake: 0.6178 (0.6790) Acc D Fake: 77.702%
Loss D: 0.940
Loss G: 0.7881 (0.7146) Acc G: 22.237%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.2185 (0.3541) Acc D Real: 71.961%
Loss D Fake: 0.6154 (0.6784) Acc D Fake: 77.708%
Loss D: 0.834
Loss G: 0.7912 (0.7154) Acc G: 22.232%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.2861 (0.3534) Acc D Real: 72.004%
Loss D Fake: 0.6130 (0.6777) Acc D Fake: 77.714%
Loss D: 0.899
Loss G: 0.7947 (0.7161) Acc G: 22.226%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.2775 (0.3527) Acc D Real: 72.036%
Loss D Fake: 0.6101 (0.6771) Acc D Fake: 77.720%
Loss D: 0.888
Loss G: 0.7987 (0.7169) Acc G: 22.221%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3063 (0.3523) Acc D Real: 72.065%
Loss D Fake: 0.6071 (0.6764) Acc D Fake: 77.726%
Loss D: 0.913
Loss G: 0.8024 (0.7177) Acc G: 22.216%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3706 (0.3524) Acc D Real: 72.003%
Loss D Fake: 0.6047 (0.6758) Acc D Fake: 77.731%
Loss D: 0.975
Loss G: 0.8048 (0.7185) Acc G: 22.211%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.2026 (0.3511) Acc D Real: 72.136%
Loss D Fake: 0.6029 (0.6751) Acc D Fake: 77.737%
Loss D: 0.805
Loss G: 0.8084 (0.7193) Acc G: 22.206%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.2499 (0.3501) Acc D Real: 72.216%
Loss D Fake: 0.5998 (0.6744) Acc D Fake: 77.742%
Loss D: 0.850
Loss G: 0.8131 (0.7202) Acc G: 22.201%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.1987 (0.3488) Acc D Real: 72.345%
Loss D Fake: 0.5957 (0.6737) Acc D Fake: 77.748%
Loss D: 0.794
Loss G: 0.8195 (0.7211) Acc G: 22.196%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3066 (0.3484) Acc D Real: 72.350%
Loss D Fake: 0.5910 (0.6730) Acc D Fake: 77.753%
Loss D: 0.898
Loss G: 0.8255 (0.7220) Acc G: 22.191%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.2349 (0.3474) Acc D Real: 72.457%
Loss D Fake: 0.5867 (0.6722) Acc D Fake: 77.758%
Loss D: 0.822
Loss G: 0.8317 (0.7230) Acc G: 22.187%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.2524 (0.3466) Acc D Real: 72.535%
Loss D Fake: 0.5821 (0.6714) Acc D Fake: 77.763%
Loss D: 0.835
Loss G: 0.8384 (0.7240) Acc G: 22.182%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3239 (0.3464) Acc D Real: 72.550%
Loss D Fake: 0.5778 (0.6706) Acc D Fake: 77.768%
Loss D: 0.902
Loss G: 0.8438 (0.7250) Acc G: 22.178%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.2865 (0.3458) Acc D Real: 72.607%
Loss D Fake: 0.5761 (0.6698) Acc D Fake: 77.773%
Loss D: 0.863
Loss G: 0.8415 (0.7260) Acc G: 22.173%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.2228 (0.3448) Acc D Real: 72.725%
Loss D Fake: 0.5804 (0.6690) Acc D Fake: 77.764%
Loss D: 0.803
Loss G: 0.8352 (0.7270) Acc G: 22.183%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.2017 (0.3436) Acc D Real: 72.835%
Loss D Fake: 0.5868 (0.6683) Acc D Fake: 77.754%
Loss D: 0.788
Loss G: 0.8270 (0.7278) Acc G: 22.193%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.2817 (0.3431) Acc D Real: 72.897%
Loss D Fake: 0.5968 (0.6677) Acc D Fake: 77.745%
Loss D: 0.879
Loss G: 0.8212 (0.7286) Acc G: 22.202%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2551 (0.3423) Acc D Real: 72.962%
Loss D Fake: 0.5977 (0.6672) Acc D Fake: 77.736%
Loss D: 0.853
Loss G: 0.8405 (0.7295) Acc G: 22.212%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3274 (0.3422) Acc D Real: 72.955%
Loss D Fake: 0.5742 (0.6664) Acc D Fake: 77.727%
Loss D: 0.902
Loss G: 0.8618 (0.7306) Acc G: 22.221%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3296 (0.3421) Acc D Real: 72.947%
Loss D Fake: 0.5607 (0.6655) Acc D Fake: 77.719%
Loss D: 0.890
Loss G: 0.8778 (0.7318) Acc G: 22.217%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3067 (0.3418) Acc D Real: 72.967%
Loss D Fake: 0.5509 (0.6646) Acc D Fake: 77.724%
Loss D: 0.858
Loss G: 0.8899 (0.7331) Acc G: 22.212%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.2732 (0.3413) Acc D Real: 73.025%
Loss D Fake: 0.5436 (0.6636) Acc D Fake: 77.728%
Loss D: 0.817
Loss G: 0.9001 (0.7345) Acc G: 22.208%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2804 (0.3408) Acc D Real: 73.081%
Loss D Fake: 0.5375 (0.6626) Acc D Fake: 77.733%
Loss D: 0.818
Loss G: 0.9089 (0.7359) Acc G: 22.203%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3904 (0.3412) Acc D Real: 73.037%
Loss D Fake: 0.5332 (0.6616) Acc D Fake: 77.738%
Loss D: 0.924
Loss G: 0.9129 (0.7373) Acc G: 22.199%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.2339 (0.3403) Acc D Real: 73.130%
Loss D Fake: 0.5320 (0.6606) Acc D Fake: 77.743%
Loss D: 0.766
Loss G: 0.9148 (0.7387) Acc G: 22.195%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3385 (0.3403) Acc D Real: 73.138%
Loss D Fake: 0.5318 (0.6595) Acc D Fake: 77.747%
Loss D: 0.870
Loss G: 0.9147 (0.7400) Acc G: 22.191%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.2255 (0.3394) Acc D Real: 73.234%
Loss D Fake: 0.5325 (0.6586) Acc D Fake: 77.739%
Loss D: 0.758
Loss G: 0.9154 (0.7414) Acc G: 22.200%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.3162 (0.3392) Acc D Real: 73.255%
Loss D Fake: 0.5349 (0.6576) Acc D Fake: 77.731%
Loss D: 0.851
Loss G: 0.9043 (0.7427) Acc G: 22.208%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3109 (0.3390) Acc D Real: 73.290%
Loss D Fake: 0.8571 (0.6591) Acc D Fake: 77.432%
Loss D: 1.168
Loss G: 0.9510 (0.7442) Acc G: 22.204%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4288 (0.3397) Acc D Real: 73.224%
Loss D Fake: 0.4966 (0.6579) Acc D Fake: 77.439%
Loss D: 0.925
Loss G: 0.9777 (0.7460) Acc G: 22.188%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3182 (0.3395) Acc D Real: 73.258%
Loss D Fake: 0.4854 (0.6566) Acc D Fake: 77.484%
Loss D: 0.804
Loss G: 0.9887 (0.7478) Acc G: 22.133%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3601 (0.3397) Acc D Real: 73.258%
Loss D Fake: 0.4797 (0.6553) Acc D Fake: 77.540%
Loss D: 0.840
Loss G: 0.9952 (0.7497) Acc G: 22.068%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.5023 (0.3409) Acc D Real: 73.136%
Loss D Fake: 0.4759 (0.6540) Acc D Fake: 77.607%
Loss D: 0.978
Loss G: 0.9994 (0.7515) Acc G: 21.991%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4477 (0.3417) Acc D Real: 73.059%
Loss D Fake: 0.4735 (0.6526) Acc D Fake: 77.686%
Loss D: 0.921
Loss G: 1.0025 (0.7534) Acc G: 21.915%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3438 (0.3417) Acc D Real: 73.065%
Loss D Fake: 0.4715 (0.6513) Acc D Fake: 77.764%
Loss D: 0.815
Loss G: 1.0056 (0.7552) Acc G: 21.828%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4271 (0.3423) Acc D Real: 73.012%
Loss D Fake: 0.4698 (0.6500) Acc D Fake: 77.853%
Loss D: 0.897
Loss G: 1.0074 (0.7570) Acc G: 21.742%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.5115 (0.3435) Acc D Real: 72.892%
Loss D Fake: 0.4693 (0.6487) Acc D Fake: 77.940%
Loss D: 0.981
Loss G: 1.0064 (0.7588) Acc G: 21.658%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.5403 (0.3449) Acc D Real: 72.756%
Loss D Fake: 0.4705 (0.6474) Acc D Fake: 78.026%
Loss D: 1.011
Loss G: 1.0025 (0.7606) Acc G: 21.574%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.4024 (0.3454) Acc D Real: 72.727%
Loss D Fake: 0.4728 (0.6462) Acc D Fake: 78.111%
Loss D: 0.875
Loss G: 0.9976 (0.7623) Acc G: 21.492%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.5580 (0.3468) Acc D Real: 72.576%
Loss D Fake: 0.4756 (0.6450) Acc D Fake: 78.195%
Loss D: 1.034
Loss G: 0.9911 (0.7639) Acc G: 21.411%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3920 (0.3472) Acc D Real: 72.546%
Loss D Fake: 0.4793 (0.6438) Acc D Fake: 78.277%
Loss D: 0.871
Loss G: 0.9845 (0.7654) Acc G: 21.332%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.5498 (0.3486) Acc D Real: 72.397%
Loss D Fake: 0.4830 (0.6427) Acc D Fake: 78.359%
Loss D: 1.033
Loss G: 0.9768 (0.7669) Acc G: 21.253%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4627 (0.3494) Acc D Real: 72.306%
Loss D Fake: 0.4875 (0.6416) Acc D Fake: 78.439%
Loss D: 0.950
Loss G: 0.9684 (0.7683) Acc G: 21.175%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.5712 (0.3509) Acc D Real: 72.136%
Loss D Fake: 0.4924 (0.6406) Acc D Fake: 78.518%
Loss D: 1.064
Loss G: 0.9586 (0.7696) Acc G: 21.099%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.5915 (0.3525) Acc D Real: 71.961%
Loss D Fake: 0.4984 (0.6396) Acc D Fake: 78.596%
Loss D: 1.090
Loss G: 0.9474 (0.7708) Acc G: 21.023%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.4009 (0.3528) Acc D Real: 71.915%
Loss D Fake: 0.5049 (0.6387) Acc D Fake: 78.673%
Loss D: 0.906
Loss G: 0.9370 (0.7719) Acc G: 20.949%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.5088 (0.3539) Acc D Real: 71.796%
Loss D Fake: 0.5110 (0.6379) Acc D Fake: 78.749%
Loss D: 1.020
Loss G: 0.9267 (0.7729) Acc G: 20.875%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.4425 (0.3545) Acc D Real: 71.719%
Loss D Fake: 0.5172 (0.6371) Acc D Fake: 78.824%
Loss D: 0.960
Loss G: 0.9166 (0.7739) Acc G: 20.803%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.4144 (0.3549) Acc D Real: 71.656%
Loss D Fake: 0.5233 (0.6363) Acc D Fake: 78.898%
Loss D: 0.938
Loss G: 0.9072 (0.7748) Acc G: 20.731%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4381 (0.3554) Acc D Real: 71.582%
Loss D Fake: 0.5290 (0.6356) Acc D Fake: 78.971%
Loss D: 0.967
Loss G: 0.8984 (0.7756) Acc G: 20.661%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.5291 (0.3566) Acc D Real: 71.435%
Loss D Fake: 0.5348 (0.6350) Acc D Fake: 79.043%
Loss D: 1.064
Loss G: 0.8890 (0.7763) Acc G: 20.591%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.5269 (0.3577) Acc D Real: 71.285%
Loss D Fake: 0.5411 (0.6343) Acc D Fake: 79.115%
Loss D: 1.068
Loss G: 0.8788 (0.7770) Acc G: 20.533%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4486 (0.3583) Acc D Real: 71.200%
Loss D Fake: 0.5480 (0.6338) Acc D Fake: 79.174%
Loss D: 0.997
Loss G: 0.8689 (0.7776) Acc G: 20.476%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4195 (0.3586) Acc D Real: 71.136%
Loss D Fake: 0.5544 (0.6333) Acc D Fake: 79.233%
Loss D: 0.974
Loss G: 0.8599 (0.7781) Acc G: 20.419%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.3093 (0.3583) Acc D Real: 71.142%
Loss D Fake: 0.5601 (0.6328) Acc D Fake: 79.291%
Loss D: 0.869
Loss G: 0.8527 (0.7786) Acc G: 20.364%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.5689 (0.3597) Acc D Real: 71.126%
Loss D Fake: 0.5651 (0.6324) Acc D Fake: 79.296%
Loss D: 1.134
Loss G: 0.8448 (0.7790) Acc G: 20.358%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.360 | Generator Loss: 0.845 | Avg: 2.205
TEST [21/180]: Discriminator Loss: 1.257 | Generator Loss: 0.845 | Avg: 2.102
TEST [31/180]: Discriminator Loss: 1.289 | Generator Loss: 0.845 | Avg: 2.133
TEST [41/180]: Discriminator Loss: 1.308 | Generator Loss: 0.845 | Avg: 2.152
TEST [51/180]: Discriminator Loss: 1.313 | Generator Loss: 0.845 | Avg: 2.158
TEST [61/180]: Discriminator Loss: 1.256 | Generator Loss: 0.845 | Avg: 2.100
TEST [71/180]: Discriminator Loss: 1.228 | Generator Loss: 0.845 | Avg: 2.073
TEST [81/180]: Discriminator Loss: 1.177 | Generator Loss: 0.845 | Avg: 2.022
TEST [91/180]: Discriminator Loss: 1.149 | Generator Loss: 0.845 | Avg: 1.994
TEST [101/180]: Discriminator Loss: 1.100 | Generator Loss: 0.845 | Avg: 1.944
TEST [111/180]: Discriminator Loss: 1.062 | Generator Loss: 0.845 | Avg: 1.907
TEST [121/180]: Discriminator Loss: 1.026 | Generator Loss: 0.845 | Avg: 1.870
TEST [131/180]: Discriminator Loss: 0.997 | Generator Loss: 0.845 | Avg: 1.842
TEST [141/180]: Discriminator Loss: 0.976 | Generator Loss: 0.845 | Avg: 1.820
TEST [151/180]: Discriminator Loss: 0.995 | Generator Loss: 0.845 | Avg: 1.839
TEST [161/180]: Discriminator Loss: 1.014 | Generator Loss: 0.845 | Avg: 1.859
TEST [171/180]: Discriminator Loss: 1.031 | Generator Loss: 0.845 | Avg: 1.876
Epoch: 12/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4105 (0.4463) Acc D Real: 56.536%
Loss D Fake: 0.5770 (0.5740) Acc D Fake: 88.333%
Loss D: 0.987
Loss G: 0.8286 (0.8325) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.4534 (0.4486) Acc D Real: 56.458%
Loss D Fake: 0.5824 (0.5768) Acc D Fake: 88.333%
Loss D: 1.036
Loss G: 0.8214 (0.8288) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.4921 (0.4595) Acc D Real: 54.622%
Loss D Fake: 0.5879 (0.5796) Acc D Fake: 88.333%
Loss D: 1.080
Loss G: 0.8139 (0.8251) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4468 (0.4570) Acc D Real: 54.781%
Loss D Fake: 0.5936 (0.5824) Acc D Fake: 88.333%
Loss D: 1.040
Loss G: 0.8065 (0.8214) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3283 (0.4355) Acc D Real: 57.274%
Loss D Fake: 0.5988 (0.5851) Acc D Fake: 88.333%
Loss D: 0.927
Loss G: 0.8007 (0.8179) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.4122 (0.4322) Acc D Real: 57.307%
Loss D Fake: 0.6030 (0.5877) Acc D Fake: 88.333%
Loss D: 1.015
Loss G: 0.7955 (0.8147) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3583 (0.4230) Acc D Real: 58.118%
Loss D Fake: 0.6069 (0.5901) Acc D Fake: 88.333%
Loss D: 0.965
Loss G: 0.7911 (0.8118) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4300 (0.4237) Acc D Real: 57.946%
Loss D Fake: 0.6103 (0.5923) Acc D Fake: 88.333%
Loss D: 1.040
Loss G: 0.7868 (0.8090) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4077 (0.4221) Acc D Real: 58.099%
Loss D Fake: 0.6137 (0.5945) Acc D Fake: 88.333%
Loss D: 1.021
Loss G: 0.7826 (0.8064) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3814 (0.4184) Acc D Real: 58.362%
Loss D Fake: 0.6169 (0.5965) Acc D Fake: 88.333%
Loss D: 0.998
Loss G: 0.7789 (0.8039) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4690 (0.4226) Acc D Real: 57.643%
Loss D Fake: 0.6201 (0.5985) Acc D Fake: 88.333%
Loss D: 1.089
Loss G: 0.7747 (0.8014) Acc G: 11.667%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4085 (0.4216) Acc D Real: 57.736%
Loss D Fake: 0.6236 (0.6004) Acc D Fake: 88.217%
Loss D: 1.032
Loss G: 0.7706 (0.7990) Acc G: 11.795%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4828 (0.4259) Acc D Real: 57.083%
Loss D Fake: 0.6271 (0.6023) Acc D Fake: 88.103%
Loss D: 1.110
Loss G: 0.7659 (0.7967) Acc G: 12.020%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3737 (0.4225) Acc D Real: 57.479%
Loss D Fake: 0.6311 (0.6042) Acc D Fake: 87.896%
Loss D: 1.005
Loss G: 0.7615 (0.7943) Acc G: 12.219%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3318 (0.4168) Acc D Real: 58.242%
Loss D Fake: 0.6344 (0.6061) Acc D Fake: 87.715%
Loss D: 0.966
Loss G: 0.7582 (0.7921) Acc G: 12.393%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3319 (0.4118) Acc D Real: 58.802%
Loss D Fake: 0.6368 (0.6079) Acc D Fake: 87.555%
Loss D: 0.969
Loss G: 0.7560 (0.7900) Acc G: 12.546%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.4747 (0.4153) Acc D Real: 58.267%
Loss D Fake: 0.6387 (0.6096) Acc D Fake: 87.413%
Loss D: 1.113
Loss G: 0.7532 (0.7879) Acc G: 12.682%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3895 (0.4139) Acc D Real: 58.391%
Loss D Fake: 0.6413 (0.6113) Acc D Fake: 87.286%
Loss D: 1.031
Loss G: 0.7503 (0.7859) Acc G: 12.892%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3481 (0.4106) Acc D Real: 58.685%
Loss D Fake: 0.6436 (0.6129) Acc D Fake: 87.089%
Loss D: 0.992
Loss G: 0.7479 (0.7840) Acc G: 13.081%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3263 (0.4066) Acc D Real: 59.149%
Loss D Fake: 0.6454 (0.6145) Acc D Fake: 86.910%
Loss D: 0.972
Loss G: 0.7465 (0.7822) Acc G: 13.251%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3546 (0.4043) Acc D Real: 59.384%
Loss D Fake: 0.6463 (0.6159) Acc D Fake: 86.747%
Loss D: 1.001
Loss G: 0.7456 (0.7806) Acc G: 13.407%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3616 (0.4024) Acc D Real: 59.667%
Loss D Fake: 0.6470 (0.6173) Acc D Fake: 86.599%
Loss D: 1.009
Loss G: 0.7449 (0.7790) Acc G: 13.548%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3974 (0.4022) Acc D Real: 59.664%
Loss D Fake: 0.6476 (0.6185) Acc D Fake: 86.463%
Loss D: 1.045
Loss G: 0.7441 (0.7776) Acc G: 13.678%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3275 (0.3992) Acc D Real: 60.048%
Loss D Fake: 0.6481 (0.6197) Acc D Fake: 86.338%
Loss D: 0.976
Loss G: 0.7440 (0.7762) Acc G: 13.798%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3902 (0.3989) Acc D Real: 60.260%
Loss D Fake: 0.6482 (0.6208) Acc D Fake: 86.222%
Loss D: 1.038
Loss G: 0.7435 (0.7750) Acc G: 13.908%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3943 (0.3987) Acc D Real: 60.258%
Loss D Fake: 0.6488 (0.6218) Acc D Fake: 86.115%
Loss D: 1.043
Loss G: 0.7428 (0.7738) Acc G: 14.010%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4516 (0.4006) Acc D Real: 59.961%
Loss D Fake: 0.6497 (0.6228) Acc D Fake: 86.016%
Loss D: 1.101
Loss G: 0.7412 (0.7726) Acc G: 14.105%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3482 (0.3988) Acc D Real: 60.167%
Loss D Fake: 0.6512 (0.6238) Acc D Fake: 85.923%
Loss D: 0.999
Loss G: 0.7399 (0.7715) Acc G: 14.194%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3816 (0.3982) Acc D Real: 60.299%
Loss D Fake: 0.6523 (0.6248) Acc D Fake: 85.837%
Loss D: 1.034
Loss G: 0.7387 (0.7704) Acc G: 14.276%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.4835 (0.4010) Acc D Real: 59.976%
Loss D Fake: 0.6537 (0.6257) Acc D Fake: 85.756%
Loss D: 1.137
Loss G: 0.7364 (0.7693) Acc G: 14.353%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3658 (0.3999) Acc D Real: 60.133%
Loss D Fake: 0.6559 (0.6266) Acc D Fake: 85.680%
Loss D: 1.022
Loss G: 0.7342 (0.7682) Acc G: 14.425%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3851 (0.3994) Acc D Real: 60.180%
Loss D Fake: 0.6577 (0.6276) Acc D Fake: 85.609%
Loss D: 1.043
Loss G: 0.7323 (0.7671) Acc G: 14.493%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.2757 (0.3958) Acc D Real: 60.625%
Loss D Fake: 0.6590 (0.6285) Acc D Fake: 85.542%
Loss D: 0.935
Loss G: 0.7315 (0.7661) Acc G: 14.557%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.2599 (0.3919) Acc D Real: 61.058%
Loss D Fake: 0.6592 (0.6294) Acc D Fake: 85.479%
Loss D: 0.919
Loss G: 0.7320 (0.7651) Acc G: 14.618%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.2847 (0.3889) Acc D Real: 61.413%
Loss D Fake: 0.6582 (0.6302) Acc D Fake: 85.420%
Loss D: 0.943
Loss G: 0.7336 (0.7642) Acc G: 14.674%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3032 (0.3866) Acc D Real: 61.653%
Loss D Fake: 0.6565 (0.6309) Acc D Fake: 85.363%
Loss D: 0.960
Loss G: 0.7357 (0.7634) Acc G: 14.728%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.4903 (0.3893) Acc D Real: 61.368%
Loss D Fake: 0.6550 (0.6315) Acc D Fake: 85.311%
Loss D: 1.145
Loss G: 0.7364 (0.7627) Acc G: 14.777%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.5113 (0.3925) Acc D Real: 61.038%
Loss D Fake: 0.6552 (0.6321) Acc D Fake: 85.274%
Loss D: 1.167
Loss G: 0.7352 (0.7620) Acc G: 14.825%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3285 (0.3909) Acc D Real: 61.255%
Loss D Fake: 0.6564 (0.6327) Acc D Fake: 85.232%
Loss D: 0.985
Loss G: 0.7343 (0.7613) Acc G: 14.867%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4846 (0.3931) Acc D Real: 61.005%
Loss D Fake: 0.6573 (0.6333) Acc D Fake: 85.202%
Loss D: 1.142
Loss G: 0.7326 (0.7606) Acc G: 14.910%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3055 (0.3911) Acc D Real: 61.298%
Loss D Fake: 0.6589 (0.6340) Acc D Fake: 85.164%
Loss D: 0.964
Loss G: 0.7314 (0.7599) Acc G: 14.952%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.4792 (0.3931) Acc D Real: 61.042%
Loss D Fake: 0.6600 (0.6346) Acc D Fake: 85.134%
Loss D: 1.139
Loss G: 0.7296 (0.7592) Acc G: 14.992%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3780 (0.3928) Acc D Real: 61.123%
Loss D Fake: 0.6619 (0.6352) Acc D Fake: 85.098%
Loss D: 1.040
Loss G: 0.7276 (0.7585) Acc G: 15.030%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4094 (0.3931) Acc D Real: 61.078%
Loss D Fake: 0.6637 (0.6358) Acc D Fake: 85.059%
Loss D: 1.073
Loss G: 0.7256 (0.7578) Acc G: 15.066%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4383 (0.3941) Acc D Real: 60.982%
Loss D Fake: 0.6657 (0.6365) Acc D Fake: 85.022%
Loss D: 1.104
Loss G: 0.7232 (0.7570) Acc G: 15.101%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.4508 (0.3953) Acc D Real: 60.995%
Loss D Fake: 0.6682 (0.6371) Acc D Fake: 84.986%
Loss D: 1.119
Loss G: 0.7203 (0.7562) Acc G: 15.134%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3738 (0.3949) Acc D Real: 61.125%
Loss D Fake: 0.6709 (0.6378) Acc D Fake: 84.951%
Loss D: 1.045
Loss G: 0.7175 (0.7554) Acc G: 15.166%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.2758 (0.3924) Acc D Real: 61.425%
Loss D Fake: 0.6730 (0.6386) Acc D Fake: 84.918%
Loss D: 0.949
Loss G: 0.7162 (0.7546) Acc G: 15.197%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4206 (0.3930) Acc D Real: 61.400%
Loss D Fake: 0.6739 (0.6393) Acc D Fake: 84.886%
Loss D: 1.095
Loss G: 0.7150 (0.7538) Acc G: 15.226%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4362 (0.3938) Acc D Real: 61.307%
Loss D Fake: 0.6754 (0.6400) Acc D Fake: 84.856%
Loss D: 1.112
Loss G: 0.7131 (0.7531) Acc G: 15.254%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3877 (0.3937) Acc D Real: 61.356%
Loss D Fake: 0.6772 (0.6407) Acc D Fake: 84.827%
Loss D: 1.065
Loss G: 0.7112 (0.7522) Acc G: 15.281%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3534 (0.3930) Acc D Real: 61.454%
Loss D Fake: 0.6789 (0.6414) Acc D Fake: 84.799%
Loss D: 1.032
Loss G: 0.7097 (0.7514) Acc G: 15.308%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.2670 (0.3906) Acc D Real: 61.831%
Loss D Fake: 0.6799 (0.6421) Acc D Fake: 84.771%
Loss D: 0.947
Loss G: 0.7095 (0.7507) Acc G: 15.333%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3361 (0.3896) Acc D Real: 61.960%
Loss D Fake: 0.6796 (0.6428) Acc D Fake: 84.745%
Loss D: 1.016
Loss G: 0.7099 (0.7499) Acc G: 15.357%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3698 (0.3893) Acc D Real: 62.050%
Loss D Fake: 0.6791 (0.6435) Acc D Fake: 84.730%
Loss D: 1.049
Loss G: 0.7104 (0.7492) Acc G: 15.359%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3545 (0.3887) Acc D Real: 62.202%
Loss D Fake: 0.6787 (0.6441) Acc D Fake: 84.735%
Loss D: 1.033
Loss G: 0.7109 (0.7485) Acc G: 15.353%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3069 (0.3873) Acc D Real: 62.500%
Loss D Fake: 0.6780 (0.6447) Acc D Fake: 84.740%
Loss D: 0.985
Loss G: 0.7119 (0.7479) Acc G: 15.347%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4149 (0.3877) Acc D Real: 62.478%
Loss D Fake: 0.6770 (0.6452) Acc D Fake: 84.744%
Loss D: 1.092
Loss G: 0.7126 (0.7473) Acc G: 15.341%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.4553 (0.3889) Acc D Real: 62.405%
Loss D Fake: 0.6768 (0.6457) Acc D Fake: 84.748%
Loss D: 1.132
Loss G: 0.7123 (0.7467) Acc G: 15.335%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.5110 (0.3909) Acc D Real: 62.217%
Loss D Fake: 0.6777 (0.6463) Acc D Fake: 84.752%
Loss D: 1.189
Loss G: 0.7106 (0.7461) Acc G: 15.330%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.4550 (0.3919) Acc D Real: 62.130%
Loss D Fake: 0.6798 (0.6468) Acc D Fake: 84.756%
Loss D: 1.135
Loss G: 0.7082 (0.7455) Acc G: 15.324%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3747 (0.3916) Acc D Real: 62.193%
Loss D Fake: 0.6822 (0.6474) Acc D Fake: 84.760%
Loss D: 1.057
Loss G: 0.7059 (0.7449) Acc G: 15.319%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.2941 (0.3901) Acc D Real: 62.393%
Loss D Fake: 0.6839 (0.6479) Acc D Fake: 84.764%
Loss D: 0.978
Loss G: 0.7048 (0.7443) Acc G: 15.314%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3941 (0.3902) Acc D Real: 62.467%
Loss D Fake: 0.6846 (0.6485) Acc D Fake: 84.768%
Loss D: 1.079
Loss G: 0.7042 (0.7437) Acc G: 15.309%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3238 (0.3892) Acc D Real: 62.608%
Loss D Fake: 0.6850 (0.6491) Acc D Fake: 84.771%
Loss D: 1.009
Loss G: 0.7040 (0.7431) Acc G: 15.305%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2675 (0.3873) Acc D Real: 62.833%
Loss D Fake: 0.6848 (0.6496) Acc D Fake: 84.775%
Loss D: 0.952
Loss G: 0.7049 (0.7425) Acc G: 15.300%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.2904 (0.3859) Acc D Real: 63.044%
Loss D Fake: 0.6835 (0.6501) Acc D Fake: 84.778%
Loss D: 0.974
Loss G: 0.7066 (0.7420) Acc G: 15.296%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3739 (0.3857) Acc D Real: 63.117%
Loss D Fake: 0.6817 (0.6505) Acc D Fake: 84.781%
Loss D: 1.056
Loss G: 0.7082 (0.7415) Acc G: 15.291%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3442 (0.3852) Acc D Real: 63.210%
Loss D Fake: 0.6803 (0.6510) Acc D Fake: 84.784%
Loss D: 1.025
Loss G: 0.7096 (0.7410) Acc G: 15.287%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3138 (0.3841) Acc D Real: 63.310%
Loss D Fake: 0.6788 (0.6514) Acc D Fake: 84.787%
Loss D: 0.993
Loss G: 0.7115 (0.7406) Acc G: 15.283%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3866 (0.3842) Acc D Real: 63.390%
Loss D Fake: 0.6771 (0.6517) Acc D Fake: 84.790%
Loss D: 1.064
Loss G: 0.7131 (0.7402) Acc G: 15.279%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.4222 (0.3847) Acc D Real: 63.396%
Loss D Fake: 0.6759 (0.6520) Acc D Fake: 84.793%
Loss D: 1.098
Loss G: 0.7139 (0.7399) Acc G: 15.275%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2809 (0.3833) Acc D Real: 63.562%
Loss D Fake: 0.6750 (0.6524) Acc D Fake: 84.796%
Loss D: 0.956
Loss G: 0.7154 (0.7395) Acc G: 15.272%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.2997 (0.3822) Acc D Real: 63.740%
Loss D Fake: 0.6732 (0.6526) Acc D Fake: 84.799%
Loss D: 0.973
Loss G: 0.7177 (0.7392) Acc G: 15.268%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4154 (0.3826) Acc D Real: 63.736%
Loss D Fake: 0.6712 (0.6529) Acc D Fake: 84.801%
Loss D: 1.087
Loss G: 0.7193 (0.7390) Acc G: 15.265%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.4167 (0.3831) Acc D Real: 63.712%
Loss D Fake: 0.6700 (0.6531) Acc D Fake: 84.804%
Loss D: 1.087
Loss G: 0.7201 (0.7387) Acc G: 15.261%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3064 (0.3821) Acc D Real: 63.831%
Loss D Fake: 0.6693 (0.6533) Acc D Fake: 84.806%
Loss D: 0.976
Loss G: 0.7213 (0.7385) Acc G: 15.258%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3672 (0.3819) Acc D Real: 63.846%
Loss D Fake: 0.6680 (0.6535) Acc D Fake: 84.818%
Loss D: 1.035
Loss G: 0.7227 (0.7383) Acc G: 15.233%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3147 (0.3811) Acc D Real: 63.910%
Loss D Fake: 0.6667 (0.6537) Acc D Fake: 84.841%
Loss D: 0.981
Loss G: 0.7241 (0.7381) Acc G: 15.210%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3159 (0.3802) Acc D Real: 63.972%
Loss D Fake: 0.6652 (0.6538) Acc D Fake: 84.864%
Loss D: 0.981
Loss G: 0.7259 (0.7380) Acc G: 15.186%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3795 (0.3802) Acc D Real: 63.960%
Loss D Fake: 0.6637 (0.6539) Acc D Fake: 84.886%
Loss D: 1.043
Loss G: 0.7274 (0.7378) Acc G: 15.164%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.4597 (0.3812) Acc D Real: 63.826%
Loss D Fake: 0.6626 (0.6540) Acc D Fake: 84.907%
Loss D: 1.122
Loss G: 0.7279 (0.7377) Acc G: 15.142%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3816 (0.3812) Acc D Real: 63.835%
Loss D Fake: 0.6625 (0.6541) Acc D Fake: 84.928%
Loss D: 1.044
Loss G: 0.7280 (0.7376) Acc G: 15.120%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4275 (0.3817) Acc D Real: 63.758%
Loss D Fake: 0.6626 (0.6542) Acc D Fake: 84.949%
Loss D: 1.090
Loss G: 0.7275 (0.7375) Acc G: 15.099%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4812 (0.3829) Acc D Real: 63.621%
Loss D Fake: 0.6635 (0.6543) Acc D Fake: 84.969%
Loss D: 1.145
Loss G: 0.7259 (0.7374) Acc G: 15.079%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3624 (0.3827) Acc D Real: 63.640%
Loss D Fake: 0.6652 (0.6545) Acc D Fake: 84.988%
Loss D: 1.028
Loss G: 0.7244 (0.7372) Acc G: 15.059%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3381 (0.3822) Acc D Real: 63.712%
Loss D Fake: 0.6663 (0.6546) Acc D Fake: 85.007%
Loss D: 1.004
Loss G: 0.7235 (0.7371) Acc G: 15.039%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3331 (0.3816) Acc D Real: 63.787%
Loss D Fake: 0.6668 (0.6547) Acc D Fake: 85.026%
Loss D: 1.000
Loss G: 0.7233 (0.7369) Acc G: 15.020%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4297 (0.3821) Acc D Real: 63.700%
Loss D Fake: 0.6670 (0.6549) Acc D Fake: 85.044%
Loss D: 1.097
Loss G: 0.7227 (0.7367) Acc G: 15.001%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4502 (0.3829) Acc D Real: 63.611%
Loss D Fake: 0.6678 (0.6550) Acc D Fake: 85.062%
Loss D: 1.118
Loss G: 0.7215 (0.7366) Acc G: 14.983%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.4427 (0.3835) Acc D Real: 63.528%
Loss D Fake: 0.6693 (0.6552) Acc D Fake: 85.079%
Loss D: 1.112
Loss G: 0.7197 (0.7364) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3801 (0.3835) Acc D Real: 63.564%
Loss D Fake: 0.6710 (0.6553) Acc D Fake: 85.078%
Loss D: 1.051
Loss G: 0.7180 (0.7362) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3801 (0.3835) Acc D Real: 63.528%
Loss D Fake: 0.6725 (0.6555) Acc D Fake: 85.078%
Loss D: 1.053
Loss G: 0.7164 (0.7360) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3689 (0.3833) Acc D Real: 63.595%
Loss D Fake: 0.6738 (0.6557) Acc D Fake: 85.077%
Loss D: 1.043
Loss G: 0.7152 (0.7358) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4254 (0.3838) Acc D Real: 63.540%
Loss D Fake: 0.6751 (0.6559) Acc D Fake: 85.076%
Loss D: 1.100
Loss G: 0.7137 (0.7355) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3500 (0.3834) Acc D Real: 63.576%
Loss D Fake: 0.6764 (0.6561) Acc D Fake: 85.075%
Loss D: 1.026
Loss G: 0.7125 (0.7353) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3492 (0.3831) Acc D Real: 63.610%
Loss D Fake: 0.6774 (0.6563) Acc D Fake: 85.074%
Loss D: 1.027
Loss G: 0.7117 (0.7351) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2663 (0.3819) Acc D Real: 63.788%
Loss D Fake: 0.6777 (0.6566) Acc D Fake: 85.074%
Loss D: 0.944
Loss G: 0.7120 (0.7348) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3878 (0.3819) Acc D Real: 63.803%
Loss D Fake: 0.6772 (0.6568) Acc D Fake: 85.073%
Loss D: 1.065
Loss G: 0.7124 (0.7346) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3143 (0.3813) Acc D Real: 63.884%
Loss D Fake: 0.6767 (0.6570) Acc D Fake: 85.072%
Loss D: 0.991
Loss G: 0.7131 (0.7344) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3709 (0.3812) Acc D Real: 63.888%
Loss D Fake: 0.6759 (0.6571) Acc D Fake: 85.071%
Loss D: 1.047
Loss G: 0.7139 (0.7342) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3391 (0.3808) Acc D Real: 63.927%
Loss D Fake: 0.6753 (0.6573) Acc D Fake: 85.071%
Loss D: 1.014
Loss G: 0.7147 (0.7340) Acc G: 14.969%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.4345 (0.3813) Acc D Real: 63.882%
Loss D Fake: 0.6746 (0.6575) Acc D Fake: 85.070%
Loss D: 1.109
Loss G: 0.7149 (0.7338) Acc G: 14.969%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.4344 (0.3818) Acc D Real: 63.840%
Loss D Fake: 0.6748 (0.6577) Acc D Fake: 85.069%
Loss D: 1.109
Loss G: 0.7145 (0.7336) Acc G: 14.969%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4346 (0.3823) Acc D Real: 63.760%
Loss D Fake: 0.6755 (0.6578) Acc D Fake: 85.069%
Loss D: 1.110
Loss G: 0.7134 (0.7334) Acc G: 14.970%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3211 (0.3817) Acc D Real: 63.908%
Loss D Fake: 0.6765 (0.6580) Acc D Fake: 85.068%
Loss D: 0.998
Loss G: 0.7127 (0.7332) Acc G: 14.970%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4373 (0.3822) Acc D Real: 63.858%
Loss D Fake: 0.6771 (0.6582) Acc D Fake: 85.068%
Loss D: 1.114
Loss G: 0.7118 (0.7330) Acc G: 14.970%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3176 (0.3816) Acc D Real: 63.909%
Loss D Fake: 0.6778 (0.6584) Acc D Fake: 85.066%
Loss D: 0.995
Loss G: 0.7114 (0.7328) Acc G: 14.970%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4139 (0.3819) Acc D Real: 63.854%
Loss D Fake: 0.6782 (0.6585) Acc D Fake: 85.051%
Loss D: 1.092
Loss G: 0.7108 (0.7326) Acc G: 14.983%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3284 (0.3814) Acc D Real: 63.921%
Loss D Fake: 0.6787 (0.6587) Acc D Fake: 85.035%
Loss D: 1.007
Loss G: 0.7106 (0.7324) Acc G: 14.998%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.2728 (0.3805) Acc D Real: 64.023%
Loss D Fake: 0.6784 (0.6589) Acc D Fake: 85.020%
Loss D: 0.951
Loss G: 0.7115 (0.7323) Acc G: 15.013%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3628 (0.3803) Acc D Real: 64.059%
Loss D Fake: 0.6773 (0.6591) Acc D Fake: 85.005%
Loss D: 1.040
Loss G: 0.7127 (0.7321) Acc G: 15.028%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3121 (0.3797) Acc D Real: 64.108%
Loss D Fake: 0.6761 (0.6592) Acc D Fake: 84.990%
Loss D: 0.988
Loss G: 0.7142 (0.7319) Acc G: 15.042%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3874 (0.3798) Acc D Real: 64.114%
Loss D Fake: 0.6746 (0.6593) Acc D Fake: 84.979%
Loss D: 1.062
Loss G: 0.7156 (0.7318) Acc G: 15.042%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3014 (0.3791) Acc D Real: 64.165%
Loss D Fake: 0.6732 (0.6595) Acc D Fake: 84.979%
Loss D: 0.975
Loss G: 0.7174 (0.7317) Acc G: 15.041%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3127 (0.3785) Acc D Real: 64.224%
Loss D Fake: 0.6713 (0.6596) Acc D Fake: 84.980%
Loss D: 0.984
Loss G: 0.7196 (0.7316) Acc G: 15.041%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3995 (0.3787) Acc D Real: 64.187%
Loss D Fake: 0.6693 (0.6596) Acc D Fake: 84.980%
Loss D: 1.069
Loss G: 0.7213 (0.7315) Acc G: 15.041%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.2326 (0.3775) Acc D Real: 64.298%
Loss D Fake: 0.6676 (0.6597) Acc D Fake: 84.980%
Loss D: 0.900
Loss G: 0.7239 (0.7314) Acc G: 15.031%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3622 (0.3774) Acc D Real: 64.322%
Loss D Fake: 0.6651 (0.6598) Acc D Fake: 84.983%
Loss D: 1.027
Loss G: 0.7264 (0.7314) Acc G: 15.017%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3436 (0.3771) Acc D Real: 64.321%
Loss D Fake: 0.6629 (0.6598) Acc D Fake: 84.993%
Loss D: 1.006
Loss G: 0.7286 (0.7313) Acc G: 15.003%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4861 (0.3780) Acc D Real: 64.195%
Loss D Fake: 0.6613 (0.6598) Acc D Fake: 85.006%
Loss D: 1.147
Loss G: 0.7295 (0.7313) Acc G: 14.990%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3657 (0.3779) Acc D Real: 64.210%
Loss D Fake: 0.6609 (0.6598) Acc D Fake: 85.015%
Loss D: 1.027
Loss G: 0.7300 (0.7313) Acc G: 14.977%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3643 (0.3778) Acc D Real: 64.191%
Loss D Fake: 0.6604 (0.6598) Acc D Fake: 85.018%
Loss D: 1.025
Loss G: 0.7304 (0.7313) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3668 (0.3777) Acc D Real: 64.197%
Loss D Fake: 0.6601 (0.6598) Acc D Fake: 85.019%
Loss D: 1.027
Loss G: 0.7309 (0.7313) Acc G: 14.961%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4190 (0.3780) Acc D Real: 64.156%
Loss D Fake: 0.6598 (0.6598) Acc D Fake: 85.019%
Loss D: 1.079
Loss G: 0.7307 (0.7313) Acc G: 14.961%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.5344 (0.3792) Acc D Real: 63.978%
Loss D Fake: 0.6605 (0.6598) Acc D Fake: 85.018%
Loss D: 1.195
Loss G: 0.7292 (0.7313) Acc G: 14.961%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.2961 (0.3786) Acc D Real: 64.049%
Loss D Fake: 0.6620 (0.6598) Acc D Fake: 85.018%
Loss D: 0.958
Loss G: 0.7282 (0.7313) Acc G: 14.962%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4506 (0.3791) Acc D Real: 63.973%
Loss D Fake: 0.6629 (0.6599) Acc D Fake: 85.018%
Loss D: 1.113
Loss G: 0.7268 (0.7312) Acc G: 14.962%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.2554 (0.3782) Acc D Real: 64.062%
Loss D Fake: 0.6639 (0.6599) Acc D Fake: 85.018%
Loss D: 0.919
Loss G: 0.7265 (0.7312) Acc G: 14.962%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3622 (0.3781) Acc D Real: 64.061%
Loss D Fake: 0.6638 (0.6599) Acc D Fake: 85.018%
Loss D: 1.026
Loss G: 0.7267 (0.7312) Acc G: 14.963%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4141 (0.3783) Acc D Real: 64.009%
Loss D Fake: 0.6637 (0.6599) Acc D Fake: 85.018%
Loss D: 1.078
Loss G: 0.7264 (0.7311) Acc G: 14.963%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.2540 (0.3774) Acc D Real: 64.103%
Loss D Fake: 0.6637 (0.6600) Acc D Fake: 85.018%
Loss D: 0.918
Loss G: 0.7271 (0.7311) Acc G: 14.963%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3886 (0.3775) Acc D Real: 64.073%
Loss D Fake: 0.6629 (0.6600) Acc D Fake: 85.017%
Loss D: 1.052
Loss G: 0.7279 (0.7311) Acc G: 14.963%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3385 (0.3772) Acc D Real: 64.101%
Loss D Fake: 0.6622 (0.6600) Acc D Fake: 85.017%
Loss D: 1.001
Loss G: 0.7287 (0.7310) Acc G: 14.964%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.2737 (0.3764) Acc D Real: 64.181%
Loss D Fake: 0.6612 (0.6600) Acc D Fake: 85.017%
Loss D: 0.935
Loss G: 0.7303 (0.7310) Acc G: 14.964%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.2856 (0.3758) Acc D Real: 64.246%
Loss D Fake: 0.6594 (0.6600) Acc D Fake: 85.017%
Loss D: 0.945
Loss G: 0.7327 (0.7311) Acc G: 14.964%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3378 (0.3755) Acc D Real: 64.261%
Loss D Fake: 0.6571 (0.6600) Acc D Fake: 85.017%
Loss D: 0.995
Loss G: 0.7351 (0.7311) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3863 (0.3756) Acc D Real: 64.234%
Loss D Fake: 0.6550 (0.6600) Acc D Fake: 85.017%
Loss D: 1.041
Loss G: 0.7371 (0.7311) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.4224 (0.3759) Acc D Real: 64.169%
Loss D Fake: 0.6537 (0.6599) Acc D Fake: 85.017%
Loss D: 1.076
Loss G: 0.7380 (0.7312) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3896 (0.3760) Acc D Real: 64.146%
Loss D Fake: 0.6532 (0.6599) Acc D Fake: 85.017%
Loss D: 1.043
Loss G: 0.7384 (0.7312) Acc G: 14.965%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.2887 (0.3754) Acc D Real: 64.211%
Loss D Fake: 0.6526 (0.6598) Acc D Fake: 85.017%
Loss D: 0.941
Loss G: 0.7395 (0.7313) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.2473 (0.3745) Acc D Real: 64.310%
Loss D Fake: 0.6511 (0.6598) Acc D Fake: 85.016%
Loss D: 0.898
Loss G: 0.7419 (0.7314) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.5152 (0.3755) Acc D Real: 64.170%
Loss D Fake: 0.6493 (0.6597) Acc D Fake: 85.016%
Loss D: 1.164
Loss G: 0.7429 (0.7314) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4833 (0.3762) Acc D Real: 64.056%
Loss D Fake: 0.6491 (0.6596) Acc D Fake: 85.016%
Loss D: 1.132
Loss G: 0.7424 (0.7315) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4735 (0.3769) Acc D Real: 63.963%
Loss D Fake: 0.6501 (0.6595) Acc D Fake: 85.016%
Loss D: 1.124
Loss G: 0.7408 (0.7316) Acc G: 14.966%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.4191 (0.3772) Acc D Real: 63.913%
Loss D Fake: 0.6518 (0.6595) Acc D Fake: 85.016%
Loss D: 1.071
Loss G: 0.7386 (0.7316) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.5376 (0.3783) Acc D Real: 63.754%
Loss D Fake: 0.6542 (0.6595) Acc D Fake: 85.016%
Loss D: 1.192
Loss G: 0.7352 (0.7317) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3193 (0.3779) Acc D Real: 63.785%
Loss D Fake: 0.6573 (0.6594) Acc D Fake: 85.016%
Loss D: 0.977
Loss G: 0.7324 (0.7317) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3457 (0.3777) Acc D Real: 63.803%
Loss D Fake: 0.6593 (0.6594) Acc D Fake: 85.016%
Loss D: 1.005
Loss G: 0.7308 (0.7317) Acc G: 14.967%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.4319 (0.3780) Acc D Real: 63.777%
Loss D Fake: 0.6607 (0.6594) Acc D Fake: 85.016%
Loss D: 1.093
Loss G: 0.7290 (0.7316) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.2828 (0.3774) Acc D Real: 63.838%
Loss D Fake: 0.6621 (0.6595) Acc D Fake: 85.015%
Loss D: 0.945
Loss G: 0.7281 (0.7316) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3344 (0.3771) Acc D Real: 63.869%
Loss D Fake: 0.6624 (0.6595) Acc D Fake: 85.015%
Loss D: 0.997
Loss G: 0.7282 (0.7316) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4194 (0.3774) Acc D Real: 63.811%
Loss D Fake: 0.6623 (0.6595) Acc D Fake: 85.015%
Loss D: 1.082
Loss G: 0.7279 (0.7316) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3111 (0.3770) Acc D Real: 63.852%
Loss D Fake: 0.6626 (0.6595) Acc D Fake: 85.015%
Loss D: 0.974
Loss G: 0.7279 (0.7315) Acc G: 14.968%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4436 (0.3774) Acc D Real: 63.778%
Loss D Fake: 0.6627 (0.6595) Acc D Fake: 85.015%
Loss D: 1.106
Loss G: 0.7274 (0.7315) Acc G: 14.969%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4530 (0.3779) Acc D Real: 63.710%
Loss D Fake: 0.6635 (0.6596) Acc D Fake: 85.015%
Loss D: 1.117
Loss G: 0.7261 (0.7315) Acc G: 14.969%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.3022 (0.3774) Acc D Real: 63.714%
Loss D Fake: 0.6646 (0.6596) Acc D Fake: 85.015%
Loss D: 0.967
Loss G: 0.7254 (0.7314) Acc G: 14.969%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.344 | Generator Loss: 0.725 | Avg: 2.069
TEST [21/180]: Discriminator Loss: 1.249 | Generator Loss: 0.725 | Avg: 1.974
TEST [31/180]: Discriminator Loss: 1.278 | Generator Loss: 0.725 | Avg: 2.003
TEST [41/180]: Discriminator Loss: 1.297 | Generator Loss: 0.725 | Avg: 2.023
TEST [51/180]: Discriminator Loss: 1.299 | Generator Loss: 0.725 | Avg: 2.024
TEST [61/180]: Discriminator Loss: 1.251 | Generator Loss: 0.725 | Avg: 1.976
TEST [71/180]: Discriminator Loss: 1.224 | Generator Loss: 0.725 | Avg: 1.949
TEST [81/180]: Discriminator Loss: 1.178 | Generator Loss: 0.725 | Avg: 1.904
TEST [91/180]: Discriminator Loss: 1.152 | Generator Loss: 0.725 | Avg: 1.878
TEST [101/180]: Discriminator Loss: 1.111 | Generator Loss: 0.725 | Avg: 1.836
TEST [111/180]: Discriminator Loss: 1.078 | Generator Loss: 0.725 | Avg: 1.803
TEST [121/180]: Discriminator Loss: 1.048 | Generator Loss: 0.725 | Avg: 1.773
TEST [131/180]: Discriminator Loss: 1.023 | Generator Loss: 0.725 | Avg: 1.749
TEST [141/180]: Discriminator Loss: 1.005 | Generator Loss: 0.725 | Avg: 1.731
TEST [151/180]: Discriminator Loss: 1.021 | Generator Loss: 0.725 | Avg: 1.747
TEST [161/180]: Discriminator Loss: 1.037 | Generator Loss: 0.725 | Avg: 1.763
TEST [171/180]: Discriminator Loss: 1.053 | Generator Loss: 0.725 | Avg: 1.778
Epoch: 13/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3018 (0.3269) Acc D Real: 67.760%
Loss D Fake: 0.6649 (0.6649) Acc D Fake: 85.000%
Loss D: 0.967
Loss G: 0.7257 (0.7254) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.4261 (0.3600) Acc D Real: 63.212%
Loss D Fake: 0.6644 (0.6648) Acc D Fake: 85.000%
Loss D: 1.091
Loss G: 0.7258 (0.7255) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.4169 (0.3742) Acc D Real: 61.549%
Loss D Fake: 0.6646 (0.6647) Acc D Fake: 85.000%
Loss D: 1.082
Loss G: 0.7253 (0.7255) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.2560 (0.3506) Acc D Real: 64.750%
Loss D Fake: 0.6648 (0.6647) Acc D Fake: 85.000%
Loss D: 0.921
Loss G: 0.7258 (0.7256) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.4857 (0.3731) Acc D Real: 61.988%
Loss D Fake: 0.6644 (0.6647) Acc D Fake: 85.000%
Loss D: 1.150
Loss G: 0.7256 (0.7256) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3009 (0.3628) Acc D Real: 63.586%
Loss D Fake: 0.6646 (0.6647) Acc D Fake: 85.000%
Loss D: 0.966
Loss G: 0.7258 (0.7256) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.4407 (0.3725) Acc D Real: 62.461%
Loss D Fake: 0.6646 (0.6647) Acc D Fake: 85.000%
Loss D: 1.105
Loss G: 0.7253 (0.7256) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4179 (0.3776) Acc D Real: 62.031%
Loss D Fake: 0.6652 (0.6647) Acc D Fake: 85.000%
Loss D: 1.083
Loss G: 0.7245 (0.7254) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4994 (0.3897) Acc D Real: 60.766%
Loss D Fake: 0.6664 (0.6649) Acc D Fake: 85.000%
Loss D: 1.166
Loss G: 0.7225 (0.7252) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3758 (0.3885) Acc D Real: 60.767%
Loss D Fake: 0.6684 (0.6652) Acc D Fake: 85.000%
Loss D: 1.044
Loss G: 0.7206 (0.7247) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.2947 (0.3807) Acc D Real: 62.044%
Loss D Fake: 0.6699 (0.6656) Acc D Fake: 85.000%
Loss D: 0.965
Loss G: 0.7196 (0.7243) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4421 (0.3854) Acc D Real: 61.498%
Loss D Fake: 0.6707 (0.6660) Acc D Fake: 84.976%
Loss D: 1.113
Loss G: 0.7183 (0.7238) Acc G: 15.064%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.2279 (0.3741) Acc D Real: 62.999%
Loss D Fake: 0.6716 (0.6664) Acc D Fake: 84.881%
Loss D: 0.899
Loss G: 0.7184 (0.7235) Acc G: 15.141%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4772 (0.3810) Acc D Real: 62.319%
Loss D Fake: 0.6714 (0.6667) Acc D Fake: 84.806%
Loss D: 1.149
Loss G: 0.7180 (0.7231) Acc G: 15.233%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3333 (0.3780) Acc D Real: 62.760%
Loss D Fake: 0.6719 (0.6671) Acc D Fake: 84.714%
Loss D: 1.005
Loss G: 0.7177 (0.7228) Acc G: 15.322%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3662 (0.3773) Acc D Real: 62.751%
Loss D Fake: 0.6720 (0.6673) Acc D Fake: 84.632%
Loss D: 1.038
Loss G: 0.7176 (0.7224) Acc G: 15.401%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3993 (0.3786) Acc D Real: 62.636%
Loss D Fake: 0.6722 (0.6676) Acc D Fake: 84.560%
Loss D: 1.071
Loss G: 0.7173 (0.7222) Acc G: 15.472%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3054 (0.3747) Acc D Real: 63.021%
Loss D Fake: 0.6723 (0.6679) Acc D Fake: 84.496%
Loss D: 0.978
Loss G: 0.7176 (0.7219) Acc G: 15.535%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.2958 (0.3708) Acc D Real: 63.539%
Loss D Fake: 0.6716 (0.6680) Acc D Fake: 84.438%
Loss D: 0.967
Loss G: 0.7187 (0.7218) Acc G: 15.591%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.2692 (0.3659) Acc D Real: 64.174%
Loss D Fake: 0.6702 (0.6682) Acc D Fake: 84.385%
Loss D: 0.939
Loss G: 0.7206 (0.7217) Acc G: 15.642%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3718 (0.3662) Acc D Real: 64.176%
Loss D Fake: 0.6684 (0.6682) Acc D Fake: 84.337%
Loss D: 1.040
Loss G: 0.7224 (0.7217) Acc G: 15.689%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3592 (0.3659) Acc D Real: 64.149%
Loss D Fake: 0.6669 (0.6681) Acc D Fake: 84.293%
Loss D: 1.026
Loss G: 0.7239 (0.7218) Acc G: 15.731%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3751 (0.3663) Acc D Real: 64.115%
Loss D Fake: 0.6656 (0.6680) Acc D Fake: 84.253%
Loss D: 1.041
Loss G: 0.7252 (0.7220) Acc G: 15.770%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4115 (0.3681) Acc D Real: 63.842%
Loss D Fake: 0.6646 (0.6679) Acc D Fake: 84.217%
Loss D: 1.076
Loss G: 0.7259 (0.7221) Acc G: 15.806%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3584 (0.3677) Acc D Real: 63.886%
Loss D Fake: 0.6641 (0.6677) Acc D Fake: 84.183%
Loss D: 1.022
Loss G: 0.7265 (0.7223) Acc G: 15.839%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3161 (0.3658) Acc D Real: 64.086%
Loss D Fake: 0.6634 (0.6676) Acc D Fake: 84.151%
Loss D: 0.979
Loss G: 0.7275 (0.7225) Acc G: 15.870%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3646 (0.3657) Acc D Real: 64.031%
Loss D Fake: 0.6624 (0.6674) Acc D Fake: 84.122%
Loss D: 1.027
Loss G: 0.7285 (0.7227) Acc G: 15.898%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3213 (0.3642) Acc D Real: 64.217%
Loss D Fake: 0.6613 (0.6672) Acc D Fake: 84.095%
Loss D: 0.983
Loss G: 0.7299 (0.7230) Acc G: 15.925%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.2717 (0.3611) Acc D Real: 64.562%
Loss D Fake: 0.6598 (0.6669) Acc D Fake: 84.069%
Loss D: 0.932
Loss G: 0.7319 (0.7233) Acc G: 15.950%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.5039 (0.3657) Acc D Real: 63.871%
Loss D Fake: 0.6583 (0.6666) Acc D Fake: 84.046%
Loss D: 1.162
Loss G: 0.7326 (0.7236) Acc G: 15.973%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3229 (0.3644) Acc D Real: 63.994%
Loss D Fake: 0.6580 (0.6664) Acc D Fake: 84.023%
Loss D: 0.981
Loss G: 0.7332 (0.7239) Acc G: 15.994%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3396 (0.3636) Acc D Real: 64.148%
Loss D Fake: 0.6573 (0.6661) Acc D Fake: 84.003%
Loss D: 0.997
Loss G: 0.7340 (0.7242) Acc G: 16.015%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3576 (0.3635) Acc D Real: 64.263%
Loss D Fake: 0.6565 (0.6658) Acc D Fake: 83.983%
Loss D: 1.014
Loss G: 0.7348 (0.7245) Acc G: 16.034%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3586 (0.3633) Acc D Real: 64.198%
Loss D Fake: 0.6559 (0.6655) Acc D Fake: 83.964%
Loss D: 1.014
Loss G: 0.7355 (0.7248) Acc G: 16.052%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.2302 (0.3596) Acc D Real: 64.631%
Loss D Fake: 0.6550 (0.6652) Acc D Fake: 83.947%
Loss D: 0.885
Loss G: 0.7371 (0.7251) Acc G: 16.069%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3236 (0.3587) Acc D Real: 64.686%
Loss D Fake: 0.6532 (0.6649) Acc D Fake: 83.932%
Loss D: 0.977
Loss G: 0.7392 (0.7255) Acc G: 16.077%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.4077 (0.3599) Acc D Real: 64.445%
Loss D Fake: 0.6516 (0.6646) Acc D Fake: 83.924%
Loss D: 1.059
Loss G: 0.7406 (0.7259) Acc G: 16.073%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3198 (0.3589) Acc D Real: 64.497%
Loss D Fake: 0.6505 (0.6642) Acc D Fake: 83.925%
Loss D: 0.970
Loss G: 0.7419 (0.7263) Acc G: 16.058%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3862 (0.3596) Acc D Real: 64.423%
Loss D Fake: 0.6493 (0.6638) Acc D Fake: 83.932%
Loss D: 1.036
Loss G: 0.7430 (0.7267) Acc G: 16.039%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3881 (0.3603) Acc D Real: 64.295%
Loss D Fake: 0.6486 (0.6635) Acc D Fake: 83.948%
Loss D: 1.037
Loss G: 0.7435 (0.7271) Acc G: 16.023%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3907 (0.3610) Acc D Real: 64.187%
Loss D Fake: 0.6483 (0.6631) Acc D Fake: 83.952%
Loss D: 1.039
Loss G: 0.7437 (0.7275) Acc G: 16.018%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3921 (0.3617) Acc D Real: 64.059%
Loss D Fake: 0.6483 (0.6628) Acc D Fake: 83.943%
Loss D: 1.040
Loss G: 0.7435 (0.7279) Acc G: 16.027%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.1968 (0.3580) Acc D Real: 64.496%
Loss D Fake: 0.6481 (0.6624) Acc D Fake: 83.933%
Loss D: 0.845
Loss G: 0.7447 (0.7283) Acc G: 16.033%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.2628 (0.3559) Acc D Real: 64.747%
Loss D Fake: 0.6464 (0.6621) Acc D Fake: 83.925%
Loss D: 0.909
Loss G: 0.7471 (0.7287) Acc G: 16.028%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3501 (0.3558) Acc D Real: 64.740%
Loss D Fake: 0.6442 (0.6617) Acc D Fake: 83.932%
Loss D: 0.994
Loss G: 0.7494 (0.7292) Acc G: 16.007%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3742 (0.3561) Acc D Real: 64.664%
Loss D Fake: 0.6424 (0.6613) Acc D Fake: 83.951%
Loss D: 1.017
Loss G: 0.7513 (0.7296) Acc G: 15.987%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3718 (0.3565) Acc D Real: 64.588%
Loss D Fake: 0.6409 (0.6608) Acc D Fake: 83.980%
Loss D: 1.013
Loss G: 0.7527 (0.7301) Acc G: 15.932%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3062 (0.3554) Acc D Real: 64.691%
Loss D Fake: 0.6397 (0.6604) Acc D Fake: 84.033%
Loss D: 0.946
Loss G: 0.7543 (0.7306) Acc G: 15.879%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3908 (0.3562) Acc D Real: 64.581%
Loss D Fake: 0.6384 (0.6600) Acc D Fake: 84.085%
Loss D: 1.029
Loss G: 0.7556 (0.7311) Acc G: 15.830%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3540 (0.3561) Acc D Real: 64.572%
Loss D Fake: 0.6374 (0.6595) Acc D Fake: 84.132%
Loss D: 0.991
Loss G: 0.7567 (0.7316) Acc G: 15.782%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3694 (0.3564) Acc D Real: 64.517%
Loss D Fake: 0.6365 (0.6591) Acc D Fake: 84.170%
Loss D: 1.006
Loss G: 0.7575 (0.7321) Acc G: 15.735%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.5251 (0.3595) Acc D Real: 64.075%
Loss D Fake: 0.6363 (0.6587) Acc D Fake: 84.195%
Loss D: 1.161
Loss G: 0.7567 (0.7326) Acc G: 15.714%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.2791 (0.3581) Acc D Real: 64.218%
Loss D Fake: 0.6372 (0.6583) Acc D Fake: 84.210%
Loss D: 0.916
Loss G: 0.7562 (0.7330) Acc G: 15.699%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3703 (0.3583) Acc D Real: 64.159%
Loss D Fake: 0.6375 (0.6579) Acc D Fake: 84.224%
Loss D: 1.008
Loss G: 0.7558 (0.7334) Acc G: 15.684%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3452 (0.3580) Acc D Real: 64.150%
Loss D Fake: 0.6378 (0.6575) Acc D Fake: 84.239%
Loss D: 0.983
Loss G: 0.7556 (0.7338) Acc G: 15.668%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.2855 (0.3568) Acc D Real: 64.308%
Loss D Fake: 0.6377 (0.6572) Acc D Fake: 84.253%
Loss D: 0.923
Loss G: 0.7561 (0.7342) Acc G: 15.640%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.2794 (0.3554) Acc D Real: 64.460%
Loss D Fake: 0.6369 (0.6568) Acc D Fake: 84.285%
Loss D: 0.916
Loss G: 0.7575 (0.7346) Acc G: 15.600%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3208 (0.3549) Acc D Real: 64.503%
Loss D Fake: 0.6355 (0.6565) Acc D Fake: 84.326%
Loss D: 0.956
Loss G: 0.7591 (0.7350) Acc G: 15.561%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3235 (0.3543) Acc D Real: 64.550%
Loss D Fake: 0.6341 (0.6561) Acc D Fake: 84.365%
Loss D: 0.958
Loss G: 0.7608 (0.7355) Acc G: 15.524%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3726 (0.3546) Acc D Real: 64.495%
Loss D Fake: 0.6327 (0.6557) Acc D Fake: 84.402%
Loss D: 1.005
Loss G: 0.7624 (0.7359) Acc G: 15.488%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2408 (0.3528) Acc D Real: 64.713%
Loss D Fake: 0.6312 (0.6553) Acc D Fake: 84.439%
Loss D: 0.872
Loss G: 0.7646 (0.7364) Acc G: 15.454%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.4683 (0.3546) Acc D Real: 64.478%
Loss D Fake: 0.6294 (0.6549) Acc D Fake: 84.474%
Loss D: 1.098
Loss G: 0.7659 (0.7368) Acc G: 15.420%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3780 (0.3550) Acc D Real: 64.425%
Loss D Fake: 0.6287 (0.6545) Acc D Fake: 84.508%
Loss D: 1.007
Loss G: 0.7666 (0.7373) Acc G: 15.387%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3120 (0.3543) Acc D Real: 64.486%
Loss D Fake: 0.6281 (0.6541) Acc D Fake: 84.542%
Loss D: 0.940
Loss G: 0.7676 (0.7378) Acc G: 15.356%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3824 (0.3548) Acc D Real: 64.443%
Loss D Fake: 0.6273 (0.6537) Acc D Fake: 84.574%
Loss D: 1.010
Loss G: 0.7684 (0.7382) Acc G: 15.325%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2860 (0.3537) Acc D Real: 64.555%
Loss D Fake: 0.6265 (0.6533) Acc D Fake: 84.605%
Loss D: 0.913
Loss G: 0.7697 (0.7387) Acc G: 15.295%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3553 (0.3538) Acc D Real: 64.540%
Loss D Fake: 0.6253 (0.6529) Acc D Fake: 84.635%
Loss D: 0.981
Loss G: 0.7710 (0.7392) Acc G: 15.267%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.4200 (0.3547) Acc D Real: 64.416%
Loss D Fake: 0.6245 (0.6525) Acc D Fake: 84.665%
Loss D: 1.044
Loss G: 0.7715 (0.7396) Acc G: 15.239%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4867 (0.3566) Acc D Real: 64.173%
Loss D Fake: 0.6245 (0.6521) Acc D Fake: 84.693%
Loss D: 1.111
Loss G: 0.7706 (0.7401) Acc G: 15.211%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4426 (0.3578) Acc D Real: 64.007%
Loss D Fake: 0.6258 (0.6517) Acc D Fake: 84.721%
Loss D: 1.068
Loss G: 0.7688 (0.7405) Acc G: 15.185%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3494 (0.3577) Acc D Real: 64.010%
Loss D Fake: 0.6274 (0.6513) Acc D Fake: 84.748%
Loss D: 0.977
Loss G: 0.7671 (0.7409) Acc G: 15.159%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3095 (0.3570) Acc D Real: 64.094%
Loss D Fake: 0.6285 (0.6510) Acc D Fake: 84.775%
Loss D: 0.938
Loss G: 0.7663 (0.7412) Acc G: 15.134%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3902 (0.3575) Acc D Real: 64.011%
Loss D Fake: 0.6291 (0.6507) Acc D Fake: 84.800%
Loss D: 1.019
Loss G: 0.7653 (0.7415) Acc G: 15.110%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3580 (0.3575) Acc D Real: 64.019%
Loss D Fake: 0.6299 (0.6505) Acc D Fake: 84.825%
Loss D: 0.988
Loss G: 0.7645 (0.7418) Acc G: 15.086%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3833 (0.3578) Acc D Real: 63.988%
Loss D Fake: 0.6305 (0.6502) Acc D Fake: 84.849%
Loss D: 1.014
Loss G: 0.7639 (0.7421) Acc G: 15.063%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2595 (0.3566) Acc D Real: 64.129%
Loss D Fake: 0.6307 (0.6499) Acc D Fake: 84.873%
Loss D: 0.890
Loss G: 0.7642 (0.7424) Acc G: 15.041%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3695 (0.3567) Acc D Real: 64.092%
Loss D Fake: 0.6303 (0.6497) Acc D Fake: 84.896%
Loss D: 1.000
Loss G: 0.7646 (0.7427) Acc G: 15.019%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3301 (0.3564) Acc D Real: 64.123%
Loss D Fake: 0.6299 (0.6494) Acc D Fake: 84.918%
Loss D: 0.960
Loss G: 0.7651 (0.7430) Acc G: 14.997%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4028 (0.3570) Acc D Real: 64.053%
Loss D Fake: 0.6296 (0.6492) Acc D Fake: 84.940%
Loss D: 1.032
Loss G: 0.7653 (0.7433) Acc G: 14.977%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4387 (0.3580) Acc D Real: 63.922%
Loss D Fake: 0.6296 (0.6489) Acc D Fake: 84.961%
Loss D: 1.068
Loss G: 0.7649 (0.7435) Acc G: 14.956%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3218 (0.3575) Acc D Real: 63.955%
Loss D Fake: 0.6301 (0.6487) Acc D Fake: 84.982%
Loss D: 0.952
Loss G: 0.7645 (0.7438) Acc G: 14.936%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3762 (0.3578) Acc D Real: 63.924%
Loss D Fake: 0.6303 (0.6485) Acc D Fake: 85.003%
Loss D: 1.006
Loss G: 0.7642 (0.7440) Acc G: 14.917%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4628 (0.3590) Acc D Real: 63.759%
Loss D Fake: 0.6308 (0.6483) Acc D Fake: 85.022%
Loss D: 1.094
Loss G: 0.7631 (0.7443) Acc G: 14.898%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3288 (0.3587) Acc D Real: 63.791%
Loss D Fake: 0.6319 (0.6481) Acc D Fake: 85.042%
Loss D: 0.961
Loss G: 0.7621 (0.7445) Acc G: 14.880%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4342 (0.3595) Acc D Real: 63.662%
Loss D Fake: 0.6328 (0.6479) Acc D Fake: 85.061%
Loss D: 1.067
Loss G: 0.7607 (0.7447) Acc G: 14.862%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3712 (0.3597) Acc D Real: 63.627%
Loss D Fake: 0.6341 (0.6478) Acc D Fake: 85.079%
Loss D: 1.005
Loss G: 0.7592 (0.7448) Acc G: 14.844%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4158 (0.3603) Acc D Real: 63.540%
Loss D Fake: 0.6354 (0.6476) Acc D Fake: 85.097%
Loss D: 1.051
Loss G: 0.7576 (0.7450) Acc G: 14.827%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4580 (0.3614) Acc D Real: 63.394%
Loss D Fake: 0.6370 (0.6475) Acc D Fake: 85.115%
Loss D: 1.095
Loss G: 0.7553 (0.7451) Acc G: 14.810%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4761 (0.3627) Acc D Real: 63.226%
Loss D Fake: 0.6393 (0.6474) Acc D Fake: 85.132%
Loss D: 1.115
Loss G: 0.7523 (0.7452) Acc G: 14.812%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3462 (0.3625) Acc D Real: 63.227%
Loss D Fake: 0.6419 (0.6473) Acc D Fake: 85.130%
Loss D: 0.988
Loss G: 0.7497 (0.7452) Acc G: 14.815%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3628 (0.3625) Acc D Real: 63.214%
Loss D Fake: 0.6440 (0.6473) Acc D Fake: 85.129%
Loss D: 1.007
Loss G: 0.7475 (0.7452) Acc G: 14.817%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3170 (0.3620) Acc D Real: 63.254%
Loss D Fake: 0.6456 (0.6473) Acc D Fake: 85.128%
Loss D: 0.963
Loss G: 0.7461 (0.7452) Acc G: 14.819%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4073 (0.3625) Acc D Real: 63.197%
Loss D Fake: 0.6467 (0.6473) Acc D Fake: 85.126%
Loss D: 1.054
Loss G: 0.7447 (0.7452) Acc G: 14.820%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2989 (0.3618) Acc D Real: 63.264%
Loss D Fake: 0.6477 (0.6473) Acc D Fake: 85.125%
Loss D: 0.947
Loss G: 0.7441 (0.7452) Acc G: 14.822%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3432 (0.3616) Acc D Real: 63.283%
Loss D Fake: 0.6480 (0.6473) Acc D Fake: 85.124%
Loss D: 0.991
Loss G: 0.7439 (0.7452) Acc G: 14.824%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.4231 (0.3623) Acc D Real: 63.175%
Loss D Fake: 0.6482 (0.6473) Acc D Fake: 85.122%
Loss D: 1.071
Loss G: 0.7433 (0.7452) Acc G: 14.826%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3396 (0.3620) Acc D Real: 63.189%
Loss D Fake: 0.6489 (0.6473) Acc D Fake: 85.121%
Loss D: 0.989
Loss G: 0.7427 (0.7452) Acc G: 14.828%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2268 (0.3607) Acc D Real: 63.351%
Loss D Fake: 0.6489 (0.6473) Acc D Fake: 85.120%
Loss D: 0.876
Loss G: 0.7435 (0.7452) Acc G: 14.830%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.2348 (0.3594) Acc D Real: 63.501%
Loss D Fake: 0.6475 (0.6473) Acc D Fake: 85.119%
Loss D: 0.882
Loss G: 0.7457 (0.7452) Acc G: 14.831%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4248 (0.3600) Acc D Real: 63.412%
Loss D Fake: 0.6456 (0.6473) Acc D Fake: 85.118%
Loss D: 1.070
Loss G: 0.7473 (0.7452) Acc G: 14.833%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4551 (0.3610) Acc D Real: 63.275%
Loss D Fake: 0.6448 (0.6473) Acc D Fake: 85.116%
Loss D: 1.100
Loss G: 0.7476 (0.7452) Acc G: 14.835%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3269 (0.3607) Acc D Real: 63.315%
Loss D Fake: 0.6447 (0.6473) Acc D Fake: 85.115%
Loss D: 0.972
Loss G: 0.7479 (0.7452) Acc G: 14.836%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3853 (0.3609) Acc D Real: 63.286%
Loss D Fake: 0.6444 (0.6472) Acc D Fake: 85.114%
Loss D: 1.030
Loss G: 0.7481 (0.7453) Acc G: 14.838%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.4358 (0.3616) Acc D Real: 63.182%
Loss D Fake: 0.6445 (0.6472) Acc D Fake: 85.113%
Loss D: 1.080
Loss G: 0.7476 (0.7453) Acc G: 14.839%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3900 (0.3619) Acc D Real: 63.141%
Loss D Fake: 0.6451 (0.6472) Acc D Fake: 85.112%
Loss D: 1.035
Loss G: 0.7469 (0.7453) Acc G: 14.841%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3448 (0.3617) Acc D Real: 63.151%
Loss D Fake: 0.6456 (0.6472) Acc D Fake: 85.111%
Loss D: 0.990
Loss G: 0.7464 (0.7453) Acc G: 14.842%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4451 (0.3625) Acc D Real: 63.048%
Loss D Fake: 0.6462 (0.6472) Acc D Fake: 85.110%
Loss D: 1.091
Loss G: 0.7454 (0.7453) Acc G: 14.844%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3427 (0.3623) Acc D Real: 63.064%
Loss D Fake: 0.6471 (0.6472) Acc D Fake: 85.109%
Loss D: 0.990
Loss G: 0.7445 (0.7453) Acc G: 14.845%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3785 (0.3624) Acc D Real: 63.035%
Loss D Fake: 0.6478 (0.6472) Acc D Fake: 85.108%
Loss D: 1.026
Loss G: 0.7438 (0.7453) Acc G: 14.847%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3685 (0.3625) Acc D Real: 63.029%
Loss D Fake: 0.6484 (0.6472) Acc D Fake: 85.107%
Loss D: 1.017
Loss G: 0.7432 (0.7453) Acc G: 14.848%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3453 (0.3623) Acc D Real: 63.046%
Loss D Fake: 0.6487 (0.6472) Acc D Fake: 85.106%
Loss D: 0.994
Loss G: 0.7431 (0.7452) Acc G: 14.849%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3448 (0.3622) Acc D Real: 63.063%
Loss D Fake: 0.6487 (0.6472) Acc D Fake: 85.105%
Loss D: 0.994
Loss G: 0.7432 (0.7452) Acc G: 14.851%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.4239 (0.3627) Acc D Real: 62.981%
Loss D Fake: 0.6488 (0.6472) Acc D Fake: 85.104%
Loss D: 1.073
Loss G: 0.7427 (0.7452) Acc G: 14.852%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3286 (0.3624) Acc D Real: 63.007%
Loss D Fake: 0.6492 (0.6472) Acc D Fake: 85.103%
Loss D: 0.978
Loss G: 0.7426 (0.7452) Acc G: 14.853%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.4498 (0.3632) Acc D Real: 62.912%
Loss D Fake: 0.6494 (0.6473) Acc D Fake: 85.102%
Loss D: 1.099
Loss G: 0.7418 (0.7452) Acc G: 14.855%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.5587 (0.3649) Acc D Real: 62.692%
Loss D Fake: 0.6508 (0.6473) Acc D Fake: 85.101%
Loss D: 1.209
Loss G: 0.7393 (0.7451) Acc G: 14.856%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3665 (0.3649) Acc D Real: 62.691%
Loss D Fake: 0.6532 (0.6473) Acc D Fake: 85.101%
Loss D: 1.020
Loss G: 0.7369 (0.7450) Acc G: 14.857%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3382 (0.3647) Acc D Real: 62.706%
Loss D Fake: 0.6550 (0.6474) Acc D Fake: 85.100%
Loss D: 0.993
Loss G: 0.7353 (0.7450) Acc G: 14.858%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3729 (0.3647) Acc D Real: 62.687%
Loss D Fake: 0.6564 (0.6475) Acc D Fake: 85.099%
Loss D: 1.029
Loss G: 0.7338 (0.7449) Acc G: 14.859%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.2975 (0.3642) Acc D Real: 62.747%
Loss D Fake: 0.6574 (0.6476) Acc D Fake: 85.098%
Loss D: 0.955
Loss G: 0.7332 (0.7448) Acc G: 14.861%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3137 (0.3638) Acc D Real: 62.789%
Loss D Fake: 0.6577 (0.6476) Acc D Fake: 85.097%
Loss D: 0.971
Loss G: 0.7332 (0.7447) Acc G: 14.862%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3983 (0.3640) Acc D Real: 62.738%
Loss D Fake: 0.6576 (0.6477) Acc D Fake: 85.097%
Loss D: 1.056
Loss G: 0.7330 (0.7446) Acc G: 14.863%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3320 (0.3638) Acc D Real: 62.757%
Loss D Fake: 0.6577 (0.6478) Acc D Fake: 85.096%
Loss D: 0.990
Loss G: 0.7331 (0.7445) Acc G: 14.864%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.4001 (0.3641) Acc D Real: 62.713%
Loss D Fake: 0.6577 (0.6479) Acc D Fake: 85.095%
Loss D: 1.058
Loss G: 0.7331 (0.7444) Acc G: 14.865%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3171 (0.3637) Acc D Real: 62.746%
Loss D Fake: 0.6577 (0.6480) Acc D Fake: 85.094%
Loss D: 0.975
Loss G: 0.7333 (0.7443) Acc G: 14.866%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3464 (0.3636) Acc D Real: 62.758%
Loss D Fake: 0.6572 (0.6480) Acc D Fake: 85.094%
Loss D: 1.004
Loss G: 0.7339 (0.7442) Acc G: 14.867%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4347 (0.3641) Acc D Real: 62.669%
Loss D Fake: 0.6570 (0.6481) Acc D Fake: 85.093%
Loss D: 1.092
Loss G: 0.7336 (0.7441) Acc G: 14.868%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.2583 (0.3633) Acc D Real: 62.766%
Loss D Fake: 0.6571 (0.6482) Acc D Fake: 85.092%
Loss D: 0.915
Loss G: 0.7342 (0.7441) Acc G: 14.869%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4142 (0.3637) Acc D Real: 62.705%
Loss D Fake: 0.6565 (0.6482) Acc D Fake: 85.091%
Loss D: 1.071
Loss G: 0.7345 (0.7440) Acc G: 14.870%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2939 (0.3632) Acc D Real: 62.758%
Loss D Fake: 0.6562 (0.6483) Acc D Fake: 85.091%
Loss D: 0.950
Loss G: 0.7351 (0.7439) Acc G: 14.871%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3257 (0.3629) Acc D Real: 62.784%
Loss D Fake: 0.6554 (0.6484) Acc D Fake: 85.090%
Loss D: 0.981
Loss G: 0.7362 (0.7439) Acc G: 14.872%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3159 (0.3625) Acc D Real: 62.819%
Loss D Fake: 0.6543 (0.6484) Acc D Fake: 85.089%
Loss D: 0.970
Loss G: 0.7376 (0.7438) Acc G: 14.873%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4242 (0.3630) Acc D Real: 62.747%
Loss D Fake: 0.6532 (0.6484) Acc D Fake: 85.089%
Loss D: 1.077
Loss G: 0.7384 (0.7438) Acc G: 14.874%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3855 (0.3631) Acc D Real: 62.724%
Loss D Fake: 0.6528 (0.6485) Acc D Fake: 85.088%
Loss D: 1.038
Loss G: 0.7387 (0.7437) Acc G: 14.875%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3428 (0.3630) Acc D Real: 62.738%
Loss D Fake: 0.6525 (0.6485) Acc D Fake: 85.087%
Loss D: 0.995
Loss G: 0.7391 (0.7437) Acc G: 14.876%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.2692 (0.3623) Acc D Real: 62.820%
Loss D Fake: 0.6519 (0.6485) Acc D Fake: 85.087%
Loss D: 0.921
Loss G: 0.7403 (0.7437) Acc G: 14.877%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.2709 (0.3616) Acc D Real: 62.891%
Loss D Fake: 0.6504 (0.6485) Acc D Fake: 85.086%
Loss D: 0.921
Loss G: 0.7423 (0.7437) Acc G: 14.878%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3838 (0.3618) Acc D Real: 62.860%
Loss D Fake: 0.6486 (0.6485) Acc D Fake: 85.085%
Loss D: 1.032
Loss G: 0.7441 (0.7437) Acc G: 14.879%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3471 (0.3617) Acc D Real: 62.867%
Loss D Fake: 0.6472 (0.6485) Acc D Fake: 85.085%
Loss D: 0.994
Loss G: 0.7455 (0.7437) Acc G: 14.879%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3605 (0.3617) Acc D Real: 62.856%
Loss D Fake: 0.6461 (0.6485) Acc D Fake: 85.084%
Loss D: 1.007
Loss G: 0.7466 (0.7437) Acc G: 14.880%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.3642 (0.3617) Acc D Real: 62.844%
Loss D Fake: 0.6453 (0.6485) Acc D Fake: 85.084%
Loss D: 1.009
Loss G: 0.7474 (0.7437) Acc G: 14.881%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3661 (0.3617) Acc D Real: 62.837%
Loss D Fake: 0.6447 (0.6485) Acc D Fake: 85.083%
Loss D: 1.011
Loss G: 0.7480 (0.7438) Acc G: 14.882%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3453 (0.3616) Acc D Real: 62.842%
Loss D Fake: 0.6441 (0.6484) Acc D Fake: 85.082%
Loss D: 0.989
Loss G: 0.7488 (0.7438) Acc G: 14.883%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.2972 (0.3612) Acc D Real: 62.892%
Loss D Fake: 0.6433 (0.6484) Acc D Fake: 85.082%
Loss D: 0.941
Loss G: 0.7500 (0.7438) Acc G: 14.884%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.2816 (0.3606) Acc D Real: 62.958%
Loss D Fake: 0.6420 (0.6484) Acc D Fake: 85.081%
Loss D: 0.924
Loss G: 0.7518 (0.7439) Acc G: 14.884%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.4506 (0.3612) Acc D Real: 62.872%
Loss D Fake: 0.6406 (0.6483) Acc D Fake: 85.081%
Loss D: 1.091
Loss G: 0.7527 (0.7440) Acc G: 14.885%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3712 (0.3613) Acc D Real: 62.858%
Loss D Fake: 0.6402 (0.6482) Acc D Fake: 85.080%
Loss D: 1.011
Loss G: 0.7530 (0.7440) Acc G: 14.886%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3891 (0.3615) Acc D Real: 62.829%
Loss D Fake: 0.6400 (0.6482) Acc D Fake: 85.080%
Loss D: 1.029
Loss G: 0.7531 (0.7441) Acc G: 14.887%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3746 (0.3616) Acc D Real: 62.816%
Loss D Fake: 0.6400 (0.6481) Acc D Fake: 85.079%
Loss D: 1.015
Loss G: 0.7531 (0.7441) Acc G: 14.888%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.2826 (0.3611) Acc D Real: 62.879%
Loss D Fake: 0.6399 (0.6481) Acc D Fake: 85.079%
Loss D: 0.922
Loss G: 0.7536 (0.7442) Acc G: 14.888%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3217 (0.3608) Acc D Real: 62.909%
Loss D Fake: 0.6391 (0.6480) Acc D Fake: 85.078%
Loss D: 0.961
Loss G: 0.7546 (0.7443) Acc G: 14.889%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4557 (0.3614) Acc D Real: 62.830%
Loss D Fake: 0.6385 (0.6480) Acc D Fake: 85.078%
Loss D: 1.094
Loss G: 0.7548 (0.7443) Acc G: 14.890%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3631 (0.3614) Acc D Real: 62.820%
Loss D Fake: 0.6385 (0.6479) Acc D Fake: 85.077%
Loss D: 1.002
Loss G: 0.7547 (0.7444) Acc G: 14.890%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4050 (0.3617) Acc D Real: 62.774%
Loss D Fake: 0.6388 (0.6478) Acc D Fake: 85.077%
Loss D: 1.044
Loss G: 0.7542 (0.7445) Acc G: 14.891%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4276 (0.3621) Acc D Real: 62.711%
Loss D Fake: 0.6395 (0.6478) Acc D Fake: 85.076%
Loss D: 1.067
Loss G: 0.7530 (0.7445) Acc G: 14.892%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.2757 (0.3616) Acc D Real: 62.771%
Loss D Fake: 0.6404 (0.6477) Acc D Fake: 85.076%
Loss D: 0.916
Loss G: 0.7526 (0.7446) Acc G: 14.893%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2812 (0.3611) Acc D Real: 62.775%
Loss D Fake: 0.6403 (0.6477) Acc D Fake: 85.076%
Loss D: 0.922
Loss G: 0.7530 (0.7446) Acc G: 14.893%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.339 | Generator Loss: 0.753 | Avg: 2.092
TEST [21/180]: Discriminator Loss: 1.222 | Generator Loss: 0.753 | Avg: 1.975
TEST [31/180]: Discriminator Loss: 1.255 | Generator Loss: 0.753 | Avg: 2.008
TEST [41/180]: Discriminator Loss: 1.281 | Generator Loss: 0.753 | Avg: 2.034
TEST [51/180]: Discriminator Loss: 1.282 | Generator Loss: 0.753 | Avg: 2.035
TEST [61/180]: Discriminator Loss: 1.232 | Generator Loss: 0.753 | Avg: 1.985
TEST [71/180]: Discriminator Loss: 1.198 | Generator Loss: 0.753 | Avg: 1.951
TEST [81/180]: Discriminator Loss: 1.150 | Generator Loss: 0.753 | Avg: 1.903
TEST [91/180]: Discriminator Loss: 1.120 | Generator Loss: 0.753 | Avg: 1.872
TEST [101/180]: Discriminator Loss: 1.077 | Generator Loss: 0.753 | Avg: 1.830
TEST [111/180]: Discriminator Loss: 1.043 | Generator Loss: 0.753 | Avg: 1.796
TEST [121/180]: Discriminator Loss: 1.013 | Generator Loss: 0.753 | Avg: 1.766
TEST [131/180]: Discriminator Loss: 0.989 | Generator Loss: 0.753 | Avg: 1.742
TEST [141/180]: Discriminator Loss: 0.969 | Generator Loss: 0.753 | Avg: 1.722
TEST [151/180]: Discriminator Loss: 0.985 | Generator Loss: 0.753 | Avg: 1.738
TEST [161/180]: Discriminator Loss: 1.001 | Generator Loss: 0.753 | Avg: 1.754
TEST [171/180]: Discriminator Loss: 1.017 | Generator Loss: 0.753 | Avg: 1.770
Epoch: 14/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3609 (0.3702) Acc D Real: 60.833%
Loss D Fake: 0.6397 (0.6398) Acc D Fake: 85.000%
Loss D: 1.001
Loss G: 0.7535 (0.7534) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3156 (0.3520) Acc D Real: 62.778%
Loss D Fake: 0.6394 (0.6397) Acc D Fake: 85.000%
Loss D: 0.955
Loss G: 0.7540 (0.7536) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2564 (0.3281) Acc D Real: 65.651%
Loss D Fake: 0.6388 (0.6395) Acc D Fake: 85.000%
Loss D: 0.895
Loss G: 0.7552 (0.7540) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3878 (0.3400) Acc D Real: 64.365%
Loss D Fake: 0.6376 (0.6391) Acc D Fake: 85.000%
Loss D: 1.025
Loss G: 0.7563 (0.7545) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3825 (0.3471) Acc D Real: 63.377%
Loss D Fake: 0.6370 (0.6387) Acc D Fake: 85.000%
Loss D: 1.019
Loss G: 0.7568 (0.7549) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.2976 (0.3400) Acc D Real: 64.286%
Loss D Fake: 0.6365 (0.6384) Acc D Fake: 85.000%
Loss D: 0.934
Loss G: 0.7576 (0.7553) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.4533 (0.3542) Acc D Real: 62.546%
Loss D Fake: 0.6360 (0.6381) Acc D Fake: 85.000%
Loss D: 1.089
Loss G: 0.7577 (0.7556) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.2071 (0.3378) Acc D Real: 64.554%
Loss D Fake: 0.6358 (0.6379) Acc D Fake: 85.000%
Loss D: 0.843
Loss G: 0.7587 (0.7559) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3376 (0.3378) Acc D Real: 64.427%
Loss D Fake: 0.6347 (0.6375) Acc D Fake: 85.000%
Loss D: 0.972
Loss G: 0.7599 (0.7563) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3386 (0.3379) Acc D Real: 64.470%
Loss D Fake: 0.6336 (0.6372) Acc D Fake: 85.000%
Loss D: 0.972
Loss G: 0.7612 (0.7568) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4165 (0.3444) Acc D Real: 63.728%
Loss D Fake: 0.6327 (0.6368) Acc D Fake: 85.000%
Loss D: 1.049
Loss G: 0.7617 (0.7572) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3474 (0.3447) Acc D Real: 63.722%
Loss D Fake: 0.6325 (0.6365) Acc D Fake: 85.000%
Loss D: 0.980
Loss G: 0.7620 (0.7575) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3012 (0.3416) Acc D Real: 64.126%
Loss D Fake: 0.6321 (0.6362) Acc D Fake: 85.000%
Loss D: 0.933
Loss G: 0.7627 (0.7579) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4768 (0.3506) Acc D Real: 63.045%
Loss D Fake: 0.6318 (0.6359) Acc D Fake: 85.000%
Loss D: 1.109
Loss G: 0.7623 (0.7582) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3687 (0.3517) Acc D Real: 62.923%
Loss D Fake: 0.6324 (0.6357) Acc D Fake: 85.000%
Loss D: 1.001
Loss G: 0.7616 (0.7584) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3662 (0.3526) Acc D Real: 62.809%
Loss D Fake: 0.6331 (0.6355) Acc D Fake: 85.000%
Loss D: 0.999
Loss G: 0.7608 (0.7585) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.2835 (0.3487) Acc D Real: 63.319%
Loss D Fake: 0.6335 (0.6354) Acc D Fake: 85.000%
Loss D: 0.917
Loss G: 0.7608 (0.7587) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.2270 (0.3423) Acc D Real: 64.093%
Loss D Fake: 0.6330 (0.6353) Acc D Fake: 85.000%
Loss D: 0.860
Loss G: 0.7620 (0.7588) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.4083 (0.3456) Acc D Real: 63.669%
Loss D Fake: 0.6319 (0.6351) Acc D Fake: 85.000%
Loss D: 1.040
Loss G: 0.7628 (0.7590) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3442 (0.3456) Acc D Real: 63.700%
Loss D Fake: 0.6315 (0.6349) Acc D Fake: 85.000%
Loss D: 0.976
Loss G: 0.7633 (0.7592) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3267 (0.3447) Acc D Real: 63.866%
Loss D Fake: 0.6310 (0.6347) Acc D Fake: 85.000%
Loss D: 0.958
Loss G: 0.7641 (0.7595) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3194 (0.3436) Acc D Real: 64.008%
Loss D Fake: 0.6302 (0.6346) Acc D Fake: 85.000%
Loss D: 0.950
Loss G: 0.7651 (0.7597) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.2343 (0.3390) Acc D Real: 64.575%
Loss D Fake: 0.6291 (0.6343) Acc D Fake: 85.000%
Loss D: 0.863
Loss G: 0.7670 (0.7600) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3502 (0.3395) Acc D Real: 64.538%
Loss D Fake: 0.6273 (0.6340) Acc D Fake: 85.000%
Loss D: 0.978
Loss G: 0.7689 (0.7604) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3673 (0.3406) Acc D Real: 64.391%
Loss D Fake: 0.6259 (0.6337) Acc D Fake: 85.000%
Loss D: 0.993
Loss G: 0.7703 (0.7608) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.2831 (0.3384) Acc D Real: 64.668%
Loss D Fake: 0.6247 (0.6334) Acc D Fake: 85.000%
Loss D: 0.908
Loss G: 0.7722 (0.7612) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4141 (0.3411) Acc D Real: 64.345%
Loss D Fake: 0.6233 (0.6330) Acc D Fake: 85.000%
Loss D: 1.037
Loss G: 0.7733 (0.7616) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3892 (0.3428) Acc D Real: 64.161%
Loss D Fake: 0.6226 (0.6327) Acc D Fake: 85.000%
Loss D: 1.012
Loss G: 0.7738 (0.7620) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3249 (0.3422) Acc D Real: 64.224%
Loss D Fake: 0.6224 (0.6323) Acc D Fake: 85.000%
Loss D: 0.947
Loss G: 0.7742 (0.7624) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3957 (0.3439) Acc D Real: 64.017%
Loss D Fake: 0.6221 (0.6320) Acc D Fake: 85.000%
Loss D: 1.018
Loss G: 0.7742 (0.7628) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3921 (0.3454) Acc D Real: 63.813%
Loss D Fake: 0.6223 (0.6317) Acc D Fake: 85.000%
Loss D: 1.014
Loss G: 0.7738 (0.7632) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3055 (0.3442) Acc D Real: 63.971%
Loss D Fake: 0.6226 (0.6314) Acc D Fake: 85.000%
Loss D: 0.928
Loss G: 0.7737 (0.7635) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3148 (0.3433) Acc D Real: 64.107%
Loss D Fake: 0.6225 (0.6312) Acc D Fake: 85.000%
Loss D: 0.937
Loss G: 0.7741 (0.7638) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.2342 (0.3402) Acc D Real: 64.497%
Loss D Fake: 0.6217 (0.6309) Acc D Fake: 85.000%
Loss D: 0.856
Loss G: 0.7756 (0.7641) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3979 (0.3418) Acc D Real: 64.372%
Loss D Fake: 0.6204 (0.6306) Acc D Fake: 85.000%
Loss D: 1.018
Loss G: 0.7768 (0.7645) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.4137 (0.3438) Acc D Real: 64.131%
Loss D Fake: 0.6198 (0.6303) Acc D Fake: 85.000%
Loss D: 1.033
Loss G: 0.7771 (0.7648) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3220 (0.3432) Acc D Real: 64.221%
Loss D Fake: 0.6197 (0.6300) Acc D Fake: 85.000%
Loss D: 0.942
Loss G: 0.7774 (0.7652) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.4420 (0.3457) Acc D Real: 63.904%
Loss D Fake: 0.6196 (0.6298) Acc D Fake: 85.000%
Loss D: 1.062
Loss G: 0.7769 (0.7655) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.5087 (0.3498) Acc D Real: 63.439%
Loss D Fake: 0.6207 (0.6295) Acc D Fake: 85.000%
Loss D: 1.129
Loss G: 0.7748 (0.7657) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3085 (0.3488) Acc D Real: 63.580%
Loss D Fake: 0.6225 (0.6294) Acc D Fake: 85.000%
Loss D: 0.931
Loss G: 0.7730 (0.7659) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3930 (0.3499) Acc D Real: 63.439%
Loss D Fake: 0.6238 (0.6292) Acc D Fake: 85.000%
Loss D: 1.017
Loss G: 0.7713 (0.7660) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3691 (0.3503) Acc D Real: 63.391%
Loss D Fake: 0.6253 (0.6291) Acc D Fake: 85.000%
Loss D: 0.994
Loss G: 0.7696 (0.7661) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.2809 (0.3487) Acc D Real: 63.584%
Loss D Fake: 0.6265 (0.6291) Acc D Fake: 85.000%
Loss D: 0.907
Loss G: 0.7687 (0.7661) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.4169 (0.3502) Acc D Real: 63.411%
Loss D Fake: 0.6271 (0.6290) Acc D Fake: 85.000%
Loss D: 1.044
Loss G: 0.7677 (0.7662) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3498 (0.3502) Acc D Real: 63.423%
Loss D Fake: 0.6281 (0.6290) Acc D Fake: 85.000%
Loss D: 0.978
Loss G: 0.7667 (0.7662) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3447 (0.3501) Acc D Real: 63.431%
Loss D Fake: 0.6288 (0.6290) Acc D Fake: 85.000%
Loss D: 0.973
Loss G: 0.7660 (0.7662) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.2749 (0.3485) Acc D Real: 63.630%
Loss D Fake: 0.6291 (0.6290) Acc D Fake: 85.000%
Loss D: 0.904
Loss G: 0.7661 (0.7662) Acc G: 15.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3504 (0.3486) Acc D Real: 63.658%
Loss D Fake: 0.6288 (0.6290) Acc D Fake: 84.971%
Loss D: 0.979
Loss G: 0.7665 (0.7662) Acc G: 15.033%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3051 (0.3477) Acc D Real: 63.780%
Loss D Fake: 0.6283 (0.6290) Acc D Fake: 84.939%
Loss D: 0.933
Loss G: 0.7674 (0.7662) Acc G: 15.066%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3279 (0.3473) Acc D Real: 63.841%
Loss D Fake: 0.6274 (0.6290) Acc D Fake: 84.907%
Loss D: 0.955
Loss G: 0.7686 (0.7663) Acc G: 15.097%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4334 (0.3490) Acc D Real: 63.632%
Loss D Fake: 0.6266 (0.6289) Acc D Fake: 84.877%
Loss D: 1.060
Loss G: 0.7689 (0.7663) Acc G: 15.127%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3259 (0.3485) Acc D Real: 63.683%
Loss D Fake: 0.6266 (0.6289) Acc D Fake: 84.848%
Loss D: 0.952
Loss G: 0.7691 (0.7664) Acc G: 15.156%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.4352 (0.3502) Acc D Real: 63.487%
Loss D Fake: 0.6265 (0.6288) Acc D Fake: 84.820%
Loss D: 1.062
Loss G: 0.7687 (0.7664) Acc G: 15.184%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.2761 (0.3488) Acc D Real: 63.658%
Loss D Fake: 0.6269 (0.6288) Acc D Fake: 84.793%
Loss D: 0.903
Loss G: 0.7687 (0.7664) Acc G: 15.211%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.4332 (0.3503) Acc D Real: 63.461%
Loss D Fake: 0.6269 (0.6288) Acc D Fake: 84.767%
Loss D: 1.060
Loss G: 0.7683 (0.7665) Acc G: 15.237%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3274 (0.3499) Acc D Real: 63.527%
Loss D Fake: 0.6273 (0.6287) Acc D Fake: 84.741%
Loss D: 0.955
Loss G: 0.7680 (0.7665) Acc G: 15.262%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3273 (0.3495) Acc D Real: 63.583%
Loss D Fake: 0.6273 (0.6287) Acc D Fake: 84.717%
Loss D: 0.955
Loss G: 0.7682 (0.7665) Acc G: 15.286%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3397 (0.3494) Acc D Real: 63.589%
Loss D Fake: 0.6271 (0.6287) Acc D Fake: 84.694%
Loss D: 0.967
Loss G: 0.7685 (0.7666) Acc G: 15.310%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.4343 (0.3508) Acc D Real: 63.411%
Loss D Fake: 0.6271 (0.6287) Acc D Fake: 84.671%
Loss D: 1.061
Loss G: 0.7680 (0.7666) Acc G: 15.332%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.4091 (0.3517) Acc D Real: 63.311%
Loss D Fake: 0.6278 (0.6286) Acc D Fake: 84.649%
Loss D: 1.037
Loss G: 0.7668 (0.7666) Acc G: 15.354%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2302 (0.3498) Acc D Real: 63.543%
Loss D Fake: 0.6286 (0.6286) Acc D Fake: 84.628%
Loss D: 0.859
Loss G: 0.7668 (0.7666) Acc G: 15.376%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3635 (0.3500) Acc D Real: 63.514%
Loss D Fake: 0.6283 (0.6286) Acc D Fake: 84.607%
Loss D: 0.992
Loss G: 0.7670 (0.7666) Acc G: 15.396%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3895 (0.3506) Acc D Real: 63.429%
Loss D Fake: 0.6283 (0.6286) Acc D Fake: 84.587%
Loss D: 1.018
Loss G: 0.7668 (0.7666) Acc G: 15.416%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4309 (0.3518) Acc D Real: 63.276%
Loss D Fake: 0.6288 (0.6286) Acc D Fake: 84.568%
Loss D: 1.060
Loss G: 0.7658 (0.7666) Acc G: 15.435%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3204 (0.3514) Acc D Real: 63.329%
Loss D Fake: 0.6297 (0.6286) Acc D Fake: 84.549%
Loss D: 0.950
Loss G: 0.7650 (0.7666) Acc G: 15.454%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2593 (0.3500) Acc D Real: 63.497%
Loss D Fake: 0.6300 (0.6287) Acc D Fake: 84.531%
Loss D: 0.889
Loss G: 0.7652 (0.7665) Acc G: 15.472%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4304 (0.3512) Acc D Real: 63.338%
Loss D Fake: 0.6297 (0.6287) Acc D Fake: 84.514%
Loss D: 1.060
Loss G: 0.7649 (0.7665) Acc G: 15.489%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3626 (0.3513) Acc D Real: 63.305%
Loss D Fake: 0.6302 (0.6287) Acc D Fake: 84.497%
Loss D: 0.993
Loss G: 0.7644 (0.7665) Acc G: 15.506%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.2670 (0.3501) Acc D Real: 63.465%
Loss D Fake: 0.6304 (0.6287) Acc D Fake: 84.480%
Loss D: 0.897
Loss G: 0.7647 (0.7665) Acc G: 15.523%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3404 (0.3500) Acc D Real: 63.477%
Loss D Fake: 0.6299 (0.6287) Acc D Fake: 84.464%
Loss D: 0.970
Loss G: 0.7654 (0.7665) Acc G: 15.539%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.4122 (0.3509) Acc D Real: 63.373%
Loss D Fake: 0.6295 (0.6288) Acc D Fake: 84.448%
Loss D: 1.042
Loss G: 0.7655 (0.7664) Acc G: 15.555%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3880 (0.3514) Acc D Real: 63.318%
Loss D Fake: 0.6296 (0.6288) Acc D Fake: 84.433%
Loss D: 1.018
Loss G: 0.7651 (0.7664) Acc G: 15.570%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2808 (0.3504) Acc D Real: 63.440%
Loss D Fake: 0.6298 (0.6288) Acc D Fake: 84.418%
Loss D: 0.911
Loss G: 0.7654 (0.7664) Acc G: 15.585%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3676 (0.3506) Acc D Real: 63.412%
Loss D Fake: 0.6294 (0.6288) Acc D Fake: 84.403%
Loss D: 0.997
Loss G: 0.7658 (0.7664) Acc G: 15.599%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4320 (0.3517) Acc D Real: 63.278%
Loss D Fake: 0.6294 (0.6288) Acc D Fake: 84.389%
Loss D: 1.061
Loss G: 0.7653 (0.7664) Acc G: 15.613%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3477 (0.3517) Acc D Real: 63.282%
Loss D Fake: 0.6300 (0.6288) Acc D Fake: 84.376%
Loss D: 0.978
Loss G: 0.7646 (0.7664) Acc G: 15.627%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.2937 (0.3509) Acc D Real: 63.365%
Loss D Fake: 0.6304 (0.6288) Acc D Fake: 84.371%
Loss D: 0.924
Loss G: 0.7646 (0.7663) Acc G: 15.622%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3275 (0.3506) Acc D Real: 63.408%
Loss D Fake: 0.6302 (0.6289) Acc D Fake: 84.379%
Loss D: 0.958
Loss G: 0.7649 (0.7663) Acc G: 15.614%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4051 (0.3513) Acc D Real: 63.305%
Loss D Fake: 0.6300 (0.6289) Acc D Fake: 84.387%
Loss D: 1.035
Loss G: 0.7648 (0.7663) Acc G: 15.606%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4048 (0.3520) Acc D Real: 63.216%
Loss D Fake: 0.6304 (0.6289) Acc D Fake: 84.394%
Loss D: 1.035
Loss G: 0.7640 (0.7663) Acc G: 15.599%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.2742 (0.3510) Acc D Real: 63.324%
Loss D Fake: 0.6310 (0.6289) Acc D Fake: 84.402%
Loss D: 0.905
Loss G: 0.7638 (0.7662) Acc G: 15.591%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3189 (0.3506) Acc D Real: 63.379%
Loss D Fake: 0.6309 (0.6289) Acc D Fake: 84.409%
Loss D: 0.950
Loss G: 0.7642 (0.7662) Acc G: 15.584%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3632 (0.3508) Acc D Real: 63.361%
Loss D Fake: 0.6305 (0.6290) Acc D Fake: 84.416%
Loss D: 0.994
Loss G: 0.7646 (0.7662) Acc G: 15.577%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3699 (0.3510) Acc D Real: 63.338%
Loss D Fake: 0.6302 (0.6290) Acc D Fake: 84.423%
Loss D: 1.000
Loss G: 0.7648 (0.7662) Acc G: 15.570%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3630 (0.3511) Acc D Real: 63.314%
Loss D Fake: 0.6302 (0.6290) Acc D Fake: 84.430%
Loss D: 0.993
Loss G: 0.7647 (0.7662) Acc G: 15.564%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.2499 (0.3500) Acc D Real: 63.461%
Loss D Fake: 0.6300 (0.6290) Acc D Fake: 84.436%
Loss D: 0.880
Loss G: 0.7655 (0.7662) Acc G: 15.557%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3035 (0.3494) Acc D Real: 63.528%
Loss D Fake: 0.6290 (0.6290) Acc D Fake: 84.442%
Loss D: 0.932
Loss G: 0.7669 (0.7662) Acc G: 15.551%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.2558 (0.3484) Acc D Real: 63.658%
Loss D Fake: 0.6277 (0.6290) Acc D Fake: 84.449%
Loss D: 0.884
Loss G: 0.7689 (0.7662) Acc G: 15.545%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3715 (0.3487) Acc D Real: 63.628%
Loss D Fake: 0.6260 (0.6289) Acc D Fake: 84.455%
Loss D: 0.997
Loss G: 0.7707 (0.7662) Acc G: 15.539%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3637 (0.3488) Acc D Real: 63.594%
Loss D Fake: 0.6247 (0.6289) Acc D Fake: 84.461%
Loss D: 0.988
Loss G: 0.7719 (0.7663) Acc G: 15.533%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3258 (0.3486) Acc D Real: 63.629%
Loss D Fake: 0.6238 (0.6288) Acc D Fake: 84.467%
Loss D: 0.950
Loss G: 0.7730 (0.7664) Acc G: 15.527%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4357 (0.3495) Acc D Real: 63.516%
Loss D Fake: 0.6231 (0.6288) Acc D Fake: 84.472%
Loss D: 1.059
Loss G: 0.7733 (0.7665) Acc G: 15.521%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.2499 (0.3484) Acc D Real: 63.642%
Loss D Fake: 0.6229 (0.6287) Acc D Fake: 84.478%
Loss D: 0.873
Loss G: 0.7741 (0.7665) Acc G: 15.516%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2602 (0.3475) Acc D Real: 63.771%
Loss D Fake: 0.6218 (0.6286) Acc D Fake: 84.484%
Loss D: 0.882
Loss G: 0.7758 (0.7666) Acc G: 15.510%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.2905 (0.3469) Acc D Real: 63.866%
Loss D Fake: 0.6201 (0.6286) Acc D Fake: 84.489%
Loss D: 0.911
Loss G: 0.7782 (0.7668) Acc G: 15.505%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.4350 (0.3478) Acc D Real: 63.748%
Loss D Fake: 0.6185 (0.6285) Acc D Fake: 84.494%
Loss D: 1.054
Loss G: 0.7794 (0.7669) Acc G: 15.500%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3884 (0.3482) Acc D Real: 63.690%
Loss D Fake: 0.6180 (0.6283) Acc D Fake: 84.499%
Loss D: 1.006
Loss G: 0.7797 (0.7670) Acc G: 15.495%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.4327 (0.3491) Acc D Real: 63.567%
Loss D Fake: 0.6181 (0.6282) Acc D Fake: 84.504%
Loss D: 1.051
Loss G: 0.7789 (0.7671) Acc G: 15.490%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3622 (0.3492) Acc D Real: 63.548%
Loss D Fake: 0.6191 (0.6282) Acc D Fake: 84.509%
Loss D: 0.981
Loss G: 0.7777 (0.7672) Acc G: 15.485%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4323 (0.3501) Acc D Real: 63.448%
Loss D Fake: 0.6203 (0.6281) Acc D Fake: 84.514%
Loss D: 1.053
Loss G: 0.7758 (0.7673) Acc G: 15.480%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3444 (0.3500) Acc D Real: 63.454%
Loss D Fake: 0.6219 (0.6280) Acc D Fake: 84.519%
Loss D: 0.966
Loss G: 0.7741 (0.7674) Acc G: 15.475%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3491 (0.3500) Acc D Real: 63.462%
Loss D Fake: 0.6232 (0.6280) Acc D Fake: 84.524%
Loss D: 0.972
Loss G: 0.7727 (0.7674) Acc G: 15.471%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.2764 (0.3493) Acc D Real: 63.542%
Loss D Fake: 0.6240 (0.6279) Acc D Fake: 84.528%
Loss D: 0.900
Loss G: 0.7722 (0.7675) Acc G: 15.466%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.2843 (0.3487) Acc D Real: 63.629%
Loss D Fake: 0.6240 (0.6279) Acc D Fake: 84.533%
Loss D: 0.908
Loss G: 0.7727 (0.7675) Acc G: 15.462%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3021 (0.3482) Acc D Real: 63.687%
Loss D Fake: 0.6233 (0.6278) Acc D Fake: 84.537%
Loss D: 0.925
Loss G: 0.7738 (0.7676) Acc G: 15.457%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3696 (0.3484) Acc D Real: 63.660%
Loss D Fake: 0.6224 (0.6278) Acc D Fake: 84.541%
Loss D: 0.992
Loss G: 0.7745 (0.7677) Acc G: 15.453%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.2611 (0.3476) Acc D Real: 63.762%
Loss D Fake: 0.6217 (0.6277) Acc D Fake: 84.546%
Loss D: 0.883
Loss G: 0.7759 (0.7677) Acc G: 15.449%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3663 (0.3478) Acc D Real: 63.741%
Loss D Fake: 0.6205 (0.6277) Acc D Fake: 84.550%
Loss D: 0.987
Loss G: 0.7772 (0.7678) Acc G: 15.445%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4085 (0.3483) Acc D Real: 63.658%
Loss D Fake: 0.6198 (0.6276) Acc D Fake: 84.554%
Loss D: 1.028
Loss G: 0.7774 (0.7679) Acc G: 15.441%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.2586 (0.3475) Acc D Real: 63.757%
Loss D Fake: 0.6197 (0.6275) Acc D Fake: 84.558%
Loss D: 0.878
Loss G: 0.7780 (0.7680) Acc G: 15.437%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3431 (0.3475) Acc D Real: 63.753%
Loss D Fake: 0.6190 (0.6275) Acc D Fake: 84.562%
Loss D: 0.962
Loss G: 0.7788 (0.7681) Acc G: 15.433%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3918 (0.3479) Acc D Real: 63.697%
Loss D Fake: 0.6186 (0.6274) Acc D Fake: 84.566%
Loss D: 1.010
Loss G: 0.7789 (0.7682) Acc G: 15.429%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.2347 (0.3469) Acc D Real: 63.821%
Loss D Fake: 0.6184 (0.6273) Acc D Fake: 84.570%
Loss D: 0.853
Loss G: 0.7798 (0.7683) Acc G: 15.425%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.5076 (0.3483) Acc D Real: 63.649%
Loss D Fake: 0.6179 (0.6272) Acc D Fake: 84.573%
Loss D: 1.126
Loss G: 0.7794 (0.7684) Acc G: 15.422%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3702 (0.3485) Acc D Real: 63.624%
Loss D Fake: 0.6187 (0.6271) Acc D Fake: 84.566%
Loss D: 0.989
Loss G: 0.7784 (0.7685) Acc G: 15.432%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3673 (0.3486) Acc D Real: 63.602%
Loss D Fake: 0.6195 (0.6271) Acc D Fake: 84.556%
Loss D: 0.987
Loss G: 0.7774 (0.7686) Acc G: 15.442%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4544 (0.3495) Acc D Real: 63.491%
Loss D Fake: 0.6206 (0.6270) Acc D Fake: 84.545%
Loss D: 1.075
Loss G: 0.7755 (0.7686) Acc G: 15.453%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.4137 (0.3501) Acc D Real: 63.420%
Loss D Fake: 0.6225 (0.6270) Acc D Fake: 84.521%
Loss D: 1.036
Loss G: 0.7729 (0.7687) Acc G: 15.477%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2940 (0.3496) Acc D Real: 63.466%
Loss D Fake: 0.6246 (0.6270) Acc D Fake: 84.497%
Loss D: 0.919
Loss G: 0.7709 (0.7687) Acc G: 15.501%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3265 (0.3494) Acc D Real: 63.490%
Loss D Fake: 0.6258 (0.6270) Acc D Fake: 84.474%
Loss D: 0.952
Loss G: 0.7697 (0.7687) Acc G: 15.524%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.2521 (0.3486) Acc D Real: 63.584%
Loss D Fake: 0.6264 (0.6270) Acc D Fake: 84.451%
Loss D: 0.879
Loss G: 0.7697 (0.7687) Acc G: 15.547%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3393 (0.3485) Acc D Real: 63.591%
Loss D Fake: 0.6262 (0.6269) Acc D Fake: 84.428%
Loss D: 0.966
Loss G: 0.7700 (0.7687) Acc G: 15.570%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.4094 (0.3490) Acc D Real: 63.525%
Loss D Fake: 0.6262 (0.6269) Acc D Fake: 84.406%
Loss D: 1.036
Loss G: 0.7695 (0.7687) Acc G: 15.592%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3403 (0.3490) Acc D Real: 63.530%
Loss D Fake: 0.6267 (0.6269) Acc D Fake: 84.384%
Loss D: 0.967
Loss G: 0.7690 (0.7687) Acc G: 15.614%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.2975 (0.3486) Acc D Real: 63.581%
Loss D Fake: 0.6270 (0.6269) Acc D Fake: 84.363%
Loss D: 0.924
Loss G: 0.7691 (0.7687) Acc G: 15.636%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4319 (0.3492) Acc D Real: 63.488%
Loss D Fake: 0.6270 (0.6269) Acc D Fake: 84.341%
Loss D: 1.059
Loss G: 0.7684 (0.7687) Acc G: 15.657%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3488 (0.3492) Acc D Real: 63.486%
Loss D Fake: 0.6278 (0.6269) Acc D Fake: 84.320%
Loss D: 0.977
Loss G: 0.7675 (0.7687) Acc G: 15.678%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3044 (0.3489) Acc D Real: 63.526%
Loss D Fake: 0.6283 (0.6270) Acc D Fake: 84.300%
Loss D: 0.933
Loss G: 0.7673 (0.7687) Acc G: 15.698%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.2942 (0.3484) Acc D Real: 63.572%
Loss D Fake: 0.6282 (0.6270) Acc D Fake: 84.292%
Loss D: 0.922
Loss G: 0.7677 (0.7687) Acc G: 15.706%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.4521 (0.3492) Acc D Real: 63.471%
Loss D Fake: 0.6281 (0.6270) Acc D Fake: 84.285%
Loss D: 1.080
Loss G: 0.7672 (0.7687) Acc G: 15.713%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.2497 (0.3485) Acc D Real: 63.562%
Loss D Fake: 0.6285 (0.6270) Acc D Fake: 84.278%
Loss D: 0.878
Loss G: 0.7673 (0.7687) Acc G: 15.720%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.4468 (0.3492) Acc D Real: 63.455%
Loss D Fake: 0.6285 (0.6270) Acc D Fake: 84.271%
Loss D: 1.075
Loss G: 0.7668 (0.7686) Acc G: 15.728%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4077 (0.3496) Acc D Real: 63.400%
Loss D Fake: 0.6293 (0.6270) Acc D Fake: 84.264%
Loss D: 1.037
Loss G: 0.7655 (0.7686) Acc G: 15.735%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4059 (0.3501) Acc D Real: 63.341%
Loss D Fake: 0.6307 (0.6270) Acc D Fake: 84.257%
Loss D: 1.037
Loss G: 0.7636 (0.7686) Acc G: 15.742%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.2717 (0.3495) Acc D Real: 63.410%
Loss D Fake: 0.6321 (0.6271) Acc D Fake: 84.250%
Loss D: 0.904
Loss G: 0.7625 (0.7685) Acc G: 15.748%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3675 (0.3496) Acc D Real: 63.391%
Loss D Fake: 0.6328 (0.6271) Acc D Fake: 84.243%
Loss D: 1.000
Loss G: 0.7615 (0.7685) Acc G: 15.755%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3397 (0.3495) Acc D Real: 63.397%
Loss D Fake: 0.6337 (0.6272) Acc D Fake: 84.237%
Loss D: 0.973
Loss G: 0.7606 (0.7684) Acc G: 15.762%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3066 (0.3492) Acc D Real: 63.420%
Loss D Fake: 0.6343 (0.6272) Acc D Fake: 84.230%
Loss D: 0.941
Loss G: 0.7603 (0.7684) Acc G: 15.768%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3154 (0.3490) Acc D Real: 63.442%
Loss D Fake: 0.6344 (0.6273) Acc D Fake: 84.224%
Loss D: 0.950
Loss G: 0.7602 (0.7683) Acc G: 15.775%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3346 (0.3489) Acc D Real: 63.454%
Loss D Fake: 0.6344 (0.6273) Acc D Fake: 84.218%
Loss D: 0.969
Loss G: 0.7603 (0.7683) Acc G: 15.781%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4036 (0.3493) Acc D Real: 63.405%
Loss D Fake: 0.6345 (0.6274) Acc D Fake: 84.211%
Loss D: 1.038
Loss G: 0.7598 (0.7682) Acc G: 15.787%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4200 (0.3498) Acc D Real: 63.336%
Loss D Fake: 0.6353 (0.6274) Acc D Fake: 84.205%
Loss D: 1.055
Loss G: 0.7585 (0.7681) Acc G: 15.793%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.2945 (0.3494) Acc D Real: 63.378%
Loss D Fake: 0.6363 (0.6275) Acc D Fake: 84.199%
Loss D: 0.931
Loss G: 0.7577 (0.7681) Acc G: 15.799%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.3359 (0.3493) Acc D Real: 63.389%
Loss D Fake: 0.6368 (0.6276) Acc D Fake: 84.182%
Loss D: 0.973
Loss G: 0.7573 (0.7680) Acc G: 15.815%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.2523 (0.3486) Acc D Real: 63.472%
Loss D Fake: 0.6368 (0.6276) Acc D Fake: 84.165%
Loss D: 0.889
Loss G: 0.7579 (0.7679) Acc G: 15.833%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3865 (0.3489) Acc D Real: 63.437%
Loss D Fake: 0.6363 (0.6277) Acc D Fake: 84.137%
Loss D: 1.023
Loss G: 0.7582 (0.7678) Acc G: 15.861%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3601 (0.3490) Acc D Real: 63.423%
Loss D Fake: 0.6362 (0.6277) Acc D Fake: 84.109%
Loss D: 0.996
Loss G: 0.7581 (0.7678) Acc G: 15.889%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3796 (0.3492) Acc D Real: 63.388%
Loss D Fake: 0.6366 (0.6278) Acc D Fake: 84.081%
Loss D: 1.016
Loss G: 0.7573 (0.7677) Acc G: 15.917%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.2902 (0.3488) Acc D Real: 63.430%
Loss D Fake: 0.6373 (0.6279) Acc D Fake: 84.054%
Loss D: 0.927
Loss G: 0.7569 (0.7676) Acc G: 15.944%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.2391 (0.3481) Acc D Real: 63.527%
Loss D Fake: 0.6372 (0.6279) Acc D Fake: 84.027%
Loss D: 0.876
Loss G: 0.7577 (0.7676) Acc G: 15.971%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3527 (0.3481) Acc D Real: 63.509%
Loss D Fake: 0.6363 (0.6280) Acc D Fake: 84.001%
Loss D: 0.989
Loss G: 0.7586 (0.7675) Acc G: 15.997%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.2755 (0.3476) Acc D Real: 63.571%
Loss D Fake: 0.6355 (0.6280) Acc D Fake: 83.975%
Loss D: 0.911
Loss G: 0.7599 (0.7675) Acc G: 16.023%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3292 (0.3475) Acc D Real: 63.579%
Loss D Fake: 0.6343 (0.6281) Acc D Fake: 83.954%
Loss D: 0.963
Loss G: 0.7613 (0.7674) Acc G: 16.039%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3367 (0.3474) Acc D Real: 63.582%
Loss D Fake: 0.6332 (0.6281) Acc D Fake: 83.939%
Loss D: 0.970
Loss G: 0.7626 (0.7674) Acc G: 16.054%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.3598 (0.3475) Acc D Real: 63.563%
Loss D Fake: 0.6323 (0.6281) Acc D Fake: 83.924%
Loss D: 0.992
Loss G: 0.7634 (0.7674) Acc G: 16.069%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.3966 (0.3478) Acc D Real: 63.513%
Loss D Fake: 0.6320 (0.6281) Acc D Fake: 83.910%
Loss D: 1.029
Loss G: 0.7634 (0.7673) Acc G: 16.083%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.5214 (0.3489) Acc D Real: 63.501%
Loss D Fake: 0.6326 (0.6282) Acc D Fake: 83.909%
Loss D: 1.154
Loss G: 0.7620 (0.7673) Acc G: 16.084%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.329 | Generator Loss: 0.762 | Avg: 2.091
TEST [21/180]: Discriminator Loss: 1.203 | Generator Loss: 0.762 | Avg: 1.964
TEST [31/180]: Discriminator Loss: 1.234 | Generator Loss: 0.762 | Avg: 1.996
TEST [41/180]: Discriminator Loss: 1.268 | Generator Loss: 0.762 | Avg: 2.029
TEST [51/180]: Discriminator Loss: 1.267 | Generator Loss: 0.762 | Avg: 2.029
TEST [61/180]: Discriminator Loss: 1.216 | Generator Loss: 0.762 | Avg: 1.978
TEST [71/180]: Discriminator Loss: 1.178 | Generator Loss: 0.762 | Avg: 1.940
TEST [81/180]: Discriminator Loss: 1.130 | Generator Loss: 0.762 | Avg: 1.892
TEST [91/180]: Discriminator Loss: 1.099 | Generator Loss: 0.762 | Avg: 1.860
TEST [101/180]: Discriminator Loss: 1.057 | Generator Loss: 0.762 | Avg: 1.819
TEST [111/180]: Discriminator Loss: 1.024 | Generator Loss: 0.762 | Avg: 1.785
TEST [121/180]: Discriminator Loss: 0.994 | Generator Loss: 0.762 | Avg: 1.756
TEST [131/180]: Discriminator Loss: 0.970 | Generator Loss: 0.762 | Avg: 1.732
TEST [141/180]: Discriminator Loss: 0.951 | Generator Loss: 0.762 | Avg: 1.712
TEST [151/180]: Discriminator Loss: 0.965 | Generator Loss: 0.762 | Avg: 1.727
TEST [161/180]: Discriminator Loss: 0.980 | Generator Loss: 0.762 | Avg: 1.742
TEST [171/180]: Discriminator Loss: 0.997 | Generator Loss: 0.762 | Avg: 1.759
Epoch: 15/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.2893 (0.2944) Acc D Real: 69.661%
Loss D Fake: 0.6349 (0.6344) Acc D Fake: 81.667%
Loss D: 0.924
Loss G: 0.7599 (0.7603) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3124 (0.3004) Acc D Real: 68.681%
Loss D Fake: 0.6353 (0.6347) Acc D Fake: 81.667%
Loss D: 0.948
Loss G: 0.7596 (0.7600) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2504 (0.2879) Acc D Real: 70.182%
Loss D Fake: 0.6354 (0.6349) Acc D Fake: 81.667%
Loss D: 0.886
Loss G: 0.7600 (0.7600) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3118 (0.2927) Acc D Real: 69.469%
Loss D Fake: 0.6350 (0.6349) Acc D Fake: 81.365%
Loss D: 0.947
Loss G: 0.7604 (0.7601) Acc G: 18.667%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.2895 (0.2921) Acc D Real: 69.392%
Loss D Fake: 0.6347 (0.6349) Acc D Fake: 80.859%
Loss D: 0.924
Loss G: 0.7610 (0.7602) Acc G: 19.167%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3595 (0.3018) Acc D Real: 68.341%
Loss D Fake: 0.6342 (0.6348) Acc D Fake: 80.499%
Loss D: 0.994
Loss G: 0.7614 (0.7604) Acc G: 19.524%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.2021 (0.2893) Acc D Real: 69.824%
Loss D Fake: 0.6338 (0.6347) Acc D Fake: 80.436%
Loss D: 0.836
Loss G: 0.7626 (0.7607) Acc G: 19.583%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.2730 (0.2875) Acc D Real: 70.139%
Loss D Fake: 0.6325 (0.6344) Acc D Fake: 80.388%
Loss D: 0.905
Loss G: 0.7645 (0.7611) Acc G: 19.630%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.2519 (0.2839) Acc D Real: 70.620%
Loss D Fake: 0.6309 (0.6341) Acc D Fake: 80.349%
Loss D: 0.883
Loss G: 0.7667 (0.7617) Acc G: 19.667%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.4106 (0.2955) Acc D Real: 69.205%
Loss D Fake: 0.6294 (0.6336) Acc D Fake: 80.317%
Loss D: 1.040
Loss G: 0.7679 (0.7622) Acc G: 19.697%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4072 (0.3048) Acc D Real: 68.121%
Loss D Fake: 0.6291 (0.6332) Acc D Fake: 80.291%
Loss D: 1.036
Loss G: 0.7677 (0.7627) Acc G: 19.722%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.3625 (0.3092) Acc D Real: 67.660%
Loss D Fake: 0.6297 (0.6330) Acc D Fake: 80.260%
Loss D: 0.992
Loss G: 0.7668 (0.7630) Acc G: 19.744%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4793 (0.3214) Acc D Real: 66.187%
Loss D Fake: 0.6312 (0.6328) Acc D Fake: 80.134%
Loss D: 1.111
Loss G: 0.7643 (0.7631) Acc G: 19.881%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.2502 (0.3166) Acc D Real: 66.771%
Loss D Fake: 0.6335 (0.6329) Acc D Fake: 80.014%
Loss D: 0.884
Loss G: 0.7623 (0.7631) Acc G: 20.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3159 (0.3166) Acc D Real: 66.758%
Loss D Fake: 0.6351 (0.6330) Acc D Fake: 79.909%
Loss D: 0.951
Loss G: 0.7607 (0.7629) Acc G: 20.104%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.4974 (0.3272) Acc D Real: 65.417%
Loss D Fake: 0.6372 (0.6333) Acc D Fake: 79.816%
Loss D: 1.135
Loss G: 0.7575 (0.7626) Acc G: 20.196%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3391 (0.3279) Acc D Real: 65.336%
Loss D Fake: 0.6405 (0.6337) Acc D Fake: 79.641%
Loss D: 0.980
Loss G: 0.7540 (0.7621) Acc G: 20.370%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.2985 (0.3263) Acc D Real: 65.573%
Loss D Fake: 0.6439 (0.6342) Acc D Fake: 79.485%
Loss D: 0.942
Loss G: 0.7508 (0.7615) Acc G: 20.526%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.2685 (0.3234) Acc D Real: 65.919%
Loss D Fake: 0.6472 (0.6349) Acc D Fake: 79.260%
Loss D: 0.916
Loss G: 0.7477 (0.7608) Acc G: 20.750%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.4082 (0.3275) Acc D Real: 65.432%
Loss D Fake: 0.6516 (0.6357) Acc D Fake: 79.015%
Loss D: 1.060
Loss G: 0.7426 (0.7600) Acc G: 21.017%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3972 (0.3306) Acc D Real: 64.979%
Loss D Fake: 0.6600 (0.6368) Acc D Fake: 78.681%
Loss D: 1.057
Loss G: 0.7339 (0.7588) Acc G: 21.349%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4000 (0.3337) Acc D Real: 64.563%
Loss D Fake: 0.6807 (0.6387) Acc D Fake: 78.132%
Loss D: 1.081
Loss G: 0.7146 (0.7569) Acc G: 21.880%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3370 (0.3338) Acc D Real: 64.570%
Loss D Fake: 3.6728 (0.7651) Acc D Fake: 74.876%
Loss D: 4.010
Loss G: 0.1368 (0.7310) Acc G: 25.135%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.2230 (0.3294) Acc D Real: 65.110%
Loss D Fake: 3.7956 (0.8863) Acc D Fake: 71.881%
Loss D: 4.019
Loss G: 0.1183 (0.7065) Acc G: 28.129%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.2242 (0.3253) Acc D Real: 65.651%
Loss D Fake: 3.8407 (1.0000) Acc D Fake: 69.117%
Loss D: 4.065
Loss G: 0.1100 (0.6836) Acc G: 30.893%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4731 (0.3308) Acc D Real: 65.085%
Loss D Fake: 3.8553 (1.1057) Acc D Fake: 66.557%
Loss D: 4.328
Loss G: 0.1050 (0.6621) Acc G: 33.453%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3442 (0.3313) Acc D Real: 65.086%
Loss D Fake: 3.8532 (1.2038) Acc D Fake: 64.180%
Loss D: 4.197
Loss G: 0.1018 (0.6421) Acc G: 35.830%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.2801 (0.3295) Acc D Real: 65.665%
Loss D Fake: 3.8407 (1.2948) Acc D Fake: 61.967%
Loss D: 4.121
Loss G: 0.0995 (0.6234) Acc G: 38.042%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3498 (0.3302) Acc D Real: 66.128%
Loss D Fake: 3.8210 (1.3790) Acc D Fake: 59.901%
Loss D: 4.171
Loss G: 0.0979 (0.6059) Acc G: 40.108%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.2507 (0.3276) Acc D Real: 66.951%
Loss D Fake: 3.7964 (1.4569) Acc D Fake: 57.969%
Loss D: 4.047
Loss G: 0.0968 (0.5895) Acc G: 42.040%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3266 (0.3276) Acc D Real: 67.812%
Loss D Fake: 3.7683 (1.5292) Acc D Fake: 56.157%
Loss D: 4.095
Loss G: 0.0961 (0.5741) Acc G: 43.851%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.2921 (0.3265) Acc D Real: 68.670%
Loss D Fake: 3.7375 (1.5961) Acc D Fake: 54.455%
Loss D: 4.030
Loss G: 0.0956 (0.5596) Acc G: 45.552%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.2486 (0.3242) Acc D Real: 69.522%
Loss D Fake: 3.7049 (1.6581) Acc D Fake: 52.854%
Loss D: 3.953
Loss G: 0.0953 (0.5459) Acc G: 47.154%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.2468 (0.3220) Acc D Real: 70.329%
Loss D Fake: 3.6709 (1.7156) Acc D Fake: 51.344%
Loss D: 3.918
Loss G: 0.0952 (0.5330) Acc G: 48.664%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.2814 (0.3209) Acc D Real: 71.092%
Loss D Fake: 3.6359 (1.7690) Acc D Fake: 49.918%
Loss D: 3.917
Loss G: 0.0953 (0.5209) Acc G: 50.090%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.2742 (0.3196) Acc D Real: 71.806%
Loss D Fake: 3.6002 (1.8185) Acc D Fake: 48.568%
Loss D: 3.874
Loss G: 0.0955 (0.5094) Acc G: 51.439%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.2549 (0.3179) Acc D Real: 72.481%
Loss D Fake: 3.5640 (1.8644) Acc D Fake: 47.290%
Loss D: 3.819
Loss G: 0.0958 (0.4985) Acc G: 52.717%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.2453 (0.3161) Acc D Real: 73.125%
Loss D Fake: 3.5275 (1.9070) Acc D Fake: 46.078%
Loss D: 3.773
Loss G: 0.0961 (0.4882) Acc G: 53.929%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.2604 (0.3147) Acc D Real: 73.724%
Loss D Fake: 3.4909 (1.9466) Acc D Fake: 44.926%
Loss D: 3.751
Loss G: 0.0966 (0.4784) Acc G: 55.081%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.2420 (0.3129) Acc D Real: 74.318%
Loss D Fake: 3.4543 (1.9834) Acc D Fake: 43.830%
Loss D: 3.696
Loss G: 0.0972 (0.4691) Acc G: 56.176%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.2630 (0.3117) Acc D Real: 74.876%
Loss D Fake: 3.4176 (2.0176) Acc D Fake: 42.786%
Loss D: 3.681
Loss G: 0.0978 (0.4602) Acc G: 57.220%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3001 (0.3114) Acc D Real: 75.389%
Loss D Fake: 3.3811 (2.0493) Acc D Fake: 41.791%
Loss D: 3.681
Loss G: 0.0985 (0.4518) Acc G: 58.215%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.2841 (0.3108) Acc D Real: 75.898%
Loss D Fake: 3.3448 (2.0787) Acc D Fake: 40.842%
Loss D: 3.629
Loss G: 0.0992 (0.4438) Acc G: 59.164%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.2141 (0.3087) Acc D Real: 76.403%
Loss D Fake: 3.3086 (2.1060) Acc D Fake: 39.934%
Loss D: 3.523
Loss G: 0.0999 (0.4362) Acc G: 60.072%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.1831 (0.3059) Acc D Real: 76.894%
Loss D Fake: 3.2727 (2.1314) Acc D Fake: 39.066%
Loss D: 3.456
Loss G: 0.1008 (0.4289) Acc G: 60.940%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.2724 (0.3052) Acc D Real: 77.342%
Loss D Fake: 3.2372 (2.1549) Acc D Fake: 38.235%
Loss D: 3.510
Loss G: 0.1016 (0.4219) Acc G: 61.771%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.2163 (0.3034) Acc D Real: 77.788%
Loss D Fake: 3.2017 (2.1767) Acc D Fake: 37.438%
Loss D: 3.418
Loss G: 0.1026 (0.4153) Acc G: 62.567%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.2622 (0.3025) Acc D Real: 78.202%
Loss D Fake: 3.1665 (2.1969) Acc D Fake: 36.674%
Loss D: 3.429
Loss G: 0.1036 (0.4089) Acc G: 63.331%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.2173 (0.3008) Acc D Real: 78.617%
Loss D Fake: 3.1314 (2.2156) Acc D Fake: 35.941%
Loss D: 3.349
Loss G: 0.1046 (0.4028) Acc G: 64.065%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.2349 (0.2995) Acc D Real: 79.008%
Loss D Fake: 3.0966 (2.2329) Acc D Fake: 35.236%
Loss D: 3.331
Loss G: 0.1057 (0.3970) Acc G: 64.769%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.2453 (0.2985) Acc D Real: 79.371%
Loss D Fake: 3.0619 (2.2488) Acc D Fake: 34.558%
Loss D: 3.307
Loss G: 0.1069 (0.3914) Acc G: 65.447%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.2341 (0.2973) Acc D Real: 79.730%
Loss D Fake: 3.0273 (2.2635) Acc D Fake: 33.906%
Loss D: 3.261
Loss G: 0.1082 (0.3861) Acc G: 66.099%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.2200 (0.2958) Acc D Real: 80.074%
Loss D Fake: 2.9929 (2.2770) Acc D Fake: 33.278%
Loss D: 3.213
Loss G: 0.1095 (0.3810) Acc G: 66.726%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.2438 (0.2949) Acc D Real: 80.412%
Loss D Fake: 2.9588 (2.2894) Acc D Fake: 32.673%
Loss D: 3.203
Loss G: 0.1109 (0.3760) Acc G: 67.331%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.2229 (0.2936) Acc D Real: 80.742%
Loss D Fake: 2.9250 (2.3008) Acc D Fake: 32.090%
Loss D: 3.148
Loss G: 0.1123 (0.3713) Acc G: 67.915%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.2325 (0.2925) Acc D Real: 81.067%
Loss D Fake: 2.8914 (2.3111) Acc D Fake: 31.527%
Loss D: 3.124
Loss G: 0.1137 (0.3668) Acc G: 68.478%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.2207 (0.2913) Acc D Real: 81.376%
Loss D Fake: 2.8580 (2.3206) Acc D Fake: 30.983%
Loss D: 3.079
Loss G: 0.1152 (0.3625) Acc G: 69.021%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.1689 (0.2892) Acc D Real: 81.685%
Loss D Fake: 2.8250 (2.3291) Acc D Fake: 30.458%
Loss D: 2.994
Loss G: 0.1167 (0.3583) Acc G: 69.546%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.2137 (0.2880) Acc D Real: 81.976%
Loss D Fake: 2.7924 (2.3368) Acc D Fake: 29.951%
Loss D: 3.006
Loss G: 0.1183 (0.3543) Acc G: 70.054%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.2297 (0.2870) Acc D Real: 82.252%
Loss D Fake: 2.7600 (2.3438) Acc D Fake: 29.460%
Loss D: 2.990
Loss G: 0.1199 (0.3505) Acc G: 70.545%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2197 (0.2859) Acc D Real: 82.524%
Loss D Fake: 2.7278 (2.3500) Acc D Fake: 28.984%
Loss D: 2.947
Loss G: 0.1216 (0.3468) Acc G: 71.020%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2050 (0.2846) Acc D Real: 82.784%
Loss D Fake: 2.6959 (2.3555) Acc D Fake: 28.524%
Loss D: 2.901
Loss G: 0.1233 (0.3432) Acc G: 71.480%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.2906 (0.2847) Acc D Real: 83.042%
Loss D Fake: 2.6641 (2.3603) Acc D Fake: 28.079%
Loss D: 2.955
Loss G: 0.1251 (0.3398) Acc G: 71.925%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.2176 (0.2837) Acc D Real: 83.297%
Loss D Fake: 2.6324 (2.3645) Acc D Fake: 27.647%
Loss D: 2.850
Loss G: 0.1270 (0.3365) Acc G: 72.357%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.2415 (0.2831) Acc D Real: 83.527%
Loss D Fake: 2.6009 (2.3681) Acc D Fake: 27.228%
Loss D: 2.842
Loss G: 0.1289 (0.3334) Acc G: 72.776%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.2003 (0.2818) Acc D Real: 83.764%
Loss D Fake: 2.5696 (2.3711) Acc D Fake: 26.821%
Loss D: 2.770
Loss G: 0.1309 (0.3304) Acc G: 73.183%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.2165 (0.2809) Acc D Real: 83.997%
Loss D Fake: 2.5386 (2.3735) Acc D Fake: 26.427%
Loss D: 2.755
Loss G: 0.1329 (0.3275) Acc G: 73.577%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.1871 (0.2795) Acc D Real: 84.220%
Loss D Fake: 2.5079 (2.3755) Acc D Fake: 26.044%
Loss D: 2.695
Loss G: 0.1350 (0.3247) Acc G: 73.960%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.2120 (0.2785) Acc D Real: 84.435%
Loss D Fake: 2.4776 (2.3769) Acc D Fake: 25.672%
Loss D: 2.690
Loss G: 0.1371 (0.3220) Acc G: 74.332%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.2119 (0.2776) Acc D Real: 84.649%
Loss D Fake: 2.4476 (2.3779) Acc D Fake: 25.310%
Loss D: 2.659
Loss G: 0.1393 (0.3194) Acc G: 74.693%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.1868 (0.2763) Acc D Real: 84.858%
Loss D Fake: 2.4176 (2.3785) Acc D Fake: 24.959%
Loss D: 2.604
Loss G: 0.1416 (0.3170) Acc G: 75.045%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.1954 (0.2752) Acc D Real: 85.060%
Loss D Fake: 2.3880 (2.3786) Acc D Fake: 24.617%
Loss D: 2.583
Loss G: 0.1439 (0.3146) Acc G: 75.387%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2198 (0.2745) Acc D Real: 85.256%
Loss D Fake: 2.3585 (2.3783) Acc D Fake: 24.284%
Loss D: 2.578
Loss G: 0.1463 (0.3123) Acc G: 75.719%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.1818 (0.2732) Acc D Real: 85.451%
Loss D Fake: 2.3292 (2.3777) Acc D Fake: 23.960%
Loss D: 2.511
Loss G: 0.1488 (0.3101) Acc G: 76.043%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.1731 (0.2719) Acc D Real: 85.641%
Loss D Fake: 2.3003 (2.3767) Acc D Fake: 23.645%
Loss D: 2.473
Loss G: 0.1513 (0.3080) Acc G: 76.358%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.2104 (0.2711) Acc D Real: 85.824%
Loss D Fake: 2.2718 (2.3753) Acc D Fake: 23.338%
Loss D: 2.482
Loss G: 0.1539 (0.3060) Acc G: 76.665%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.1957 (0.2702) Acc D Real: 86.003%
Loss D Fake: 2.2434 (2.3736) Acc D Fake: 23.039%
Loss D: 2.439
Loss G: 0.1566 (0.3041) Acc G: 76.964%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.1955 (0.2692) Acc D Real: 86.177%
Loss D Fake: 2.2153 (2.3716) Acc D Fake: 22.747%
Loss D: 2.411
Loss G: 0.1593 (0.3023) Acc G: 77.256%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.2055 (0.2684) Acc D Real: 86.346%
Loss D Fake: 2.1874 (2.3693) Acc D Fake: 22.463%
Loss D: 2.393
Loss G: 0.1622 (0.3005) Acc G: 77.540%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.2087 (0.2677) Acc D Real: 86.512%
Loss D Fake: 2.1597 (2.3667) Acc D Fake: 22.186%
Loss D: 2.368
Loss G: 0.1651 (0.2989) Acc G: 77.818%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.2012 (0.2669) Acc D Real: 86.670%
Loss D Fake: 2.1321 (2.3639) Acc D Fake: 21.915%
Loss D: 2.333
Loss G: 0.1681 (0.2973) Acc G: 78.088%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.1979 (0.2660) Acc D Real: 86.830%
Loss D Fake: 2.1049 (2.3607) Acc D Fake: 21.651%
Loss D: 2.303
Loss G: 0.1712 (0.2958) Acc G: 78.352%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.2188 (0.2655) Acc D Real: 86.979%
Loss D Fake: 2.0780 (2.3574) Acc D Fake: 21.393%
Loss D: 2.297
Loss G: 0.1743 (0.2943) Acc G: 78.610%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.2084 (0.2648) Acc D Real: 87.129%
Loss D Fake: 2.0512 (2.3538) Acc D Fake: 21.142%
Loss D: 2.260
Loss G: 0.1775 (0.2929) Acc G: 78.862%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.1838 (0.2639) Acc D Real: 87.279%
Loss D Fake: 2.0248 (2.3499) Acc D Fake: 20.896%
Loss D: 2.209
Loss G: 0.1808 (0.2916) Acc G: 79.107%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.2099 (0.2632) Acc D Real: 87.425%
Loss D Fake: 1.9988 (2.3459) Acc D Fake: 20.656%
Loss D: 2.209
Loss G: 0.1842 (0.2904) Acc G: 79.347%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.2220 (0.2628) Acc D Real: 87.568%
Loss D Fake: 1.9729 (2.3417) Acc D Fake: 20.421%
Loss D: 2.195
Loss G: 0.1876 (0.2892) Acc G: 79.582%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.2046 (0.2621) Acc D Real: 87.708%
Loss D Fake: 1.9470 (2.3372) Acc D Fake: 20.191%
Loss D: 2.152
Loss G: 0.1912 (0.2881) Acc G: 79.812%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.2019 (0.2614) Acc D Real: 87.844%
Loss D Fake: 1.9214 (2.3326) Acc D Fake: 19.967%
Loss D: 2.123
Loss G: 0.1949 (0.2871) Acc G: 80.036%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.2091 (0.2609) Acc D Real: 87.978%
Loss D Fake: 1.8962 (2.3278) Acc D Fake: 19.748%
Loss D: 2.105
Loss G: 0.1986 (0.2861) Acc G: 80.255%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.2023 (0.2602) Acc D Real: 88.106%
Loss D Fake: 1.8714 (2.3229) Acc D Fake: 19.533%
Loss D: 2.074
Loss G: 0.2023 (0.2852) Acc G: 80.470%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.1993 (0.2596) Acc D Real: 88.234%
Loss D Fake: 1.8472 (2.3177) Acc D Fake: 19.323%
Loss D: 2.047
Loss G: 0.2061 (0.2844) Acc G: 80.680%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.2124 (0.2591) Acc D Real: 88.354%
Loss D Fake: 1.8233 (2.3125) Acc D Fake: 19.117%
Loss D: 2.036
Loss G: 0.2100 (0.2836) Acc G: 80.885%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2128 (0.2586) Acc D Real: 88.467%
Loss D Fake: 1.7996 (2.3071) Acc D Fake: 18.916%
Loss D: 2.012
Loss G: 0.2139 (0.2828) Acc G: 81.087%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.2180 (0.2582) Acc D Real: 88.587%
Loss D Fake: 1.7762 (2.3016) Acc D Fake: 18.719%
Loss D: 1.994
Loss G: 0.2180 (0.2822) Acc G: 81.284%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.2155 (0.2577) Acc D Real: 88.705%
Loss D Fake: 1.7532 (2.2959) Acc D Fake: 18.526%
Loss D: 1.969
Loss G: 0.2221 (0.2815) Acc G: 81.477%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.2074 (0.2572) Acc D Real: 88.820%
Loss D Fake: 1.7306 (2.2901) Acc D Fake: 18.337%
Loss D: 1.938
Loss G: 0.2262 (0.2810) Acc G: 81.666%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.2149 (0.2568) Acc D Real: 88.933%
Loss D Fake: 1.7083 (2.2843) Acc D Fake: 18.152%
Loss D: 1.923
Loss G: 0.2304 (0.2805) Acc G: 81.851%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.2212 (0.2564) Acc D Real: 89.044%
Loss D Fake: 1.6866 (2.2783) Acc D Fake: 17.970%
Loss D: 1.908
Loss G: 0.2346 (0.2800) Acc G: 82.032%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.2182 (0.2561) Acc D Real: 89.152%
Loss D Fake: 1.6651 (2.2722) Acc D Fake: 17.792%
Loss D: 1.883
Loss G: 0.2389 (0.2796) Acc G: 82.210%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.2349 (0.2558) Acc D Real: 89.252%
Loss D Fake: 1.6441 (2.2660) Acc D Fake: 17.618%
Loss D: 1.879
Loss G: 0.2433 (0.2792) Acc G: 82.385%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2143 (0.2554) Acc D Real: 89.356%
Loss D Fake: 1.6233 (2.2598) Acc D Fake: 17.447%
Loss D: 1.838
Loss G: 0.2477 (0.2789) Acc G: 82.556%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.2348 (0.2552) Acc D Real: 89.459%
Loss D Fake: 1.6028 (2.2535) Acc D Fake: 17.279%
Loss D: 1.838
Loss G: 0.2521 (0.2787) Acc G: 82.723%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.2365 (0.2551) Acc D Real: 89.553%
Loss D Fake: 1.5827 (2.2471) Acc D Fake: 17.115%
Loss D: 1.819
Loss G: 0.2567 (0.2785) Acc G: 82.888%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.2402 (0.2549) Acc D Real: 89.647%
Loss D Fake: 1.5625 (2.2406) Acc D Fake: 16.953%
Loss D: 1.803
Loss G: 0.2614 (0.2783) Acc G: 83.049%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.2319 (0.2547) Acc D Real: 89.744%
Loss D Fake: 1.5427 (2.2341) Acc D Fake: 16.795%
Loss D: 1.775
Loss G: 0.2661 (0.2782) Acc G: 83.208%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.2464 (0.2546) Acc D Real: 89.837%
Loss D Fake: 1.5232 (2.2275) Acc D Fake: 16.639%
Loss D: 1.770
Loss G: 0.2708 (0.2781) Acc G: 83.363%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.2401 (0.2545) Acc D Real: 89.930%
Loss D Fake: 1.5042 (2.2209) Acc D Fake: 16.487%
Loss D: 1.744
Loss G: 0.2755 (0.2781) Acc G: 83.516%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.2490 (0.2545) Acc D Real: 90.021%
Loss D Fake: 1.4858 (2.2142) Acc D Fake: 16.337%
Loss D: 1.735
Loss G: 0.2802 (0.2781) Acc G: 83.666%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.2320 (0.2542) Acc D Real: 90.108%
Loss D Fake: 1.4678 (2.2075) Acc D Fake: 16.189%
Loss D: 1.700
Loss G: 0.2850 (0.2782) Acc G: 83.813%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.2438 (0.2542) Acc D Real: 90.196%
Loss D Fake: 1.4499 (2.2007) Acc D Fake: 16.045%
Loss D: 1.694
Loss G: 0.2899 (0.2783) Acc G: 83.957%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.2497 (0.2541) Acc D Real: 90.283%
Loss D Fake: 1.4324 (2.1939) Acc D Fake: 15.903%
Loss D: 1.682
Loss G: 0.2947 (0.2784) Acc G: 84.099%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.2548 (0.2541) Acc D Real: 90.368%
Loss D Fake: 1.4155 (2.1871) Acc D Fake: 15.763%
Loss D: 1.670
Loss G: 0.2995 (0.2786) Acc G: 84.239%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.2302 (0.2539) Acc D Real: 90.452%
Loss D Fake: 1.3989 (2.1802) Acc D Fake: 15.626%
Loss D: 1.629
Loss G: 0.3044 (0.2788) Acc G: 84.376%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.2317 (0.2537) Acc D Real: 90.530%
Loss D Fake: 1.3820 (2.1734) Acc D Fake: 15.492%
Loss D: 1.614
Loss G: 0.3096 (0.2791) Acc G: 84.511%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.2481 (0.2537) Acc D Real: 90.610%
Loss D Fake: 1.3651 (2.1665) Acc D Fake: 15.359%
Loss D: 1.613
Loss G: 0.3148 (0.2794) Acc G: 84.643%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.2680 (0.2538) Acc D Real: 90.689%
Loss D Fake: 1.3485 (2.1595) Acc D Fake: 15.229%
Loss D: 1.617
Loss G: 0.3200 (0.2798) Acc G: 84.773%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.2683 (0.2539) Acc D Real: 90.766%
Loss D Fake: 1.3324 (2.1526) Acc D Fake: 15.101%
Loss D: 1.601
Loss G: 0.3251 (0.2801) Acc G: 84.901%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.2610 (0.2540) Acc D Real: 90.843%
Loss D Fake: 1.3166 (2.1456) Acc D Fake: 14.975%
Loss D: 1.578
Loss G: 0.3304 (0.2806) Acc G: 85.027%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.2669 (0.2541) Acc D Real: 90.917%
Loss D Fake: 1.3011 (2.1386) Acc D Fake: 14.851%
Loss D: 1.568
Loss G: 0.3356 (0.2810) Acc G: 85.151%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.2503 (0.2541) Acc D Real: 90.992%
Loss D Fake: 1.2858 (2.1316) Acc D Fake: 14.730%
Loss D: 1.536
Loss G: 0.3410 (0.2815) Acc G: 85.272%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.2820 (0.2543) Acc D Real: 91.062%
Loss D Fake: 1.2707 (2.1246) Acc D Fake: 14.610%
Loss D: 1.553
Loss G: 0.3463 (0.2820) Acc G: 85.392%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.2569 (0.2543) Acc D Real: 91.134%
Loss D Fake: 1.2560 (2.1176) Acc D Fake: 14.492%
Loss D: 1.513
Loss G: 0.3516 (0.2826) Acc G: 85.510%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2888 (0.2546) Acc D Real: 91.202%
Loss D Fake: 1.2415 (2.1106) Acc D Fake: 14.376%
Loss D: 1.530
Loss G: 0.3569 (0.2832) Acc G: 85.626%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.2749 (0.2547) Acc D Real: 91.267%
Loss D Fake: 1.2276 (2.1036) Acc D Fake: 14.262%
Loss D: 1.503
Loss G: 0.3622 (0.2838) Acc G: 85.740%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.2922 (0.2550) Acc D Real: 91.331%
Loss D Fake: 1.2141 (2.0966) Acc D Fake: 14.150%
Loss D: 1.506
Loss G: 0.3674 (0.2845) Acc G: 85.852%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.2888 (0.2553) Acc D Real: 91.392%
Loss D Fake: 1.2010 (2.0896) Acc D Fake: 14.039%
Loss D: 1.490
Loss G: 0.3726 (0.2852) Acc G: 85.963%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.2854 (0.2555) Acc D Real: 91.459%
Loss D Fake: 1.1882 (2.0826) Acc D Fake: 13.930%
Loss D: 1.474
Loss G: 0.3777 (0.2859) Acc G: 86.072%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.2842 (0.2557) Acc D Real: 91.519%
Loss D Fake: 1.1758 (2.0757) Acc D Fake: 13.823%
Loss D: 1.460
Loss G: 0.3828 (0.2866) Acc G: 86.179%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2819 (0.2559) Acc D Real: 91.584%
Loss D Fake: 1.1637 (2.0687) Acc D Fake: 13.718%
Loss D: 1.446
Loss G: 0.3879 (0.2874) Acc G: 86.284%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3102 (0.2564) Acc D Real: 91.645%
Loss D Fake: 1.1519 (2.0617) Acc D Fake: 13.614%
Loss D: 1.462
Loss G: 0.3928 (0.2882) Acc G: 86.388%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3063 (0.2567) Acc D Real: 91.703%
Loss D Fake: 1.1406 (2.0548) Acc D Fake: 13.512%
Loss D: 1.447
Loss G: 0.3977 (0.2890) Acc G: 86.490%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.2894 (0.2570) Acc D Real: 91.761%
Loss D Fake: 1.1295 (2.0479) Acc D Fake: 13.411%
Loss D: 1.419
Loss G: 0.4027 (0.2899) Acc G: 86.591%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3045 (0.2573) Acc D Real: 91.821%
Loss D Fake: 1.1185 (2.0410) Acc D Fake: 13.311%
Loss D: 1.423
Loss G: 0.4076 (0.2907) Acc G: 86.691%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.2499 (0.2573) Acc D Real: 91.881%
Loss D Fake: 1.1076 (2.0342) Acc D Fake: 13.213%
Loss D: 1.358
Loss G: 0.4128 (0.2916) Acc G: 86.788%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3569 (0.2580) Acc D Real: 91.940%
Loss D Fake: 1.0967 (2.0273) Acc D Fake: 13.117%
Loss D: 1.454
Loss G: 0.4176 (0.2926) Acc G: 86.885%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.2978 (0.2583) Acc D Real: 91.997%
Loss D Fake: 1.0868 (2.0205) Acc D Fake: 13.022%
Loss D: 1.385
Loss G: 0.4224 (0.2935) Acc G: 86.980%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3283 (0.2588) Acc D Real: 92.052%
Loss D Fake: 1.0769 (2.0137) Acc D Fake: 12.928%
Loss D: 1.405
Loss G: 0.4272 (0.2945) Acc G: 87.074%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3231 (0.2593) Acc D Real: 92.109%
Loss D Fake: 1.0674 (2.0070) Acc D Fake: 12.836%
Loss D: 1.391
Loss G: 0.4317 (0.2954) Acc G: 87.166%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3093 (0.2596) Acc D Real: 92.165%
Loss D Fake: 1.0585 (2.0002) Acc D Fake: 12.745%
Loss D: 1.368
Loss G: 0.4362 (0.2964) Acc G: 87.257%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.3190 (0.2600) Acc D Real: 92.219%
Loss D Fake: 1.0497 (1.9935) Acc D Fake: 12.655%
Loss D: 1.369
Loss G: 0.4406 (0.2974) Acc G: 87.347%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3361 (0.2606) Acc D Real: 92.274%
Loss D Fake: 1.0413 (1.9869) Acc D Fake: 12.567%
Loss D: 1.377
Loss G: 0.4449 (0.2985) Acc G: 87.435%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.2910 (0.2608) Acc D Real: 92.327%
Loss D Fake: 1.0331 (1.9803) Acc D Fake: 12.479%
Loss D: 1.324
Loss G: 0.4492 (0.2995) Acc G: 87.522%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.3451 (0.2614) Acc D Real: 92.378%
Loss D Fake: 1.0250 (1.9737) Acc D Fake: 12.393%
Loss D: 1.370
Loss G: 0.4534 (0.3006) Acc G: 87.608%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.3118 (0.2617) Acc D Real: 92.430%
Loss D Fake: 1.0172 (1.9671) Acc D Fake: 12.308%
Loss D: 1.329
Loss G: 0.4576 (0.3017) Acc G: 87.693%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3099 (0.2620) Acc D Real: 92.477%
Loss D Fake: 1.0094 (1.9606) Acc D Fake: 12.225%
Loss D: 1.319
Loss G: 0.4619 (0.3028) Acc G: 87.777%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3473 (0.2626) Acc D Real: 92.528%
Loss D Fake: 1.0016 (1.9541) Acc D Fake: 12.142%
Loss D: 1.349
Loss G: 0.4661 (0.3039) Acc G: 87.860%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3298 (0.2631) Acc D Real: 92.575%
Loss D Fake: 0.9942 (1.9477) Acc D Fake: 12.061%
Loss D: 1.324
Loss G: 0.4703 (0.3050) Acc G: 87.941%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3353 (0.2635) Acc D Real: 92.621%
Loss D Fake: 0.9870 (1.9413) Acc D Fake: 11.980%
Loss D: 1.322
Loss G: 0.4744 (0.3061) Acc G: 88.022%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3685 (0.2642) Acc D Real: 92.666%
Loss D Fake: 0.9799 (1.9349) Acc D Fake: 11.901%
Loss D: 1.348
Loss G: 0.4783 (0.3072) Acc G: 88.101%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3485 (0.2648) Acc D Real: 92.715%
Loss D Fake: 0.9734 (1.9286) Acc D Fake: 11.823%
Loss D: 1.322
Loss G: 0.4820 (0.3084) Acc G: 88.179%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3263 (0.2652) Acc D Real: 92.762%
Loss D Fake: 0.9671 (1.9223) Acc D Fake: 11.745%
Loss D: 1.293
Loss G: 0.4857 (0.3096) Acc G: 88.256%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3396 (0.2657) Acc D Real: 92.809%
Loss D Fake: 0.9608 (1.9161) Acc D Fake: 11.669%
Loss D: 1.300
Loss G: 0.4894 (0.3107) Acc G: 88.333%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3888 (0.2665) Acc D Real: 92.854%
Loss D Fake: 0.9549 (1.9099) Acc D Fake: 11.594%
Loss D: 1.344
Loss G: 0.4928 (0.3119) Acc G: 88.408%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.3289 (0.2669) Acc D Real: 92.899%
Loss D Fake: 0.9496 (1.9037) Acc D Fake: 11.519%
Loss D: 1.278
Loss G: 0.4961 (0.3131) Acc G: 88.482%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.3358 (0.2673) Acc D Real: 92.940%
Loss D Fake: 0.9441 (1.8976) Acc D Fake: 11.446%
Loss D: 1.280
Loss G: 0.4995 (0.3143) Acc G: 88.556%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2986 (0.2675) Acc D Real: 92.944%
Loss D Fake: 0.9384 (1.8915) Acc D Fake: 11.439%
Loss D: 1.237
Loss G: 0.5033 (0.3155) Acc G: 88.562%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 1.100 | Generator Loss: 0.503 | Avg: 1.603
TEST [21/180]: Discriminator Loss: 1.165 | Generator Loss: 0.503 | Avg: 1.668
TEST [31/180]: Discriminator Loss: 1.148 | Generator Loss: 0.503 | Avg: 1.651
TEST [41/180]: Discriminator Loss: 1.130 | Generator Loss: 0.503 | Avg: 1.633
TEST [51/180]: Discriminator Loss: 1.131 | Generator Loss: 0.503 | Avg: 1.634
TEST [61/180]: Discriminator Loss: 1.157 | Generator Loss: 0.503 | Avg: 1.660
TEST [71/180]: Discriminator Loss: 1.178 | Generator Loss: 0.503 | Avg: 1.681
TEST [81/180]: Discriminator Loss: 1.203 | Generator Loss: 0.503 | Avg: 1.707
TEST [91/180]: Discriminator Loss: 1.219 | Generator Loss: 0.503 | Avg: 1.723
TEST [101/180]: Discriminator Loss: 1.240 | Generator Loss: 0.503 | Avg: 1.743
TEST [111/180]: Discriminator Loss: 1.257 | Generator Loss: 0.503 | Avg: 1.761
TEST [121/180]: Discriminator Loss: 1.271 | Generator Loss: 0.503 | Avg: 1.774
TEST [131/180]: Discriminator Loss: 1.283 | Generator Loss: 0.503 | Avg: 1.787
TEST [141/180]: Discriminator Loss: 1.294 | Generator Loss: 0.503 | Avg: 1.797
TEST [151/180]: Discriminator Loss: 1.287 | Generator Loss: 0.503 | Avg: 1.790
TEST [161/180]: Discriminator Loss: 1.280 | Generator Loss: 0.503 | Avg: 1.783
TEST [171/180]: Discriminator Loss: 1.271 | Generator Loss: 0.503 | Avg: 1.774
Epoch: 16/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3972 (0.3875) Acc D Real: 99.922%
Loss D Fake: 0.9266 (0.9294) Acc D Fake: 0.000%
Loss D: 1.324
Loss G: 0.5103 (0.5087) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3507 (0.3752) Acc D Real: 99.948%
Loss D Fake: 0.9216 (0.9268) Acc D Fake: 0.000%
Loss D: 1.272
Loss G: 0.5135 (0.5103) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3154 (0.3603) Acc D Real: 99.961%
Loss D Fake: 0.9166 (0.9243) Acc D Fake: 0.000%
Loss D: 1.232
Loss G: 0.5168 (0.5119) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4278 (0.3738) Acc D Real: 99.823%
Loss D Fake: 0.9117 (0.9217) Acc D Fake: 0.000%
Loss D: 1.340
Loss G: 0.5198 (0.5135) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.4335 (0.3837) Acc D Real: 99.818%
Loss D Fake: 0.9076 (0.9194) Acc D Fake: 0.000%
Loss D: 1.341
Loss G: 0.5221 (0.5149) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3103 (0.3733) Acc D Real: 99.814%
Loss D Fake: 0.9042 (0.9172) Acc D Fake: 0.000%
Loss D: 1.214
Loss G: 0.5246 (0.5163) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.2945 (0.3634) Acc D Real: 99.818%
Loss D Fake: 0.9001 (0.9151) Acc D Fake: 0.000%
Loss D: 1.195
Loss G: 0.5275 (0.5177) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3716 (0.3643) Acc D Real: 99.809%
Loss D Fake: 0.8956 (0.9129) Acc D Fake: 0.000%
Loss D: 1.267
Loss G: 0.5305 (0.5191) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3537 (0.3633) Acc D Real: 99.807%
Loss D Fake: 0.8913 (0.9107) Acc D Fake: 0.000%
Loss D: 1.245
Loss G: 0.5334 (0.5205) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3819 (0.3649) Acc D Real: 99.692%
Loss D Fake: 0.8871 (0.9086) Acc D Fake: 0.000%
Loss D: 1.269
Loss G: 0.5362 (0.5220) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.3706 (0.3654) Acc D Real: 99.614%
Loss D Fake: 0.8830 (0.9065) Acc D Fake: 0.000%
Loss D: 1.254
Loss G: 0.5391 (0.5234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4059 (0.3685) Acc D Real: 99.591%
Loss D Fake: 0.8790 (0.9043) Acc D Fake: 0.000%
Loss D: 1.285
Loss G: 0.5416 (0.5248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3660 (0.3683) Acc D Real: 99.587%
Loss D Fake: 0.8755 (0.9023) Acc D Fake: 0.000%
Loss D: 1.241
Loss G: 0.5441 (0.5262) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4337 (0.3727) Acc D Real: 99.549%
Loss D Fake: 0.8722 (0.9003) Acc D Fake: 0.000%
Loss D: 1.306
Loss G: 0.5461 (0.5275) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3242 (0.3697) Acc D Real: 99.538%
Loss D Fake: 0.8694 (0.8983) Acc D Fake: 0.000%
Loss D: 1.194
Loss G: 0.5483 (0.5288) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3177 (0.3666) Acc D Real: 99.519%
Loss D Fake: 0.8659 (0.8964) Acc D Fake: 0.000%
Loss D: 1.184
Loss G: 0.5510 (0.5301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3361 (0.3649) Acc D Real: 99.511%
Loss D Fake: 0.8620 (0.8945) Acc D Fake: 0.000%
Loss D: 1.198
Loss G: 0.5539 (0.5314) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3644 (0.3649) Acc D Real: 99.501%
Loss D Fake: 0.8579 (0.8926) Acc D Fake: 0.000%
Loss D: 1.222
Loss G: 0.5568 (0.5328) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3802 (0.3657) Acc D Real: 99.477%
Loss D Fake: 0.8541 (0.8907) Acc D Fake: 0.000%
Loss D: 1.234
Loss G: 0.5595 (0.5341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3530 (0.3651) Acc D Real: 99.472%
Loss D Fake: 0.8505 (0.8888) Acc D Fake: 0.000%
Loss D: 1.203
Loss G: 0.5621 (0.5354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3907 (0.3662) Acc D Real: 99.427%
Loss D Fake: 0.8469 (0.8869) Acc D Fake: 0.000%
Loss D: 1.238
Loss G: 0.5646 (0.5368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4192 (0.3685) Acc D Real: 99.404%
Loss D Fake: 0.8438 (0.8850) Acc D Fake: 0.000%
Loss D: 1.263
Loss G: 0.5668 (0.5381) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.4095 (0.3702) Acc D Real: 99.368%
Loss D Fake: 0.8410 (0.8832) Acc D Fake: 0.000%
Loss D: 1.250
Loss G: 0.5687 (0.5393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3961 (0.3713) Acc D Real: 99.358%
Loss D Fake: 0.8386 (0.8814) Acc D Fake: 0.000%
Loss D: 1.235
Loss G: 0.5705 (0.5406) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3245 (0.3695) Acc D Real: 99.353%
Loss D Fake: 0.8362 (0.8796) Acc D Fake: 0.000%
Loss D: 1.161
Loss G: 0.5725 (0.5418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3674 (0.3694) Acc D Real: 99.356%
Loss D Fake: 0.8335 (0.8779) Acc D Fake: 0.000%
Loss D: 1.201
Loss G: 0.5746 (0.5430) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4508 (0.3723) Acc D Real: 99.340%
Loss D Fake: 0.8310 (0.8762) Acc D Fake: 0.000%
Loss D: 1.282
Loss G: 0.5762 (0.5442) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3583 (0.3718) Acc D Real: 99.330%
Loss D Fake: 0.8289 (0.8746) Acc D Fake: 0.000%
Loss D: 1.187
Loss G: 0.5778 (0.5454) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3979 (0.3727) Acc D Real: 99.321%
Loss D Fake: 0.8268 (0.8730) Acc D Fake: 0.000%
Loss D: 1.225
Loss G: 0.5794 (0.5465) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.4174 (0.3741) Acc D Real: 99.299%
Loss D Fake: 0.8249 (0.8715) Acc D Fake: 0.000%
Loss D: 1.242
Loss G: 0.5807 (0.5476) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3871 (0.3745) Acc D Real: 99.297%
Loss D Fake: 0.8233 (0.8700) Acc D Fake: 0.000%
Loss D: 1.210
Loss G: 0.5820 (0.5487) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3206 (0.3729) Acc D Real: 99.233%
Loss D Fake: 0.8214 (0.8685) Acc D Fake: 0.000%
Loss D: 1.142
Loss G: 0.5838 (0.5498) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3881 (0.3733) Acc D Real: 99.223%
Loss D Fake: 0.8190 (0.8670) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.5856 (0.5508) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3592 (0.3729) Acc D Real: 99.213%
Loss D Fake: 0.8166 (0.8656) Acc D Fake: 0.000%
Loss D: 1.176
Loss G: 0.5876 (0.5519) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3926 (0.3735) Acc D Real: 99.203%
Loss D Fake: 0.8141 (0.8642) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.5895 (0.5529) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.4169 (0.3747) Acc D Real: 99.185%
Loss D Fake: 0.8118 (0.8627) Acc D Fake: 0.000%
Loss D: 1.229
Loss G: 0.5911 (0.5539) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.4077 (0.3755) Acc D Real: 99.132%
Loss D Fake: 0.8099 (0.8614) Acc D Fake: 0.000%
Loss D: 1.218
Loss G: 0.5926 (0.5550) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3482 (0.3748) Acc D Real: 99.125%
Loss D Fake: 0.8079 (0.8600) Acc D Fake: 0.000%
Loss D: 1.156
Loss G: 0.5944 (0.5560) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3854 (0.3751) Acc D Real: 99.124%
Loss D Fake: 0.8056 (0.8586) Acc D Fake: 0.000%
Loss D: 1.191
Loss G: 0.5962 (0.5570) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3663 (0.3749) Acc D Real: 99.122%
Loss D Fake: 0.8034 (0.8573) Acc D Fake: 0.000%
Loss D: 1.170
Loss G: 0.5980 (0.5580) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4058 (0.3756) Acc D Real: 99.108%
Loss D Fake: 0.8012 (0.8559) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.5997 (0.5590) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3906 (0.3760) Acc D Real: 99.113%
Loss D Fake: 0.7992 (0.8546) Acc D Fake: 0.000%
Loss D: 1.190
Loss G: 0.6013 (0.5599) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.4281 (0.3771) Acc D Real: 99.100%
Loss D Fake: 0.7973 (0.8533) Acc D Fake: 0.000%
Loss D: 1.225
Loss G: 0.6026 (0.5609) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3784 (0.3772) Acc D Real: 99.103%
Loss D Fake: 0.7958 (0.8520) Acc D Fake: 0.000%
Loss D: 1.174
Loss G: 0.6039 (0.5619) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3733 (0.3771) Acc D Real: 99.096%
Loss D Fake: 0.7941 (0.8508) Acc D Fake: 0.000%
Loss D: 1.167
Loss G: 0.6053 (0.5628) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3629 (0.3768) Acc D Real: 99.066%
Loss D Fake: 0.7923 (0.8495) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6069 (0.5638) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3788 (0.3768) Acc D Real: 99.071%
Loss D Fake: 0.7903 (0.8483) Acc D Fake: 0.000%
Loss D: 1.169
Loss G: 0.6085 (0.5647) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3437 (0.3762) Acc D Real: 99.073%
Loss D Fake: 0.7883 (0.8471) Acc D Fake: 0.000%
Loss D: 1.132
Loss G: 0.6104 (0.5656) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.4053 (0.3767) Acc D Real: 99.057%
Loss D Fake: 0.7861 (0.8459) Acc D Fake: 0.000%
Loss D: 1.191
Loss G: 0.6121 (0.5665) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4039 (0.3773) Acc D Real: 99.059%
Loss D Fake: 0.7841 (0.8447) Acc D Fake: 0.000%
Loss D: 1.188
Loss G: 0.6137 (0.5675) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3435 (0.3766) Acc D Real: 99.065%
Loss D Fake: 0.7822 (0.8435) Acc D Fake: 0.000%
Loss D: 1.126
Loss G: 0.6154 (0.5684) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3705 (0.3765) Acc D Real: 99.066%
Loss D Fake: 0.7801 (0.8423) Acc D Fake: 0.000%
Loss D: 1.151
Loss G: 0.6172 (0.5693) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3498 (0.3760) Acc D Real: 99.065%
Loss D Fake: 0.7780 (0.8411) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.6191 (0.5702) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3765 (0.3760) Acc D Real: 99.072%
Loss D Fake: 0.7757 (0.8399) Acc D Fake: 0.000%
Loss D: 1.152
Loss G: 0.6210 (0.5712) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.4050 (0.3765) Acc D Real: 99.073%
Loss D Fake: 0.7736 (0.8387) Acc D Fake: 0.000%
Loss D: 1.179
Loss G: 0.6227 (0.5721) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3768 (0.3765) Acc D Real: 99.075%
Loss D Fake: 0.7717 (0.8375) Acc D Fake: 0.000%
Loss D: 1.149
Loss G: 0.6243 (0.5730) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3939 (0.3768) Acc D Real: 99.060%
Loss D Fake: 0.7698 (0.8364) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6259 (0.5739) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4080 (0.3774) Acc D Real: 99.060%
Loss D Fake: 0.7681 (0.8352) Acc D Fake: 0.000%
Loss D: 1.176
Loss G: 0.6273 (0.5748) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3770 (0.3774) Acc D Real: 99.050%
Loss D Fake: 0.7665 (0.8341) Acc D Fake: 0.000%
Loss D: 1.144
Loss G: 0.6286 (0.5757) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3924 (0.3776) Acc D Real: 99.045%
Loss D Fake: 0.7650 (0.8329) Acc D Fake: 0.000%
Loss D: 1.157
Loss G: 0.6299 (0.5766) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.4249 (0.3784) Acc D Real: 99.044%
Loss D Fake: 0.7636 (0.8318) Acc D Fake: 0.000%
Loss D: 1.189
Loss G: 0.6310 (0.5775) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.4568 (0.3796) Acc D Real: 99.043%
Loss D Fake: 0.7626 (0.8307) Acc D Fake: 0.000%
Loss D: 1.219
Loss G: 0.6316 (0.5783) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.4018 (0.3800) Acc D Real: 99.038%
Loss D Fake: 0.7621 (0.8296) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6321 (0.5792) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.3735 (0.3799) Acc D Real: 99.040%
Loss D Fake: 0.7614 (0.8286) Acc D Fake: 0.000%
Loss D: 1.135
Loss G: 0.6328 (0.5800) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3723 (0.3797) Acc D Real: 99.041%
Loss D Fake: 0.7605 (0.8275) Acc D Fake: 0.000%
Loss D: 1.133
Loss G: 0.6338 (0.5808) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.4916 (0.3814) Acc D Real: 99.042%
Loss D Fake: 0.7596 (0.8265) Acc D Fake: 0.000%
Loss D: 1.251
Loss G: 0.6342 (0.5816) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3915 (0.3816) Acc D Real: 99.046%
Loss D Fake: 0.7593 (0.8255) Acc D Fake: 0.000%
Loss D: 1.151
Loss G: 0.6345 (0.5824) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.4039 (0.3819) Acc D Real: 99.038%
Loss D Fake: 0.7589 (0.8246) Acc D Fake: 0.000%
Loss D: 1.163
Loss G: 0.6348 (0.5831) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4527 (0.3829) Acc D Real: 99.034%
Loss D Fake: 0.7585 (0.8236) Acc D Fake: 0.000%
Loss D: 1.211
Loss G: 0.6350 (0.5839) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4135 (0.3833) Acc D Real: 99.028%
Loss D Fake: 0.7585 (0.8227) Acc D Fake: 0.000%
Loss D: 1.172
Loss G: 0.6350 (0.5846) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3340 (0.3826) Acc D Real: 99.034%
Loss D Fake: 0.7582 (0.8218) Acc D Fake: 0.000%
Loss D: 1.092
Loss G: 0.6355 (0.5853) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3958 (0.3828) Acc D Real: 99.036%
Loss D Fake: 0.7576 (0.8209) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6361 (0.5860) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.4557 (0.3838) Acc D Real: 99.032%
Loss D Fake: 0.7570 (0.8201) Acc D Fake: 0.000%
Loss D: 1.213
Loss G: 0.6364 (0.5867) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.4070 (0.3841) Acc D Real: 99.028%
Loss D Fake: 0.7568 (0.8192) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6366 (0.5874) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3598 (0.3838) Acc D Real: 99.033%
Loss D Fake: 0.7565 (0.8184) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6370 (0.5880) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.4064 (0.3841) Acc D Real: 99.036%
Loss D Fake: 0.7560 (0.8176) Acc D Fake: 0.000%
Loss D: 1.162
Loss G: 0.6374 (0.5887) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3993 (0.3843) Acc D Real: 99.038%
Loss D Fake: 0.7555 (0.8168) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6379 (0.5893) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4129 (0.3847) Acc D Real: 99.038%
Loss D Fake: 0.7550 (0.8160) Acc D Fake: 0.000%
Loss D: 1.168
Loss G: 0.6383 (0.5899) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4018 (0.3849) Acc D Real: 99.041%
Loss D Fake: 0.7545 (0.8153) Acc D Fake: 0.000%
Loss D: 1.156
Loss G: 0.6387 (0.5905) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3621 (0.3846) Acc D Real: 99.045%
Loss D Fake: 0.7540 (0.8145) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6393 (0.5911) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3413 (0.3841) Acc D Real: 99.050%
Loss D Fake: 0.7531 (0.8137) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.6403 (0.5917) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.4016 (0.3843) Acc D Real: 99.039%
Loss D Fake: 0.7519 (0.8130) Acc D Fake: 0.000%
Loss D: 1.154
Loss G: 0.6413 (0.5923) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4293 (0.3848) Acc D Real: 99.040%
Loss D Fake: 0.7509 (0.8123) Acc D Fake: 0.000%
Loss D: 1.180
Loss G: 0.6422 (0.5929) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4138 (0.3852) Acc D Real: 99.040%
Loss D Fake: 0.7501 (0.8115) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6428 (0.5935) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4034 (0.3854) Acc D Real: 99.043%
Loss D Fake: 0.7494 (0.8108) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6434 (0.5941) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.4416 (0.3860) Acc D Real: 99.041%
Loss D Fake: 0.7488 (0.8101) Acc D Fake: 0.000%
Loss D: 1.190
Loss G: 0.6438 (0.5946) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4701 (0.3870) Acc D Real: 99.035%
Loss D Fake: 0.7487 (0.8094) Acc D Fake: 0.000%
Loss D: 1.219
Loss G: 0.6437 (0.5952) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4402 (0.3876) Acc D Real: 99.037%
Loss D Fake: 0.7489 (0.8087) Acc D Fake: 0.000%
Loss D: 1.189
Loss G: 0.6433 (0.5957) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4783 (0.3886) Acc D Real: 99.036%
Loss D Fake: 0.7495 (0.8081) Acc D Fake: 0.000%
Loss D: 1.228
Loss G: 0.6426 (0.5963) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4601 (0.3894) Acc D Real: 99.038%
Loss D Fake: 0.7504 (0.8074) Acc D Fake: 0.000%
Loss D: 1.210
Loss G: 0.6418 (0.5968) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.4040 (0.3895) Acc D Real: 99.040%
Loss D Fake: 0.7513 (0.8068) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6411 (0.5972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3560 (0.3892) Acc D Real: 99.037%
Loss D Fake: 0.7518 (0.8062) Acc D Fake: 0.000%
Loss D: 1.108
Loss G: 0.6409 (0.5977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4407 (0.3897) Acc D Real: 99.039%
Loss D Fake: 0.7519 (0.8056) Acc D Fake: 0.000%
Loss D: 1.193
Loss G: 0.6407 (0.5982) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.4278 (0.3901) Acc D Real: 99.038%
Loss D Fake: 0.7523 (0.8051) Acc D Fake: 0.000%
Loss D: 1.180
Loss G: 0.6403 (0.5986) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4056 (0.3903) Acc D Real: 99.041%
Loss D Fake: 0.7527 (0.8045) Acc D Fake: 0.000%
Loss D: 1.158
Loss G: 0.6399 (0.5990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3678 (0.3900) Acc D Real: 99.046%
Loss D Fake: 0.7530 (0.8040) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.6399 (0.5995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.4015 (0.3902) Acc D Real: 99.049%
Loss D Fake: 0.7529 (0.8035) Acc D Fake: 0.000%
Loss D: 1.154
Loss G: 0.6400 (0.5999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3491 (0.3897) Acc D Real: 99.053%
Loss D Fake: 0.7526 (0.8030) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.6404 (0.6003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3708 (0.3895) Acc D Real: 99.052%
Loss D Fake: 0.7520 (0.8025) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6411 (0.6007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3291 (0.3890) Acc D Real: 99.054%
Loss D Fake: 0.7511 (0.8020) Acc D Fake: 0.000%
Loss D: 1.080
Loss G: 0.6421 (0.6011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4281 (0.3893) Acc D Real: 99.054%
Loss D Fake: 0.7499 (0.8014) Acc D Fake: 0.000%
Loss D: 1.178
Loss G: 0.6430 (0.6015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.4030 (0.3895) Acc D Real: 99.050%
Loss D Fake: 0.7491 (0.8009) Acc D Fake: 0.000%
Loss D: 1.152
Loss G: 0.6437 (0.6019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.4276 (0.3898) Acc D Real: 99.052%
Loss D Fake: 0.7484 (0.8004) Acc D Fake: 0.000%
Loss D: 1.176
Loss G: 0.6442 (0.6023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3375 (0.3893) Acc D Real: 99.057%
Loss D Fake: 0.7477 (0.7999) Acc D Fake: 0.000%
Loss D: 1.085
Loss G: 0.6451 (0.6027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4170 (0.3896) Acc D Real: 99.060%
Loss D Fake: 0.7468 (0.7994) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6458 (0.6032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3783 (0.3895) Acc D Real: 99.064%
Loss D Fake: 0.7460 (0.7989) Acc D Fake: 0.000%
Loss D: 1.124
Loss G: 0.6466 (0.6036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4624 (0.3902) Acc D Real: 99.063%
Loss D Fake: 0.7453 (0.7984) Acc D Fake: 0.000%
Loss D: 1.208
Loss G: 0.6469 (0.6040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3523 (0.3898) Acc D Real: 99.068%
Loss D Fake: 0.7449 (0.7979) Acc D Fake: 0.000%
Loss D: 1.097
Loss G: 0.6475 (0.6044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4710 (0.3906) Acc D Real: 99.069%
Loss D Fake: 0.7443 (0.7975) Acc D Fake: 0.000%
Loss D: 1.215
Loss G: 0.6477 (0.6048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.4035 (0.3907) Acc D Real: 99.070%
Loss D Fake: 0.7442 (0.7970) Acc D Fake: 0.000%
Loss D: 1.148
Loss G: 0.6479 (0.6051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.4662 (0.3913) Acc D Real: 99.070%
Loss D Fake: 0.7441 (0.7965) Acc D Fake: 0.000%
Loss D: 1.210
Loss G: 0.6477 (0.6055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.4180 (0.3916) Acc D Real: 99.070%
Loss D Fake: 0.7445 (0.7960) Acc D Fake: 0.000%
Loss D: 1.162
Loss G: 0.6474 (0.6059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3960 (0.3916) Acc D Real: 99.072%
Loss D Fake: 0.7448 (0.7956) Acc D Fake: 0.000%
Loss D: 1.141
Loss G: 0.6472 (0.6063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.4016 (0.3917) Acc D Real: 99.073%
Loss D Fake: 0.7449 (0.7951) Acc D Fake: 0.000%
Loss D: 1.146
Loss G: 0.6472 (0.6066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3550 (0.3914) Acc D Real: 99.076%
Loss D Fake: 0.7448 (0.7947) Acc D Fake: 0.000%
Loss D: 1.100
Loss G: 0.6475 (0.6070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3524 (0.3911) Acc D Real: 99.075%
Loss D Fake: 0.7442 (0.7943) Acc D Fake: 0.000%
Loss D: 1.097
Loss G: 0.6481 (0.6073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4341 (0.3914) Acc D Real: 99.076%
Loss D Fake: 0.7434 (0.7939) Acc D Fake: 0.000%
Loss D: 1.178
Loss G: 0.6487 (0.6077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3954 (0.3915) Acc D Real: 99.078%
Loss D Fake: 0.7429 (0.7934) Acc D Fake: 0.000%
Loss D: 1.138
Loss G: 0.6492 (0.6080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3156 (0.3908) Acc D Real: 99.082%
Loss D Fake: 0.7422 (0.7930) Acc D Fake: 0.000%
Loss D: 1.058
Loss G: 0.6501 (0.6084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3578 (0.3906) Acc D Real: 99.085%
Loss D Fake: 0.7411 (0.7926) Acc D Fake: 0.000%
Loss D: 1.099
Loss G: 0.6511 (0.6087) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3930 (0.3906) Acc D Real: 99.087%
Loss D Fake: 0.7400 (0.7921) Acc D Fake: 0.000%
Loss D: 1.133
Loss G: 0.6521 (0.6091) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3963 (0.3906) Acc D Real: 99.088%
Loss D Fake: 0.7390 (0.7917) Acc D Fake: 0.000%
Loss D: 1.135
Loss G: 0.6529 (0.6094) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.4172 (0.3908) Acc D Real: 99.091%
Loss D Fake: 0.7383 (0.7913) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6535 (0.6098) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3415 (0.3904) Acc D Real: 99.094%
Loss D Fake: 0.7376 (0.7908) Acc D Fake: 0.000%
Loss D: 1.079
Loss G: 0.6542 (0.6101) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4150 (0.3906) Acc D Real: 99.096%
Loss D Fake: 0.7367 (0.7904) Acc D Fake: 0.000%
Loss D: 1.152
Loss G: 0.6549 (0.6105) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.4446 (0.3911) Acc D Real: 99.095%
Loss D Fake: 0.7361 (0.7900) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.6553 (0.6108) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4369 (0.3914) Acc D Real: 99.097%
Loss D Fake: 0.7359 (0.7896) Acc D Fake: 0.000%
Loss D: 1.173
Loss G: 0.6554 (0.6112) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4668 (0.3920) Acc D Real: 99.100%
Loss D Fake: 0.7360 (0.7891) Acc D Fake: 0.000%
Loss D: 1.203
Loss G: 0.6550 (0.6115) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4164 (0.3922) Acc D Real: 99.102%
Loss D Fake: 0.7366 (0.7887) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6545 (0.6119) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3729 (0.3920) Acc D Real: 99.104%
Loss D Fake: 0.7370 (0.7884) Acc D Fake: 0.000%
Loss D: 1.110
Loss G: 0.6544 (0.6122) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3533 (0.3917) Acc D Real: 99.109%
Loss D Fake: 0.7369 (0.7880) Acc D Fake: 0.000%
Loss D: 1.090
Loss G: 0.6546 (0.6125) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.4328 (0.3921) Acc D Real: 99.111%
Loss D Fake: 0.7366 (0.7876) Acc D Fake: 0.000%
Loss D: 1.169
Loss G: 0.6547 (0.6128) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4028 (0.3921) Acc D Real: 99.113%
Loss D Fake: 0.7366 (0.7872) Acc D Fake: 0.000%
Loss D: 1.139
Loss G: 0.6548 (0.6131) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3795 (0.3920) Acc D Real: 99.113%
Loss D Fake: 0.7365 (0.7868) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6550 (0.6135) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4287 (0.3923) Acc D Real: 99.112%
Loss D Fake: 0.7363 (0.7864) Acc D Fake: 0.000%
Loss D: 1.165
Loss G: 0.6550 (0.6138) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3863 (0.3923) Acc D Real: 99.113%
Loss D Fake: 0.7362 (0.7861) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6551 (0.6141) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4505 (0.3927) Acc D Real: 99.115%
Loss D Fake: 0.7362 (0.7857) Acc D Fake: 0.000%
Loss D: 1.187
Loss G: 0.6550 (0.6144) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.4795 (0.3933) Acc D Real: 99.115%
Loss D Fake: 0.7367 (0.7854) Acc D Fake: 0.000%
Loss D: 1.216
Loss G: 0.6543 (0.6146) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.4832 (0.3940) Acc D Real: 99.118%
Loss D Fake: 0.7376 (0.7850) Acc D Fake: 0.000%
Loss D: 1.221
Loss G: 0.6532 (0.6149) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3422 (0.3936) Acc D Real: 99.119%
Loss D Fake: 0.7387 (0.7847) Acc D Fake: 0.000%
Loss D: 1.081
Loss G: 0.6526 (0.6152) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4513 (0.3940) Acc D Real: 99.122%
Loss D Fake: 0.7392 (0.7844) Acc D Fake: 0.000%
Loss D: 1.190
Loss G: 0.6520 (0.6154) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4199 (0.3942) Acc D Real: 99.125%
Loss D Fake: 0.7399 (0.7841) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6513 (0.6157) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3112 (0.3936) Acc D Real: 99.128%
Loss D Fake: 0.7404 (0.7838) Acc D Fake: 0.000%
Loss D: 1.052
Loss G: 0.6513 (0.6159) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4256 (0.3938) Acc D Real: 99.130%
Loss D Fake: 0.7403 (0.7835) Acc D Fake: 0.000%
Loss D: 1.166
Loss G: 0.6513 (0.6162) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4143 (0.3940) Acc D Real: 99.132%
Loss D Fake: 0.7403 (0.7832) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6512 (0.6164) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3968 (0.3940) Acc D Real: 99.134%
Loss D Fake: 0.7404 (0.7829) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.6511 (0.6167) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3703 (0.3938) Acc D Real: 99.137%
Loss D Fake: 0.7405 (0.7826) Acc D Fake: 0.000%
Loss D: 1.111
Loss G: 0.6512 (0.6169) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3152 (0.3933) Acc D Real: 99.140%
Loss D Fake: 0.7402 (0.7823) Acc D Fake: 0.000%
Loss D: 1.055
Loss G: 0.6518 (0.6171) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3174 (0.3928) Acc D Real: 99.145%
Loss D Fake: 0.7392 (0.7820) Acc D Fake: 0.000%
Loss D: 1.057
Loss G: 0.6529 (0.6174) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3825 (0.3927) Acc D Real: 99.148%
Loss D Fake: 0.7379 (0.7817) Acc D Fake: 0.000%
Loss D: 1.120
Loss G: 0.6541 (0.6176) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4335 (0.3930) Acc D Real: 99.149%
Loss D Fake: 0.7368 (0.7814) Acc D Fake: 0.000%
Loss D: 1.170
Loss G: 0.6549 (0.6179) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4612 (0.3934) Acc D Real: 99.146%
Loss D Fake: 0.7361 (0.7811) Acc D Fake: 0.000%
Loss D: 1.197
Loss G: 0.6553 (0.6181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4175 (0.3936) Acc D Real: 99.149%
Loss D Fake: 0.7359 (0.7808) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6554 (0.6183) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3840 (0.3935) Acc D Real: 99.152%
Loss D Fake: 0.7358 (0.7805) Acc D Fake: 0.000%
Loss D: 1.120
Loss G: 0.6555 (0.6186) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4321 (0.3938) Acc D Real: 99.154%
Loss D Fake: 0.7357 (0.7803) Acc D Fake: 0.000%
Loss D: 1.168
Loss G: 0.6555 (0.6188) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4015 (0.3938) Acc D Real: 99.157%
Loss D Fake: 0.7358 (0.7800) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.6554 (0.6191) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.3044 (0.3933) Acc D Real: 99.157%
Loss D Fake: 0.7356 (0.7797) Acc D Fake: 0.000%
Loss D: 1.040
Loss G: 0.6560 (0.6193) Acc G: 100.000%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.854 | Generator Loss: 0.656 | Avg: 1.510
TEST [21/180]: Discriminator Loss: 0.944 | Generator Loss: 0.656 | Avg: 1.600
TEST [31/180]: Discriminator Loss: 0.920 | Generator Loss: 0.656 | Avg: 1.576
TEST [41/180]: Discriminator Loss: 0.896 | Generator Loss: 0.656 | Avg: 1.552
TEST [51/180]: Discriminator Loss: 0.895 | Generator Loss: 0.656 | Avg: 1.551
TEST [61/180]: Discriminator Loss: 0.938 | Generator Loss: 0.656 | Avg: 1.594
TEST [71/180]: Discriminator Loss: 0.965 | Generator Loss: 0.656 | Avg: 1.621
TEST [81/180]: Discriminator Loss: 1.004 | Generator Loss: 0.656 | Avg: 1.660
TEST [91/180]: Discriminator Loss: 1.026 | Generator Loss: 0.656 | Avg: 1.682
TEST [101/180]: Discriminator Loss: 1.062 | Generator Loss: 0.656 | Avg: 1.718
TEST [111/180]: Discriminator Loss: 1.089 | Generator Loss: 0.656 | Avg: 1.745
TEST [121/180]: Discriminator Loss: 1.114 | Generator Loss: 0.656 | Avg: 1.770
TEST [131/180]: Discriminator Loss: 1.134 | Generator Loss: 0.656 | Avg: 1.790
TEST [141/180]: Discriminator Loss: 1.150 | Generator Loss: 0.656 | Avg: 1.806
TEST [151/180]: Discriminator Loss: 1.138 | Generator Loss: 0.656 | Avg: 1.794
TEST [161/180]: Discriminator Loss: 1.125 | Generator Loss: 0.656 | Avg: 1.781
TEST [171/180]: Discriminator Loss: 1.112 | Generator Loss: 0.656 | Avg: 1.768
Epoch: 17/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4032 (0.4052) Acc D Real: 99.323%
Loss D Fake: 0.7342 (0.7345) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.6572 (0.6569) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.5374 (0.4493) Acc D Real: 99.253%
Loss D Fake: 0.7339 (0.7343) Acc D Fake: 0.000%
Loss D: 1.271
Loss G: 0.6569 (0.6569) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3301 (0.4195) Acc D Real: 99.362%
Loss D Fake: 0.7344 (0.7343) Acc D Fake: 0.000%
Loss D: 1.064
Loss G: 0.6568 (0.6569) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4379 (0.4232) Acc D Real: 99.417%
Loss D Fake: 0.7344 (0.7343) Acc D Fake: 0.000%
Loss D: 1.172
Loss G: 0.6566 (0.6568) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3655 (0.4136) Acc D Real: 99.427%
Loss D Fake: 0.7346 (0.7344) Acc D Fake: 0.000%
Loss D: 1.100
Loss G: 0.6566 (0.6568) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3264 (0.4011) Acc D Real: 99.479%
Loss D Fake: 0.7343 (0.7344) Acc D Fake: 0.000%
Loss D: 1.061
Loss G: 0.6571 (0.6568) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3871 (0.3993) Acc D Real: 99.486%
Loss D Fake: 0.7337 (0.7343) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.6577 (0.6569) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4065 (0.4001) Acc D Real: 99.479%
Loss D Fake: 0.7331 (0.7342) Acc D Fake: 0.000%
Loss D: 1.140
Loss G: 0.6582 (0.6571) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3886 (0.3990) Acc D Real: 99.479%
Loss D Fake: 0.7325 (0.7340) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.6588 (0.6573) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.3324 (0.3929) Acc D Real: 99.498%
Loss D Fake: 0.7318 (0.7338) Acc D Fake: 0.000%
Loss D: 1.064
Loss G: 0.6596 (0.6575) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.3968 (0.3933) Acc D Real: 99.510%
Loss D Fake: 0.7309 (0.7336) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.6604 (0.6577) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4691 (0.3991) Acc D Real: 99.479%
Loss D Fake: 0.7302 (0.7333) Acc D Fake: 0.000%
Loss D: 1.199
Loss G: 0.6607 (0.6579) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.4188 (0.4005) Acc D Real: 99.479%
Loss D Fake: 0.7302 (0.7331) Acc D Fake: 0.000%
Loss D: 1.149
Loss G: 0.6607 (0.6581) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3590 (0.3977) Acc D Real: 99.476%
Loss D Fake: 0.7302 (0.7329) Acc D Fake: 0.000%
Loss D: 1.089
Loss G: 0.6608 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.4113 (0.3986) Acc D Real: 99.473%
Loss D Fake: 0.7300 (0.7327) Acc D Fake: 0.000%
Loss D: 1.141
Loss G: 0.6608 (0.6585) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.4343 (0.4007) Acc D Real: 99.479%
Loss D Fake: 0.7301 (0.7325) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.6607 (0.6586) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3870 (0.3999) Acc D Real: 99.479%
Loss D Fake: 0.7303 (0.7324) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.6605 (0.6587) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3799 (0.3989) Acc D Real: 99.490%
Loss D Fake: 0.7304 (0.7323) Acc D Fake: 0.000%
Loss D: 1.110
Loss G: 0.6605 (0.6588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.4637 (0.4021) Acc D Real: 99.477%
Loss D Fake: 0.7305 (0.7322) Acc D Fake: 0.000%
Loss D: 1.194
Loss G: 0.6601 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.4193 (0.4029) Acc D Real: 99.484%
Loss D Fake: 0.7310 (0.7322) Acc D Fake: 0.000%
Loss D: 1.150
Loss G: 0.6596 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.4381 (0.4045) Acc D Real: 99.496%
Loss D Fake: 0.7316 (0.7321) Acc D Fake: 0.000%
Loss D: 1.170
Loss G: 0.6589 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.4485 (0.4064) Acc D Real: 99.500%
Loss D Fake: 0.7325 (0.7322) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.6580 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3638 (0.4047) Acc D Real: 99.507%
Loss D Fake: 0.7333 (0.7322) Acc D Fake: 0.000%
Loss D: 1.097
Loss G: 0.6575 (0.6588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3818 (0.4037) Acc D Real: 99.513%
Loss D Fake: 0.7338 (0.7323) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6572 (0.6587) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3976 (0.4035) Acc D Real: 99.517%
Loss D Fake: 0.7340 (0.7323) Acc D Fake: 0.000%
Loss D: 1.132
Loss G: 0.6570 (0.6587) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.4029 (0.4035) Acc D Real: 99.516%
Loss D Fake: 0.7341 (0.7324) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.6569 (0.6586) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3819 (0.4027) Acc D Real: 99.513%
Loss D Fake: 0.7342 (0.7325) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6569 (0.6585) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3757 (0.4018) Acc D Real: 99.519%
Loss D Fake: 0.7341 (0.7325) Acc D Fake: 0.000%
Loss D: 1.110
Loss G: 0.6570 (0.6585) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.4320 (0.4028) Acc D Real: 99.523%
Loss D Fake: 0.7340 (0.7326) Acc D Fake: 0.000%
Loss D: 1.166
Loss G: 0.6570 (0.6584) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3831 (0.4022) Acc D Real: 99.530%
Loss D Fake: 0.7341 (0.7326) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.6570 (0.6584) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.4713 (0.4043) Acc D Real: 99.528%
Loss D Fake: 0.7342 (0.7327) Acc D Fake: 0.000%
Loss D: 1.205
Loss G: 0.6566 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3816 (0.4036) Acc D Real: 99.528%
Loss D Fake: 0.7346 (0.7327) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6564 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3501 (0.4021) Acc D Real: 99.534%
Loss D Fake: 0.7347 (0.7328) Acc D Fake: 0.000%
Loss D: 1.085
Loss G: 0.6565 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3882 (0.4017) Acc D Real: 99.540%
Loss D Fake: 0.7345 (0.7328) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6568 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3826 (0.4011) Acc D Real: 99.544%
Loss D Fake: 0.7341 (0.7329) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.6571 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3284 (0.3992) Acc D Real: 99.552%
Loss D Fake: 0.7336 (0.7329) Acc D Fake: 0.000%
Loss D: 1.062
Loss G: 0.6578 (0.6581) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3941 (0.3990) Acc D Real: 99.559%
Loss D Fake: 0.7328 (0.7329) Acc D Fake: 0.000%
Loss D: 1.127
Loss G: 0.6584 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3255 (0.3971) Acc D Real: 99.561%
Loss D Fake: 0.7321 (0.7329) Acc D Fake: 0.000%
Loss D: 1.058
Loss G: 0.6594 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.4767 (0.3991) Acc D Real: 99.556%
Loss D Fake: 0.7312 (0.7328) Acc D Fake: 0.000%
Loss D: 1.208
Loss G: 0.6598 (0.6582) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4414 (0.4002) Acc D Real: 99.559%
Loss D Fake: 0.7311 (0.7328) Acc D Fake: 0.000%
Loss D: 1.173
Loss G: 0.6597 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4397 (0.4011) Acc D Real: 99.559%
Loss D Fake: 0.7313 (0.7328) Acc D Fake: 0.000%
Loss D: 1.171
Loss G: 0.6593 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3813 (0.4006) Acc D Real: 99.560%
Loss D Fake: 0.7317 (0.7327) Acc D Fake: 0.000%
Loss D: 1.113
Loss G: 0.6590 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3447 (0.3994) Acc D Real: 99.564%
Loss D Fake: 0.7319 (0.7327) Acc D Fake: 0.000%
Loss D: 1.077
Loss G: 0.6591 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3748 (0.3988) Acc D Real: 99.565%
Loss D Fake: 0.7316 (0.7327) Acc D Fake: 0.000%
Loss D: 1.106
Loss G: 0.6595 (0.6583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.2894 (0.3965) Acc D Real: 99.570%
Loss D Fake: 0.7310 (0.7326) Acc D Fake: 0.000%
Loss D: 1.020
Loss G: 0.6604 (0.6584) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.4298 (0.3972) Acc D Real: 99.573%
Loss D Fake: 0.7299 (0.7326) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6611 (0.6585) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.4354 (0.3980) Acc D Real: 99.574%
Loss D Fake: 0.7294 (0.7325) Acc D Fake: 0.000%
Loss D: 1.165
Loss G: 0.6614 (0.6585) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.4521 (0.3991) Acc D Real: 99.575%
Loss D Fake: 0.7293 (0.7325) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.6613 (0.6586) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3774 (0.3986) Acc D Real: 99.576%
Loss D Fake: 0.7295 (0.7324) Acc D Fake: 0.000%
Loss D: 1.107
Loss G: 0.6612 (0.6586) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.4032 (0.3987) Acc D Real: 99.580%
Loss D Fake: 0.7295 (0.7323) Acc D Fake: 0.000%
Loss D: 1.133
Loss G: 0.6612 (0.6587) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4113 (0.3990) Acc D Real: 99.582%
Loss D Fake: 0.7296 (0.7323) Acc D Fake: 0.000%
Loss D: 1.141
Loss G: 0.6610 (0.6587) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4469 (0.3999) Acc D Real: 99.586%
Loss D Fake: 0.7299 (0.7322) Acc D Fake: 0.000%
Loss D: 1.177
Loss G: 0.6606 (0.6588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3430 (0.3988) Acc D Real: 99.586%
Loss D Fake: 0.7303 (0.7322) Acc D Fake: 0.000%
Loss D: 1.073
Loss G: 0.6606 (0.6588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3854 (0.3986) Acc D Real: 99.587%
Loss D Fake: 0.7302 (0.7322) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6607 (0.6588) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.4166 (0.3989) Acc D Real: 99.589%
Loss D Fake: 0.7301 (0.7321) Acc D Fake: 0.000%
Loss D: 1.147
Loss G: 0.6607 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.4766 (0.4003) Acc D Real: 99.587%
Loss D Fake: 0.7303 (0.7321) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.6602 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3926 (0.4001) Acc D Real: 99.591%
Loss D Fake: 0.7309 (0.7321) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6597 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3332 (0.3990) Acc D Real: 99.596%
Loss D Fake: 0.7312 (0.7321) Acc D Fake: 0.000%
Loss D: 1.064
Loss G: 0.6597 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3618 (0.3984) Acc D Real: 99.599%
Loss D Fake: 0.7310 (0.7320) Acc D Fake: 0.000%
Loss D: 1.093
Loss G: 0.6600 (0.6589) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3092 (0.3969) Acc D Real: 99.601%
Loss D Fake: 0.7305 (0.7320) Acc D Fake: 0.000%
Loss D: 1.040
Loss G: 0.6608 (0.6590) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3895 (0.3968) Acc D Real: 99.603%
Loss D Fake: 0.7295 (0.7320) Acc D Fake: 0.000%
Loss D: 1.119
Loss G: 0.6616 (0.6590) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3688 (0.3963) Acc D Real: 99.605%
Loss D Fake: 0.7286 (0.7319) Acc D Fake: 0.000%
Loss D: 1.097
Loss G: 0.6625 (0.6591) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3836 (0.3961) Acc D Real: 99.605%
Loss D Fake: 0.7277 (0.7319) Acc D Fake: 0.000%
Loss D: 1.111
Loss G: 0.6634 (0.6591) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4125 (0.3964) Acc D Real: 99.607%
Loss D Fake: 0.7269 (0.7318) Acc D Fake: 0.000%
Loss D: 1.139
Loss G: 0.6639 (0.6592) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.4015 (0.3965) Acc D Real: 99.607%
Loss D Fake: 0.7264 (0.7317) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.6643 (0.6593) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3678 (0.3960) Acc D Real: 99.609%
Loss D Fake: 0.7260 (0.7316) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.6648 (0.6594) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4104 (0.3963) Acc D Real: 99.611%
Loss D Fake: 0.7255 (0.7315) Acc D Fake: 0.000%
Loss D: 1.136
Loss G: 0.6651 (0.6594) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3996 (0.3963) Acc D Real: 99.611%
Loss D Fake: 0.7252 (0.7314) Acc D Fake: 0.000%
Loss D: 1.125
Loss G: 0.6654 (0.6595) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4281 (0.3968) Acc D Real: 99.613%
Loss D Fake: 0.7250 (0.7313) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6654 (0.6596) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4501 (0.3975) Acc D Real: 99.610%
Loss D Fake: 0.7252 (0.7313) Acc D Fake: 0.000%
Loss D: 1.175
Loss G: 0.6650 (0.6597) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3990 (0.3975) Acc D Real: 99.612%
Loss D Fake: 0.7257 (0.7312) Acc D Fake: 0.000%
Loss D: 1.125
Loss G: 0.6646 (0.6598) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3724 (0.3972) Acc D Real: 99.615%
Loss D Fake: 0.7261 (0.7311) Acc D Fake: 0.000%
Loss D: 1.099
Loss G: 0.6643 (0.6598) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3766 (0.3969) Acc D Real: 99.617%
Loss D Fake: 0.7262 (0.7310) Acc D Fake: 0.000%
Loss D: 1.103
Loss G: 0.6643 (0.6599) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3802 (0.3967) Acc D Real: 99.619%
Loss D Fake: 0.7263 (0.7310) Acc D Fake: 0.000%
Loss D: 1.106
Loss G: 0.6643 (0.6599) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4636 (0.3976) Acc D Real: 99.623%
Loss D Fake: 0.7264 (0.7309) Acc D Fake: 0.000%
Loss D: 1.190
Loss G: 0.6639 (0.6600) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3629 (0.3971) Acc D Real: 99.626%
Loss D Fake: 0.7268 (0.7309) Acc D Fake: 0.000%
Loss D: 1.090
Loss G: 0.6637 (0.6600) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.2715 (0.3955) Acc D Real: 99.627%
Loss D Fake: 0.7267 (0.7308) Acc D Fake: 0.000%
Loss D: 0.998
Loss G: 0.6642 (0.6601) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4329 (0.3960) Acc D Real: 99.629%
Loss D Fake: 0.7260 (0.7308) Acc D Fake: 0.000%
Loss D: 1.159
Loss G: 0.6646 (0.6601) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3749 (0.3957) Acc D Real: 99.631%
Loss D Fake: 0.7257 (0.7307) Acc D Fake: 0.000%
Loss D: 1.101
Loss G: 0.6650 (0.6602) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3799 (0.3955) Acc D Real: 99.633%
Loss D Fake: 0.7253 (0.7306) Acc D Fake: 0.000%
Loss D: 1.105
Loss G: 0.6655 (0.6603) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4223 (0.3958) Acc D Real: 99.632%
Loss D Fake: 0.7248 (0.7306) Acc D Fake: 0.000%
Loss D: 1.147
Loss G: 0.6657 (0.6603) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3445 (0.3952) Acc D Real: 99.633%
Loss D Fake: 0.7245 (0.7305) Acc D Fake: 0.000%
Loss D: 1.069
Loss G: 0.6661 (0.6604) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3289 (0.3944) Acc D Real: 99.635%
Loss D Fake: 0.7239 (0.7304) Acc D Fake: 0.000%
Loss D: 1.053
Loss G: 0.6669 (0.6605) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3215 (0.3936) Acc D Real: 99.637%
Loss D Fake: 0.7229 (0.7303) Acc D Fake: 0.000%
Loss D: 1.044
Loss G: 0.6681 (0.6606) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3072 (0.3926) Acc D Real: 99.638%
Loss D Fake: 0.7215 (0.7302) Acc D Fake: 0.000%
Loss D: 1.029
Loss G: 0.6697 (0.6607) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3840 (0.3925) Acc D Real: 99.639%
Loss D Fake: 0.7198 (0.7301) Acc D Fake: 0.000%
Loss D: 1.104
Loss G: 0.6712 (0.6608) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.5043 (0.3938) Acc D Real: 99.638%
Loss D Fake: 0.7186 (0.7300) Acc D Fake: 0.000%
Loss D: 1.223
Loss G: 0.6717 (0.6609) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4008 (0.3938) Acc D Real: 99.640%
Loss D Fake: 0.7183 (0.7298) Acc D Fake: 0.000%
Loss D: 1.119
Loss G: 0.6720 (0.6611) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4542 (0.3945) Acc D Real: 99.639%
Loss D Fake: 0.7183 (0.7297) Acc D Fake: 0.000%
Loss D: 1.172
Loss G: 0.6717 (0.6612) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3496 (0.3940) Acc D Real: 99.641%
Loss D Fake: 0.7185 (0.7296) Acc D Fake: 0.000%
Loss D: 1.068
Loss G: 0.6717 (0.6613) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3899 (0.3940) Acc D Real: 99.641%
Loss D Fake: 0.7184 (0.7295) Acc D Fake: 0.000%
Loss D: 1.108
Loss G: 0.6718 (0.6614) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4179 (0.3942) Acc D Real: 99.643%
Loss D Fake: 0.7184 (0.7293) Acc D Fake: 0.000%
Loss D: 1.136
Loss G: 0.6717 (0.6615) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4706 (0.3950) Acc D Real: 99.642%
Loss D Fake: 0.7187 (0.7292) Acc D Fake: 0.000%
Loss D: 1.189
Loss G: 0.6711 (0.6616) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3885 (0.3950) Acc D Real: 99.643%
Loss D Fake: 0.7195 (0.7291) Acc D Fake: 0.000%
Loss D: 1.108
Loss G: 0.6704 (0.6617) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.4608 (0.3957) Acc D Real: 99.642%
Loss D Fake: 0.7202 (0.7290) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.6696 (0.6618) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.5416 (0.3972) Acc D Real: 99.639%
Loss D Fake: 0.7214 (0.7290) Acc D Fake: 0.000%
Loss D: 1.263
Loss G: 0.6679 (0.6619) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3247 (0.3964) Acc D Real: 99.640%
Loss D Fake: 0.7232 (0.7289) Acc D Fake: 0.000%
Loss D: 1.048
Loss G: 0.6666 (0.6619) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3850 (0.3963) Acc D Real: 99.642%
Loss D Fake: 0.7242 (0.7288) Acc D Fake: 0.000%
Loss D: 1.109
Loss G: 0.6659 (0.6619) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.4357 (0.3967) Acc D Real: 99.644%
Loss D Fake: 0.7249 (0.7288) Acc D Fake: 0.000%
Loss D: 1.161
Loss G: 0.6651 (0.6620) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.4055 (0.3968) Acc D Real: 99.646%
Loss D Fake: 0.7258 (0.7288) Acc D Fake: 0.000%
Loss D: 1.131
Loss G: 0.6642 (0.6620) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3603 (0.3964) Acc D Real: 99.647%
Loss D Fake: 0.7266 (0.7288) Acc D Fake: 0.000%
Loss D: 1.087
Loss G: 0.6636 (0.6620) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2971 (0.3955) Acc D Real: 99.649%
Loss D Fake: 0.7269 (0.7287) Acc D Fake: 0.000%
Loss D: 1.024
Loss G: 0.6638 (0.6620) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3099 (0.3946) Acc D Real: 99.651%
Loss D Fake: 0.7264 (0.7287) Acc D Fake: 0.000%
Loss D: 1.036
Loss G: 0.6646 (0.6621) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3764 (0.3945) Acc D Real: 99.653%
Loss D Fake: 0.7254 (0.7287) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.6654 (0.6621) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3149 (0.3937) Acc D Real: 99.655%
Loss D Fake: 0.7245 (0.7286) Acc D Fake: 0.000%
Loss D: 1.039
Loss G: 0.6666 (0.6621) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3337 (0.3932) Acc D Real: 99.656%
Loss D Fake: 0.7230 (0.7286) Acc D Fake: 0.000%
Loss D: 1.057
Loss G: 0.6680 (0.6622) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3972 (0.3932) Acc D Real: 99.656%
Loss D Fake: 0.7216 (0.7285) Acc D Fake: 0.000%
Loss D: 1.119
Loss G: 0.6692 (0.6622) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.4561 (0.3938) Acc D Real: 99.655%
Loss D Fake: 0.7206 (0.7285) Acc D Fake: 0.000%
Loss D: 1.177
Loss G: 0.6698 (0.6623) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.4199 (0.3940) Acc D Real: 99.657%
Loss D Fake: 0.7203 (0.7284) Acc D Fake: 0.000%
Loss D: 1.140
Loss G: 0.6700 (0.6624) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3842 (0.3939) Acc D Real: 99.657%
Loss D Fake: 0.7201 (0.7283) Acc D Fake: 0.000%
Loss D: 1.104
Loss G: 0.6701 (0.6625) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3060 (0.3931) Acc D Real: 99.660%
Loss D Fake: 0.7198 (0.7282) Acc D Fake: 0.000%
Loss D: 1.026
Loss G: 0.6707 (0.6625) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.4159 (0.3933) Acc D Real: 99.662%
Loss D Fake: 0.7192 (0.7282) Acc D Fake: 0.000%
Loss D: 1.135
Loss G: 0.6712 (0.6626) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3986 (0.3934) Acc D Real: 99.664%
Loss D Fake: 0.7188 (0.7281) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.6714 (0.6627) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3478 (0.3930) Acc D Real: 99.665%
Loss D Fake: 0.7185 (0.7280) Acc D Fake: 0.000%
Loss D: 1.066
Loss G: 0.6719 (0.6628) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3825 (0.3929) Acc D Real: 99.667%
Loss D Fake: 0.7180 (0.7279) Acc D Fake: 0.000%
Loss D: 1.101
Loss G: 0.6723 (0.6628) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.4425 (0.3933) Acc D Real: 99.667%
Loss D Fake: 0.7177 (0.7278) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6724 (0.6629) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3659 (0.3931) Acc D Real: 99.670%
Loss D Fake: 0.7176 (0.7277) Acc D Fake: 0.000%
Loss D: 1.084
Loss G: 0.6725 (0.6630) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3641 (0.3928) Acc D Real: 99.671%
Loss D Fake: 0.7174 (0.7276) Acc D Fake: 0.000%
Loss D: 1.082
Loss G: 0.6728 (0.6631) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3538 (0.3925) Acc D Real: 99.671%
Loss D Fake: 0.7171 (0.7276) Acc D Fake: 0.000%
Loss D: 1.071
Loss G: 0.6733 (0.6632) Acc G: 99.583%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3612 (0.3923) Acc D Real: 99.557%
Loss D Fake: 0.7165 (0.7275) Acc D Fake: 0.413%
Loss D: 1.078
Loss G: 0.6739 (0.6633) Acc G: 99.091%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3945 (0.3923) Acc D Real: 99.381%
Loss D Fake: 0.7159 (0.7274) Acc D Fake: 0.902%
Loss D: 1.110
Loss G: 0.6744 (0.6634) Acc G: 98.579%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4318 (0.3926) Acc D Real: 99.175%
Loss D Fake: 0.7154 (0.7273) Acc D Fake: 1.396%
Loss D: 1.147
Loss G: 0.6747 (0.6634) Acc G: 98.062%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3787 (0.3925) Acc D Real: 98.950%
Loss D Fake: 0.7152 (0.7272) Acc D Fake: 1.895%
Loss D: 1.094
Loss G: 0.6750 (0.6635) Acc G: 97.554%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3715 (0.3923) Acc D Real: 98.731%
Loss D Fake: 0.7148 (0.7271) Acc D Fake: 2.400%
Loss D: 1.086
Loss G: 0.6754 (0.6636) Acc G: 97.040%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3800 (0.3922) Acc D Real: 98.488%
Loss D Fake: 0.7144 (0.7270) Acc D Fake: 2.910%
Loss D: 1.094
Loss G: 0.6757 (0.6637) Acc G: 96.534%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3563 (0.3919) Acc D Real: 98.263%
Loss D Fake: 0.7140 (0.7269) Acc D Fake: 3.412%
Loss D: 1.070
Loss G: 0.6762 (0.6638) Acc G: 96.024%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3822 (0.3919) Acc D Real: 98.005%
Loss D Fake: 0.7135 (0.7268) Acc D Fake: 3.919%
Loss D: 1.096
Loss G: 0.6766 (0.6639) Acc G: 95.521%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.2889 (0.3911) Acc D Real: 97.862%
Loss D Fake: 0.7129 (0.7267) Acc D Fake: 4.419%
Loss D: 1.002
Loss G: 0.6776 (0.6640) Acc G: 95.013%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.3996 (0.3911) Acc D Real: 97.605%
Loss D Fake: 0.7118 (0.7265) Acc D Fake: 4.923%
Loss D: 1.111
Loss G: 0.6785 (0.6641) Acc G: 94.513%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.2938 (0.3904) Acc D Real: 97.435%
Loss D Fake: 0.7109 (0.7264) Acc D Fake: 5.433%
Loss D: 1.005
Loss G: 0.6797 (0.6643) Acc G: 94.008%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3642 (0.3902) Acc D Real: 97.204%
Loss D Fake: 0.7095 (0.7263) Acc D Fake: 5.934%
Loss D: 1.074
Loss G: 0.6810 (0.6644) Acc G: 93.497%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3527 (0.3899) Acc D Real: 96.974%
Loss D Fake: 0.7082 (0.7262) Acc D Fake: 6.441%
Loss D: 1.061
Loss G: 0.6823 (0.6645) Acc G: 92.995%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.3252 (0.3894) Acc D Real: 96.788%
Loss D Fake: 0.7069 (0.7260) Acc D Fake: 6.940%
Loss D: 1.032
Loss G: 0.6838 (0.6647) Acc G: 92.500%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4558 (0.3899) Acc D Real: 96.477%
Loss D Fake: 0.7055 (0.7259) Acc D Fake: 7.432%
Loss D: 1.161
Loss G: 0.6847 (0.6648) Acc G: 92.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4037 (0.3900) Acc D Real: 96.211%
Loss D Fake: 0.7048 (0.7257) Acc D Fake: 7.929%
Loss D: 1.108
Loss G: 0.6853 (0.6650) Acc G: 91.507%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4588 (0.3905) Acc D Real: 95.893%
Loss D Fake: 0.7044 (0.7256) Acc D Fake: 8.418%
Loss D: 1.163
Loss G: 0.6853 (0.6651) Acc G: 91.022%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3213 (0.3900) Acc D Real: 95.716%
Loss D Fake: 0.7044 (0.7254) Acc D Fake: 8.901%
Loss D: 1.026
Loss G: 0.6856 (0.6653) Acc G: 90.543%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3357 (0.3896) Acc D Real: 95.520%
Loss D Fake: 0.7039 (0.7252) Acc D Fake: 9.376%
Loss D: 1.040
Loss G: 0.6863 (0.6654) Acc G: 90.072%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3491 (0.3893) Acc D Real: 95.323%
Loss D Fake: 0.7032 (0.7251) Acc D Fake: 9.845%
Loss D: 1.052
Loss G: 0.6871 (0.6656) Acc G: 89.607%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3892 (0.3893) Acc D Real: 95.083%
Loss D Fake: 0.7024 (0.7249) Acc D Fake: 10.307%
Loss D: 1.092
Loss G: 0.6878 (0.6657) Acc G: 89.149%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.3647 (0.3892) Acc D Real: 94.886%
Loss D Fake: 0.7016 (0.7248) Acc D Fake: 10.763%
Loss D: 1.066
Loss G: 0.6886 (0.6659) Acc G: 88.697%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3339 (0.3888) Acc D Real: 94.704%
Loss D Fake: 0.7008 (0.7246) Acc D Fake: 11.212%
Loss D: 1.035
Loss G: 0.6896 (0.6661) Acc G: 88.252%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.4855 (0.3894) Acc D Real: 94.394%
Loss D Fake: 0.7000 (0.7244) Acc D Fake: 11.655%
Loss D: 1.185
Loss G: 0.6899 (0.6662) Acc G: 87.812%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.2813 (0.3887) Acc D Real: 94.265%
Loss D Fake: 0.6997 (0.7243) Acc D Fake: 12.092%
Loss D: 0.981
Loss G: 0.6906 (0.6664) Acc G: 87.379%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.4636 (0.3892) Acc D Real: 93.982%
Loss D Fake: 0.6990 (0.7241) Acc D Fake: 12.523%
Loss D: 1.163
Loss G: 0.6909 (0.6666) Acc G: 86.941%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3760 (0.3891) Acc D Real: 93.777%
Loss D Fake: 0.6988 (0.7239) Acc D Fake: 12.948%
Loss D: 1.075
Loss G: 0.6911 (0.6667) Acc G: 86.508%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.4099 (0.3893) Acc D Real: 93.541%
Loss D Fake: 0.6987 (0.7237) Acc D Fake: 13.378%
Loss D: 1.109
Loss G: 0.6912 (0.6669) Acc G: 86.081%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3409 (0.3889) Acc D Real: 93.370%
Loss D Fake: 0.6986 (0.7236) Acc D Fake: 13.803%
Loss D: 1.039
Loss G: 0.6914 (0.6671) Acc G: 85.660%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3633 (0.3888) Acc D Real: 93.188%
Loss D Fake: 0.6982 (0.7234) Acc D Fake: 14.222%
Loss D: 1.062
Loss G: 0.6919 (0.6672) Acc G: 85.244%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3663 (0.3886) Acc D Real: 93.003%
Loss D Fake: 0.6977 (0.7232) Acc D Fake: 14.636%
Loss D: 1.064
Loss G: 0.6925 (0.6674) Acc G: 84.834%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3878 (0.3886) Acc D Real: 92.791%
Loss D Fake: 0.6971 (0.7231) Acc D Fake: 15.044%
Loss D: 1.085
Loss G: 0.6930 (0.6676) Acc G: 84.430%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.4084 (0.3887) Acc D Real: 92.567%
Loss D Fake: 0.6968 (0.7229) Acc D Fake: 15.447%
Loss D: 1.105
Loss G: 0.6932 (0.6677) Acc G: 84.031%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4856 (0.3894) Acc D Real: 92.276%
Loss D Fake: 0.6968 (0.7227) Acc D Fake: 15.844%
Loss D: 1.182
Loss G: 0.6927 (0.6679) Acc G: 83.636%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.4042 (0.3895) Acc D Real: 92.054%
Loss D Fake: 0.6975 (0.7226) Acc D Fake: 16.237%
Loss D: 1.102
Loss G: 0.6919 (0.6680) Acc G: 83.247%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.4449 (0.3898) Acc D Real: 91.816%
Loss D Fake: 0.6984 (0.7224) Acc D Fake: 16.624%
Loss D: 1.143
Loss G: 0.6909 (0.6682) Acc G: 82.874%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4314 (0.3901) Acc D Real: 91.597%
Loss D Fake: 0.6995 (0.7223) Acc D Fake: 16.996%
Loss D: 1.131
Loss G: 0.6898 (0.6683) Acc G: 82.505%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.6905 (0.3920) Acc D Real: 91.554%
Loss D Fake: 0.7012 (0.7221) Acc D Fake: 17.030%
Loss D: 1.392
Loss G: 0.6869 (0.6684) Acc G: 82.471%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.797 | Generator Loss: 0.687 | Avg: 1.484
TEST [21/180]: Discriminator Loss: 0.884 | Generator Loss: 0.687 | Avg: 1.571
TEST [31/180]: Discriminator Loss: 0.861 | Generator Loss: 0.687 | Avg: 1.548
TEST [41/180]: Discriminator Loss: 0.838 | Generator Loss: 0.687 | Avg: 1.525
TEST [51/180]: Discriminator Loss: 0.837 | Generator Loss: 0.687 | Avg: 1.524
TEST [61/180]: Discriminator Loss: 0.886 | Generator Loss: 0.687 | Avg: 1.573
TEST [71/180]: Discriminator Loss: 0.910 | Generator Loss: 0.687 | Avg: 1.597
TEST [81/180]: Discriminator Loss: 0.952 | Generator Loss: 0.687 | Avg: 1.639
TEST [91/180]: Discriminator Loss: 0.975 | Generator Loss: 0.687 | Avg: 1.662
TEST [101/180]: Discriminator Loss: 1.015 | Generator Loss: 0.687 | Avg: 1.702
TEST [111/180]: Discriminator Loss: 1.044 | Generator Loss: 0.687 | Avg: 1.731
TEST [121/180]: Discriminator Loss: 1.073 | Generator Loss: 0.687 | Avg: 1.760
TEST [131/180]: Discriminator Loss: 1.096 | Generator Loss: 0.687 | Avg: 1.783
TEST [141/180]: Discriminator Loss: 1.112 | Generator Loss: 0.687 | Avg: 1.799
TEST [151/180]: Discriminator Loss: 1.098 | Generator Loss: 0.687 | Avg: 1.785
TEST [161/180]: Discriminator Loss: 1.083 | Generator Loss: 0.687 | Avg: 1.770
TEST [171/180]: Discriminator Loss: 1.069 | Generator Loss: 0.687 | Avg: 1.756
Epoch: 18/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4380 (0.3861) Acc D Real: 63.255%
Loss D Fake: 0.7066 (0.7054) Acc D Fake: 74.167%
Loss D: 1.145
Loss G: 0.6821 (0.6833) Acc G: 26.667%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3838 (0.3853) Acc D Real: 63.455%
Loss D Fake: 0.7087 (0.7065) Acc D Fake: 73.333%
Loss D: 1.092
Loss G: 0.6802 (0.6822) Acc G: 27.222%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3807 (0.3842) Acc D Real: 63.438%
Loss D Fake: 0.7104 (0.7075) Acc D Fake: 72.917%
Loss D: 1.091
Loss G: 0.6787 (0.6814) Acc G: 27.500%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3338 (0.3741) Acc D Real: 65.448%
Loss D Fake: 0.7117 (0.7083) Acc D Fake: 72.333%
Loss D: 1.046
Loss G: 0.6778 (0.6807) Acc G: 28.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.2942 (0.3608) Acc D Real: 67.578%
Loss D Fake: 0.7122 (0.7090) Acc D Fake: 71.944%
Loss D: 1.006
Loss G: 0.6778 (0.6802) Acc G: 28.333%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3479 (0.3590) Acc D Real: 67.820%
Loss D Fake: 0.7119 (0.7094) Acc D Fake: 71.667%
Loss D: 1.060
Loss G: 0.6782 (0.6799) Acc G: 28.571%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.4723 (0.3731) Acc D Real: 66.250%
Loss D Fake: 0.7117 (0.7097) Acc D Fake: 71.458%
Loss D: 1.184
Loss G: 0.6780 (0.6797) Acc G: 28.750%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.4026 (0.3764) Acc D Real: 65.642%
Loss D Fake: 0.7121 (0.7099) Acc D Fake: 71.296%
Loss D: 1.115
Loss G: 0.6775 (0.6794) Acc G: 28.889%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3834 (0.3771) Acc D Real: 65.531%
Loss D Fake: 0.7125 (0.7102) Acc D Fake: 71.000%
Loss D: 1.096
Loss G: 0.6771 (0.6792) Acc G: 29.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.4125 (0.3803) Acc D Real: 65.128%
Loss D Fake: 0.7130 (0.7105) Acc D Fake: 70.758%
Loss D: 1.125
Loss G: 0.6766 (0.6790) Acc G: 29.242%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.3822 (0.3805) Acc D Real: 65.642%
Loss D Fake: 0.7135 (0.7107) Acc D Fake: 70.556%
Loss D: 1.096
Loss G: 0.6762 (0.6787) Acc G: 29.444%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4784 (0.3880) Acc D Real: 64.900%
Loss D Fake: 0.7141 (0.7110) Acc D Fake: 70.256%
Loss D: 1.193
Loss G: 0.6753 (0.6785) Acc G: 29.744%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3857 (0.3878) Acc D Real: 65.320%
Loss D Fake: 0.7151 (0.7113) Acc D Fake: 69.762%
Loss D: 1.101
Loss G: 0.6745 (0.6782) Acc G: 30.238%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.2996 (0.3820) Acc D Real: 66.208%
Loss D Fake: 0.7157 (0.7116) Acc D Fake: 69.111%
Loss D: 1.015
Loss G: 0.6742 (0.6779) Acc G: 30.778%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3603 (0.3806) Acc D Real: 66.865%
Loss D Fake: 0.7157 (0.7118) Acc D Fake: 68.542%
Loss D: 1.076
Loss G: 0.6743 (0.6777) Acc G: 31.146%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.4161 (0.3827) Acc D Real: 67.194%
Loss D Fake: 0.7156 (0.7120) Acc D Fake: 68.137%
Loss D: 1.132
Loss G: 0.6743 (0.6775) Acc G: 31.471%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3633 (0.3816) Acc D Real: 67.804%
Loss D Fake: 0.7157 (0.7122) Acc D Fake: 67.778%
Loss D: 1.079
Loss G: 0.6743 (0.6773) Acc G: 31.759%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.4700 (0.3863) Acc D Real: 67.569%
Loss D Fake: 0.7158 (0.7124) Acc D Fake: 67.368%
Loss D: 1.186
Loss G: 0.6739 (0.6771) Acc G: 32.193%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3981 (0.3869) Acc D Real: 68.151%
Loss D Fake: 0.7164 (0.7126) Acc D Fake: 66.583%
Loss D: 1.115
Loss G: 0.6732 (0.6769) Acc G: 33.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.3620 (0.3857) Acc D Real: 69.187%
Loss D Fake: 0.7169 (0.7128) Acc D Fake: 63.413%
Loss D: 1.079
Loss G: 0.6729 (0.6767) Acc G: 36.190%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3463 (0.3839) Acc D Real: 70.530%
Loss D Fake: 0.7171 (0.7130) Acc D Fake: 60.530%
Loss D: 1.063
Loss G: 0.6729 (0.6766) Acc G: 39.091%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3866 (0.3840) Acc D Real: 71.517%
Loss D Fake: 0.7170 (0.7132) Acc D Fake: 57.899%
Loss D: 1.104
Loss G: 0.6730 (0.6764) Acc G: 40.290%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.4526 (0.3869) Acc D Real: 72.437%
Loss D Fake: 0.7171 (0.7134) Acc D Fake: 55.486%
Loss D: 1.170
Loss G: 0.6727 (0.6763) Acc G: 42.778%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.3797 (0.3866) Acc D Real: 73.515%
Loss D Fake: 0.7175 (0.7135) Acc D Fake: 53.267%
Loss D: 1.097
Loss G: 0.6723 (0.6761) Acc G: 45.067%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.4185 (0.3878) Acc D Real: 74.519%
Loss D Fake: 0.7179 (0.7137) Acc D Fake: 51.218%
Loss D: 1.136
Loss G: 0.6718 (0.6759) Acc G: 47.179%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3851 (0.3877) Acc D Real: 75.455%
Loss D Fake: 0.7184 (0.7139) Acc D Fake: 49.321%
Loss D: 1.104
Loss G: 0.6714 (0.6758) Acc G: 49.136%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4185 (0.3888) Acc D Real: 76.328%
Loss D Fake: 0.7189 (0.7140) Acc D Fake: 47.560%
Loss D: 1.137
Loss G: 0.6709 (0.6756) Acc G: 50.952%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.3735 (0.3883) Acc D Real: 77.141%
Loss D Fake: 0.7194 (0.7142) Acc D Fake: 45.920%
Loss D: 1.093
Loss G: 0.6705 (0.6754) Acc G: 52.644%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.4600 (0.3907) Acc D Real: 77.898%
Loss D Fake: 0.7198 (0.7144) Acc D Fake: 44.389%
Loss D: 1.180
Loss G: 0.6699 (0.6752) Acc G: 54.222%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3311 (0.3888) Acc D Real: 78.607%
Loss D Fake: 0.7204 (0.7146) Acc D Fake: 42.957%
Loss D: 1.051
Loss G: 0.6696 (0.6750) Acc G: 55.699%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3907 (0.3888) Acc D Real: 79.269%
Loss D Fake: 0.7206 (0.7148) Acc D Fake: 41.615%
Loss D: 1.111
Loss G: 0.6695 (0.6749) Acc G: 57.083%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.4636 (0.3911) Acc D Real: 79.894%
Loss D Fake: 0.7208 (0.7150) Acc D Fake: 40.354%
Loss D: 1.184
Loss G: 0.6689 (0.6747) Acc G: 58.384%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3030 (0.3885) Acc D Real: 80.481%
Loss D Fake: 0.7214 (0.7152) Acc D Fake: 39.167%
Loss D: 1.024
Loss G: 0.6687 (0.6745) Acc G: 59.608%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3879 (0.3885) Acc D Real: 81.036%
Loss D Fake: 0.7214 (0.7153) Acc D Fake: 38.048%
Loss D: 1.109
Loss G: 0.6686 (0.6743) Acc G: 60.762%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3586 (0.3876) Acc D Real: 81.560%
Loss D Fake: 0.7214 (0.7155) Acc D Fake: 36.991%
Loss D: 1.080
Loss G: 0.6687 (0.6742) Acc G: 61.852%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3426 (0.3864) Acc D Real: 82.058%
Loss D Fake: 0.7212 (0.7157) Acc D Fake: 35.991%
Loss D: 1.064
Loss G: 0.6690 (0.6740) Acc G: 62.883%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.3798 (0.3863) Acc D Real: 82.526%
Loss D Fake: 0.7208 (0.7158) Acc D Fake: 35.044%
Loss D: 1.101
Loss G: 0.6694 (0.6739) Acc G: 63.860%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.2483 (0.3827) Acc D Real: 82.971%
Loss D Fake: 0.7202 (0.7159) Acc D Fake: 34.145%
Loss D: 0.968
Loss G: 0.6705 (0.6738) Acc G: 64.786%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3437 (0.3817) Acc D Real: 83.396%
Loss D Fake: 0.7188 (0.7160) Acc D Fake: 33.292%
Loss D: 1.063
Loss G: 0.6718 (0.6738) Acc G: 65.667%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.4155 (0.3826) Acc D Real: 83.793%
Loss D Fake: 0.7176 (0.7160) Acc D Fake: 32.480%
Loss D: 1.133
Loss G: 0.6728 (0.6738) Acc G: 66.504%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4351 (0.3838) Acc D Real: 84.017%
Loss D Fake: 0.7168 (0.7161) Acc D Fake: 31.706%
Loss D: 1.152
Loss G: 0.6732 (0.6737) Acc G: 66.071%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3968 (0.3841) Acc D Real: 84.090%
Loss D Fake: 0.7166 (0.7161) Acc D Fake: 31.899%
Loss D: 1.113
Loss G: 0.6734 (0.6737) Acc G: 65.581%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3174 (0.3826) Acc D Real: 84.272%
Loss D Fake: 0.7163 (0.7161) Acc D Fake: 32.386%
Loss D: 1.034
Loss G: 0.6739 (0.6737) Acc G: 65.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3962 (0.3829) Acc D Real: 84.119%
Loss D Fake: 0.7158 (0.7161) Acc D Fake: 33.000%
Loss D: 1.112
Loss G: 0.6743 (0.6738) Acc G: 64.370%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4225 (0.3838) Acc D Real: 83.899%
Loss D Fake: 0.7155 (0.7161) Acc D Fake: 33.623%
Loss D: 1.138
Loss G: 0.6744 (0.6738) Acc G: 63.768%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3750 (0.3836) Acc D Real: 83.757%
Loss D Fake: 0.7155 (0.7160) Acc D Fake: 34.220%
Loss D: 1.090
Loss G: 0.6744 (0.6738) Acc G: 63.191%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3842 (0.3836) Acc D Real: 83.600%
Loss D Fake: 0.7154 (0.7160) Acc D Fake: 34.792%
Loss D: 1.100
Loss G: 0.6745 (0.6738) Acc G: 62.639%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3614 (0.3831) Acc D Real: 83.476%
Loss D Fake: 0.7153 (0.7160) Acc D Fake: 35.340%
Loss D: 1.077
Loss G: 0.6746 (0.6738) Acc G: 62.109%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3836 (0.3831) Acc D Real: 83.281%
Loss D Fake: 0.7151 (0.7160) Acc D Fake: 35.900%
Loss D: 1.099
Loss G: 0.6748 (0.6738) Acc G: 61.567%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3955 (0.3834) Acc D Real: 83.086%
Loss D Fake: 0.7150 (0.7160) Acc D Fake: 36.438%
Loss D: 1.110
Loss G: 0.6749 (0.6739) Acc G: 61.046%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.4250 (0.3842) Acc D Real: 82.755%
Loss D Fake: 0.7150 (0.7160) Acc D Fake: 36.955%
Loss D: 1.140
Loss G: 0.6747 (0.6739) Acc G: 60.545%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3304 (0.3832) Acc D Real: 82.696%
Loss D Fake: 0.7152 (0.7159) Acc D Fake: 37.453%
Loss D: 1.046
Loss G: 0.6748 (0.6739) Acc G: 60.063%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3136 (0.3819) Acc D Real: 82.747%
Loss D Fake: 0.7148 (0.7159) Acc D Fake: 37.963%
Loss D: 1.028
Loss G: 0.6754 (0.6739) Acc G: 59.568%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3289 (0.3809) Acc D Real: 82.661%
Loss D Fake: 0.7140 (0.7159) Acc D Fake: 38.485%
Loss D: 1.043
Loss G: 0.6763 (0.6740) Acc G: 59.061%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3098 (0.3796) Acc D Real: 82.557%
Loss D Fake: 0.7129 (0.7158) Acc D Fake: 39.018%
Loss D: 1.023
Loss G: 0.6776 (0.6740) Acc G: 58.542%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3894 (0.3798) Acc D Real: 82.282%
Loss D Fake: 0.7116 (0.7158) Acc D Fake: 39.561%
Loss D: 1.101
Loss G: 0.6787 (0.6741) Acc G: 58.041%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3168 (0.3787) Acc D Real: 82.126%
Loss D Fake: 0.7104 (0.7157) Acc D Fake: 40.115%
Loss D: 1.027
Loss G: 0.6800 (0.6742) Acc G: 57.529%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3847 (0.3788) Acc D Real: 81.806%
Loss D Fake: 0.7091 (0.7156) Acc D Fake: 40.650%
Loss D: 1.094
Loss G: 0.6812 (0.6743) Acc G: 57.034%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3938 (0.3791) Acc D Real: 81.463%
Loss D Fake: 0.7081 (0.7154) Acc D Fake: 41.167%
Loss D: 1.102
Loss G: 0.6820 (0.6745) Acc G: 56.528%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.3468 (0.3786) Acc D Real: 81.237%
Loss D Fake: 0.7073 (0.7153) Acc D Fake: 41.694%
Loss D: 1.054
Loss G: 0.6829 (0.6746) Acc G: 56.038%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3887 (0.3787) Acc D Real: 80.946%
Loss D Fake: 0.7064 (0.7152) Acc D Fake: 42.204%
Loss D: 1.095
Loss G: 0.6836 (0.6747) Acc G: 55.565%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3608 (0.3784) Acc D Real: 80.747%
Loss D Fake: 0.7057 (0.7150) Acc D Fake: 42.698%
Loss D: 1.066
Loss G: 0.6844 (0.6749) Acc G: 55.106%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3546 (0.3781) Acc D Real: 80.491%
Loss D Fake: 0.7049 (0.7148) Acc D Fake: 43.177%
Loss D: 1.060
Loss G: 0.6851 (0.6750) Acc G: 54.661%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4430 (0.3791) Acc D Real: 80.102%
Loss D Fake: 0.7043 (0.7147) Acc D Fake: 43.641%
Loss D: 1.147
Loss G: 0.6855 (0.6752) Acc G: 54.231%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.3937 (0.3793) Acc D Real: 79.857%
Loss D Fake: 0.7041 (0.7145) Acc D Fake: 44.091%
Loss D: 1.098
Loss G: 0.6856 (0.6754) Acc G: 53.813%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3490 (0.3788) Acc D Real: 79.661%
Loss D Fake: 0.7040 (0.7144) Acc D Fake: 44.527%
Loss D: 1.053
Loss G: 0.6858 (0.6755) Acc G: 53.408%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3653 (0.3786) Acc D Real: 79.435%
Loss D Fake: 0.7037 (0.7142) Acc D Fake: 44.951%
Loss D: 1.069
Loss G: 0.6862 (0.6757) Acc G: 52.999%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3507 (0.3782) Acc D Real: 79.253%
Loss D Fake: 0.7033 (0.7140) Acc D Fake: 45.362%
Loss D: 1.054
Loss G: 0.6867 (0.6758) Acc G: 52.594%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3851 (0.3783) Acc D Real: 78.996%
Loss D Fake: 0.7028 (0.7139) Acc D Fake: 45.786%
Loss D: 1.088
Loss G: 0.6871 (0.6760) Acc G: 52.199%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4011 (0.3786) Acc D Real: 78.724%
Loss D Fake: 0.7025 (0.7137) Acc D Fake: 46.197%
Loss D: 1.104
Loss G: 0.6872 (0.6762) Acc G: 51.816%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3357 (0.3781) Acc D Real: 78.586%
Loss D Fake: 0.7023 (0.7136) Acc D Fake: 46.597%
Loss D: 1.038
Loss G: 0.6876 (0.6763) Acc G: 51.444%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.4028 (0.3784) Acc D Real: 78.330%
Loss D Fake: 0.7019 (0.7134) Acc D Fake: 46.986%
Loss D: 1.105
Loss G: 0.6879 (0.6765) Acc G: 51.082%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.3674 (0.3782) Acc D Real: 78.131%
Loss D Fake: 0.7017 (0.7132) Acc D Fake: 47.365%
Loss D: 1.069
Loss G: 0.6881 (0.6766) Acc G: 50.729%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3526 (0.3779) Acc D Real: 77.969%
Loss D Fake: 0.7014 (0.7131) Acc D Fake: 47.733%
Loss D: 1.054
Loss G: 0.6884 (0.6768) Acc G: 50.386%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.4241 (0.3785) Acc D Real: 77.684%
Loss D Fake: 0.7011 (0.7129) Acc D Fake: 48.092%
Loss D: 1.125
Loss G: 0.6885 (0.6769) Acc G: 50.052%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.4243 (0.3791) Acc D Real: 77.427%
Loss D Fake: 0.7013 (0.7128) Acc D Fake: 48.442%
Loss D: 1.126
Loss G: 0.6881 (0.6771) Acc G: 49.727%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.4223 (0.3797) Acc D Real: 77.149%
Loss D Fake: 0.7018 (0.7126) Acc D Fake: 48.782%
Loss D: 1.124
Loss G: 0.6875 (0.6772) Acc G: 49.410%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4465 (0.3805) Acc D Real: 76.864%
Loss D Fake: 0.7026 (0.7125) Acc D Fake: 49.114%
Loss D: 1.149
Loss G: 0.6865 (0.6773) Acc G: 49.122%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3530 (0.3802) Acc D Real: 76.748%
Loss D Fake: 0.7035 (0.7124) Acc D Fake: 49.417%
Loss D: 1.057
Loss G: 0.6858 (0.6774) Acc G: 48.841%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.4554 (0.3811) Acc D Real: 76.448%
Loss D Fake: 0.7042 (0.7123) Acc D Fake: 49.712%
Loss D: 1.160
Loss G: 0.6848 (0.6775) Acc G: 48.567%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3621 (0.3809) Acc D Real: 76.306%
Loss D Fake: 0.7052 (0.7122) Acc D Fake: 50.000%
Loss D: 1.067
Loss G: 0.6840 (0.6776) Acc G: 48.300%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3524 (0.3805) Acc D Real: 76.194%
Loss D Fake: 0.7059 (0.7121) Acc D Fake: 50.281%
Loss D: 1.058
Loss G: 0.6835 (0.6777) Acc G: 48.040%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3030 (0.3796) Acc D Real: 76.149%
Loss D Fake: 0.7062 (0.7121) Acc D Fake: 50.556%
Loss D: 1.009
Loss G: 0.6836 (0.6778) Acc G: 47.785%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3822 (0.3796) Acc D Real: 75.971%
Loss D Fake: 0.7059 (0.7120) Acc D Fake: 50.824%
Loss D: 1.088
Loss G: 0.6838 (0.6778) Acc G: 47.537%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.4433 (0.3804) Acc D Real: 75.733%
Loss D Fake: 0.7059 (0.7119) Acc D Fake: 51.085%
Loss D: 1.149
Loss G: 0.6835 (0.6779) Acc G: 47.294%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.2599 (0.3790) Acc D Real: 75.768%
Loss D Fake: 0.7060 (0.7119) Acc D Fake: 51.341%
Loss D: 0.966
Loss G: 0.6838 (0.6780) Acc G: 47.057%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3317 (0.3784) Acc D Real: 75.732%
Loss D Fake: 0.7054 (0.7118) Acc D Fake: 51.591%
Loss D: 1.037
Loss G: 0.6846 (0.6780) Acc G: 46.825%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3320 (0.3779) Acc D Real: 75.653%
Loss D Fake: 0.7045 (0.7117) Acc D Fake: 51.835%
Loss D: 1.036
Loss G: 0.6856 (0.6781) Acc G: 46.599%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3861 (0.3780) Acc D Real: 75.498%
Loss D Fake: 0.7035 (0.7116) Acc D Fake: 52.074%
Loss D: 1.090
Loss G: 0.6865 (0.6782) Acc G: 46.377%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4812 (0.3791) Acc D Real: 75.228%
Loss D Fake: 0.7030 (0.7115) Acc D Fake: 52.308%
Loss D: 1.184
Loss G: 0.6866 (0.6783) Acc G: 46.161%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3632 (0.3790) Acc D Real: 75.093%
Loss D Fake: 0.7030 (0.7114) Acc D Fake: 52.536%
Loss D: 1.066
Loss G: 0.6865 (0.6784) Acc G: 45.949%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4971 (0.3802) Acc D Real: 74.796%
Loss D Fake: 0.7033 (0.7113) Acc D Fake: 52.760%
Loss D: 1.200
Loss G: 0.6858 (0.6785) Acc G: 45.741%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3892 (0.3803) Acc D Real: 74.648%
Loss D Fake: 0.7043 (0.7113) Acc D Fake: 52.979%
Loss D: 1.093
Loss G: 0.6849 (0.6785) Acc G: 45.539%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.3757 (0.3803) Acc D Real: 74.538%
Loss D Fake: 0.7051 (0.7112) Acc D Fake: 53.193%
Loss D: 1.081
Loss G: 0.6842 (0.6786) Acc G: 45.340%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3781 (0.3803) Acc D Real: 74.411%
Loss D Fake: 0.7057 (0.7111) Acc D Fake: 53.403%
Loss D: 1.084
Loss G: 0.6837 (0.6787) Acc G: 45.145%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3142 (0.3796) Acc D Real: 74.375%
Loss D Fake: 0.7060 (0.7111) Acc D Fake: 53.608%
Loss D: 1.020
Loss G: 0.6836 (0.6787) Acc G: 44.955%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.4103 (0.3799) Acc D Real: 74.225%
Loss D Fake: 0.7061 (0.7110) Acc D Fake: 53.810%
Loss D: 1.116
Loss G: 0.6834 (0.6788) Acc G: 44.768%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3609 (0.3797) Acc D Real: 74.163%
Loss D Fake: 0.7062 (0.7110) Acc D Fake: 54.007%
Loss D: 1.067
Loss G: 0.6833 (0.6788) Acc G: 44.585%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.4391 (0.3803) Acc D Real: 73.987%
Loss D Fake: 0.7064 (0.7109) Acc D Fake: 54.200%
Loss D: 1.145
Loss G: 0.6829 (0.6788) Acc G: 44.406%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3424 (0.3799) Acc D Real: 73.922%
Loss D Fake: 0.7069 (0.7109) Acc D Fake: 54.373%
Loss D: 1.049
Loss G: 0.6826 (0.6789) Acc G: 44.231%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.3796 (0.3799) Acc D Real: 73.806%
Loss D Fake: 0.7071 (0.7109) Acc D Fake: 54.542%
Loss D: 1.087
Loss G: 0.6824 (0.6789) Acc G: 44.075%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3476 (0.3796) Acc D Real: 73.750%
Loss D Fake: 0.7072 (0.7108) Acc D Fake: 54.709%
Loss D: 1.055
Loss G: 0.6824 (0.6789) Acc G: 43.922%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3520 (0.3793) Acc D Real: 73.682%
Loss D Fake: 0.7071 (0.7108) Acc D Fake: 54.872%
Loss D: 1.059
Loss G: 0.6826 (0.6790) Acc G: 43.772%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3985 (0.3795) Acc D Real: 73.578%
Loss D Fake: 0.7069 (0.7108) Acc D Fake: 55.032%
Loss D: 1.105
Loss G: 0.6827 (0.6790) Acc G: 43.609%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.4952 (0.3806) Acc D Real: 73.342%
Loss D Fake: 0.7071 (0.7107) Acc D Fake: 55.189%
Loss D: 1.202
Loss G: 0.6821 (0.6790) Acc G: 43.465%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3582 (0.3804) Acc D Real: 73.265%
Loss D Fake: 0.7079 (0.7107) Acc D Fake: 55.343%
Loss D: 1.066
Loss G: 0.6814 (0.6791) Acc G: 43.324%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.2971 (0.3796) Acc D Real: 73.267%
Loss D Fake: 0.7083 (0.7107) Acc D Fake: 55.494%
Loss D: 1.005
Loss G: 0.6814 (0.6791) Acc G: 43.185%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3801 (0.3796) Acc D Real: 73.179%
Loss D Fake: 0.7081 (0.7106) Acc D Fake: 55.642%
Loss D: 1.088
Loss G: 0.6815 (0.6791) Acc G: 43.049%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3488 (0.3794) Acc D Real: 73.124%
Loss D Fake: 0.7079 (0.7106) Acc D Fake: 55.788%
Loss D: 1.057
Loss G: 0.6818 (0.6791) Acc G: 42.915%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.4372 (0.3799) Acc D Real: 72.972%
Loss D Fake: 0.7078 (0.7106) Acc D Fake: 55.931%
Loss D: 1.145
Loss G: 0.6817 (0.6792) Acc G: 42.783%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.4027 (0.3801) Acc D Real: 72.879%
Loss D Fake: 0.7080 (0.7106) Acc D Fake: 56.071%
Loss D: 1.111
Loss G: 0.6814 (0.6792) Acc G: 42.654%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3776 (0.3801) Acc D Real: 72.791%
Loss D Fake: 0.7084 (0.7106) Acc D Fake: 56.209%
Loss D: 1.086
Loss G: 0.6810 (0.6792) Acc G: 42.528%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3411 (0.3797) Acc D Real: 72.745%
Loss D Fake: 0.7086 (0.7105) Acc D Fake: 56.345%
Loss D: 1.050
Loss G: 0.6810 (0.6792) Acc G: 42.403%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3569 (0.3795) Acc D Real: 72.697%
Loss D Fake: 0.7085 (0.7105) Acc D Fake: 56.478%
Loss D: 1.065
Loss G: 0.6811 (0.6792) Acc G: 42.281%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3273 (0.3791) Acc D Real: 72.668%
Loss D Fake: 0.7082 (0.7105) Acc D Fake: 56.609%
Loss D: 1.036
Loss G: 0.6816 (0.6792) Acc G: 42.161%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.3697 (0.3790) Acc D Real: 72.605%
Loss D Fake: 0.7077 (0.7105) Acc D Fake: 56.738%
Loss D: 1.077
Loss G: 0.6821 (0.6793) Acc G: 42.042%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.4246 (0.3794) Acc D Real: 72.471%
Loss D Fake: 0.7073 (0.7104) Acc D Fake: 56.864%
Loss D: 1.132
Loss G: 0.6823 (0.6793) Acc G: 41.926%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3454 (0.3791) Acc D Real: 72.423%
Loss D Fake: 0.7072 (0.7104) Acc D Fake: 56.989%
Loss D: 1.053
Loss G: 0.6825 (0.6793) Acc G: 41.812%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3364 (0.3787) Acc D Real: 72.389%
Loss D Fake: 0.7069 (0.7104) Acc D Fake: 57.111%
Loss D: 1.043
Loss G: 0.6829 (0.6794) Acc G: 41.700%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3299 (0.3783) Acc D Real: 72.368%
Loss D Fake: 0.7063 (0.7104) Acc D Fake: 57.231%
Loss D: 1.036
Loss G: 0.6836 (0.6794) Acc G: 41.575%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3771 (0.3783) Acc D Real: 72.286%
Loss D Fake: 0.7056 (0.7103) Acc D Fake: 57.363%
Loss D: 1.083
Loss G: 0.6842 (0.6794) Acc G: 41.453%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3233 (0.3779) Acc D Real: 72.262%
Loss D Fake: 0.7049 (0.7103) Acc D Fake: 57.493%
Loss D: 1.028
Loss G: 0.6850 (0.6795) Acc G: 41.333%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3694 (0.3778) Acc D Real: 72.195%
Loss D Fake: 0.7041 (0.7102) Acc D Fake: 57.621%
Loss D: 1.074
Loss G: 0.6858 (0.6795) Acc G: 41.215%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3236 (0.3774) Acc D Real: 72.175%
Loss D Fake: 0.7033 (0.7102) Acc D Fake: 57.747%
Loss D: 1.027
Loss G: 0.6867 (0.6796) Acc G: 41.098%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4437 (0.3779) Acc D Real: 72.027%
Loss D Fake: 0.7025 (0.7101) Acc D Fake: 57.870%
Loss D: 1.146
Loss G: 0.6871 (0.6796) Acc G: 40.984%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3759 (0.3779) Acc D Real: 71.970%
Loss D Fake: 0.7023 (0.7100) Acc D Fake: 57.992%
Loss D: 1.078
Loss G: 0.6873 (0.6797) Acc G: 40.871%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.4238 (0.3782) Acc D Real: 71.851%
Loss D Fake: 0.7021 (0.7100) Acc D Fake: 58.112%
Loss D: 1.126
Loss G: 0.6873 (0.6798) Acc G: 40.760%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.4212 (0.3786) Acc D Real: 71.738%
Loss D Fake: 0.7024 (0.7099) Acc D Fake: 58.230%
Loss D: 1.124
Loss G: 0.6868 (0.6798) Acc G: 40.651%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.3626 (0.3785) Acc D Real: 71.674%
Loss D Fake: 0.7029 (0.7099) Acc D Fake: 58.346%
Loss D: 1.065
Loss G: 0.6864 (0.6799) Acc G: 40.543%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3955 (0.3786) Acc D Real: 71.598%
Loss D Fake: 0.7033 (0.7098) Acc D Fake: 58.461%
Loss D: 1.099
Loss G: 0.6859 (0.6799) Acc G: 40.437%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.3633 (0.3785) Acc D Real: 71.551%
Loss D Fake: 0.7037 (0.7098) Acc D Fake: 58.573%
Loss D: 1.067
Loss G: 0.6856 (0.6800) Acc G: 40.333%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3675 (0.3784) Acc D Real: 71.500%
Loss D Fake: 0.7040 (0.7097) Acc D Fake: 58.684%
Loss D: 1.072
Loss G: 0.6853 (0.6800) Acc G: 40.230%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4055 (0.3786) Acc D Real: 71.417%
Loss D Fake: 0.7043 (0.7097) Acc D Fake: 58.794%
Loss D: 1.110
Loss G: 0.6850 (0.6800) Acc G: 40.129%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4002 (0.3787) Acc D Real: 71.330%
Loss D Fake: 0.7047 (0.7097) Acc D Fake: 58.901%
Loss D: 1.105
Loss G: 0.6846 (0.6801) Acc G: 40.029%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.4188 (0.3790) Acc D Real: 71.219%
Loss D Fake: 0.7052 (0.7096) Acc D Fake: 58.995%
Loss D: 1.124
Loss G: 0.6838 (0.6801) Acc G: 39.943%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4581 (0.3796) Acc D Real: 71.085%
Loss D Fake: 0.7062 (0.7096) Acc D Fake: 59.088%
Loss D: 1.164
Loss G: 0.6827 (0.6801) Acc G: 39.859%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4025 (0.3798) Acc D Real: 71.015%
Loss D Fake: 0.7074 (0.7096) Acc D Fake: 59.179%
Loss D: 1.110
Loss G: 0.6814 (0.6801) Acc G: 39.775%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3880 (0.3798) Acc D Real: 70.966%
Loss D Fake: 0.7087 (0.7096) Acc D Fake: 59.269%
Loss D: 1.097
Loss G: 0.6803 (0.6801) Acc G: 39.705%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.4183 (0.3801) Acc D Real: 70.887%
Loss D Fake: 0.7098 (0.7096) Acc D Fake: 59.345%
Loss D: 1.128
Loss G: 0.6791 (0.6801) Acc G: 39.635%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.2889 (0.3795) Acc D Real: 70.909%
Loss D Fake: 0.7108 (0.7096) Acc D Fake: 59.421%
Loss D: 1.000
Loss G: 0.6785 (0.6801) Acc G: 39.567%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4046 (0.3797) Acc D Real: 70.838%
Loss D Fake: 0.7112 (0.7096) Acc D Fake: 59.484%
Loss D: 1.116
Loss G: 0.6780 (0.6801) Acc G: 39.500%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3676 (0.3796) Acc D Real: 70.815%
Loss D Fake: 0.7117 (0.7096) Acc D Fake: 59.545%
Loss D: 1.079
Loss G: 0.6777 (0.6801) Acc G: 39.445%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3454 (0.3793) Acc D Real: 70.802%
Loss D Fake: 0.7119 (0.7096) Acc D Fake: 59.606%
Loss D: 1.057
Loss G: 0.6776 (0.6801) Acc G: 39.391%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.3571 (0.3792) Acc D Real: 70.795%
Loss D Fake: 0.7119 (0.7096) Acc D Fake: 59.667%
Loss D: 1.069
Loss G: 0.6777 (0.6800) Acc G: 39.338%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.3851 (0.3792) Acc D Real: 70.754%
Loss D Fake: 0.7118 (0.7097) Acc D Fake: 59.726%
Loss D: 1.097
Loss G: 0.6777 (0.6800) Acc G: 39.285%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3980 (0.3793) Acc D Real: 70.692%
Loss D Fake: 0.7118 (0.7097) Acc D Fake: 59.785%
Loss D: 1.110
Loss G: 0.6776 (0.6800) Acc G: 39.233%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3777 (0.3793) Acc D Real: 70.664%
Loss D Fake: 0.7120 (0.7097) Acc D Fake: 59.842%
Loss D: 1.090
Loss G: 0.6774 (0.6800) Acc G: 39.182%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3067 (0.3788) Acc D Real: 70.677%
Loss D Fake: 0.7121 (0.7097) Acc D Fake: 59.899%
Loss D: 1.019
Loss G: 0.6776 (0.6800) Acc G: 39.132%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3372 (0.3786) Acc D Real: 70.665%
Loss D Fake: 0.7117 (0.7097) Acc D Fake: 59.956%
Loss D: 1.049
Loss G: 0.6780 (0.6800) Acc G: 39.082%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3842 (0.3786) Acc D Real: 70.623%
Loss D Fake: 0.7112 (0.7097) Acc D Fake: 60.011%
Loss D: 1.095
Loss G: 0.6784 (0.6800) Acc G: 39.022%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4748 (0.3792) Acc D Real: 70.494%
Loss D Fake: 0.7111 (0.7097) Acc D Fake: 60.066%
Loss D: 1.186
Loss G: 0.6782 (0.6799) Acc G: 38.973%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3695 (0.3792) Acc D Real: 70.474%
Loss D Fake: 0.7115 (0.7097) Acc D Fake: 60.120%
Loss D: 1.081
Loss G: 0.6778 (0.6799) Acc G: 38.926%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3792 (0.3792) Acc D Real: 70.430%
Loss D Fake: 0.7118 (0.7098) Acc D Fake: 60.173%
Loss D: 1.091
Loss G: 0.6775 (0.6799) Acc G: 38.879%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.2625 (0.3784) Acc D Real: 70.475%
Loss D Fake: 0.7119 (0.7098) Acc D Fake: 60.226%
Loss D: 0.974
Loss G: 0.6779 (0.6799) Acc G: 38.832%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.2650 (0.3777) Acc D Real: 70.516%
Loss D Fake: 0.7111 (0.7098) Acc D Fake: 60.278%
Loss D: 0.976
Loss G: 0.6789 (0.6799) Acc G: 38.775%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.3269 (0.3774) Acc D Real: 70.520%
Loss D Fake: 0.7099 (0.7098) Acc D Fake: 60.340%
Loss D: 1.037
Loss G: 0.6802 (0.6799) Acc G: 38.719%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.4849 (0.3781) Acc D Real: 70.506%
Loss D Fake: 0.7088 (0.7098) Acc D Fake: 60.345%
Loss D: 1.194
Loss G: 0.6807 (0.6799) Acc G: 38.714%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.788 | Generator Loss: 0.681 | Avg: 1.468
TEST [21/180]: Discriminator Loss: 0.869 | Generator Loss: 0.681 | Avg: 1.550
TEST [31/180]: Discriminator Loss: 0.848 | Generator Loss: 0.681 | Avg: 1.528
TEST [41/180]: Discriminator Loss: 0.827 | Generator Loss: 0.681 | Avg: 1.508
TEST [51/180]: Discriminator Loss: 0.825 | Generator Loss: 0.681 | Avg: 1.506
TEST [61/180]: Discriminator Loss: 0.876 | Generator Loss: 0.681 | Avg: 1.556
TEST [71/180]: Discriminator Loss: 0.896 | Generator Loss: 0.681 | Avg: 1.577
TEST [81/180]: Discriminator Loss: 0.938 | Generator Loss: 0.681 | Avg: 1.619
TEST [91/180]: Discriminator Loss: 0.960 | Generator Loss: 0.681 | Avg: 1.641
TEST [101/180]: Discriminator Loss: 1.002 | Generator Loss: 0.681 | Avg: 1.682
TEST [111/180]: Discriminator Loss: 1.030 | Generator Loss: 0.681 | Avg: 1.711
TEST [121/180]: Discriminator Loss: 1.060 | Generator Loss: 0.681 | Avg: 1.741
TEST [131/180]: Discriminator Loss: 1.084 | Generator Loss: 0.681 | Avg: 1.765
TEST [141/180]: Discriminator Loss: 1.100 | Generator Loss: 0.681 | Avg: 1.780
TEST [151/180]: Discriminator Loss: 1.085 | Generator Loss: 0.681 | Avg: 1.766
TEST [161/180]: Discriminator Loss: 1.070 | Generator Loss: 0.681 | Avg: 1.751
TEST [171/180]: Discriminator Loss: 1.056 | Generator Loss: 0.681 | Avg: 1.737
Epoch: 19/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.4214 (0.4035) Acc D Real: 61.745%
Loss D Fake: 0.7088 (0.7087) Acc D Fake: 70.000%
Loss D: 1.130
Loss G: 0.6804 (0.6806) Acc G: 30.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.4547 (0.4205) Acc D Real: 58.594%
Loss D Fake: 0.7093 (0.7089) Acc D Fake: 70.000%
Loss D: 1.164
Loss G: 0.6796 (0.6803) Acc G: 30.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.3826 (0.4111) Acc D Real: 59.688%
Loss D Fake: 0.7102 (0.7092) Acc D Fake: 70.000%
Loss D: 1.093
Loss G: 0.6787 (0.6799) Acc G: 30.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.4452 (0.4179) Acc D Real: 59.260%
Loss D Fake: 0.7112 (0.7096) Acc D Fake: 69.667%
Loss D: 1.156
Loss G: 0.6776 (0.6794) Acc G: 30.333%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3416 (0.4052) Acc D Real: 60.547%
Loss D Fake: 0.7123 (0.7101) Acc D Fake: 69.444%
Loss D: 1.054
Loss G: 0.6767 (0.6790) Acc G: 30.833%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3599 (0.3987) Acc D Real: 61.406%
Loss D Fake: 0.7130 (0.7105) Acc D Fake: 69.048%
Loss D: 1.073
Loss G: 0.6761 (0.6786) Acc G: 31.190%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.3194 (0.3888) Acc D Real: 62.513%
Loss D Fake: 0.7134 (0.7109) Acc D Fake: 68.750%
Loss D: 1.033
Loss G: 0.6759 (0.6782) Acc G: 31.458%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3819 (0.3880) Acc D Real: 62.691%
Loss D Fake: 0.7136 (0.7112) Acc D Fake: 68.333%
Loss D: 1.096
Loss G: 0.6758 (0.6780) Acc G: 31.667%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.3846 (0.3877) Acc D Real: 62.990%
Loss D Fake: 0.7138 (0.7114) Acc D Fake: 68.000%
Loss D: 1.098
Loss G: 0.6756 (0.6777) Acc G: 32.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.2453 (0.3747) Acc D Real: 64.564%
Loss D Fake: 0.7137 (0.7116) Acc D Fake: 67.727%
Loss D: 0.959
Loss G: 0.6761 (0.6776) Acc G: 32.121%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.3704 (0.3744) Acc D Real: 65.113%
Loss D Fake: 0.7130 (0.7117) Acc D Fake: 67.639%
Loss D: 1.083
Loss G: 0.6767 (0.6775) Acc G: 32.222%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4018 (0.3765) Acc D Real: 64.996%
Loss D Fake: 0.7125 (0.7118) Acc D Fake: 67.564%
Loss D: 1.114
Loss G: 0.6770 (0.6775) Acc G: 32.179%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3669 (0.3758) Acc D Real: 65.160%
Loss D Fake: 0.7122 (0.7118) Acc D Fake: 67.500%
Loss D: 1.079
Loss G: 0.6773 (0.6775) Acc G: 32.143%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.4427 (0.3803) Acc D Real: 64.660%
Loss D Fake: 0.7121 (0.7118) Acc D Fake: 67.444%
Loss D: 1.155
Loss G: 0.6771 (0.6774) Acc G: 32.111%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3465 (0.3782) Acc D Real: 65.020%
Loss D Fake: 0.7123 (0.7119) Acc D Fake: 67.396%
Loss D: 1.059
Loss G: 0.6770 (0.6774) Acc G: 32.083%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.4217 (0.3807) Acc D Real: 64.770%
Loss D Fake: 0.7124 (0.7119) Acc D Fake: 67.353%
Loss D: 1.134
Loss G: 0.6767 (0.6774) Acc G: 32.157%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3701 (0.3801) Acc D Real: 64.933%
Loss D Fake: 0.7128 (0.7120) Acc D Fake: 67.315%
Loss D: 1.083
Loss G: 0.6764 (0.6773) Acc G: 32.222%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3469 (0.3784) Acc D Real: 65.197%
Loss D Fake: 0.7130 (0.7120) Acc D Fake: 67.281%
Loss D: 1.060
Loss G: 0.6763 (0.6773) Acc G: 32.281%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3970 (0.3793) Acc D Real: 65.344%
Loss D Fake: 0.7131 (0.7121) Acc D Fake: 67.250%
Loss D: 1.110
Loss G: 0.6762 (0.6772) Acc G: 32.333%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.2992 (0.3755) Acc D Real: 65.801%
Loss D Fake: 0.7131 (0.7121) Acc D Fake: 67.222%
Loss D: 1.012
Loss G: 0.6764 (0.6772) Acc G: 32.381%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.3041 (0.3723) Acc D Real: 66.233%
Loss D Fake: 0.7127 (0.7121) Acc D Fake: 67.197%
Loss D: 1.017
Loss G: 0.6770 (0.6772) Acc G: 32.424%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3072 (0.3694) Acc D Real: 66.558%
Loss D Fake: 0.7118 (0.7121) Acc D Fake: 67.246%
Loss D: 1.019
Loss G: 0.6780 (0.6772) Acc G: 32.391%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3916 (0.3704) Acc D Real: 66.382%
Loss D Fake: 0.7108 (0.7121) Acc D Fake: 67.292%
Loss D: 1.102
Loss G: 0.6788 (0.6773) Acc G: 32.361%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4397 (0.3731) Acc D Real: 66.094%
Loss D Fake: 0.7103 (0.7120) Acc D Fake: 67.333%
Loss D: 1.150
Loss G: 0.6791 (0.6773) Acc G: 32.333%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3595 (0.3726) Acc D Real: 66.030%
Loss D Fake: 0.7102 (0.7119) Acc D Fake: 67.372%
Loss D: 1.070
Loss G: 0.6792 (0.6774) Acc G: 32.308%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3082 (0.3702) Acc D Real: 66.360%
Loss D Fake: 0.7099 (0.7119) Acc D Fake: 67.407%
Loss D: 1.018
Loss G: 0.6796 (0.6775) Acc G: 32.222%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.3889 (0.3709) Acc D Real: 66.326%
Loss D Fake: 0.7094 (0.7118) Acc D Fake: 67.500%
Loss D: 1.098
Loss G: 0.6801 (0.6776) Acc G: 32.143%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.4041 (0.3720) Acc D Real: 66.097%
Loss D Fake: 0.7091 (0.7117) Acc D Fake: 67.586%
Loss D: 1.113
Loss G: 0.6802 (0.6777) Acc G: 32.069%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3116 (0.3700) Acc D Real: 66.278%
Loss D Fake: 0.7089 (0.7116) Acc D Fake: 67.667%
Loss D: 1.021
Loss G: 0.6806 (0.6778) Acc G: 32.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.3829 (0.3704) Acc D Real: 66.240%
Loss D Fake: 0.7084 (0.7115) Acc D Fake: 67.742%
Loss D: 1.091
Loss G: 0.6810 (0.6779) Acc G: 31.935%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3844 (0.3709) Acc D Real: 66.180%
Loss D Fake: 0.7081 (0.7114) Acc D Fake: 67.812%
Loss D: 1.093
Loss G: 0.6812 (0.6780) Acc G: 31.875%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3927 (0.3715) Acc D Real: 66.053%
Loss D Fake: 0.7080 (0.7113) Acc D Fake: 67.879%
Loss D: 1.101
Loss G: 0.6812 (0.6781) Acc G: 31.818%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.4282 (0.3732) Acc D Real: 65.780%
Loss D Fake: 0.7081 (0.7112) Acc D Fake: 67.941%
Loss D: 1.136
Loss G: 0.6809 (0.6782) Acc G: 31.765%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.3078 (0.3713) Acc D Real: 65.988%
Loss D Fake: 0.7084 (0.7111) Acc D Fake: 68.000%
Loss D: 1.016
Loss G: 0.6809 (0.6782) Acc G: 31.714%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3422 (0.3705) Acc D Real: 66.068%
Loss D Fake: 0.7082 (0.7110) Acc D Fake: 68.056%
Loss D: 1.050
Loss G: 0.6811 (0.6783) Acc G: 31.667%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.3167 (0.3691) Acc D Real: 66.223%
Loss D Fake: 0.7078 (0.7109) Acc D Fake: 68.108%
Loss D: 1.025
Loss G: 0.6817 (0.6784) Acc G: 31.622%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.2973 (0.3672) Acc D Real: 66.357%
Loss D Fake: 0.7070 (0.7108) Acc D Fake: 68.158%
Loss D: 1.004
Loss G: 0.6827 (0.6785) Acc G: 31.579%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3254 (0.3661) Acc D Real: 66.433%
Loss D Fake: 0.7060 (0.7107) Acc D Fake: 68.205%
Loss D: 1.031
Loss G: 0.6838 (0.6787) Acc G: 31.496%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.3212 (0.3650) Acc D Real: 66.509%
Loss D Fake: 0.7048 (0.7106) Acc D Fake: 68.292%
Loss D: 1.026
Loss G: 0.6850 (0.6788) Acc G: 31.417%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3991 (0.3658) Acc D Real: 66.331%
Loss D Fake: 0.7036 (0.7104) Acc D Fake: 68.374%
Loss D: 1.103
Loss G: 0.6859 (0.6790) Acc G: 31.341%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.4027 (0.3667) Acc D Real: 66.166%
Loss D Fake: 0.7030 (0.7102) Acc D Fake: 68.452%
Loss D: 1.106
Loss G: 0.6864 (0.6792) Acc G: 31.270%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.3112 (0.3654) Acc D Real: 66.271%
Loss D Fake: 0.7025 (0.7100) Acc D Fake: 68.527%
Loss D: 1.014
Loss G: 0.6870 (0.6793) Acc G: 31.202%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.4296 (0.3669) Acc D Real: 66.050%
Loss D Fake: 0.7019 (0.7099) Acc D Fake: 68.598%
Loss D: 1.132
Loss G: 0.6873 (0.6795) Acc G: 31.136%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3947 (0.3675) Acc D Real: 65.918%
Loss D Fake: 0.7018 (0.7097) Acc D Fake: 68.667%
Loss D: 1.097
Loss G: 0.6873 (0.6797) Acc G: 31.074%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.3620 (0.3674) Acc D Real: 65.851%
Loss D Fake: 0.7019 (0.7095) Acc D Fake: 68.732%
Loss D: 1.064
Loss G: 0.6872 (0.6799) Acc G: 31.014%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3796 (0.3676) Acc D Real: 65.769%
Loss D Fake: 0.7020 (0.7093) Acc D Fake: 68.794%
Loss D: 1.082
Loss G: 0.6871 (0.6800) Acc G: 30.957%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3412 (0.3671) Acc D Real: 65.789%
Loss D Fake: 0.7021 (0.7092) Acc D Fake: 68.854%
Loss D: 1.043
Loss G: 0.6870 (0.6802) Acc G: 30.903%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.3824 (0.3674) Acc D Real: 65.757%
Loss D Fake: 0.7022 (0.7091) Acc D Fake: 68.912%
Loss D: 1.085
Loss G: 0.6868 (0.6803) Acc G: 30.850%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3225 (0.3665) Acc D Real: 65.838%
Loss D Fake: 0.7023 (0.7089) Acc D Fake: 68.967%
Loss D: 1.025
Loss G: 0.6869 (0.6804) Acc G: 30.800%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.3597 (0.3664) Acc D Real: 65.843%
Loss D Fake: 0.7021 (0.7088) Acc D Fake: 69.020%
Loss D: 1.062
Loss G: 0.6871 (0.6806) Acc G: 30.752%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3766 (0.3665) Acc D Real: 65.744%
Loss D Fake: 0.7020 (0.7087) Acc D Fake: 69.071%
Loss D: 1.079
Loss G: 0.6871 (0.6807) Acc G: 30.705%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.3414 (0.3661) Acc D Real: 65.792%
Loss D Fake: 0.7019 (0.7085) Acc D Fake: 69.117%
Loss D: 1.043
Loss G: 0.6873 (0.6808) Acc G: 30.660%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3885 (0.3665) Acc D Real: 65.715%
Loss D Fake: 0.7018 (0.7084) Acc D Fake: 69.133%
Loss D: 1.090
Loss G: 0.6873 (0.6809) Acc G: 30.648%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.4621 (0.3682) Acc D Real: 65.444%
Loss D Fake: 0.7019 (0.7083) Acc D Fake: 69.149%
Loss D: 1.164
Loss G: 0.6868 (0.6810) Acc G: 30.636%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3630 (0.3681) Acc D Real: 65.425%
Loss D Fake: 0.7026 (0.7082) Acc D Fake: 69.164%
Loss D: 1.066
Loss G: 0.6862 (0.6811) Acc G: 30.625%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.3267 (0.3674) Acc D Real: 65.458%
Loss D Fake: 0.7031 (0.7081) Acc D Fake: 69.179%
Loss D: 1.030
Loss G: 0.6858 (0.6812) Acc G: 30.614%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3171 (0.3665) Acc D Real: 65.514%
Loss D Fake: 0.7033 (0.7080) Acc D Fake: 69.193%
Loss D: 1.020
Loss G: 0.6858 (0.6813) Acc G: 30.603%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.4005 (0.3671) Acc D Real: 65.400%
Loss D Fake: 0.7033 (0.7079) Acc D Fake: 69.206%
Loss D: 1.104
Loss G: 0.6856 (0.6814) Acc G: 30.593%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.3672 (0.3671) Acc D Real: 65.387%
Loss D Fake: 0.7035 (0.7079) Acc D Fake: 69.220%
Loss D: 1.071
Loss G: 0.6854 (0.6814) Acc G: 30.583%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.4786 (0.3689) Acc D Real: 65.098%
Loss D Fake: 0.7040 (0.7078) Acc D Fake: 69.232%
Loss D: 1.183
Loss G: 0.6844 (0.6815) Acc G: 30.574%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.2578 (0.3672) Acc D Real: 65.299%
Loss D Fake: 0.7049 (0.7077) Acc D Fake: 69.218%
Loss D: 0.963
Loss G: 0.6840 (0.6815) Acc G: 30.565%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.2671 (0.3656) Acc D Real: 65.460%
Loss D Fake: 0.7049 (0.7077) Acc D Fake: 69.204%
Loss D: 0.972
Loss G: 0.6843 (0.6816) Acc G: 30.556%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3507 (0.3653) Acc D Real: 65.467%
Loss D Fake: 0.7044 (0.7077) Acc D Fake: 69.190%
Loss D: 1.055
Loss G: 0.6848 (0.6816) Acc G: 30.547%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.4390 (0.3665) Acc D Real: 65.284%
Loss D Fake: 0.7041 (0.7076) Acc D Fake: 69.177%
Loss D: 1.143
Loss G: 0.6847 (0.6817) Acc G: 30.544%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.2978 (0.3654) Acc D Real: 65.415%
Loss D Fake: 0.7042 (0.7075) Acc D Fake: 69.164%
Loss D: 1.002
Loss G: 0.6849 (0.6817) Acc G: 30.561%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.3665 (0.3654) Acc D Real: 65.410%
Loss D Fake: 0.7039 (0.7075) Acc D Fake: 69.152%
Loss D: 1.070
Loss G: 0.6852 (0.6818) Acc G: 30.578%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.4229 (0.3663) Acc D Real: 65.276%
Loss D Fake: 0.7038 (0.7074) Acc D Fake: 69.140%
Loss D: 1.127
Loss G: 0.6850 (0.6818) Acc G: 30.594%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3041 (0.3654) Acc D Real: 65.347%
Loss D Fake: 0.7040 (0.7074) Acc D Fake: 69.128%
Loss D: 1.008
Loss G: 0.6850 (0.6819) Acc G: 30.609%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.4395 (0.3664) Acc D Real: 65.193%
Loss D Fake: 0.7040 (0.7073) Acc D Fake: 69.117%
Loss D: 1.144
Loss G: 0.6847 (0.6819) Acc G: 30.624%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.3658 (0.3664) Acc D Real: 65.187%
Loss D Fake: 0.7045 (0.7073) Acc D Fake: 69.106%
Loss D: 1.070
Loss G: 0.6842 (0.6819) Acc G: 30.639%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3888 (0.3667) Acc D Real: 65.129%
Loss D Fake: 0.7050 (0.7073) Acc D Fake: 69.095%
Loss D: 1.094
Loss G: 0.6837 (0.6820) Acc G: 30.653%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3066 (0.3659) Acc D Real: 65.233%
Loss D Fake: 0.7054 (0.7072) Acc D Fake: 69.085%
Loss D: 1.012
Loss G: 0.6835 (0.6820) Acc G: 30.667%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.4218 (0.3667) Acc D Real: 65.110%
Loss D Fake: 0.7056 (0.7072) Acc D Fake: 69.074%
Loss D: 1.127
Loss G: 0.6830 (0.6820) Acc G: 30.681%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3572 (0.3666) Acc D Real: 65.097%
Loss D Fake: 0.7061 (0.7072) Acc D Fake: 69.065%
Loss D: 1.063
Loss G: 0.6825 (0.6820) Acc G: 30.694%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.2868 (0.3655) Acc D Real: 65.221%
Loss D Fake: 0.7065 (0.7072) Acc D Fake: 69.033%
Loss D: 0.993
Loss G: 0.6824 (0.6820) Acc G: 30.728%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.3703 (0.3656) Acc D Real: 65.212%
Loss D Fake: 0.7064 (0.7072) Acc D Fake: 69.002%
Loss D: 1.077
Loss G: 0.6825 (0.6820) Acc G: 30.762%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3056 (0.3648) Acc D Real: 65.317%
Loss D Fake: 0.7062 (0.7072) Acc D Fake: 68.972%
Loss D: 1.012
Loss G: 0.6828 (0.6820) Acc G: 30.795%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.3955 (0.3652) Acc D Real: 65.251%
Loss D Fake: 0.7059 (0.7072) Acc D Fake: 68.943%
Loss D: 1.101
Loss G: 0.6829 (0.6820) Acc G: 30.827%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.3643 (0.3652) Acc D Real: 65.247%
Loss D Fake: 0.7059 (0.7071) Acc D Fake: 68.915%
Loss D: 1.070
Loss G: 0.6829 (0.6820) Acc G: 30.858%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.3740 (0.3653) Acc D Real: 65.218%
Loss D Fake: 0.7059 (0.7071) Acc D Fake: 68.887%
Loss D: 1.080
Loss G: 0.6828 (0.6820) Acc G: 30.889%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.3147 (0.3647) Acc D Real: 65.259%
Loss D Fake: 0.7059 (0.7071) Acc D Fake: 68.860%
Loss D: 1.021
Loss G: 0.6829 (0.6821) Acc G: 30.918%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.2878 (0.3637) Acc D Real: 65.352%
Loss D Fake: 0.7057 (0.7071) Acc D Fake: 68.833%
Loss D: 0.993
Loss G: 0.6834 (0.6821) Acc G: 30.948%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.4018 (0.3642) Acc D Real: 65.297%
Loss D Fake: 0.7052 (0.7071) Acc D Fake: 68.808%
Loss D: 1.107
Loss G: 0.6836 (0.6821) Acc G: 30.976%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.4424 (0.3651) Acc D Real: 65.159%
Loss D Fake: 0.7053 (0.7071) Acc D Fake: 68.782%
Loss D: 1.148
Loss G: 0.6832 (0.6821) Acc G: 31.004%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3801 (0.3653) Acc D Real: 65.137%
Loss D Fake: 0.7059 (0.7070) Acc D Fake: 68.758%
Loss D: 1.086
Loss G: 0.6825 (0.6821) Acc G: 31.031%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.2716 (0.3642) Acc D Real: 65.284%
Loss D Fake: 0.7064 (0.7070) Acc D Fake: 68.734%
Loss D: 0.978
Loss G: 0.6824 (0.6821) Acc G: 31.057%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.4799 (0.3655) Acc D Real: 65.115%
Loss D Fake: 0.7065 (0.7070) Acc D Fake: 68.710%
Loss D: 1.186
Loss G: 0.6818 (0.6821) Acc G: 31.096%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.3312 (0.3651) Acc D Real: 65.156%
Loss D Fake: 0.7072 (0.7070) Acc D Fake: 68.669%
Loss D: 1.038
Loss G: 0.6812 (0.6821) Acc G: 31.140%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.3656 (0.3651) Acc D Real: 65.157%
Loss D Fake: 0.7077 (0.7070) Acc D Fake: 68.628%
Loss D: 1.073
Loss G: 0.6808 (0.6821) Acc G: 31.183%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.3087 (0.3645) Acc D Real: 65.221%
Loss D Fake: 0.7080 (0.7070) Acc D Fake: 68.588%
Loss D: 1.017
Loss G: 0.6806 (0.6821) Acc G: 31.225%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3757 (0.3646) Acc D Real: 65.183%
Loss D Fake: 0.7081 (0.7071) Acc D Fake: 68.549%
Loss D: 1.084
Loss G: 0.6804 (0.6821) Acc G: 31.266%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.3256 (0.3642) Acc D Real: 65.223%
Loss D Fake: 0.7083 (0.7071) Acc D Fake: 68.511%
Loss D: 1.034
Loss G: 0.6804 (0.6820) Acc G: 31.306%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.3024 (0.3636) Acc D Real: 65.288%
Loss D Fake: 0.7082 (0.7071) Acc D Fake: 68.456%
Loss D: 1.011
Loss G: 0.6806 (0.6820) Acc G: 31.345%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.4619 (0.3646) Acc D Real: 65.156%
Loss D Fake: 0.7081 (0.7071) Acc D Fake: 68.402%
Loss D: 1.170
Loss G: 0.6802 (0.6820) Acc G: 31.401%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3852 (0.3648) Acc D Real: 65.117%
Loss D Fake: 0.7087 (0.7071) Acc D Fake: 68.349%
Loss D: 1.094
Loss G: 0.6796 (0.6820) Acc G: 31.456%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3873 (0.3651) Acc D Real: 65.082%
Loss D Fake: 0.7094 (0.7071) Acc D Fake: 68.297%
Loss D: 1.097
Loss G: 0.6788 (0.6819) Acc G: 31.510%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3445 (0.3648) Acc D Real: 65.113%
Loss D Fake: 0.7102 (0.7072) Acc D Fake: 68.230%
Loss D: 1.055
Loss G: 0.6781 (0.6819) Acc G: 31.580%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.3623 (0.3648) Acc D Real: 65.132%
Loss D Fake: 0.7108 (0.7072) Acc D Fake: 68.163%
Loss D: 1.073
Loss G: 0.6775 (0.6819) Acc G: 31.648%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.2706 (0.3639) Acc D Real: 65.247%
Loss D Fake: 0.7112 (0.7072) Acc D Fake: 68.082%
Loss D: 0.982
Loss G: 0.6774 (0.6818) Acc G: 31.730%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3468 (0.3637) Acc D Real: 65.275%
Loss D Fake: 0.7112 (0.7073) Acc D Fake: 68.002%
Loss D: 1.058
Loss G: 0.6774 (0.6818) Acc G: 31.812%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.4185 (0.3642) Acc D Real: 65.210%
Loss D Fake: 0.7112 (0.7073) Acc D Fake: 67.923%
Loss D: 1.130
Loss G: 0.6771 (0.6817) Acc G: 31.892%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.2456 (0.3631) Acc D Real: 65.345%
Loss D Fake: 0.7115 (0.7074) Acc D Fake: 67.846%
Loss D: 0.957
Loss G: 0.6771 (0.6817) Acc G: 31.971%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3571 (0.3630) Acc D Real: 65.344%
Loss D Fake: 0.7113 (0.7074) Acc D Fake: 67.755%
Loss D: 1.068
Loss G: 0.6772 (0.6816) Acc G: 32.048%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3756 (0.3632) Acc D Real: 65.327%
Loss D Fake: 0.7113 (0.7074) Acc D Fake: 67.665%
Loss D: 1.087
Loss G: 0.6770 (0.6816) Acc G: 32.139%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.3934 (0.3634) Acc D Real: 65.294%
Loss D Fake: 0.7116 (0.7075) Acc D Fake: 67.561%
Loss D: 1.105
Loss G: 0.6765 (0.6815) Acc G: 32.245%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3208 (0.3630) Acc D Real: 65.339%
Loss D Fake: 0.7122 (0.7075) Acc D Fake: 67.460%
Loss D: 1.033
Loss G: 0.6760 (0.6815) Acc G: 32.349%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.4191 (0.3636) Acc D Real: 65.271%
Loss D Fake: 0.7129 (0.7076) Acc D Fake: 67.344%
Loss D: 1.132
Loss G: 0.6751 (0.6814) Acc G: 32.481%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3132 (0.3631) Acc D Real: 65.313%
Loss D Fake: 0.7139 (0.7076) Acc D Fake: 67.200%
Loss D: 1.027
Loss G: 0.6742 (0.6814) Acc G: 32.627%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3917 (0.3634) Acc D Real: 65.342%
Loss D Fake: 0.7150 (0.7077) Acc D Fake: 67.029%
Loss D: 1.107
Loss G: 0.6729 (0.6813) Acc G: 32.815%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.3740 (0.3635) Acc D Real: 65.362%
Loss D Fake: 0.7169 (0.7078) Acc D Fake: 66.770%
Loss D: 1.091
Loss G: 0.6711 (0.6812) Acc G: 33.138%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3909 (0.3637) Acc D Real: 65.436%
Loss D Fake: 2.5470 (0.7242) Acc D Fake: 66.174%
Loss D: 2.938
Loss G: 0.6717 (0.6811) Acc G: 33.735%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3927 (0.3640) Acc D Real: 65.724%
Loss D Fake: 0.7174 (0.7241) Acc D Fake: 65.589%
Loss D: 1.110
Loss G: 0.6702 (0.6810) Acc G: 34.322%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.3001 (0.3634) Acc D Real: 66.023%
Loss D Fake: 0.7193 (0.7241) Acc D Fake: 65.013%
Loss D: 1.019
Loss G: 0.6685 (0.6809) Acc G: 34.898%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3778 (0.3635) Acc D Real: 66.318%
Loss D Fake: 0.7209 (0.7241) Acc D Fake: 64.448%
Loss D: 1.099
Loss G: 0.6671 (0.6808) Acc G: 35.464%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.2963 (0.3629) Acc D Real: 66.608%
Loss D Fake: 0.7223 (0.7240) Acc D Fake: 63.892%
Loss D: 1.019
Loss G: 0.6661 (0.6807) Acc G: 36.020%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.5230 (0.3643) Acc D Real: 66.892%
Loss D Fake: 0.7235 (0.7240) Acc D Fake: 63.346%
Loss D: 1.246
Loss G: 0.6645 (0.6805) Acc G: 36.567%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3331 (0.3640) Acc D Real: 67.172%
Loss D Fake: 0.7252 (0.7241) Acc D Fake: 62.809%
Loss D: 1.058
Loss G: 0.6631 (0.6804) Acc G: 37.105%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.2969 (0.3635) Acc D Real: 67.447%
Loss D Fake: 0.7263 (0.7241) Acc D Fake: 62.282%
Loss D: 1.023
Loss G: 0.6624 (0.6802) Acc G: 37.633%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.4635 (0.3643) Acc D Real: 67.717%
Loss D Fake: 0.7271 (0.7241) Acc D Fake: 61.763%
Loss D: 1.191
Loss G: 0.6615 (0.6801) Acc G: 38.153%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.4423 (0.3650) Acc D Real: 67.984%
Loss D Fake: 0.7283 (0.7241) Acc D Fake: 61.252%
Loss D: 1.171
Loss G: 0.6602 (0.6799) Acc G: 38.664%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.4241 (0.3654) Acc D Real: 68.246%
Loss D Fake: 0.7298 (0.7242) Acc D Fake: 60.750%
Loss D: 1.154
Loss G: 0.6587 (0.6797) Acc G: 39.167%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.4036 (0.3658) Acc D Real: 68.504%
Loss D Fake: 0.7314 (0.7242) Acc D Fake: 60.256%
Loss D: 1.135
Loss G: 0.6573 (0.6795) Acc G: 39.661%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.4259 (0.3662) Acc D Real: 68.758%
Loss D Fake: 0.7329 (0.7243) Acc D Fake: 59.770%
Loss D: 1.159
Loss G: 0.6557 (0.6794) Acc G: 40.148%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.2710 (0.3655) Acc D Real: 69.007%
Loss D Fake: 0.7344 (0.7244) Acc D Fake: 59.292%
Loss D: 1.005
Loss G: 0.6549 (0.6792) Acc G: 40.627%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.4405 (0.3661) Acc D Real: 69.252%
Loss D Fake: 0.7351 (0.7245) Acc D Fake: 58.822%
Loss D: 1.176
Loss G: 0.6541 (0.6790) Acc G: 41.098%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3944 (0.3663) Acc D Real: 69.494%
Loss D Fake: 0.7361 (0.7246) Acc D Fake: 58.358%
Loss D: 1.130
Loss G: 0.6531 (0.6788) Acc G: 41.562%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3845 (0.3664) Acc D Real: 69.732%
Loss D Fake: 0.7370 (0.7247) Acc D Fake: 57.902%
Loss D: 1.122
Loss G: 0.6523 (0.6785) Acc G: 42.018%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3971 (0.3667) Acc D Real: 69.967%
Loss D Fake: 0.7379 (0.7248) Acc D Fake: 57.454%
Loss D: 1.135
Loss G: 0.6514 (0.6783) Acc G: 42.468%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4729 (0.3675) Acc D Real: 70.198%
Loss D Fake: 0.7390 (0.7249) Acc D Fake: 57.012%
Loss D: 1.212
Loss G: 0.6502 (0.6781) Acc G: 42.910%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3599 (0.3674) Acc D Real: 70.425%
Loss D Fake: 0.7404 (0.7250) Acc D Fake: 56.576%
Loss D: 1.100
Loss G: 0.6491 (0.6779) Acc G: 43.346%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4333 (0.3679) Acc D Real: 70.648%
Loss D Fake: 0.7416 (0.7251) Acc D Fake: 56.148%
Loss D: 1.175
Loss G: 0.6479 (0.6777) Acc G: 43.775%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3744 (0.3680) Acc D Real: 70.869%
Loss D Fake: 0.7429 (0.7253) Acc D Fake: 55.726%
Loss D: 1.117
Loss G: 0.6468 (0.6774) Acc G: 44.198%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.4682 (0.3687) Acc D Real: 71.086%
Loss D Fake: 0.7442 (0.7254) Acc D Fake: 55.310%
Loss D: 1.212
Loss G: 0.6453 (0.6772) Acc G: 44.614%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.3969 (0.3689) Acc D Real: 71.299%
Loss D Fake: 0.7459 (0.7255) Acc D Fake: 54.900%
Loss D: 1.143
Loss G: 0.6439 (0.6770) Acc G: 45.025%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.3403 (0.3687) Acc D Real: 71.510%
Loss D Fake: 0.7473 (0.7257) Acc D Fake: 54.496%
Loss D: 1.088
Loss G: 0.6428 (0.6767) Acc G: 45.429%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.4033 (0.3690) Acc D Real: 71.718%
Loss D Fake: 0.7484 (0.7259) Acc D Fake: 54.099%
Loss D: 1.152
Loss G: 0.6417 (0.6764) Acc G: 45.827%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.4644 (0.3697) Acc D Real: 71.923%
Loss D Fake: 0.7497 (0.7260) Acc D Fake: 53.707%
Loss D: 1.214
Loss G: 0.6404 (0.6762) Acc G: 46.220%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3912 (0.3698) Acc D Real: 72.124%
Loss D Fake: 0.7513 (0.7262) Acc D Fake: 53.320%
Loss D: 1.143
Loss G: 0.6390 (0.6759) Acc G: 46.607%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.3177 (0.3695) Acc D Real: 72.323%
Loss D Fake: 0.7525 (0.7264) Acc D Fake: 52.939%
Loss D: 1.070
Loss G: 0.6383 (0.6756) Acc G: 46.988%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3207 (0.3691) Acc D Real: 72.520%
Loss D Fake: 0.7531 (0.7266) Acc D Fake: 52.564%
Loss D: 1.074
Loss G: 0.6381 (0.6754) Acc G: 47.364%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.4252 (0.3695) Acc D Real: 72.713%
Loss D Fake: 0.7532 (0.7268) Acc D Fake: 52.194%
Loss D: 1.178
Loss G: 0.6378 (0.6751) Acc G: 47.735%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.3191 (0.3692) Acc D Real: 72.904%
Loss D Fake: 0.7536 (0.7270) Acc D Fake: 51.829%
Loss D: 1.073
Loss G: 0.6377 (0.6749) Acc G: 48.100%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3319 (0.3689) Acc D Real: 73.092%
Loss D Fake: 0.7534 (0.7272) Acc D Fake: 51.469%
Loss D: 1.085
Loss G: 0.6379 (0.6746) Acc G: 48.461%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4068 (0.3692) Acc D Real: 73.277%
Loss D Fake: 0.7532 (0.7273) Acc D Fake: 51.114%
Loss D: 1.160
Loss G: 0.6380 (0.6743) Acc G: 48.816%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.2995 (0.3687) Acc D Real: 73.460%
Loss D Fake: 0.7530 (0.7275) Acc D Fake: 50.764%
Loss D: 1.052
Loss G: 0.6384 (0.6741) Acc G: 49.167%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3490 (0.3685) Acc D Real: 73.640%
Loss D Fake: 0.7524 (0.7277) Acc D Fake: 50.418%
Loss D: 1.101
Loss G: 0.6390 (0.6739) Acc G: 49.512%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3934 (0.3687) Acc D Real: 73.818%
Loss D Fake: 0.7517 (0.7278) Acc D Fake: 50.078%
Loss D: 1.145
Loss G: 0.6395 (0.6736) Acc G: 49.854%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.4072 (0.3690) Acc D Real: 73.993%
Loss D Fake: 0.7514 (0.7280) Acc D Fake: 49.742%
Loss D: 1.159
Loss G: 0.6396 (0.6734) Acc G: 50.190%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3365 (0.3688) Acc D Real: 74.166%
Loss D Fake: 0.7513 (0.7282) Acc D Fake: 49.410%
Loss D: 1.088
Loss G: 0.6398 (0.6732) Acc G: 50.522%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.3425 (0.3686) Acc D Real: 74.337%
Loss D Fake: 0.7510 (0.7283) Acc D Fake: 49.083%
Loss D: 1.093
Loss G: 0.6402 (0.6730) Acc G: 50.850%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.4121 (0.3689) Acc D Real: 74.506%
Loss D Fake: 0.7506 (0.7285) Acc D Fake: 48.760%
Loss D: 1.163
Loss G: 0.6404 (0.6727) Acc G: 51.173%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3647 (0.3688) Acc D Real: 74.673%
Loss D Fake: 0.7504 (0.7286) Acc D Fake: 48.441%
Loss D: 1.115
Loss G: 0.6405 (0.6725) Acc G: 51.492%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.4102 (0.3691) Acc D Real: 74.836%
Loss D Fake: 0.7503 (0.7287) Acc D Fake: 48.127%
Loss D: 1.160
Loss G: 0.6405 (0.6723) Acc G: 51.807%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3715 (0.3691) Acc D Real: 74.998%
Loss D Fake: 0.7504 (0.7289) Acc D Fake: 47.816%
Loss D: 1.122
Loss G: 0.6404 (0.6721) Acc G: 52.118%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.3760 (0.3692) Acc D Real: 75.159%
Loss D Fake: 0.7505 (0.7290) Acc D Fake: 47.510%
Loss D: 1.127
Loss G: 0.6403 (0.6719) Acc G: 52.425%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4957 (0.3700) Acc D Real: 75.317%
Loss D Fake: 0.7509 (0.7292) Acc D Fake: 47.207%
Loss D: 1.247
Loss G: 0.6395 (0.6717) Acc G: 52.728%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2512 (0.3692) Acc D Real: 75.332%
Loss D Fake: 0.7516 (0.7293) Acc D Fake: 47.179%
Loss D: 1.003
Loss G: 0.6393 (0.6715) Acc G: 52.756%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.845 | Generator Loss: 0.639 | Avg: 1.485
TEST [21/180]: Discriminator Loss: 0.939 | Generator Loss: 0.639 | Avg: 1.579
TEST [31/180]: Discriminator Loss: 0.914 | Generator Loss: 0.639 | Avg: 1.553
TEST [41/180]: Discriminator Loss: 0.889 | Generator Loss: 0.639 | Avg: 1.528
TEST [51/180]: Discriminator Loss: 0.890 | Generator Loss: 0.639 | Avg: 1.529
TEST [61/180]: Discriminator Loss: 0.933 | Generator Loss: 0.639 | Avg: 1.572
TEST [71/180]: Discriminator Loss: 0.962 | Generator Loss: 0.639 | Avg: 1.602
TEST [81/180]: Discriminator Loss: 1.003 | Generator Loss: 0.639 | Avg: 1.642
TEST [91/180]: Discriminator Loss: 1.027 | Generator Loss: 0.639 | Avg: 1.666
TEST [101/180]: Discriminator Loss: 1.062 | Generator Loss: 0.639 | Avg: 1.702
TEST [111/180]: Discriminator Loss: 1.090 | Generator Loss: 0.639 | Avg: 1.730
TEST [121/180]: Discriminator Loss: 1.115 | Generator Loss: 0.639 | Avg: 1.754
TEST [131/180]: Discriminator Loss: 1.136 | Generator Loss: 0.639 | Avg: 1.775
TEST [141/180]: Discriminator Loss: 1.152 | Generator Loss: 0.639 | Avg: 1.791
TEST [151/180]: Discriminator Loss: 1.140 | Generator Loss: 0.639 | Avg: 1.779
TEST [161/180]: Discriminator Loss: 1.127 | Generator Loss: 0.639 | Avg: 1.766
TEST [171/180]: Discriminator Loss: 1.113 | Generator Loss: 0.639 | Avg: 1.753
Epoch: 20/20
TRAIN Iteration: [   2/158]
Loss D Real: 0.3939 (0.3941) Acc D Real: 100.000%
Loss D Fake: 0.7518 (0.7517) Acc D Fake: 0.000%
Loss D: 1.146
Loss G: 0.6391 (0.6392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/158]
Loss D Real: 0.3385 (0.3756) Acc D Real: 100.000%
Loss D Fake: 0.7520 (0.7518) Acc D Fake: 0.000%
Loss D: 1.090
Loss G: 0.6391 (0.6391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/158]
Loss D Real: 0.2320 (0.3397) Acc D Real: 100.000%
Loss D Fake: 0.7516 (0.7517) Acc D Fake: 0.000%
Loss D: 0.984
Loss G: 0.6399 (0.6393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/158]
Loss D Real: 0.3918 (0.3501) Acc D Real: 100.000%
Loss D Fake: 0.7505 (0.7515) Acc D Fake: 0.000%
Loss D: 1.142
Loss G: 0.6407 (0.6396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/158]
Loss D Real: 0.3524 (0.3505) Acc D Real: 100.000%
Loss D Fake: 0.7497 (0.7512) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.6414 (0.6399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/158]
Loss D Real: 0.3867 (0.3556) Acc D Real: 100.000%
Loss D Fake: 0.7489 (0.7509) Acc D Fake: 0.000%
Loss D: 1.136
Loss G: 0.6420 (0.6402) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/158]
Loss D Real: 0.4078 (0.3622) Acc D Real: 99.993%
Loss D Fake: 0.7485 (0.7506) Acc D Fake: 0.000%
Loss D: 1.156
Loss G: 0.6422 (0.6405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/158]
Loss D Real: 0.3208 (0.3576) Acc D Real: 99.994%
Loss D Fake: 0.7483 (0.7503) Acc D Fake: 0.000%
Loss D: 1.069
Loss G: 0.6426 (0.6407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/158]
Loss D Real: 0.4903 (0.3708) Acc D Real: 99.995%
Loss D Fake: 0.7480 (0.7501) Acc D Fake: 0.000%
Loss D: 1.238
Loss G: 0.6423 (0.6409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/158]
Loss D Real: 0.4605 (0.3790) Acc D Real: 99.991%
Loss D Fake: 0.7487 (0.7500) Acc D Fake: 0.000%
Loss D: 1.209
Loss G: 0.6414 (0.6409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/158]
Loss D Real: 0.4104 (0.3816) Acc D Real: 99.991%
Loss D Fake: 0.7499 (0.7500) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6403 (0.6409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/158]
Loss D Real: 0.4430 (0.3863) Acc D Real: 99.988%
Loss D Fake: 0.7512 (0.7501) Acc D Fake: 0.000%
Loss D: 1.194
Loss G: 0.6390 (0.6407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/158]
Loss D Real: 0.3360 (0.3827) Acc D Real: 99.985%
Loss D Fake: 0.7527 (0.7502) Acc D Fake: 0.000%
Loss D: 1.089
Loss G: 0.6379 (0.6405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/158]
Loss D Real: 0.3492 (0.3805) Acc D Real: 99.986%
Loss D Fake: 0.7536 (0.7505) Acc D Fake: 0.000%
Loss D: 1.103
Loss G: 0.6372 (0.6403) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/158]
Loss D Real: 0.3224 (0.3769) Acc D Real: 99.987%
Loss D Fake: 0.7542 (0.7507) Acc D Fake: 0.000%
Loss D: 1.077
Loss G: 0.6370 (0.6401) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/158]
Loss D Real: 0.3893 (0.3776) Acc D Real: 99.985%
Loss D Fake: 0.7544 (0.7509) Acc D Fake: 0.000%
Loss D: 1.144
Loss G: 0.6367 (0.6399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/158]
Loss D Real: 0.3618 (0.3767) Acc D Real: 99.980%
Loss D Fake: 0.7546 (0.7511) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6366 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/158]
Loss D Real: 0.3721 (0.3765) Acc D Real: 99.978%
Loss D Fake: 0.7547 (0.7513) Acc D Fake: 0.000%
Loss D: 1.127
Loss G: 0.6365 (0.6395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/158]
Loss D Real: 0.3679 (0.3761) Acc D Real: 99.979%
Loss D Fake: 0.7548 (0.7515) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6364 (0.6394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/158]
Loss D Real: 0.2969 (0.3723) Acc D Real: 99.980%
Loss D Fake: 0.7547 (0.7516) Acc D Fake: 0.000%
Loss D: 1.052
Loss G: 0.6368 (0.6393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/158]
Loss D Real: 0.2707 (0.3677) Acc D Real: 99.979%
Loss D Fake: 0.7538 (0.7517) Acc D Fake: 0.000%
Loss D: 1.025
Loss G: 0.6379 (0.6392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/158]
Loss D Real: 0.3290 (0.3660) Acc D Real: 99.980%
Loss D Fake: 0.7525 (0.7518) Acc D Fake: 0.000%
Loss D: 1.082
Loss G: 0.6391 (0.6392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/158]
Loss D Real: 0.3629 (0.3659) Acc D Real: 99.980%
Loss D Fake: 0.7511 (0.7517) Acc D Fake: 0.000%
Loss D: 1.114
Loss G: 0.6403 (0.6392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/158]
Loss D Real: 0.4516 (0.3693) Acc D Real: 99.981%
Loss D Fake: 0.7501 (0.7517) Acc D Fake: 0.000%
Loss D: 1.202
Loss G: 0.6408 (0.6393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/158]
Loss D Real: 0.3346 (0.3680) Acc D Real: 99.980%
Loss D Fake: 0.7496 (0.7516) Acc D Fake: 0.000%
Loss D: 1.084
Loss G: 0.6413 (0.6394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/158]
Loss D Real: 0.3527 (0.3674) Acc D Real: 99.981%
Loss D Fake: 0.7490 (0.7515) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.6419 (0.6395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/158]
Loss D Real: 0.4125 (0.3690) Acc D Real: 99.980%
Loss D Fake: 0.7486 (0.7514) Acc D Fake: 0.000%
Loss D: 1.161
Loss G: 0.6421 (0.6396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/158]
Loss D Real: 0.4289 (0.3711) Acc D Real: 99.980%
Loss D Fake: 0.7486 (0.7513) Acc D Fake: 0.000%
Loss D: 1.177
Loss G: 0.6419 (0.6396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/158]
Loss D Real: 0.3981 (0.3720) Acc D Real: 99.977%
Loss D Fake: 0.7490 (0.7512) Acc D Fake: 0.000%
Loss D: 1.147
Loss G: 0.6414 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/158]
Loss D Real: 0.4575 (0.3747) Acc D Real: 99.978%
Loss D Fake: 0.7496 (0.7512) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.6405 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/158]
Loss D Real: 0.3668 (0.3745) Acc D Real: 99.977%
Loss D Fake: 0.7507 (0.7512) Acc D Fake: 0.000%
Loss D: 1.118
Loss G: 0.6396 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/158]
Loss D Real: 0.3583 (0.3740) Acc D Real: 99.978%
Loss D Fake: 0.7516 (0.7512) Acc D Fake: 0.000%
Loss D: 1.110
Loss G: 0.6389 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/158]
Loss D Real: 0.3980 (0.3747) Acc D Real: 99.977%
Loss D Fake: 0.7523 (0.7512) Acc D Fake: 0.000%
Loss D: 1.150
Loss G: 0.6383 (0.6397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/158]
Loss D Real: 0.4085 (0.3757) Acc D Real: 99.978%
Loss D Fake: 0.7531 (0.7513) Acc D Fake: 0.000%
Loss D: 1.162
Loss G: 0.6375 (0.6396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/158]
Loss D Real: 0.3907 (0.3761) Acc D Real: 99.975%
Loss D Fake: 0.7540 (0.7513) Acc D Fake: 0.000%
Loss D: 1.145
Loss G: 0.6367 (0.6395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/158]
Loss D Real: 0.4047 (0.3769) Acc D Real: 99.976%
Loss D Fake: 0.7550 (0.7514) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6358 (0.6394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/158]
Loss D Real: 0.4622 (0.3791) Acc D Real: 99.977%
Loss D Fake: 0.7562 (0.7516) Acc D Fake: 0.000%
Loss D: 1.218
Loss G: 0.6345 (0.6393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/158]
Loss D Real: 0.3317 (0.3779) Acc D Real: 99.976%
Loss D Fake: 0.7575 (0.7517) Acc D Fake: 0.000%
Loss D: 1.089
Loss G: 0.6336 (0.6391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/158]
Loss D Real: 0.4429 (0.3795) Acc D Real: 99.977%
Loss D Fake: 0.7585 (0.7519) Acc D Fake: 0.000%
Loss D: 1.201
Loss G: 0.6325 (0.6390) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/158]
Loss D Real: 0.3491 (0.3788) Acc D Real: 99.977%
Loss D Fake: 0.7597 (0.7521) Acc D Fake: 0.000%
Loss D: 1.109
Loss G: 0.6317 (0.6388) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/158]
Loss D Real: 0.3664 (0.3785) Acc D Real: 99.976%
Loss D Fake: 0.7606 (0.7523) Acc D Fake: 0.000%
Loss D: 1.127
Loss G: 0.6310 (0.6386) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/158]
Loss D Real: 0.4235 (0.3795) Acc D Real: 99.977%
Loss D Fake: 0.7613 (0.7525) Acc D Fake: 0.000%
Loss D: 1.185
Loss G: 0.6304 (0.6384) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/158]
Loss D Real: 0.3194 (0.3782) Acc D Real: 99.978%
Loss D Fake: 0.7619 (0.7527) Acc D Fake: 0.000%
Loss D: 1.081
Loss G: 0.6300 (0.6382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/158]
Loss D Real: 0.3824 (0.3783) Acc D Real: 99.978%
Loss D Fake: 0.7622 (0.7529) Acc D Fake: 0.000%
Loss D: 1.145
Loss G: 0.6298 (0.6380) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/158]
Loss D Real: 0.4692 (0.3802) Acc D Real: 99.978%
Loss D Fake: 0.7627 (0.7531) Acc D Fake: 0.000%
Loss D: 1.232
Loss G: 0.6290 (0.6379) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/158]
Loss D Real: 0.3105 (0.3787) Acc D Real: 99.979%
Loss D Fake: 0.7635 (0.7533) Acc D Fake: 0.000%
Loss D: 1.074
Loss G: 0.6286 (0.6377) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/158]
Loss D Real: 0.3568 (0.3783) Acc D Real: 99.979%
Loss D Fake: 0.7638 (0.7536) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.6284 (0.6375) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/158]
Loss D Real: 0.2958 (0.3766) Acc D Real: 99.980%
Loss D Fake: 0.7637 (0.7538) Acc D Fake: 0.000%
Loss D: 1.059
Loss G: 0.6288 (0.6373) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/158]
Loss D Real: 0.3871 (0.3768) Acc D Real: 99.980%
Loss D Fake: 0.7632 (0.7540) Acc D Fake: 0.000%
Loss D: 1.150
Loss G: 0.6291 (0.6371) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/158]
Loss D Real: 0.2932 (0.3752) Acc D Real: 99.981%
Loss D Fake: 0.7627 (0.7541) Acc D Fake: 0.000%
Loss D: 1.056
Loss G: 0.6298 (0.6370) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/158]
Loss D Real: 0.3644 (0.3750) Acc D Real: 99.981%
Loss D Fake: 0.7619 (0.7543) Acc D Fake: 0.000%
Loss D: 1.126
Loss G: 0.6304 (0.6369) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/158]
Loss D Real: 0.4719 (0.3768) Acc D Real: 99.981%
Loss D Fake: 0.7614 (0.7544) Acc D Fake: 0.000%
Loss D: 1.233
Loss G: 0.6305 (0.6367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/158]
Loss D Real: 0.3731 (0.3767) Acc D Real: 99.982%
Loss D Fake: 0.7616 (0.7545) Acc D Fake: 0.000%
Loss D: 1.135
Loss G: 0.6304 (0.6366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/158]
Loss D Real: 0.3352 (0.3760) Acc D Real: 99.979%
Loss D Fake: 0.7616 (0.7547) Acc D Fake: 0.000%
Loss D: 1.097
Loss G: 0.6305 (0.6365) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/158]
Loss D Real: 0.3319 (0.3752) Acc D Real: 99.980%
Loss D Fake: 0.7613 (0.7548) Acc D Fake: 0.000%
Loss D: 1.093
Loss G: 0.6308 (0.6364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/158]
Loss D Real: 0.4385 (0.3763) Acc D Real: 99.980%
Loss D Fake: 0.7610 (0.7549) Acc D Fake: 0.000%
Loss D: 1.200
Loss G: 0.6308 (0.6363) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/158]
Loss D Real: 0.3985 (0.3767) Acc D Real: 99.980%
Loss D Fake: 0.7613 (0.7550) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6305 (0.6362) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/158]
Loss D Real: 0.3447 (0.3761) Acc D Real: 99.981%
Loss D Fake: 0.7616 (0.7551) Acc D Fake: 0.000%
Loss D: 1.106
Loss G: 0.6303 (0.6361) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/158]
Loss D Real: 0.5042 (0.3783) Acc D Real: 99.981%
Loss D Fake: 0.7621 (0.7552) Acc D Fake: 0.000%
Loss D: 1.266
Loss G: 0.6295 (0.6360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/158]
Loss D Real: 0.2959 (0.3769) Acc D Real: 99.980%
Loss D Fake: 0.7630 (0.7554) Acc D Fake: 0.000%
Loss D: 1.059
Loss G: 0.6290 (0.6359) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/158]
Loss D Real: 0.3311 (0.3762) Acc D Real: 99.980%
Loss D Fake: 0.7632 (0.7555) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.6290 (0.6358) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/158]
Loss D Real: 0.3972 (0.3765) Acc D Real: 99.980%
Loss D Fake: 0.7632 (0.7556) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6289 (0.6357) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/158]
Loss D Real: 0.3419 (0.3760) Acc D Real: 99.980%
Loss D Fake: 0.7634 (0.7557) Acc D Fake: 0.000%
Loss D: 1.105
Loss G: 0.6289 (0.6355) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/158]
Loss D Real: 0.2930 (0.3747) Acc D Real: 99.980%
Loss D Fake: 0.7631 (0.7559) Acc D Fake: 0.000%
Loss D: 1.056
Loss G: 0.6293 (0.6355) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/158]
Loss D Real: 0.4356 (0.3756) Acc D Real: 99.980%
Loss D Fake: 0.7627 (0.7560) Acc D Fake: 0.000%
Loss D: 1.198
Loss G: 0.6294 (0.6354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/158]
Loss D Real: 0.4165 (0.3762) Acc D Real: 99.981%
Loss D Fake: 0.7628 (0.7561) Acc D Fake: 0.000%
Loss D: 1.179
Loss G: 0.6292 (0.6353) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/158]
Loss D Real: 0.3876 (0.3764) Acc D Real: 99.981%
Loss D Fake: 0.7631 (0.7562) Acc D Fake: 0.000%
Loss D: 1.151
Loss G: 0.6289 (0.6352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/158]
Loss D Real: 0.3353 (0.3758) Acc D Real: 99.981%
Loss D Fake: 0.7633 (0.7563) Acc D Fake: 0.000%
Loss D: 1.099
Loss G: 0.6288 (0.6351) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/158]
Loss D Real: 0.3965 (0.3761) Acc D Real: 99.981%
Loss D Fake: 0.7634 (0.7564) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.6287 (0.6350) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/158]
Loss D Real: 0.4041 (0.3765) Acc D Real: 99.982%
Loss D Fake: 0.7637 (0.7565) Acc D Fake: 0.000%
Loss D: 1.168
Loss G: 0.6284 (0.6349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/158]
Loss D Real: 0.3896 (0.3767) Acc D Real: 99.981%
Loss D Fake: 0.7641 (0.7566) Acc D Fake: 0.000%
Loss D: 1.154
Loss G: 0.6280 (0.6348) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/158]
Loss D Real: 0.3344 (0.3761) Acc D Real: 99.981%
Loss D Fake: 0.7645 (0.7567) Acc D Fake: 0.000%
Loss D: 1.099
Loss G: 0.6278 (0.6347) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/158]
Loss D Real: 0.2557 (0.3745) Acc D Real: 99.982%
Loss D Fake: 0.7643 (0.7568) Acc D Fake: 0.000%
Loss D: 1.020
Loss G: 0.6284 (0.6346) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/158]
Loss D Real: 0.3646 (0.3743) Acc D Real: 99.982%
Loss D Fake: 0.7634 (0.7569) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.6291 (0.6345) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/158]
Loss D Real: 0.3311 (0.3738) Acc D Real: 99.982%
Loss D Fake: 0.7626 (0.7569) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.6298 (0.6345) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/158]
Loss D Real: 0.4028 (0.3741) Acc D Real: 99.982%
Loss D Fake: 0.7618 (0.7570) Acc D Fake: 0.000%
Loss D: 1.165
Loss G: 0.6304 (0.6344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/158]
Loss D Real: 0.3246 (0.3735) Acc D Real: 99.983%
Loss D Fake: 0.7612 (0.7571) Acc D Fake: 0.000%
Loss D: 1.086
Loss G: 0.6311 (0.6344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/158]
Loss D Real: 0.4335 (0.3743) Acc D Real: 99.983%
Loss D Fake: 0.7605 (0.7571) Acc D Fake: 0.000%
Loss D: 1.194
Loss G: 0.6314 (0.6344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/158]
Loss D Real: 0.4486 (0.3752) Acc D Real: 99.983%
Loss D Fake: 0.7605 (0.7572) Acc D Fake: 0.000%
Loss D: 1.209
Loss G: 0.6311 (0.6343) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/158]
Loss D Real: 0.2420 (0.3736) Acc D Real: 99.983%
Loss D Fake: 0.7606 (0.7572) Acc D Fake: 0.000%
Loss D: 1.003
Loss G: 0.6315 (0.6343) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/158]
Loss D Real: 0.4192 (0.3741) Acc D Real: 99.983%
Loss D Fake: 0.7600 (0.7572) Acc D Fake: 0.000%
Loss D: 1.179
Loss G: 0.6318 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/158]
Loss D Real: 0.3532 (0.3739) Acc D Real: 99.984%
Loss D Fake: 0.7598 (0.7573) Acc D Fake: 0.000%
Loss D: 1.113
Loss G: 0.6320 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/158]
Loss D Real: 0.3875 (0.3740) Acc D Real: 99.984%
Loss D Fake: 0.7596 (0.7573) Acc D Fake: 0.000%
Loss D: 1.147
Loss G: 0.6321 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/158]
Loss D Real: 0.3641 (0.3739) Acc D Real: 99.984%
Loss D Fake: 0.7595 (0.7573) Acc D Fake: 0.000%
Loss D: 1.124
Loss G: 0.6322 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/158]
Loss D Real: 0.3427 (0.3735) Acc D Real: 99.984%
Loss D Fake: 0.7593 (0.7573) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.6324 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/158]
Loss D Real: 0.3998 (0.3738) Acc D Real: 99.983%
Loss D Fake: 0.7592 (0.7574) Acc D Fake: 0.000%
Loss D: 1.159
Loss G: 0.6324 (0.6341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/158]
Loss D Real: 0.3634 (0.3737) Acc D Real: 99.983%
Loss D Fake: 0.7592 (0.7574) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6324 (0.6341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/158]
Loss D Real: 0.4360 (0.3744) Acc D Real: 99.984%
Loss D Fake: 0.7594 (0.7574) Acc D Fake: 0.000%
Loss D: 1.195
Loss G: 0.6320 (0.6341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/158]
Loss D Real: 0.4063 (0.3748) Acc D Real: 99.984%
Loss D Fake: 0.7599 (0.7574) Acc D Fake: 0.000%
Loss D: 1.166
Loss G: 0.6315 (0.6341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/158]
Loss D Real: 0.4416 (0.3755) Acc D Real: 99.984%
Loss D Fake: 0.7607 (0.7575) Acc D Fake: 0.000%
Loss D: 1.202
Loss G: 0.6306 (0.6340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/158]
Loss D Real: 0.3884 (0.3757) Acc D Real: 99.984%
Loss D Fake: 0.7618 (0.7575) Acc D Fake: 0.000%
Loss D: 1.150
Loss G: 0.6297 (0.6340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/158]
Loss D Real: 0.4021 (0.3759) Acc D Real: 99.984%
Loss D Fake: 0.7628 (0.7576) Acc D Fake: 0.000%
Loss D: 1.165
Loss G: 0.6288 (0.6339) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/158]
Loss D Real: 0.4045 (0.3762) Acc D Real: 99.984%
Loss D Fake: 0.7639 (0.7576) Acc D Fake: 0.000%
Loss D: 1.168
Loss G: 0.6278 (0.6339) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/158]
Loss D Real: 0.2886 (0.3753) Acc D Real: 99.984%
Loss D Fake: 0.7648 (0.7577) Acc D Fake: 0.000%
Loss D: 1.053
Loss G: 0.6274 (0.6338) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/158]
Loss D Real: 0.3285 (0.3748) Acc D Real: 99.984%
Loss D Fake: 0.7650 (0.7578) Acc D Fake: 0.000%
Loss D: 1.093
Loss G: 0.6274 (0.6337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/158]
Loss D Real: 0.3144 (0.3742) Acc D Real: 99.984%
Loss D Fake: 0.7648 (0.7579) Acc D Fake: 0.000%
Loss D: 1.079
Loss G: 0.6278 (0.6337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/158]
Loss D Real: 0.3239 (0.3737) Acc D Real: 99.984%
Loss D Fake: 0.7641 (0.7579) Acc D Fake: 0.000%
Loss D: 1.088
Loss G: 0.6285 (0.6336) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/158]
Loss D Real: 0.4194 (0.3742) Acc D Real: 99.984%
Loss D Fake: 0.7633 (0.7580) Acc D Fake: 0.000%
Loss D: 1.183
Loss G: 0.6289 (0.6336) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/158]
Loss D Real: 0.3647 (0.3741) Acc D Real: 99.984%
Loss D Fake: 0.7630 (0.7580) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.6292 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/158]
Loss D Real: 0.3351 (0.3737) Acc D Real: 99.985%
Loss D Fake: 0.7626 (0.7581) Acc D Fake: 0.000%
Loss D: 1.098
Loss G: 0.6297 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/158]
Loss D Real: 0.2379 (0.3723) Acc D Real: 99.985%
Loss D Fake: 0.7617 (0.7581) Acc D Fake: 0.000%
Loss D: 1.000
Loss G: 0.6309 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/158]
Loss D Real: 0.3938 (0.3726) Acc D Real: 99.985%
Loss D Fake: 0.7602 (0.7581) Acc D Fake: 0.000%
Loss D: 1.154
Loss G: 0.6320 (0.6334) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/158]
Loss D Real: 0.3324 (0.3722) Acc D Real: 99.984%
Loss D Fake: 0.7590 (0.7581) Acc D Fake: 0.000%
Loss D: 1.091
Loss G: 0.6330 (0.6334) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/158]
Loss D Real: 0.3303 (0.3718) Acc D Real: 99.985%
Loss D Fake: 0.7578 (0.7581) Acc D Fake: 0.000%
Loss D: 1.088
Loss G: 0.6341 (0.6334) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/158]
Loss D Real: 0.2930 (0.3710) Acc D Real: 99.985%
Loss D Fake: 0.7565 (0.7581) Acc D Fake: 0.000%
Loss D: 1.049
Loss G: 0.6354 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/158]
Loss D Real: 0.3672 (0.3710) Acc D Real: 99.984%
Loss D Fake: 0.7550 (0.7581) Acc D Fake: 0.000%
Loss D: 1.122
Loss G: 0.6366 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/158]
Loss D Real: 0.3693 (0.3710) Acc D Real: 99.984%
Loss D Fake: 0.7538 (0.7581) Acc D Fake: 0.000%
Loss D: 1.123
Loss G: 0.6376 (0.6335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/158]
Loss D Real: 0.3126 (0.3704) Acc D Real: 99.984%
Loss D Fake: 0.7527 (0.7580) Acc D Fake: 0.000%
Loss D: 1.065
Loss G: 0.6387 (0.6336) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/158]
Loss D Real: 0.3695 (0.3704) Acc D Real: 99.984%
Loss D Fake: 0.7515 (0.7579) Acc D Fake: 0.000%
Loss D: 1.121
Loss G: 0.6397 (0.6336) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/158]
Loss D Real: 0.4455 (0.3711) Acc D Real: 99.985%
Loss D Fake: 0.7506 (0.7579) Acc D Fake: 0.000%
Loss D: 1.196
Loss G: 0.6401 (0.6337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/158]
Loss D Real: 0.3178 (0.3706) Acc D Real: 99.984%
Loss D Fake: 0.7502 (0.7578) Acc D Fake: 0.000%
Loss D: 1.068
Loss G: 0.6406 (0.6337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/158]
Loss D Real: 0.3891 (0.3708) Acc D Real: 99.984%
Loss D Fake: 0.7496 (0.7577) Acc D Fake: 0.000%
Loss D: 1.139
Loss G: 0.6410 (0.6338) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/158]
Loss D Real: 0.2840 (0.3700) Acc D Real: 99.984%
Loss D Fake: 0.7490 (0.7577) Acc D Fake: 0.000%
Loss D: 1.033
Loss G: 0.6418 (0.6339) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/158]
Loss D Real: 0.3039 (0.3695) Acc D Real: 99.983%
Loss D Fake: 0.7480 (0.7576) Acc D Fake: 0.000%
Loss D: 1.052
Loss G: 0.6429 (0.6340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/158]
Loss D Real: 0.3381 (0.3692) Acc D Real: 99.983%
Loss D Fake: 0.7467 (0.7575) Acc D Fake: 0.000%
Loss D: 1.085
Loss G: 0.6440 (0.6340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/158]
Loss D Real: 0.4388 (0.3698) Acc D Real: 99.983%
Loss D Fake: 0.7457 (0.7574) Acc D Fake: 0.000%
Loss D: 1.185
Loss G: 0.6446 (0.6341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/158]
Loss D Real: 0.3771 (0.3698) Acc D Real: 99.983%
Loss D Fake: 0.7453 (0.7573) Acc D Fake: 0.000%
Loss D: 1.122
Loss G: 0.6449 (0.6342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/158]
Loss D Real: 0.3958 (0.3701) Acc D Real: 99.983%
Loss D Fake: 0.7451 (0.7572) Acc D Fake: 0.000%
Loss D: 1.141
Loss G: 0.6449 (0.6343) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/158]
Loss D Real: 0.3235 (0.3697) Acc D Real: 99.983%
Loss D Fake: 0.7450 (0.7571) Acc D Fake: 0.000%
Loss D: 1.068
Loss G: 0.6452 (0.6344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/158]
Loss D Real: 0.3429 (0.3695) Acc D Real: 99.983%
Loss D Fake: 0.7446 (0.7570) Acc D Fake: 0.000%
Loss D: 1.087
Loss G: 0.6456 (0.6345) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/158]
Loss D Real: 0.3715 (0.3695) Acc D Real: 99.983%
Loss D Fake: 0.7441 (0.7569) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6459 (0.6346) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/158]
Loss D Real: 0.3884 (0.3696) Acc D Real: 99.982%
Loss D Fake: 0.7439 (0.7568) Acc D Fake: 0.000%
Loss D: 1.132
Loss G: 0.6460 (0.6347) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/158]
Loss D Real: 0.3426 (0.3694) Acc D Real: 99.982%
Loss D Fake: 0.7438 (0.7567) Acc D Fake: 0.000%
Loss D: 1.086
Loss G: 0.6462 (0.6348) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/158]
Loss D Real: 0.3255 (0.3691) Acc D Real: 99.983%
Loss D Fake: 0.7434 (0.7565) Acc D Fake: 0.000%
Loss D: 1.069
Loss G: 0.6466 (0.6349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/158]
Loss D Real: 0.3727 (0.3691) Acc D Real: 99.983%
Loss D Fake: 0.7429 (0.7564) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.6470 (0.6350) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/158]
Loss D Real: 0.3586 (0.3690) Acc D Real: 99.983%
Loss D Fake: 0.7426 (0.7563) Acc D Fake: 0.000%
Loss D: 1.101
Loss G: 0.6473 (0.6351) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/158]
Loss D Real: 0.3393 (0.3688) Acc D Real: 99.983%
Loss D Fake: 0.7422 (0.7562) Acc D Fake: 0.000%
Loss D: 1.082
Loss G: 0.6477 (0.6352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/158]
Loss D Real: 0.3702 (0.3688) Acc D Real: 99.983%
Loss D Fake: 0.7418 (0.7561) Acc D Fake: 0.000%
Loss D: 1.112
Loss G: 0.6480 (0.6353) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/158]
Loss D Real: 0.4137 (0.3691) Acc D Real: 99.982%
Loss D Fake: 0.7416 (0.7560) Acc D Fake: 0.000%
Loss D: 1.155
Loss G: 0.6479 (0.6354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/158]
Loss D Real: 0.3787 (0.3692) Acc D Real: 99.982%
Loss D Fake: 0.7418 (0.7559) Acc D Fake: 0.000%
Loss D: 1.120
Loss G: 0.6477 (0.6355) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/158]
Loss D Real: 0.4794 (0.3700) Acc D Real: 99.982%
Loss D Fake: 0.7423 (0.7558) Acc D Fake: 0.000%
Loss D: 1.222
Loss G: 0.6468 (0.6355) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/158]
Loss D Real: 0.3006 (0.3695) Acc D Real: 99.982%
Loss D Fake: 0.7433 (0.7557) Acc D Fake: 0.000%
Loss D: 1.044
Loss G: 0.6462 (0.6356) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/158]
Loss D Real: 0.2601 (0.3687) Acc D Real: 99.982%
Loss D Fake: 0.7436 (0.7556) Acc D Fake: 0.000%
Loss D: 1.004
Loss G: 0.6464 (0.6357) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/158]
Loss D Real: 0.4238 (0.3691) Acc D Real: 99.982%
Loss D Fake: 0.7433 (0.7555) Acc D Fake: 0.000%
Loss D: 1.167
Loss G: 0.6464 (0.6358) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/158]
Loss D Real: 0.2940 (0.3686) Acc D Real: 99.982%
Loss D Fake: 0.7434 (0.7554) Acc D Fake: 0.000%
Loss D: 1.037
Loss G: 0.6465 (0.6359) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/158]
Loss D Real: 0.3820 (0.3686) Acc D Real: 99.981%
Loss D Fake: 0.7431 (0.7553) Acc D Fake: 0.000%
Loss D: 1.125
Loss G: 0.6467 (0.6359) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/158]
Loss D Real: 0.3809 (0.3687) Acc D Real: 99.980%
Loss D Fake: 0.7429 (0.7552) Acc D Fake: 0.000%
Loss D: 1.124
Loss G: 0.6468 (0.6360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/158]
Loss D Real: 0.3516 (0.3686) Acc D Real: 99.981%
Loss D Fake: 0.7428 (0.7552) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.6470 (0.6361) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/158]
Loss D Real: 0.4329 (0.3691) Acc D Real: 99.980%
Loss D Fake: 0.7427 (0.7551) Acc D Fake: 0.000%
Loss D: 1.176
Loss G: 0.6468 (0.6362) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/158]
Loss D Real: 0.3546 (0.3690) Acc D Real: 99.980%
Loss D Fake: 0.7431 (0.7550) Acc D Fake: 0.000%
Loss D: 1.098
Loss G: 0.6466 (0.6363) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/158]
Loss D Real: 0.3695 (0.3690) Acc D Real: 99.980%
Loss D Fake: 0.7433 (0.7549) Acc D Fake: 0.000%
Loss D: 1.113
Loss G: 0.6463 (0.6363) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/158]
Loss D Real: 0.4819 (0.3698) Acc D Real: 99.980%
Loss D Fake: 0.7438 (0.7548) Acc D Fake: 0.000%
Loss D: 1.226
Loss G: 0.6455 (0.6364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/158]
Loss D Real: 0.3567 (0.3697) Acc D Real: 99.980%
Loss D Fake: 0.7448 (0.7547) Acc D Fake: 0.000%
Loss D: 1.101
Loss G: 0.6447 (0.6364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/158]
Loss D Real: 0.4427 (0.3702) Acc D Real: 99.980%
Loss D Fake: 0.7457 (0.7547) Acc D Fake: 0.000%
Loss D: 1.188
Loss G: 0.6437 (0.6365) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/158]
Loss D Real: 0.3703 (0.3702) Acc D Real: 99.980%
Loss D Fake: 0.7470 (0.7546) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.6426 (0.6365) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/158]
Loss D Real: 0.3562 (0.3701) Acc D Real: 99.979%
Loss D Fake: 0.7481 (0.7546) Acc D Fake: 0.000%
Loss D: 1.104
Loss G: 0.6418 (0.6366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/158]
Loss D Real: 0.3310 (0.3698) Acc D Real: 99.980%
Loss D Fake: 0.7488 (0.7546) Acc D Fake: 0.000%
Loss D: 1.080
Loss G: 0.6412 (0.6366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/158]
Loss D Real: 0.3565 (0.3697) Acc D Real: 99.980%
Loss D Fake: 0.7493 (0.7545) Acc D Fake: 0.000%
Loss D: 1.106
Loss G: 0.6409 (0.6366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/158]
Loss D Real: 0.3363 (0.3695) Acc D Real: 99.980%
Loss D Fake: 0.7495 (0.7545) Acc D Fake: 0.000%
Loss D: 1.086
Loss G: 0.6408 (0.6367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/158]
Loss D Real: 0.4031 (0.3697) Acc D Real: 99.980%
Loss D Fake: 0.7496 (0.7544) Acc D Fake: 0.000%
Loss D: 1.153
Loss G: 0.6406 (0.6367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/158]
Loss D Real: 0.3871 (0.3698) Acc D Real: 99.980%
Loss D Fake: 0.7500 (0.7544) Acc D Fake: 0.000%
Loss D: 1.137
Loss G: 0.6402 (0.6367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/158]
Loss D Real: 0.3348 (0.3696) Acc D Real: 99.980%
Loss D Fake: 0.7504 (0.7544) Acc D Fake: 0.000%
Loss D: 1.085
Loss G: 0.6400 (0.6367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/158]
Loss D Real: 0.3699 (0.3696) Acc D Real: 99.980%
Loss D Fake: 0.7505 (0.7544) Acc D Fake: 0.000%
Loss D: 1.120
Loss G: 0.6399 (0.6368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/158]
Loss D Real: 0.3759 (0.3697) Acc D Real: 99.980%
Loss D Fake: 0.7507 (0.7543) Acc D Fake: 0.000%
Loss D: 1.127
Loss G: 0.6397 (0.6368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/158]
Loss D Real: 0.2994 (0.3692) Acc D Real: 99.979%
Loss D Fake: 0.7508 (0.7543) Acc D Fake: 0.000%
Loss D: 1.050
Loss G: 0.6398 (0.6368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/158]
Loss D Real: 0.4256 (0.3696) Acc D Real: 99.979%
Loss D Fake: 0.7506 (0.7543) Acc D Fake: 0.000%
Loss D: 1.176
Loss G: 0.6398 (0.6368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/158]
Loss D Real: 0.2504 (0.3688) Acc D Real: 99.979%
Loss D Fake: 0.7505 (0.7543) Acc D Fake: 0.000%
Loss D: 1.001
Loss G: 0.6403 (0.6368) Acc G: 100.000%
LR: 2.000e-04
TEST [11/180]: Discriminator Loss: 0.825 | Generator Loss: 0.640 | Avg: 1.465
TEST [21/180]: Discriminator Loss: 0.912 | Generator Loss: 0.640 | Avg: 1.552
TEST [31/180]: Discriminator Loss: 0.889 | Generator Loss: 0.640 | Avg: 1.529
TEST [41/180]: Discriminator Loss: 0.867 | Generator Loss: 0.640 | Avg: 1.507
TEST [51/180]: Discriminator Loss: 0.865 | Generator Loss: 0.640 | Avg: 1.506
TEST [61/180]: Discriminator Loss: 0.911 | Generator Loss: 0.640 | Avg: 1.551
TEST [71/180]: Discriminator Loss: 0.935 | Generator Loss: 0.640 | Avg: 1.575
TEST [81/180]: Discriminator Loss: 0.975 | Generator Loss: 0.640 | Avg: 1.615
TEST [91/180]: Discriminator Loss: 0.997 | Generator Loss: 0.640 | Avg: 1.638
TEST [101/180]: Discriminator Loss: 1.035 | Generator Loss: 0.640 | Avg: 1.675
TEST [111/180]: Discriminator Loss: 1.062 | Generator Loss: 0.640 | Avg: 1.703
TEST [121/180]: Discriminator Loss: 1.089 | Generator Loss: 0.640 | Avg: 1.729
TEST [131/180]: Discriminator Loss: 1.110 | Generator Loss: 0.640 | Avg: 1.751
TEST [141/180]: Discriminator Loss: 1.126 | Generator Loss: 0.640 | Avg: 1.766
TEST [151/180]: Discriminator Loss: 1.113 | Generator Loss: 0.640 | Avg: 1.753
TEST [161/180]: Discriminator Loss: 1.099 | Generator Loss: 0.640 | Avg: 1.740
TEST [171/180]: Discriminator Loss: 1.086 | Generator Loss: 0.640 | Avg: 1.726
Best Metric: At 2 Epoch Gen 0.849 Dis
MODEL TRAINING COMPLETED.
 BEST RESULT SAVED
TEST [11/44]: Discriminator Loss: 0.619 | Generator Loss: 0.849 | Avg: 1.468
TEST [21/44]: Discriminator Loss: 0.617 | Generator Loss: 0.849 | Avg: 1.465
TEST [31/44]: Discriminator Loss: 0.615 | Generator Loss: 0.849 | Avg: 1.464
TEST [41/44]: Discriminator Loss: 0.616 | Generator Loss: 0.849 | Avg: 1.464
 Batch: 1/121
121
Batch [1/121]: Anomaly Score: 466.257 label: 0.0
 Batch: 2/121
Batch [2/121]: Anomaly Score: 529.977 label: 0.0
 Batch: 3/121
Batch [3/121]: Anomaly Score: 504.801 label: 0.0
 Batch: 4/121
Batch [4/121]: Anomaly Score: 443.575 label: 0.0
 Batch: 5/121
Batch [5/121]: Anomaly Score: 504.627 label: 0.0
 Batch: 6/121
Batch [6/121]: Anomaly Score: 389.892 label: 0.0
 Batch: 7/121
Batch [7/121]: Anomaly Score: 413.785 label: 0.0
 Batch: 8/121
Batch [8/121]: Anomaly Score: 510.531 label: 0.0
 Batch: 9/121
Batch [9/121]: Anomaly Score: 463.740 label: 0.0
 Batch: 10/121
Batch [10/121]: Anomaly Score: 358.456 label: 0.0
 Batch: 11/121
Batch [11/121]: Anomaly Score: 389.799 label: 0.0
 Batch: 12/121
Batch [12/121]: Anomaly Score: 351.639 label: 0.0
 Batch: 13/121
Batch [13/121]: Anomaly Score: 499.466 label: 0.0
 Batch: 14/121
Batch [14/121]: Anomaly Score: 420.870 label: 0.0
 Batch: 15/121
Batch [15/121]: Anomaly Score: 481.751 label: 0.0
 Batch: 16/121
Batch [16/121]: Anomaly Score: 524.861 label: 0.0
 Batch: 17/121
Batch [17/121]: Anomaly Score: 478.398 label: 0.0
 Batch: 18/121
Batch [18/121]: Anomaly Score: 463.407 label: 0.0
 Batch: 19/121
Batch [19/121]: Anomaly Score: 512.908 label: 0.0
 Batch: 20/121
Batch [20/121]: Anomaly Score: 487.421 label: 0.0
 Batch: 21/121
Batch [21/121]: Anomaly Score: 536.308 label: 0.0
 Batch: 22/121
Batch [22/121]: Anomaly Score: 502.256 label: 0.0
 Batch: 23/121
Batch [23/121]: Anomaly Score: 516.259 label: 0.0
 Batch: 24/121
Batch [24/121]: Anomaly Score: 482.294 label: 0.0
 Batch: 25/121
Batch [25/121]: Anomaly Score: 444.781 label: 0.0
 Batch: 26/121
Batch [26/121]: Anomaly Score: 450.907 label: 0.0
 Batch: 27/121
Batch [27/121]: Anomaly Score: 398.580 label: 0.0
 Batch: 28/121
Batch [28/121]: Anomaly Score: 500.339 label: 0.0
 Batch: 29/121
Batch [29/121]: Anomaly Score: 470.945 label: 0.0
 Batch: 30/121
Batch [30/121]: Anomaly Score: 401.075 label: 0.0
 Batch: 31/121
Batch [31/121]: Anomaly Score: 277.443 label: 0.0
 Batch: 32/121
Batch [32/121]: Anomaly Score: 250.701 label: 0.0
 Batch: 33/121
Batch [33/121]: Anomaly Score: 278.422 label: 0.0
 Batch: 34/121
Batch [34/121]: Anomaly Score: 351.372 label: 0.0
 Batch: 35/121
Batch [35/121]: Anomaly Score: 351.406 label: 0.0
 Batch: 36/121
Batch [36/121]: Anomaly Score: 409.445 label: 0.0
 Batch: 37/121
Batch [37/121]: Anomaly Score: 388.781 label: 0.0
 Batch: 38/121
Batch [38/121]: Anomaly Score: 387.812 label: 0.0
 Batch: 39/121
Batch [39/121]: Anomaly Score: 263.026 label: 0.0
 Batch: 40/121
Batch [40/121]: Anomaly Score: 414.920 label: 0.0
 Batch: 41/121
Batch [41/121]: Anomaly Score: 356.912 label: 0.0
 Batch: 42/121
Batch [42/121]: Anomaly Score: 233.457 label: 0.0
 Batch: 43/121
Batch [43/121]: Anomaly Score: 259.992 label: 0.0
 Batch: 44/121
Batch [44/121]: Anomaly Score: 225.597 label: 0.0
 Batch: 45/121
Batch [45/121]: Anomaly Score: 271.384 label: 0.0
 Batch: 46/121
Batch [46/121]: Anomaly Score: 377.532 label: 0.0
 Batch: 47/121
Batch [47/121]: Anomaly Score: 324.280 label: 0.0
 Batch: 48/121
Batch [48/121]: Anomaly Score: 402.056 label: 0.0
 Batch: 49/121
Batch [49/121]: Anomaly Score: 414.724 label: 0.0
 Batch: 50/121
Batch [50/121]: Anomaly Score: 48.807 label: 0.0
 Batch: 51/121
Batch [51/121]: Anomaly Score: 306.523 label: 0.0
 Batch: 52/121
Batch [52/121]: Anomaly Score: 18.860 label: 0.0
 Batch: 53/121
Batch [53/121]: Anomaly Score: 280.499 label: 0.0
 Batch: 54/121
Batch [54/121]: Anomaly Score: 278.947 label: 0.0
 Batch: 55/121
Batch [55/121]: Anomaly Score: 293.226 label: 0.0
 Batch: 56/121
Batch [56/121]: Anomaly Score: 262.013 label: 0.0
 Batch: 57/121
Batch [57/121]: Anomaly Score: 271.355 label: 0.0
 Batch: 58/121
Batch [58/121]: Anomaly Score: 367.570 label: 0.0
 Batch: 59/121
Batch [59/121]: Anomaly Score: 259.245 label: 0.0
 Batch: 60/121
Batch [60/121]: Anomaly Score: 275.737 label: 1.0
 Batch: 61/121
Batch [61/121]: Anomaly Score: 267.439 label: 1.0
 Batch: 62/121
Batch [62/121]: Anomaly Score: 296.469 label: 1.0
 Batch: 63/121
Batch [63/121]: Anomaly Score: 346.789 label: 1.0
 Batch: 64/121
Batch [64/121]: Anomaly Score: 281.667 label: 1.0
 Batch: 65/121
Batch [65/121]: Anomaly Score: 255.648 label: 1.0
 Batch: 66/121
Batch [66/121]: Anomaly Score: 258.009 label: 1.0
 Batch: 67/121
Batch [67/121]: Anomaly Score: 278.039 label: 0.0
 Batch: 68/121
Batch [68/121]: Anomaly Score: 360.976 label: 0.0
 Batch: 69/121
Batch [69/121]: Anomaly Score: 295.035 label: 0.0
 Batch: 70/121
Batch [70/121]: Anomaly Score: 216.804 label: 0.0
 Batch: 71/121
Batch [71/121]: Anomaly Score: 291.379 label: 0.0
 Batch: 72/121
Batch [72/121]: Anomaly Score: 272.524 label: 0.0
 Batch: 73/121
Batch [73/121]: Anomaly Score: 333.014 label: 0.0
 Batch: 74/121
Batch [74/121]: Anomaly Score: 364.602 label: 0.0
 Batch: 75/121
Batch [75/121]: Anomaly Score: 350.230 label: 0.0
 Batch: 76/121
Batch [76/121]: Anomaly Score: 364.371 label: 0.0
 Batch: 77/121
Batch [77/121]: Anomaly Score: 414.719 label: 0.0
 Batch: 78/121
Batch [78/121]: Anomaly Score: 463.004 label: 0.0
 Batch: 79/121
Batch [79/121]: Anomaly Score: 390.393 label: 0.0
 Batch: 80/121
Batch [80/121]: Anomaly Score: 423.657 label: 0.0
 Batch: 81/121
Batch [81/121]: Anomaly Score: 394.235 label: 0.0
 Batch: 82/121
Batch [82/121]: Anomaly Score: 416.885 label: 0.0
 Batch: 83/121
Batch [83/121]: Anomaly Score: 386.050 label: 0.0
 Batch: 84/121
Batch [84/121]: Anomaly Score: 423.716 label: 0.0
 Batch: 85/121
Batch [85/121]: Anomaly Score: 513.518 label: 0.0
 Batch: 86/121
Batch [86/121]: Anomaly Score: 483.231 label: 0.0
 Batch: 87/121
Batch [87/121]: Anomaly Score: 409.316 label: 0.0
 Batch: 88/121
Batch [88/121]: Anomaly Score: 455.813 label: 0.0
 Batch: 89/121
Batch [89/121]: Anomaly Score: 374.110 label: 0.0
 Batch: 90/121
Batch [90/121]: Anomaly Score: 470.483 label: 0.0
 Batch: 91/121
Batch [91/121]: Anomaly Score: 502.853 label: 0.0
 Batch: 92/121
Batch [92/121]: Anomaly Score: 535.836 label: 0.0
 Batch: 93/121
Batch [93/121]: Anomaly Score: 543.372 label: 0.0
 Batch: 94/121
Batch [94/121]: Anomaly Score: 453.029 label: 0.0
 Batch: 95/121
Batch [95/121]: Anomaly Score: 504.012 label: 0.0
 Batch: 96/121
Batch [96/121]: Anomaly Score: 531.092 label: 0.0
 Batch: 97/121
Batch [97/121]: Anomaly Score: 500.644 label: 0.0
 Batch: 98/121
Batch [98/121]: Anomaly Score: 502.354 label: 0.0
 Batch: 99/121
Batch [99/121]: Anomaly Score: 512.126 label: 0.0
 Batch: 100/121
Batch [100/121]: Anomaly Score: 503.317 label: 1.0
 Batch: 101/121
Batch [101/121]: Anomaly Score: 534.251 label: 1.0
 Batch: 102/121
Batch [102/121]: Anomaly Score: 510.888 label: 1.0
 Batch: 103/121
Batch [103/121]: Anomaly Score: 545.569 label: 1.0
 Batch: 104/121
Batch [104/121]: Anomaly Score: 568.716 label: 1.0
 Batch: 105/121
Batch [105/121]: Anomaly Score: 518.923 label: 1.0
 Batch: 106/121
Batch [106/121]: Anomaly Score: 538.571 label: 1.0
 Batch: 107/121
Batch [107/121]: Anomaly Score: 546.892 label: 1.0
 Batch: 108/121
Batch [108/121]: Anomaly Score: 495.599 label: 0.0
 Batch: 109/121
Batch [109/121]: Anomaly Score: 527.425 label: 0.0
 Batch: 110/121
Batch [110/121]: Anomaly Score: 536.287 label: 0.0
 Batch: 111/121
Batch [111/121]: Anomaly Score: 534.817 label: 0.0
 Batch: 112/121
Batch [112/121]: Anomaly Score: 561.760 label: 0.0
 Batch: 113/121
Batch [113/121]: Anomaly Score: 537.073 label: 0.0
 Batch: 114/121
Batch [114/121]: Anomaly Score: 491.927 label: 0.0
 Batch: 115/121
Batch [115/121]: Anomaly Score: 550.126 label: 0.0
 Batch: 116/121
Batch [116/121]: Anomaly Score: 500.297 label: 0.0
 Batch: 117/121
Batch [117/121]: Anomaly Score: 514.858 label: 0.0
 Batch: 118/121
Batch [118/121]: Anomaly Score: 565.347 label: 0.0
 Batch: 119/121
Batch [119/121]: Anomaly Score: 504.058 label: 0.0
 Batch: 120/121
Batch [120/121]: Anomaly Score: 506.758 label: 0.0
 Batch: 121/121
Batch [121/121]: Anomaly Score: 530.517 label: 0.0