Epoch: 1/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.6765 (0.6781) Acc D Real: 100.000%
Loss D Fake: 0.7037 (0.7025) Acc D Fake: 0.000%
Loss D: 1.380
Loss G: 0.6817 (0.6829) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.6729 (0.6764) Acc D Real: 100.000%
Loss D Fake: 0.7062 (0.7037) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.6793 (0.6817) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.6700 (0.6748) Acc D Real: 100.000%
Loss D Fake: 0.7086 (0.7049) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.6769 (0.6805) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.6671 (0.6733) Acc D Real: 100.000%
Loss D Fake: 0.7111 (0.7062) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6745 (0.6793) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.6662 (0.6721) Acc D Real: 100.000%
Loss D Fake: 0.7136 (0.7074) Acc D Fake: 0.000%
Loss D: 1.380
Loss G: 0.6721 (0.6781) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.6615 (0.6706) Acc D Real: 100.000%
Loss D Fake: 0.7161 (0.7086) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6697 (0.6769) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.6592 (0.6691) Acc D Real: 100.000%
Loss D Fake: 0.7187 (0.7099) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6672 (0.6757) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.6570 (0.6678) Acc D Real: 100.000%
Loss D Fake: 0.7214 (0.7112) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6646 (0.6744) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.6538 (0.6664) Acc D Real: 100.000%
Loss D Fake: 0.7241 (0.7125) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6620 (0.6732) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.6512 (0.6650) Acc D Real: 100.000%
Loss D Fake: 0.7269 (0.7138) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6593 (0.6719) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.6475 (0.6635) Acc D Real: 100.000%
Loss D Fake: 0.7298 (0.7151) Acc D Fake: 0.000%
Loss D: 1.377
Loss G: 0.6566 (0.6707) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.6436 (0.6620) Acc D Real: 100.000%
Loss D Fake: 0.7329 (0.7165) Acc D Fake: 0.000%
Loss D: 1.376
Loss G: 0.6538 (0.6694) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.6420 (0.6606) Acc D Real: 100.000%
Loss D Fake: 0.7360 (0.7179) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6508 (0.6680) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.6386 (0.6591) Acc D Real: 100.000%
Loss D Fake: 0.7393 (0.7193) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6478 (0.6667) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.6359 (0.6577) Acc D Real: 100.000%
Loss D Fake: 0.7427 (0.7208) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.6446 (0.6653) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.6324 (0.6562) Acc D Real: 100.000%
Loss D Fake: 0.7463 (0.7223) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.6413 (0.6639) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.6280 (0.6546) Acc D Real: 100.000%
Loss D Fake: 0.7501 (0.7238) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6379 (0.6624) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.6253 (0.6531) Acc D Real: 100.000%
Loss D Fake: 0.7541 (0.7254) Acc D Fake: 0.000%
Loss D: 1.379
Loss G: 0.6342 (0.6610) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.6198 (0.6514) Acc D Real: 100.000%
Loss D Fake: 0.7584 (0.7271) Acc D Fake: 0.000%
Loss D: 1.378
Loss G: 0.6304 (0.6594) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.6179 (0.6498) Acc D Real: 100.000%
Loss D Fake: 0.7629 (0.7288) Acc D Fake: 0.000%
Loss D: 1.381
Loss G: 0.6264 (0.6579) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.6136 (0.6482) Acc D Real: 100.000%
Loss D Fake: 0.7677 (0.7305) Acc D Fake: 0.000%
Loss D: 1.381
Loss G: 0.6221 (0.6562) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.6109 (0.6465) Acc D Real: 100.000%
Loss D Fake: 0.7729 (0.7324) Acc D Fake: 0.000%
Loss D: 1.384
Loss G: 0.6176 (0.6546) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.6035 (0.6448) Acc D Real: 100.000%
Loss D Fake: 0.7784 (0.7343) Acc D Fake: 0.000%
Loss D: 1.382
Loss G: 0.6127 (0.6528) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.5980 (0.6429) Acc D Real: 100.000%
Loss D Fake: 0.7845 (0.7363) Acc D Fake: 0.000%
Loss D: 1.382
Loss G: 0.6076 (0.6510) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.5956 (0.6411) Acc D Real: 100.000%
Loss D Fake: 0.7910 (0.7384) Acc D Fake: 0.000%
Loss D: 1.387
Loss G: 0.6020 (0.6491) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.5883 (0.6391) Acc D Real: 100.000%
Loss D Fake: 0.7982 (0.7406) Acc D Fake: 0.000%
Loss D: 1.386
Loss G: 0.5960 (0.6471) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.5831 (0.6371) Acc D Real: 100.000%
Loss D Fake: 0.8060 (0.7430) Acc D Fake: 0.000%
Loss D: 1.389
Loss G: 0.5895 (0.6451) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.5761 (0.6350) Acc D Real: 100.000%
Loss D Fake: 0.8147 (0.7454) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.5824 (0.6429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.5680 (0.6328) Acc D Real: 100.000%
Loss D Fake: 0.8243 (0.7481) Acc D Fake: 0.000%
Loss D: 1.392
Loss G: 0.5746 (0.6406) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.5624 (0.6305) Acc D Real: 100.000%
Loss D Fake: 0.8352 (0.7509) Acc D Fake: 0.000%
Loss D: 1.398
Loss G: 0.5661 (0.6382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.5557 (0.6282) Acc D Real: 100.000%
Loss D Fake: 0.8473 (0.7539) Acc D Fake: 0.000%
Loss D: 1.403
Loss G: 0.5568 (0.6357) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.5431 (0.6256) Acc D Real: 100.000%
Loss D Fake: 0.8608 (0.7571) Acc D Fake: 0.000%
Loss D: 1.404
Loss G: 0.5466 (0.6330) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.5385 (0.6230) Acc D Real: 100.000%
Loss D Fake: 0.8762 (0.7606) Acc D Fake: 0.000%
Loss D: 1.415
Loss G: 0.5355 (0.6301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.5230 (0.6202) Acc D Real: 100.000%
Loss D Fake: 0.8935 (0.7644) Acc D Fake: 0.000%
Loss D: 1.417
Loss G: 0.5234 (0.6271) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.5182 (0.6173) Acc D Real: 100.000%
Loss D Fake: 0.9131 (0.7686) Acc D Fake: 0.000%
Loss D: 1.431
Loss G: 0.5105 (0.6238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.5097 (0.6144) Acc D Real: 100.000%
Loss D Fake: 0.9344 (0.7730) Acc D Fake: 0.000%
Loss D: 1.444
Loss G: 0.4972 (0.6204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4966 (0.6113) Acc D Real: 100.000%
Loss D Fake: 0.9570 (0.7779) Acc D Fake: 0.000%
Loss D: 1.454
Loss G: 0.4838 (0.6168) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4885 (0.6082) Acc D Real: 100.000%
Loss D Fake: 0.9802 (0.7831) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4710 (0.6131) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4779 (0.6049) Acc D Real: 100.000%
Loss D Fake: 1.0030 (0.7886) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4592 (0.6092) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4785 (0.6018) Acc D Real: 100.000%
Loss D Fake: 1.0240 (0.7943) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4492 (0.6053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4750 (0.5988) Acc D Real: 100.000%
Loss D Fake: 1.0412 (0.8002) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4414 (0.6014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4691 (0.5958) Acc D Real: 100.000%
Loss D Fake: 1.0543 (0.8061) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4357 (0.5976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4685 (0.5929) Acc D Real: 100.000%
Loss D Fake: 1.0634 (0.8119) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.4318 (0.5938) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4699 (0.5902) Acc D Real: 100.000%
Loss D Fake: 1.0687 (0.8176) Acc D Fake: 0.000%
Loss D: 1.539
Loss G: 0.4297 (0.5902) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4683 (0.5875) Acc D Real: 100.000%
Loss D Fake: 1.0704 (0.8231) Acc D Fake: 0.000%
Loss D: 1.539
Loss G: 0.4290 (0.5867) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4793 (0.5852) Acc D Real: 100.000%
Loss D Fake: 1.0690 (0.8284) Acc D Fake: 0.000%
Loss D: 1.548
Loss G: 0.4298 (0.5833) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4775 (0.5830) Acc D Real: 100.000%
Loss D Fake: 1.0646 (0.8333) Acc D Fake: 0.000%
Loss D: 1.542
Loss G: 0.4319 (0.5802) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4823 (0.5809) Acc D Real: 100.000%
Loss D Fake: 1.0581 (0.8379) Acc D Fake: 0.000%
Loss D: 1.540
Loss G: 0.4349 (0.5772) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4826 (0.5790) Acc D Real: 100.000%
Loss D Fake: 1.0504 (0.8421) Acc D Fake: 0.000%
Loss D: 1.533
Loss G: 0.4384 (0.5744) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4868 (0.5771) Acc D Real: 100.000%
Loss D Fake: 1.0424 (0.8461) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4421 (0.5718) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4870 (0.5754) Acc D Real: 100.000%
Loss D Fake: 1.0347 (0.8497) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4458 (0.5694) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4962 (0.5739) Acc D Real: 100.000%
Loss D Fake: 1.0274 (0.8530) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4494 (0.5671) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4958 (0.5725) Acc D Real: 100.000%
Loss D Fake: 1.0206 (0.8561) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4527 (0.5650) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4972 (0.5711) Acc D Real: 100.000%
Loss D Fake: 1.0145 (0.8590) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4557 (0.5630) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.5011 (0.5699) Acc D Real: 100.000%
Loss D Fake: 1.0091 (0.8617) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4584 (0.5612) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.5001 (0.5686) Acc D Real: 100.000%
Loss D Fake: 1.0043 (0.8642) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4608 (0.5594) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.5027 (0.5675) Acc D Real: 100.000%
Loss D Fake: 1.0000 (0.8665) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4630 (0.5577) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.5038 (0.5664) Acc D Real: 100.000%
Loss D Fake: 0.9963 (0.8687) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4649 (0.5562) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.5031 (0.5654) Acc D Real: 100.000%
Loss D Fake: 0.9931 (0.8708) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4666 (0.5547) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.5025 (0.5643) Acc D Real: 100.000%
Loss D Fake: 0.9903 (0.8728) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4680 (0.5533) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.5008 (0.5633) Acc D Real: 100.000%
Loss D Fake: 0.9880 (0.8746) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4691 (0.5519) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.5041 (0.5624) Acc D Real: 100.000%
Loss D Fake: 0.9861 (0.8764) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4701 (0.5506) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.5073 (0.5615) Acc D Real: 100.000%
Loss D Fake: 0.9844 (0.8781) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4709 (0.5494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.5065 (0.5607) Acc D Real: 100.000%
Loss D Fake: 0.9830 (0.8797) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4717 (0.5482) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.5082 (0.5599) Acc D Real: 100.000%
Loss D Fake: 0.9818 (0.8813) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4723 (0.5470) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.5031 (0.5590) Acc D Real: 100.000%
Loss D Fake: 0.9807 (0.8827) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4728 (0.5459) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.5047 (0.5582) Acc D Real: 100.000%
Loss D Fake: 0.9799 (0.8842) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4732 (0.5448) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.5051 (0.5574) Acc D Real: 100.000%
Loss D Fake: 0.9793 (0.8855) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4735 (0.5438) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.5089 (0.5568) Acc D Real: 100.000%
Loss D Fake: 0.9788 (0.8869) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4738 (0.5428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.5007 (0.5560) Acc D Real: 100.000%
Loss D Fake: 0.9784 (0.8882) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4739 (0.5418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.5048 (0.5553) Acc D Real: 100.000%
Loss D Fake: 0.9781 (0.8894) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4740 (0.5409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.5056 (0.5546) Acc D Real: 100.000%
Loss D Fake: 0.9780 (0.8906) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4741 (0.5400) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.5033 (0.5539) Acc D Real: 100.000%
Loss D Fake: 0.9779 (0.8918) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4741 (0.5391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.5013 (0.5532) Acc D Real: 100.000%
Loss D Fake: 0.9780 (0.8930) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4740 (0.5382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.5002 (0.5525) Acc D Real: 100.000%
Loss D Fake: 0.9781 (0.8941) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4738 (0.5374) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4990 (0.5518) Acc D Real: 100.000%
Loss D Fake: 0.9784 (0.8952) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4736 (0.5365) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4997 (0.5511) Acc D Real: 100.000%
Loss D Fake: 0.9788 (0.8962) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4734 (0.5357) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4974 (0.5504) Acc D Real: 100.000%
Loss D Fake: 0.9793 (0.8973) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4730 (0.5349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.5001 (0.5498) Acc D Real: 100.000%
Loss D Fake: 0.9799 (0.8983) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4727 (0.5342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4971 (0.5492) Acc D Real: 100.000%
Loss D Fake: 0.9805 (0.8993) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4723 (0.5334) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4940 (0.5485) Acc D Real: 100.000%
Loss D Fake: 0.9812 (0.9003) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4719 (0.5326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4944 (0.5478) Acc D Real: 100.000%
Loss D Fake: 0.9819 (0.9013) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4714 (0.5319) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4914 (0.5472) Acc D Real: 100.000%
Loss D Fake: 0.9828 (0.9023) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4708 (0.5312) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4904 (0.5465) Acc D Real: 100.000%
Loss D Fake: 0.9838 (0.9033) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4702 (0.5305) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4913 (0.5459) Acc D Real: 100.000%
Loss D Fake: 0.9849 (0.9042) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4696 (0.5298) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4907 (0.5452) Acc D Real: 100.000%
Loss D Fake: 0.9860 (0.9051) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4689 (0.5291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4872 (0.5446) Acc D Real: 100.000%
Loss D Fake: 0.9872 (0.9061) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4682 (0.5284) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4871 (0.5439) Acc D Real: 100.000%
Loss D Fake: 0.9884 (0.9070) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4674 (0.5277) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4834 (0.5432) Acc D Real: 100.000%
Loss D Fake: 0.9898 (0.9079) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4666 (0.5270) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4828 (0.5426) Acc D Real: 100.000%
Loss D Fake: 0.9912 (0.9088) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4658 (0.5263) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4814 (0.5419) Acc D Real: 100.000%
Loss D Fake: 0.9928 (0.9097) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4649 (0.5257) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4792 (0.5412) Acc D Real: 100.000%
Loss D Fake: 0.9944 (0.9107) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4639 (0.5250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4768 (0.5406) Acc D Real: 100.000%
Loss D Fake: 0.9962 (0.9116) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4629 (0.5243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4764 (0.5399) Acc D Real: 100.000%
Loss D Fake: 0.9981 (0.9125) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4618 (0.5237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4737 (0.5392) Acc D Real: 100.000%
Loss D Fake: 1.0001 (0.9134) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4606 (0.5230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4717 (0.5385) Acc D Real: 100.000%
Loss D Fake: 1.0022 (0.9143) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4594 (0.5224) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4681 (0.5378) Acc D Real: 100.000%
Loss D Fake: 1.0045 (0.9152) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4580 (0.5217) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4667 (0.5371) Acc D Real: 100.000%
Loss D Fake: 1.0070 (0.9162) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4566 (0.5210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4634 (0.5363) Acc D Real: 100.000%
Loss D Fake: 1.0096 (0.9171) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4551 (0.5204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4595 (0.5356) Acc D Real: 100.000%
Loss D Fake: 1.0126 (0.9180) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4534 (0.5197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4561 (0.5348) Acc D Real: 100.000%
Loss D Fake: 1.0159 (0.9190) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4515 (0.5191) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4523 (0.5340) Acc D Real: 100.000%
Loss D Fake: 1.0195 (0.9200) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4494 (0.5184) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4481 (0.5332) Acc D Real: 100.000%
Loss D Fake: 1.0237 (0.9210) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4471 (0.5177) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4434 (0.5323) Acc D Real: 100.000%
Loss D Fake: 1.0284 (0.9220) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4444 (0.5170) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4380 (0.5314) Acc D Real: 100.000%
Loss D Fake: 1.0339 (0.9230) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4413 (0.5163) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4315 (0.5305) Acc D Real: 100.000%
Loss D Fake: 1.0404 (0.9241) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4377 (0.5155) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4240 (0.5295) Acc D Real: 100.000%
Loss D Fake: 1.0483 (0.9253) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4333 (0.5148) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4132 (0.5284) Acc D Real: 100.000%
Loss D Fake: 1.0581 (0.9265) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4278 (0.5140) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4012 (0.5273) Acc D Real: 100.000%
Loss D Fake: 1.0712 (0.9278) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4205 (0.5131) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.3886 (0.5260) Acc D Real: 100.000%
Loss D Fake: 1.0894 (0.9293) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4108 (0.5122) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.3592 (0.5245) Acc D Real: 100.000%
Loss D Fake: 1.1158 (0.9309) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.3970 (0.5112) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.3281 (0.5228) Acc D Real: 100.000%
Loss D Fake: 1.1579 (0.9330) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.3794 (0.5100) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.2830 (0.5207) Acc D Real: 100.000%
Loss D Fake: 1.2039 (0.9353) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.3751 (0.5088) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.2713 (0.5185) Acc D Real: 100.000%
Loss D Fake: 1.1779 (0.9374) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.3916 (0.5078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.2659 (0.5163) Acc D Real: 100.000%
Loss D Fake: 1.1221 (0.9390) Acc D Fake: 0.000%
Loss D: 1.388
Loss G: 0.4119 (0.5070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.2657 (0.5142) Acc D Real: 100.000%
Loss D Fake: 1.0823 (0.9403) Acc D Fake: 0.000%
Loss D: 1.348
Loss G: 0.4252 (0.5063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.2669 (0.5121) Acc D Real: 100.000%
Loss D Fake: 1.0631 (0.9413) Acc D Fake: 0.000%
Loss D: 1.330
Loss G: 0.4302 (0.5056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.2426 (0.5098) Acc D Real: 100.000%
Loss D Fake: 1.0594 (0.9423) Acc D Fake: 0.000%
Loss D: 1.302
Loss G: 0.4308 (0.5050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.2247 (0.5075) Acc D Real: 100.000%
Loss D Fake: 1.0596 (0.9433) Acc D Fake: 0.000%
Loss D: 1.284
Loss G: 0.4327 (0.5044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.1999 (0.5049) Acc D Real: 100.000%
Loss D Fake: 1.0494 (0.9441) Acc D Fake: 0.000%
Loss D: 1.249
Loss G: 0.4423 (0.5039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.2101 (0.5025) Acc D Real: 100.000%
Loss D Fake: 1.0258 (0.9448) Acc D Fake: 0.000%
Loss D: 1.236
Loss G: 0.4540 (0.5035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.1978 (0.5000) Acc D Real: 100.000%
Loss D Fake: 1.0045 (0.9453) Acc D Fake: 0.000%
Loss D: 1.202
Loss G: 0.4649 (0.5032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.1950 (0.4976) Acc D Real: 100.000%
Loss D Fake: 0.9882 (0.9456) Acc D Fake: 0.000%
Loss D: 1.183
Loss G: 0.4714 (0.5029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.1844 (0.4951) Acc D Real: 100.000%
Loss D Fake: 0.9801 (0.9459) Acc D Fake: 0.000%
Loss D: 1.164
Loss G: 0.4755 (0.5027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.1730 (0.4925) Acc D Real: 100.000%
Loss D Fake: 0.9732 (0.9461) Acc D Fake: 0.000%
Loss D: 1.146
Loss G: 0.4806 (0.5025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.1649 (0.4899) Acc D Real: 100.000%
Loss D Fake: 0.9637 (0.9463) Acc D Fake: 0.000%
Loss D: 1.129
Loss G: 0.4873 (0.5024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.1592 (0.4873) Acc D Real: 100.000%
Loss D Fake: 0.9522 (0.9463) Acc D Fake: 0.000%
Loss D: 1.111
Loss G: 0.4945 (0.5023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.1529 (0.4848) Acc D Real: 100.000%
Loss D Fake: 0.9405 (0.9463) Acc D Fake: 0.000%
Loss D: 1.093
Loss G: 0.5023 (0.5023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.1390 (0.4821) Acc D Real: 100.000%
Loss D Fake: 0.9274 (0.9461) Acc D Fake: 0.000%
Loss D: 1.066
Loss G: 0.5119 (0.5024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.1435 (0.4795) Acc D Real: 100.000%
Loss D Fake: 0.9122 (0.9459) Acc D Fake: 0.000%
Loss D: 1.056
Loss G: 0.5217 (0.5026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.1453 (0.4770) Acc D Real: 100.000%
Loss D Fake: 0.8985 (0.9455) Acc D Fake: 0.000%
Loss D: 1.044
Loss G: 0.5304 (0.5028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.1673 (0.4746) Acc D Real: 100.000%
Loss D Fake: 0.8879 (0.9451) Acc D Fake: 0.000%
Loss D: 1.055
Loss G: 0.5362 (0.5030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.1654 (0.4723) Acc D Real: 100.000%
Loss D Fake: 0.8824 (0.9446) Acc D Fake: 0.000%
Loss D: 1.048
Loss G: 0.5392 (0.5033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.1489 (0.4699) Acc D Real: 100.000%
Loss D Fake: 0.8821 (0.9442) Acc D Fake: 0.000%
Loss D: 1.031
Loss G: 0.5375 (0.5036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.1411 (0.4675) Acc D Real: 100.000%
Loss D Fake: 0.8890 (0.9437) Acc D Fake: 0.000%
Loss D: 1.030
Loss G: 0.5343 (0.5038) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.1232 (0.4650) Acc D Real: 100.000%
Loss D Fake: 0.8948 (0.9434) Acc D Fake: 0.000%
Loss D: 1.018
Loss G: 0.5355 (0.5040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.1303 (0.4626) Acc D Real: 100.000%
Loss D Fake: 0.8895 (0.9430) Acc D Fake: 0.000%
Loss D: 1.020
Loss G: 0.5437 (0.5043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.1151 (0.4601) Acc D Real: 100.000%
Loss D Fake: 0.8733 (0.9425) Acc D Fake: 0.000%
Loss D: 0.988
Loss G: 0.5560 (0.5047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.1204 (0.4577) Acc D Real: 100.000%
Loss D Fake: 0.8549 (0.9419) Acc D Fake: 0.000%
Loss D: 0.975
Loss G: 0.5680 (0.5051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.1327 (0.4554) Acc D Real: 100.000%
Loss D Fake: 0.8421 (0.9412) Acc D Fake: 0.000%
Loss D: 0.975
Loss G: 0.5735 (0.5056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.1204 (0.4530) Acc D Real: 100.000%
Loss D Fake: 0.8384 (0.9404) Acc D Fake: 0.000%
Loss D: 0.959
Loss G: 0.5775 (0.5061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.1300 (0.4507) Acc D Real: 100.000%
Loss D Fake: 0.8353 (0.9397) Acc D Fake: 0.000%
Loss D: 0.965
Loss G: 0.5800 (0.5066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.1439 (0.4486) Acc D Real: 100.000%
Loss D Fake: 0.8352 (0.9390) Acc D Fake: 0.000%
Loss D: 0.979
Loss G: 0.5818 (0.5072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.1196 (0.4463) Acc D Real: 100.000%
Loss D Fake: 0.8354 (0.9383) Acc D Fake: 0.011%
Loss D: 0.955
Loss G: 0.5846 (0.5077) Acc G: 99.977%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.1920 (0.4446) Acc D Real: 100.000%
Loss D Fake: 2.6019 (0.9497) Acc D Fake: 0.011%
Loss D: 2.794
Loss G: 0.5854 (0.5082) Acc G: 99.943%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.1199 (0.4424) Acc D Real: 100.000%
Loss D Fake: 0.8083 (0.9487) Acc D Fake: 0.045%
Loss D: 0.928
Loss G: 0.6092 (0.5089) Acc G: 99.929%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.2744 (0.4413) Acc D Real: 100.000%
Loss D Fake: 0.7851 (0.9476) Acc D Fake: 0.068%
Loss D: 1.060
Loss G: 0.6212 (0.5097) Acc G: 99.896%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.3250 (0.4405) Acc D Real: 100.000%
Loss D Fake: 0.7725 (0.9464) Acc D Fake: 0.101%
Loss D: 1.097
Loss G: 0.6288 (0.5105) Acc G: 99.863%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4457 (0.4405) Acc D Real: 100.000%
Loss D Fake: 0.7645 (0.9452) Acc D Fake: 0.133%
Loss D: 1.210
Loss G: 0.6341 (0.5113) Acc G: 99.831%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.5235 (0.4411) Acc D Real: 100.000%
Loss D Fake: 0.7591 (0.9440) Acc D Fake: 0.173%
Loss D: 1.283
Loss G: 0.6376 (0.5121) Acc G: 99.788%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.5660 (0.4419) Acc D Real: 100.000%
Loss D Fake: 0.7555 (0.9427) Acc D Fake: 0.216%
Loss D: 1.322
Loss G: 0.6400 (0.5130) Acc G: 99.745%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.5659 (0.4427) Acc D Real: 100.000%
Loss D Fake: 0.7533 (0.9415) Acc D Fake: 0.258%
Loss D: 1.319
Loss G: 0.6415 (0.5138) Acc G: 99.703%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.5823 (0.4436) Acc D Real: 100.000%
Loss D Fake: 0.7520 (0.9403) Acc D Fake: 0.300%
Loss D: 1.334
Loss G: 0.6423 (0.5146) Acc G: 99.662%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.5624 (0.4444) Acc D Real: 100.000%
Loss D Fake: 0.7515 (0.9390) Acc D Fake: 0.341%
Loss D: 1.314
Loss G: 0.6425 (0.5155) Acc G: 99.621%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.5848 (0.4453) Acc D Real: 100.000%
Loss D Fake: 0.7516 (0.9378) Acc D Fake: 0.382%
Loss D: 1.336
Loss G: 0.6421 (0.5163) Acc G: 99.581%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.5860 (0.4462) Acc D Real: 100.000%
Loss D Fake: 0.7525 (0.9367) Acc D Fake: 0.411%
Loss D: 1.339
Loss G: 0.6412 (0.5171) Acc G: 99.552%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.5742 (0.4470) Acc D Real: 99.997%
Loss D Fake: 0.7540 (0.9355) Acc D Fake: 0.440%
Loss D: 1.328
Loss G: 0.6398 (0.5178) Acc G: 99.534%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.5795 (0.4478) Acc D Real: 99.997%
Loss D Fake: 0.7563 (0.9344) Acc D Fake: 0.448%
Loss D: 1.336
Loss G: 0.6377 (0.5186) Acc G: 99.536%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.5898 (0.4487) Acc D Real: 99.997%
Loss D Fake: 0.7595 (0.9333) Acc D Fake: 0.445%
Loss D: 1.349
Loss G: 0.6347 (0.5193) Acc G: 99.539%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.5862 (0.4495) Acc D Real: 99.995%
Loss D Fake: 0.7639 (0.9322) Acc D Fake: 0.442%
Loss D: 1.350
Loss G: 0.6308 (0.5200) Acc G: 99.542%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.5902 (0.4504) Acc D Real: 99.995%
Loss D Fake: 0.7697 (0.9312) Acc D Fake: 0.439%
Loss D: 1.360
Loss G: 0.6257 (0.5207) Acc G: 99.545%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.5896 (0.4513) Acc D Real: 99.995%
Loss D Fake: 0.7771 (0.9303) Acc D Fake: 0.437%
Loss D: 1.367
Loss G: 0.6193 (0.5213) Acc G: 99.548%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.5886 (0.4521) Acc D Real: 99.993%
Loss D Fake: 0.7860 (0.9294) Acc D Fake: 0.434%
Loss D: 1.375
Loss G: 0.6116 (0.5218) Acc G: 99.551%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.5894 (0.4529) Acc D Real: 99.993%
Loss D Fake: 0.7963 (0.9286) Acc D Fake: 0.432%
Loss D: 1.386
Loss G: 0.6030 (0.5223) Acc G: 99.553%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.5791 (0.4537) Acc D Real: 99.993%
Loss D Fake: 0.8076 (0.9279) Acc D Fake: 0.429%
Loss D: 1.387
Loss G: 0.5937 (0.5228) Acc G: 99.556%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.5878 (0.4545) Acc D Real: 99.993%
Loss D Fake: 0.8196 (0.9272) Acc D Fake: 0.426%
Loss D: 1.407
Loss G: 0.5841 (0.5231) Acc G: 99.559%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.5875 (0.4553) Acc D Real: 99.993%
Loss D Fake: 0.8322 (0.9267) Acc D Fake: 0.424%
Loss D: 1.420
Loss G: 0.5743 (0.5234) Acc G: 99.561%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.5849 (0.4561) Acc D Real: 99.993%
Loss D Fake: 0.8451 (0.9262) Acc D Fake: 0.421%
Loss D: 1.430
Loss G: 0.5646 (0.5237) Acc G: 99.564%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.5909 (0.4568) Acc D Real: 99.993%
Loss D Fake: 0.8583 (0.9258) Acc D Fake: 0.419%
Loss D: 1.449
Loss G: 0.5549 (0.5239) Acc G: 99.566%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.5839 (0.4576) Acc D Real: 99.993%
Loss D Fake: 0.8718 (0.9255) Acc D Fake: 0.416%
Loss D: 1.456
Loss G: 0.5454 (0.5240) Acc G: 99.569%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.5751 (0.4583) Acc D Real: 99.993%
Loss D Fake: 0.8857 (0.9252) Acc D Fake: 0.414%
Loss D: 1.461
Loss G: 0.5360 (0.5240) Acc G: 99.572%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.5818 (0.4590) Acc D Real: 99.993%
Loss D Fake: 0.9002 (0.9251) Acc D Fake: 0.412%
Loss D: 1.482
Loss G: 0.5265 (0.5241) Acc G: 99.574%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.5907 (0.4597) Acc D Real: 99.993%
Loss D Fake: 0.9155 (0.9250) Acc D Fake: 0.409%
Loss D: 1.506
Loss G: 0.5170 (0.5240) Acc G: 99.576%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.5867 (0.4605) Acc D Real: 99.993%
Loss D Fake: 0.9323 (0.9251) Acc D Fake: 0.407%
Loss D: 1.519
Loss G: 0.5070 (0.5239) Acc G: 99.579%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.5856 (0.4612) Acc D Real: 99.993%
Loss D Fake: 0.9514 (0.9252) Acc D Fake: 0.405%
Loss D: 1.537
Loss G: 0.4964 (0.5238) Acc G: 99.581%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.5769 (0.4618) Acc D Real: 99.994%
Loss D Fake: 0.9742 (0.9255) Acc D Fake: 0.402%
Loss D: 1.551
Loss G: 0.4846 (0.5235) Acc G: 99.584%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.5837 (0.4625) Acc D Real: 99.994%
Loss D Fake: 1.0030 (0.9259) Acc D Fake: 0.400%
Loss D: 1.587
Loss G: 0.4710 (0.5232) Acc G: 99.586%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.5854 (0.4632) Acc D Real: 99.994%
Loss D Fake: 1.0416 (0.9266) Acc D Fake: 0.398%
Loss D: 1.627
Loss G: 0.4552 (0.5229) Acc G: 99.588%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.5740 (0.4638) Acc D Real: 99.994%
Loss D Fake: 1.0941 (0.9275) Acc D Fake: 0.396%
Loss D: 1.668
Loss G: 0.4384 (0.5224) Acc G: 99.591%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.5738 (0.4644) Acc D Real: 99.993%
Loss D Fake: 1.1671 (0.9288) Acc D Fake: 0.393%
Loss D: 1.741
Loss G: 0.4290 (0.5219) Acc G: 99.593%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.5883 (0.4651) Acc D Real: 99.993%
Loss D Fake: 1.1610 (0.9301) Acc D Fake: 0.391%
Loss D: 1.749
Loss G: 0.4294 (0.5214) Acc G: 99.595%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.5812 (0.4657) Acc D Real: 99.993%
Loss D Fake: 1.1389 (0.9313) Acc D Fake: 0.389%
Loss D: 1.720
Loss G: 0.4328 (0.5209) Acc G: 99.597%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.5758 (0.4663) Acc D Real: 99.993%
Loss D Fake: 1.1237 (0.9323) Acc D Fake: 0.387%
Loss D: 1.700
Loss G: 0.4369 (0.5204) Acc G: 99.599%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.5904 (0.4670) Acc D Real: 99.993%
Loss D Fake: 1.1111 (0.9333) Acc D Fake: 0.385%
Loss D: 1.701
Loss G: 0.4411 (0.5200) Acc G: 99.602%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.5875 (0.4677) Acc D Real: 99.993%
Loss D Fake: 1.1007 (0.9342) Acc D Fake: 0.383%
Loss D: 1.688
Loss G: 0.4448 (0.5196) Acc G: 99.604%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.5910 (0.4683) Acc D Real: 99.993%
Loss D Fake: 1.0930 (0.9350) Acc D Fake: 0.381%
Loss D: 1.684
Loss G: 0.4480 (0.5192) Acc G: 99.606%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.5940 (0.4690) Acc D Real: 99.993%
Loss D Fake: 1.0879 (0.9358) Acc D Fake: 0.379%
Loss D: 1.682
Loss G: 0.4503 (0.5189) Acc G: 99.608%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.5869 (0.4696) Acc D Real: 99.993%
Loss D Fake: 1.0855 (0.9366) Acc D Fake: 0.377%
Loss D: 1.672
Loss G: 0.4518 (0.5185) Acc G: 99.610%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.5901 (0.4702) Acc D Real: 99.993%
Loss D Fake: 1.0860 (0.9374) Acc D Fake: 0.375%
Loss D: 1.676
Loss G: 0.4525 (0.5182) Acc G: 99.612%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.5891 (0.4709) Acc D Real: 99.993%
Loss D Fake: 1.0890 (0.9382) Acc D Fake: 0.381%
Loss D: 1.678
Loss G: 0.4523 (0.5178) Acc G: 99.614%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.5954 (0.4715) Acc D Real: 99.993%
Loss D Fake: 1.0948 (0.9390) Acc D Fake: 0.397%
Loss D: 1.690
Loss G: 0.4513 (0.5175) Acc G: 99.607%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.5961 (0.4722) Acc D Real: 99.993%
Loss D Fake: 1.1037 (0.9399) Acc D Fake: 0.421%
Loss D: 1.700
Loss G: 0.4494 (0.5171) Acc G: 99.592%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.5891 (0.4728) Acc D Real: 99.993%
Loss D Fake: 1.1159 (0.9408) Acc D Fake: 0.453%
Loss D: 1.705
Loss G: 0.4465 (0.5167) Acc G: 99.569%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.5966 (0.4734) Acc D Real: 99.993%
Loss D Fake: 1.1316 (0.9418) Acc D Fake: 0.493%
Loss D: 1.728
Loss G: 0.4426 (0.5164) Acc G: 99.519%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.5925 (0.4740) Acc D Real: 99.993%
Loss D Fake: 1.1518 (0.9428) Acc D Fake: 0.525%
Loss D: 1.744
Loss G: 0.4377 (0.5160) Acc G: 99.471%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.5961 (0.4746) Acc D Real: 99.993%
Loss D Fake: 1.1764 (0.9440) Acc D Fake: 0.556%
Loss D: 1.772
Loss G: 0.4316 (0.5155) Acc G: 99.423%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.5971 (0.4752) Acc D Real: 99.993%
Loss D Fake: 1.2050 (0.9453) Acc D Fake: 0.587%
Loss D: 1.802
Loss G: 0.4247 (0.5151) Acc G: 99.384%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.6017 (0.4759) Acc D Real: 99.993%
Loss D Fake: 1.2363 (0.9468) Acc D Fake: 0.615%
Loss D: 1.838
Loss G: 0.4171 (0.5146) Acc G: 99.337%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.5984 (0.4765) Acc D Real: 99.993%
Loss D Fake: 1.2679 (0.9484) Acc D Fake: 0.645%
Loss D: 1.866
Loss G: 0.4094 (0.5141) Acc G: 99.290%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.5996 (0.4771) Acc D Real: 99.993%
Loss D Fake: 1.2968 (0.9501) Acc D Fake: 0.675%
Loss D: 1.896
Loss G: 0.4021 (0.5135) Acc G: 99.252%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.6007 (0.4777) Acc D Real: 99.993%
Loss D Fake: 1.3197 (0.9520) Acc D Fake: 0.704%
Loss D: 1.920
Loss G: 0.3960 (0.5129) Acc G: 99.214%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.6020 (0.4783) Acc D Real: 99.993%
Loss D Fake: 1.3331 (0.9538) Acc D Fake: 0.726%
Loss D: 1.935
Loss G: 0.3922 (0.5123) Acc G: 99.185%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.6026 (0.4789) Acc D Real: 99.993%
Loss D Fake: 1.3329 (0.9557) Acc D Fake: 0.747%
Loss D: 1.935
Loss G: 0.3923 (0.5117) Acc G: 99.157%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.6016 (0.4795) Acc D Real: 99.993%
Loss D Fake: 1.3150 (0.9574) Acc D Fake: 0.767%
Loss D: 1.917
Loss G: 0.3975 (0.5112) Acc G: 99.128%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.6086 (0.4802) Acc D Real: 99.993%
Loss D Fake: 1.2792 (0.9590) Acc D Fake: 0.795%
Loss D: 1.888
Loss G: 0.4082 (0.5107) Acc G: 99.084%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.6087 (0.4808) Acc D Real: 99.993%
Loss D Fake: 1.2317 (0.9603) Acc D Fake: 0.832%
Loss D: 1.840
Loss G: 0.4222 (0.5103) Acc G: 99.032%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.6085 (0.4814) Acc D Real: 99.993%
Loss D Fake: 1.1827 (0.9614) Acc D Fake: 0.884%
Loss D: 1.791
Loss G: 0.4365 (0.5099) Acc G: 98.981%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.6104 (0.4820) Acc D Real: 99.994%
Loss D Fake: 1.1395 (0.9622) Acc D Fake: 0.935%
Loss D: 1.750
Loss G: 0.4492 (0.5096) Acc G: 98.938%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.6102 (0.4826) Acc D Real: 99.994%
Loss D Fake: 1.1046 (0.9629) Acc D Fake: 0.986%
Loss D: 1.715
Loss G: 0.4594 (0.5094) Acc G: 98.887%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.6131 (0.4832) Acc D Real: 99.994%
Loss D Fake: 1.0773 (0.9635) Acc D Fake: 1.037%
Loss D: 1.690
Loss G: 0.4674 (0.5092) Acc G: 98.837%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.6127 (0.4839) Acc D Real: 99.994%
Loss D Fake: 1.0562 (0.9639) Acc D Fake: 1.079%
Loss D: 1.669
Loss G: 0.4736 (0.5090) Acc G: 98.788%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.6131 (0.4845) Acc D Real: 99.994%
Loss D Fake: 1.0398 (0.9643) Acc D Fake: 1.129%
Loss D: 1.653
Loss G: 0.4786 (0.5089) Acc G: 98.746%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.6161 (0.4851) Acc D Real: 99.994%
Loss D Fake: 1.0268 (0.9646) Acc D Fake: 1.170%
Loss D: 1.643
Loss G: 0.4825 (0.5087) Acc G: 98.698%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.6130 (0.4857) Acc D Real: 99.994%
Loss D Fake: 1.0164 (0.9648) Acc D Fake: 1.211%
Loss D: 1.629
Loss G: 0.4858 (0.5086) Acc G: 98.665%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.6128 (0.4863) Acc D Real: 99.994%
Loss D Fake: 1.0079 (0.9650) Acc D Fake: 1.244%
Loss D: 1.621
Loss G: 0.4886 (0.5085) Acc G: 98.625%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.6178 (0.4869) Acc D Real: 99.994%
Loss D Fake: 1.0007 (0.9652) Acc D Fake: 1.285%
Loss D: 1.619
Loss G: 0.4910 (0.5085) Acc G: 98.585%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.6147 (0.4875) Acc D Real: 99.994%
Loss D Fake: 0.9946 (0.9653) Acc D Fake: 1.325%
Loss D: 1.609
Loss G: 0.4932 (0.5084) Acc G: 98.546%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.6151 (0.4880) Acc D Real: 99.994%
Loss D Fake: 0.9892 (0.9654) Acc D Fake: 1.364%
Loss D: 1.604
Loss G: 0.4952 (0.5083) Acc G: 98.507%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.6163 (0.4886) Acc D Real: 99.994%
Loss D Fake: 0.9844 (0.9655) Acc D Fake: 1.404%
Loss D: 1.601
Loss G: 0.4970 (0.5083) Acc G: 98.468%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.6156 (0.4892) Acc D Real: 99.994%
Loss D Fake: 0.9801 (0.9656) Acc D Fake: 1.443%
Loss D: 1.596
Loss G: 0.4987 (0.5082) Acc G: 98.430%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.6129 (0.4898) Acc D Real: 99.994%
Loss D Fake: 0.9761 (0.9656) Acc D Fake: 1.481%
Loss D: 1.589
Loss G: 0.5003 (0.5082) Acc G: 98.392%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.6143 (0.4903) Acc D Real: 99.994%
Loss D Fake: 0.9724 (0.9656) Acc D Fake: 1.519%
Loss D: 1.587
Loss G: 0.5018 (0.5082) Acc G: 98.354%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.6154 (0.4909) Acc D Real: 99.994%
Loss D Fake: 0.9689 (0.9656) Acc D Fake: 1.557%
Loss D: 1.584
Loss G: 0.5033 (0.5081) Acc G: 98.324%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.6167 (0.4914) Acc D Real: 99.994%
Loss D Fake: 0.9656 (0.9656) Acc D Fake: 1.587%
Loss D: 1.582
Loss G: 0.5047 (0.5081) Acc G: 98.295%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.6147 (0.4920) Acc D Real: 99.994%
Loss D Fake: 0.9624 (0.9656) Acc D Fake: 1.595%
Loss D: 1.577
Loss G: 0.5061 (0.5081) Acc G: 98.287%
LR: 2.000e-04
Best Loss 100000000000.000 to 0.983
Epoch: 2/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.6175 (0.6167) Acc D Real: 100.000%
Loss D Fake: 0.9565 (0.9579) Acc D Fake: 8.333%
Loss D: 1.574
Loss G: 0.5087 (0.5081) Acc G: 91.667%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.6154 (0.6163) Acc D Real: 100.000%
Loss D Fake: 0.9536 (0.9565) Acc D Fake: 7.778%
Loss D: 1.569
Loss G: 0.5100 (0.5087) Acc G: 92.222%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.6172 (0.6165) Acc D Real: 100.000%
Loss D Fake: 0.9509 (0.9551) Acc D Fake: 7.500%
Loss D: 1.568
Loss G: 0.5113 (0.5094) Acc G: 92.500%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.6176 (0.6167) Acc D Real: 100.000%
Loss D Fake: 0.9482 (0.9537) Acc D Fake: 7.333%
Loss D: 1.566
Loss G: 0.5126 (0.5100) Acc G: 92.667%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.6179 (0.6169) Acc D Real: 100.000%
Loss D Fake: 0.9456 (0.9523) Acc D Fake: 7.222%
Loss D: 1.563
Loss G: 0.5138 (0.5106) Acc G: 92.778%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.6182 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9430 (0.9510) Acc D Fake: 7.143%
Loss D: 1.561
Loss G: 0.5150 (0.5113) Acc G: 92.857%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.6167 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9404 (0.9497) Acc D Fake: 7.083%
Loss D: 1.557
Loss G: 0.5162 (0.5119) Acc G: 92.917%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.6170 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9380 (0.9484) Acc D Fake: 7.037%
Loss D: 1.555
Loss G: 0.5174 (0.5125) Acc G: 92.963%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.6178 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9355 (0.9471) Acc D Fake: 7.000%
Loss D: 1.553
Loss G: 0.5186 (0.5131) Acc G: 93.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.6168 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9331 (0.9458) Acc D Fake: 6.970%
Loss D: 1.550
Loss G: 0.5198 (0.5137) Acc G: 93.030%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.6188 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9308 (0.9446) Acc D Fake: 6.944%
Loss D: 1.550
Loss G: 0.5210 (0.5143) Acc G: 93.056%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.6176 (0.6173) Acc D Real: 100.000%
Loss D Fake: 0.9284 (0.9433) Acc D Fake: 6.923%
Loss D: 1.546
Loss G: 0.5221 (0.5149) Acc G: 93.077%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.6172 (0.6173) Acc D Real: 100.000%
Loss D Fake: 0.9261 (0.9421) Acc D Fake: 6.905%
Loss D: 1.543
Loss G: 0.5233 (0.5155) Acc G: 93.095%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.6166 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9239 (0.9409) Acc D Fake: 6.889%
Loss D: 1.540
Loss G: 0.5244 (0.5161) Acc G: 93.111%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.6173 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9216 (0.9397) Acc D Fake: 6.875%
Loss D: 1.539
Loss G: 0.5256 (0.5167) Acc G: 93.125%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.6165 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9194 (0.9385) Acc D Fake: 6.863%
Loss D: 1.536
Loss G: 0.5267 (0.5173) Acc G: 93.137%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.6164 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9173 (0.9373) Acc D Fake: 6.852%
Loss D: 1.534
Loss G: 0.5278 (0.5179) Acc G: 93.148%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.6181 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9151 (0.9361) Acc D Fake: 6.842%
Loss D: 1.533
Loss G: 0.5289 (0.5185) Acc G: 93.158%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.6182 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9130 (0.9350) Acc D Fake: 6.833%
Loss D: 1.531
Loss G: 0.5300 (0.5190) Acc G: 93.167%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.6156 (0.6172) Acc D Real: 100.000%
Loss D Fake: 0.9109 (0.9338) Acc D Fake: 6.825%
Loss D: 1.527
Loss G: 0.5311 (0.5196) Acc G: 93.175%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.6168 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9089 (0.9327) Acc D Fake: 6.742%
Loss D: 1.526
Loss G: 0.5322 (0.5202) Acc G: 93.258%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.6155 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9068 (0.9316) Acc D Fake: 6.667%
Loss D: 1.522
Loss G: 0.5333 (0.5208) Acc G: 93.333%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.6168 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.9048 (0.9305) Acc D Fake: 6.597%
Loss D: 1.522
Loss G: 0.5344 (0.5213) Acc G: 93.403%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.6164 (0.6170) Acc D Real: 100.000%
Loss D Fake: 0.9028 (0.9294) Acc D Fake: 6.533%
Loss D: 1.519
Loss G: 0.5355 (0.5219) Acc G: 93.467%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.6172 (0.6170) Acc D Real: 100.000%
Loss D Fake: 0.9009 (0.9283) Acc D Fake: 6.474%
Loss D: 1.518
Loss G: 0.5365 (0.5225) Acc G: 93.526%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.6181 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.8989 (0.9272) Acc D Fake: 6.420%
Loss D: 1.517
Loss G: 0.5376 (0.5230) Acc G: 93.580%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.6165 (0.6171) Acc D Real: 100.000%
Loss D Fake: 0.8970 (0.9261) Acc D Fake: 6.310%
Loss D: 1.514
Loss G: 0.5386 (0.5236) Acc G: 93.690%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.6152 (0.6170) Acc D Real: 100.000%
Loss D Fake: 0.8951 (0.9250) Acc D Fake: 6.149%
Loss D: 1.510
Loss G: 0.5397 (0.5241) Acc G: 93.851%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.6146 (0.6169) Acc D Real: 100.000%
Loss D Fake: 0.8932 (0.9240) Acc D Fake: 6.000%
Loss D: 1.508
Loss G: 0.5407 (0.5247) Acc G: 94.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.6165 (0.6169) Acc D Real: 100.000%
Loss D Fake: 0.8914 (0.9229) Acc D Fake: 5.860%
Loss D: 1.508
Loss G: 0.5418 (0.5252) Acc G: 94.140%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.6159 (0.6169) Acc D Real: 100.000%
Loss D Fake: 0.8895 (0.9219) Acc D Fake: 5.729%
Loss D: 1.505
Loss G: 0.5428 (0.5258) Acc G: 94.271%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.6162 (0.6168) Acc D Real: 100.000%
Loss D Fake: 0.8877 (0.9208) Acc D Fake: 5.606%
Loss D: 1.504
Loss G: 0.5438 (0.5263) Acc G: 94.394%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.6145 (0.6168) Acc D Real: 100.000%
Loss D Fake: 0.8859 (0.9198) Acc D Fake: 5.490%
Loss D: 1.500
Loss G: 0.5448 (0.5269) Acc G: 94.510%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.6138 (0.6167) Acc D Real: 100.000%
Loss D Fake: 0.8842 (0.9188) Acc D Fake: 5.333%
Loss D: 1.498
Loss G: 0.5458 (0.5274) Acc G: 94.667%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.6157 (0.6167) Acc D Real: 100.000%
Loss D Fake: 0.8824 (0.9178) Acc D Fake: 5.185%
Loss D: 1.498
Loss G: 0.5468 (0.5280) Acc G: 94.815%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.6162 (0.6167) Acc D Real: 100.000%
Loss D Fake: 0.8807 (0.9168) Acc D Fake: 5.045%
Loss D: 1.497
Loss G: 0.5478 (0.5285) Acc G: 94.955%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.6148 (0.6166) Acc D Real: 100.000%
Loss D Fake: 0.8790 (0.9158) Acc D Fake: 4.912%
Loss D: 1.494
Loss G: 0.5488 (0.5290) Acc G: 95.088%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.6163 (0.6166) Acc D Real: 100.000%
Loss D Fake: 0.8773 (0.9148) Acc D Fake: 4.786%
Loss D: 1.494
Loss G: 0.5498 (0.5296) Acc G: 95.214%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.6154 (0.6166) Acc D Real: 100.000%
Loss D Fake: 0.8756 (0.9138) Acc D Fake: 4.667%
Loss D: 1.491
Loss G: 0.5508 (0.5301) Acc G: 95.333%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.6134 (0.6165) Acc D Real: 100.000%
Loss D Fake: 0.8739 (0.9128) Acc D Fake: 4.553%
Loss D: 1.487
Loss G: 0.5518 (0.5306) Acc G: 95.447%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.6152 (0.6165) Acc D Real: 100.000%
Loss D Fake: 0.8722 (0.9119) Acc D Fake: 4.444%
Loss D: 1.487
Loss G: 0.5528 (0.5311) Acc G: 95.556%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.6145 (0.6164) Acc D Real: 100.000%
Loss D Fake: 0.8706 (0.9109) Acc D Fake: 4.341%
Loss D: 1.485
Loss G: 0.5537 (0.5317) Acc G: 95.659%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.6131 (0.6163) Acc D Real: 100.000%
Loss D Fake: 0.8690 (0.9100) Acc D Fake: 4.242%
Loss D: 1.482
Loss G: 0.5547 (0.5322) Acc G: 95.758%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.6141 (0.6163) Acc D Real: 100.000%
Loss D Fake: 0.8674 (0.9090) Acc D Fake: 4.148%
Loss D: 1.482
Loss G: 0.5557 (0.5327) Acc G: 95.852%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.6133 (0.6162) Acc D Real: 100.000%
Loss D Fake: 0.8658 (0.9081) Acc D Fake: 4.058%
Loss D: 1.479
Loss G: 0.5566 (0.5332) Acc G: 95.942%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.6134 (0.6162) Acc D Real: 100.000%
Loss D Fake: 0.8642 (0.9071) Acc D Fake: 3.972%
Loss D: 1.478
Loss G: 0.5576 (0.5338) Acc G: 96.028%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.6136 (0.6161) Acc D Real: 100.000%
Loss D Fake: 0.8627 (0.9062) Acc D Fake: 3.889%
Loss D: 1.476
Loss G: 0.5585 (0.5343) Acc G: 96.111%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.6137 (0.6161) Acc D Real: 100.000%
Loss D Fake: 0.8611 (0.9053) Acc D Fake: 3.810%
Loss D: 1.475
Loss G: 0.5595 (0.5348) Acc G: 96.190%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.6126 (0.6160) Acc D Real: 100.000%
Loss D Fake: 0.8596 (0.9044) Acc D Fake: 3.733%
Loss D: 1.472
Loss G: 0.5604 (0.5353) Acc G: 96.267%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.6135 (0.6159) Acc D Real: 100.000%
Loss D Fake: 0.8581 (0.9035) Acc D Fake: 3.660%
Loss D: 1.472
Loss G: 0.5613 (0.5358) Acc G: 96.340%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.6126 (0.6159) Acc D Real: 100.000%
Loss D Fake: 0.8566 (0.9026) Acc D Fake: 3.590%
Loss D: 1.469
Loss G: 0.5623 (0.5363) Acc G: 96.410%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.6118 (0.6158) Acc D Real: 100.000%
Loss D Fake: 0.8551 (0.9017) Acc D Fake: 3.522%
Loss D: 1.467
Loss G: 0.5632 (0.5368) Acc G: 96.478%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.6123 (0.6157) Acc D Real: 100.000%
Loss D Fake: 0.8536 (0.9008) Acc D Fake: 3.457%
Loss D: 1.466
Loss G: 0.5641 (0.5373) Acc G: 96.543%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.6126 (0.6157) Acc D Real: 100.000%
Loss D Fake: 0.8521 (0.8999) Acc D Fake: 3.394%
Loss D: 1.465
Loss G: 0.5651 (0.5378) Acc G: 96.606%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.6120 (0.6156) Acc D Real: 100.000%
Loss D Fake: 0.8507 (0.8990) Acc D Fake: 3.333%
Loss D: 1.463
Loss G: 0.5660 (0.5383) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.6120 (0.6156) Acc D Real: 100.000%
Loss D Fake: 0.8492 (0.8981) Acc D Fake: 3.275%
Loss D: 1.461
Loss G: 0.5669 (0.5388) Acc G: 96.725%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.6122 (0.6155) Acc D Real: 100.000%
Loss D Fake: 0.8478 (0.8973) Acc D Fake: 3.218%
Loss D: 1.460
Loss G: 0.5678 (0.5393) Acc G: 96.782%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.6111 (0.6154) Acc D Real: 100.000%
Loss D Fake: 0.8463 (0.8964) Acc D Fake: 3.164%
Loss D: 1.457
Loss G: 0.5687 (0.5398) Acc G: 96.836%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.6104 (0.6153) Acc D Real: 100.000%
Loss D Fake: 0.8449 (0.8956) Acc D Fake: 3.111%
Loss D: 1.455
Loss G: 0.5696 (0.5403) Acc G: 96.889%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.6106 (0.6153) Acc D Real: 100.000%
Loss D Fake: 0.8435 (0.8947) Acc D Fake: 3.060%
Loss D: 1.454
Loss G: 0.5705 (0.5408) Acc G: 96.940%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.6112 (0.6152) Acc D Real: 100.000%
Loss D Fake: 0.8421 (0.8939) Acc D Fake: 3.011%
Loss D: 1.453
Loss G: 0.5714 (0.5413) Acc G: 96.989%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.6094 (0.6151) Acc D Real: 100.000%
Loss D Fake: 0.8407 (0.8930) Acc D Fake: 2.963%
Loss D: 1.450
Loss G: 0.5723 (0.5418) Acc G: 97.037%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.6105 (0.6150) Acc D Real: 100.000%
Loss D Fake: 0.8394 (0.8922) Acc D Fake: 2.917%
Loss D: 1.450
Loss G: 0.5732 (0.5423) Acc G: 97.083%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.6091 (0.6149) Acc D Real: 100.000%
Loss D Fake: 0.8380 (0.8913) Acc D Fake: 2.872%
Loss D: 1.447
Loss G: 0.5741 (0.5428) Acc G: 97.128%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.6101 (0.6149) Acc D Real: 100.000%
Loss D Fake: 0.8367 (0.8905) Acc D Fake: 2.828%
Loss D: 1.447
Loss G: 0.5750 (0.5433) Acc G: 97.172%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.6095 (0.6148) Acc D Real: 100.000%
Loss D Fake: 0.8354 (0.8897) Acc D Fake: 2.786%
Loss D: 1.445
Loss G: 0.5759 (0.5438) Acc G: 97.214%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.6086 (0.6147) Acc D Real: 100.000%
Loss D Fake: 0.8340 (0.8889) Acc D Fake: 2.745%
Loss D: 1.443
Loss G: 0.5768 (0.5443) Acc G: 97.255%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.6092 (0.6146) Acc D Real: 100.000%
Loss D Fake: 0.8327 (0.8881) Acc D Fake: 2.705%
Loss D: 1.442
Loss G: 0.5776 (0.5447) Acc G: 97.295%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.6092 (0.6145) Acc D Real: 100.000%
Loss D Fake: 0.8314 (0.8873) Acc D Fake: 2.667%
Loss D: 1.441
Loss G: 0.5785 (0.5452) Acc G: 97.333%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.6095 (0.6145) Acc D Real: 100.000%
Loss D Fake: 0.8301 (0.8864) Acc D Fake: 2.629%
Loss D: 1.440
Loss G: 0.5794 (0.5457) Acc G: 97.371%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.6089 (0.6144) Acc D Real: 100.000%
Loss D Fake: 0.8288 (0.8856) Acc D Fake: 2.593%
Loss D: 1.438
Loss G: 0.5803 (0.5462) Acc G: 97.407%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.6084 (0.6143) Acc D Real: 100.000%
Loss D Fake: 0.8275 (0.8848) Acc D Fake: 2.557%
Loss D: 1.436
Loss G: 0.5812 (0.5467) Acc G: 97.443%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.6084 (0.6142) Acc D Real: 100.000%
Loss D Fake: 0.8262 (0.8841) Acc D Fake: 2.523%
Loss D: 1.435
Loss G: 0.5821 (0.5471) Acc G: 97.477%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.6070 (0.6141) Acc D Real: 100.000%
Loss D Fake: 0.8249 (0.8833) Acc D Fake: 2.489%
Loss D: 1.432
Loss G: 0.5830 (0.5476) Acc G: 97.511%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.6073 (0.6140) Acc D Real: 100.000%
Loss D Fake: 0.8236 (0.8825) Acc D Fake: 2.456%
Loss D: 1.431
Loss G: 0.5838 (0.5481) Acc G: 97.544%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.6070 (0.6139) Acc D Real: 100.000%
Loss D Fake: 0.8223 (0.8817) Acc D Fake: 2.424%
Loss D: 1.429
Loss G: 0.5847 (0.5486) Acc G: 97.576%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.6069 (0.6139) Acc D Real: 100.000%
Loss D Fake: 0.8211 (0.8809) Acc D Fake: 2.393%
Loss D: 1.428
Loss G: 0.5856 (0.5490) Acc G: 97.607%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.6064 (0.6138) Acc D Real: 100.000%
Loss D Fake: 0.8198 (0.8801) Acc D Fake: 2.363%
Loss D: 1.426
Loss G: 0.5865 (0.5495) Acc G: 97.637%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.6059 (0.6137) Acc D Real: 100.000%
Loss D Fake: 0.8186 (0.8794) Acc D Fake: 2.333%
Loss D: 1.424
Loss G: 0.5873 (0.5500) Acc G: 97.667%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.6059 (0.6136) Acc D Real: 100.000%
Loss D Fake: 0.8173 (0.8786) Acc D Fake: 2.305%
Loss D: 1.423
Loss G: 0.5882 (0.5505) Acc G: 97.695%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.6060 (0.6135) Acc D Real: 100.000%
Loss D Fake: 0.8161 (0.8779) Acc D Fake: 2.276%
Loss D: 1.422
Loss G: 0.5891 (0.5509) Acc G: 97.724%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.6057 (0.6134) Acc D Real: 100.000%
Loss D Fake: 0.8149 (0.8771) Acc D Fake: 2.249%
Loss D: 1.421
Loss G: 0.5899 (0.5514) Acc G: 97.751%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.6055 (0.6133) Acc D Real: 100.000%
Loss D Fake: 0.8137 (0.8763) Acc D Fake: 2.222%
Loss D: 1.419
Loss G: 0.5908 (0.5519) Acc G: 97.778%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.6052 (0.6132) Acc D Real: 100.000%
Loss D Fake: 0.8125 (0.8756) Acc D Fake: 2.196%
Loss D: 1.418
Loss G: 0.5917 (0.5523) Acc G: 97.804%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.6050 (0.6131) Acc D Real: 100.000%
Loss D Fake: 0.8112 (0.8748) Acc D Fake: 2.171%
Loss D: 1.416
Loss G: 0.5925 (0.5528) Acc G: 97.829%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.6045 (0.6130) Acc D Real: 100.000%
Loss D Fake: 0.8100 (0.8741) Acc D Fake: 2.146%
Loss D: 1.414
Loss G: 0.5934 (0.5533) Acc G: 97.854%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.6044 (0.6129) Acc D Real: 100.000%
Loss D Fake: 0.8088 (0.8734) Acc D Fake: 2.121%
Loss D: 1.413
Loss G: 0.5943 (0.5537) Acc G: 97.879%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.6038 (0.6128) Acc D Real: 100.000%
Loss D Fake: 0.8076 (0.8726) Acc D Fake: 2.097%
Loss D: 1.411
Loss G: 0.5952 (0.5542) Acc G: 97.903%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.6035 (0.6127) Acc D Real: 100.000%
Loss D Fake: 0.8064 (0.8719) Acc D Fake: 2.074%
Loss D: 1.410
Loss G: 0.5960 (0.5547) Acc G: 97.926%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.6032 (0.6126) Acc D Real: 100.000%
Loss D Fake: 0.8052 (0.8711) Acc D Fake: 2.051%
Loss D: 1.408
Loss G: 0.5969 (0.5551) Acc G: 97.949%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.6029 (0.6125) Acc D Real: 100.000%
Loss D Fake: 0.8040 (0.8704) Acc D Fake: 2.029%
Loss D: 1.407
Loss G: 0.5978 (0.5556) Acc G: 97.971%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.6027 (0.6124) Acc D Real: 100.000%
Loss D Fake: 0.8028 (0.8697) Acc D Fake: 2.007%
Loss D: 1.406
Loss G: 0.5986 (0.5561) Acc G: 97.993%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.6025 (0.6123) Acc D Real: 100.000%
Loss D Fake: 0.8017 (0.8690) Acc D Fake: 1.986%
Loss D: 1.404
Loss G: 0.5995 (0.5565) Acc G: 98.014%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.6021 (0.6122) Acc D Real: 100.000%
Loss D Fake: 0.8005 (0.8682) Acc D Fake: 1.965%
Loss D: 1.403
Loss G: 0.6004 (0.5570) Acc G: 98.035%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.6020 (0.6121) Acc D Real: 100.000%
Loss D Fake: 0.7993 (0.8675) Acc D Fake: 1.944%
Loss D: 1.401
Loss G: 0.6012 (0.5574) Acc G: 98.056%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.6016 (0.6120) Acc D Real: 100.000%
Loss D Fake: 0.7981 (0.8668) Acc D Fake: 1.924%
Loss D: 1.400
Loss G: 0.6021 (0.5579) Acc G: 98.076%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.6013 (0.6118) Acc D Real: 100.000%
Loss D Fake: 0.7970 (0.8661) Acc D Fake: 1.905%
Loss D: 1.398
Loss G: 0.6030 (0.5584) Acc G: 98.095%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.6010 (0.6117) Acc D Real: 100.000%
Loss D Fake: 0.7958 (0.8654) Acc D Fake: 1.886%
Loss D: 1.397
Loss G: 0.6039 (0.5588) Acc G: 98.114%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.6006 (0.6116) Acc D Real: 100.000%
Loss D Fake: 0.7946 (0.8647) Acc D Fake: 1.867%
Loss D: 1.395
Loss G: 0.6048 (0.5593) Acc G: 98.133%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.6003 (0.6115) Acc D Real: 100.000%
Loss D Fake: 0.7934 (0.8640) Acc D Fake: 1.848%
Loss D: 1.394
Loss G: 0.6057 (0.5597) Acc G: 98.152%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.6000 (0.6114) Acc D Real: 100.000%
Loss D Fake: 0.7922 (0.8633) Acc D Fake: 1.830%
Loss D: 1.392
Loss G: 0.6066 (0.5602) Acc G: 98.170%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.5997 (0.6113) Acc D Real: 100.000%
Loss D Fake: 0.7910 (0.8626) Acc D Fake: 1.812%
Loss D: 1.391
Loss G: 0.6075 (0.5607) Acc G: 98.188%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.5993 (0.6112) Acc D Real: 100.000%
Loss D Fake: 0.7898 (0.8619) Acc D Fake: 1.795%
Loss D: 1.389
Loss G: 0.6084 (0.5611) Acc G: 98.205%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.5990 (0.6111) Acc D Real: 100.000%
Loss D Fake: 0.7887 (0.8612) Acc D Fake: 1.778%
Loss D: 1.388
Loss G: 0.6093 (0.5616) Acc G: 98.222%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.5988 (0.6109) Acc D Real: 100.000%
Loss D Fake: 0.7875 (0.8605) Acc D Fake: 1.761%
Loss D: 1.386
Loss G: 0.6103 (0.5620) Acc G: 98.239%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.5984 (0.6108) Acc D Real: 100.000%
Loss D Fake: 0.7863 (0.8598) Acc D Fake: 1.745%
Loss D: 1.385
Loss G: 0.6112 (0.5625) Acc G: 98.255%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.5981 (0.6107) Acc D Real: 100.000%
Loss D Fake: 0.7851 (0.8591) Acc D Fake: 1.728%
Loss D: 1.383
Loss G: 0.6121 (0.5630) Acc G: 98.272%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.5976 (0.6106) Acc D Real: 100.000%
Loss D Fake: 0.7840 (0.8584) Acc D Fake: 1.713%
Loss D: 1.382
Loss G: 0.6130 (0.5634) Acc G: 98.287%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.5977 (0.6105) Acc D Real: 100.000%
Loss D Fake: 0.7828 (0.8577) Acc D Fake: 1.697%
Loss D: 1.380
Loss G: 0.6139 (0.5639) Acc G: 98.303%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.5970 (0.6103) Acc D Real: 100.000%
Loss D Fake: 0.7816 (0.8570) Acc D Fake: 1.682%
Loss D: 1.379
Loss G: 0.6148 (0.5643) Acc G: 98.318%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.5966 (0.6102) Acc D Real: 100.000%
Loss D Fake: 0.7805 (0.8563) Acc D Fake: 1.667%
Loss D: 1.377
Loss G: 0.6157 (0.5648) Acc G: 98.333%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.5963 (0.6101) Acc D Real: 100.000%
Loss D Fake: 0.7793 (0.8557) Acc D Fake: 1.652%
Loss D: 1.376
Loss G: 0.6167 (0.5653) Acc G: 98.348%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.5960 (0.6100) Acc D Real: 100.000%
Loss D Fake: 0.7781 (0.8550) Acc D Fake: 1.637%
Loss D: 1.374
Loss G: 0.6176 (0.5657) Acc G: 98.363%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.5956 (0.6099) Acc D Real: 100.000%
Loss D Fake: 0.7770 (0.8543) Acc D Fake: 1.623%
Loss D: 1.373
Loss G: 0.6186 (0.5662) Acc G: 98.377%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.5955 (0.6097) Acc D Real: 100.000%
Loss D Fake: 0.7758 (0.8536) Acc D Fake: 1.609%
Loss D: 1.371
Loss G: 0.6195 (0.5666) Acc G: 98.391%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.5947 (0.6096) Acc D Real: 100.000%
Loss D Fake: 0.7746 (0.8530) Acc D Fake: 1.595%
Loss D: 1.369
Loss G: 0.6204 (0.5671) Acc G: 98.405%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.5946 (0.6095) Acc D Real: 100.000%
Loss D Fake: 0.7734 (0.8523) Acc D Fake: 1.582%
Loss D: 1.368
Loss G: 0.6214 (0.5676) Acc G: 98.418%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.5938 (0.6093) Acc D Real: 100.000%
Loss D Fake: 0.7722 (0.8516) Acc D Fake: 1.569%
Loss D: 1.366
Loss G: 0.6224 (0.5680) Acc G: 98.431%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.5941 (0.6092) Acc D Real: 100.000%
Loss D Fake: 0.7710 (0.8509) Acc D Fake: 1.556%
Loss D: 1.365
Loss G: 0.6233 (0.5685) Acc G: 98.444%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.5937 (0.6091) Acc D Real: 100.000%
Loss D Fake: 0.7699 (0.8503) Acc D Fake: 1.543%
Loss D: 1.364
Loss G: 0.6243 (0.5689) Acc G: 98.457%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.5934 (0.6090) Acc D Real: 100.000%
Loss D Fake: 0.7687 (0.8496) Acc D Fake: 1.530%
Loss D: 1.362
Loss G: 0.6253 (0.5694) Acc G: 98.470%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.5924 (0.6088) Acc D Real: 100.000%
Loss D Fake: 0.7675 (0.8489) Acc D Fake: 1.518%
Loss D: 1.360
Loss G: 0.6263 (0.5699) Acc G: 98.482%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.5923 (0.6087) Acc D Real: 100.000%
Loss D Fake: 0.7663 (0.8483) Acc D Fake: 1.505%
Loss D: 1.359
Loss G: 0.6273 (0.5703) Acc G: 98.495%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.5925 (0.6086) Acc D Real: 100.000%
Loss D Fake: 0.7651 (0.8476) Acc D Fake: 1.493%
Loss D: 1.358
Loss G: 0.6283 (0.5708) Acc G: 98.507%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.5917 (0.6084) Acc D Real: 100.000%
Loss D Fake: 0.7639 (0.8469) Acc D Fake: 1.481%
Loss D: 1.356
Loss G: 0.6293 (0.5713) Acc G: 98.519%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.5915 (0.6083) Acc D Real: 100.000%
Loss D Fake: 0.7627 (0.8463) Acc D Fake: 1.470%
Loss D: 1.354
Loss G: 0.6303 (0.5717) Acc G: 98.530%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.5904 (0.6082) Acc D Real: 100.000%
Loss D Fake: 0.7615 (0.8456) Acc D Fake: 1.458%
Loss D: 1.352
Loss G: 0.6313 (0.5722) Acc G: 98.542%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.5903 (0.6080) Acc D Real: 100.000%
Loss D Fake: 0.7603 (0.8449) Acc D Fake: 1.447%
Loss D: 1.351
Loss G: 0.6323 (0.5726) Acc G: 98.553%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.5898 (0.6079) Acc D Real: 100.000%
Loss D Fake: 0.7590 (0.8443) Acc D Fake: 1.436%
Loss D: 1.349
Loss G: 0.6334 (0.5731) Acc G: 98.564%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.5894 (0.6077) Acc D Real: 100.000%
Loss D Fake: 0.7578 (0.8436) Acc D Fake: 1.425%
Loss D: 1.347
Loss G: 0.6344 (0.5736) Acc G: 98.575%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.5890 (0.6076) Acc D Real: 100.000%
Loss D Fake: 0.7565 (0.8430) Acc D Fake: 1.414%
Loss D: 1.346
Loss G: 0.6355 (0.5741) Acc G: 98.586%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.5899 (0.6075) Acc D Real: 100.000%
Loss D Fake: 0.7553 (0.8423) Acc D Fake: 1.404%
Loss D: 1.345
Loss G: 0.6365 (0.5745) Acc G: 98.596%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.5877 (0.6073) Acc D Real: 100.000%
Loss D Fake: 0.7540 (0.8416) Acc D Fake: 1.393%
Loss D: 1.342
Loss G: 0.6376 (0.5750) Acc G: 98.607%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.5880 (0.6072) Acc D Real: 100.000%
Loss D Fake: 0.7528 (0.8410) Acc D Fake: 1.383%
Loss D: 1.341
Loss G: 0.6387 (0.5755) Acc G: 98.617%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.5876 (0.6070) Acc D Real: 100.000%
Loss D Fake: 0.7515 (0.8403) Acc D Fake: 1.373%
Loss D: 1.339
Loss G: 0.6398 (0.5759) Acc G: 98.627%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.5870 (0.6069) Acc D Real: 100.000%
Loss D Fake: 0.7502 (0.8397) Acc D Fake: 1.363%
Loss D: 1.337
Loss G: 0.6409 (0.5764) Acc G: 98.637%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.5870 (0.6067) Acc D Real: 100.000%
Loss D Fake: 0.7489 (0.8390) Acc D Fake: 1.353%
Loss D: 1.336
Loss G: 0.6421 (0.5769) Acc G: 98.635%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.5864 (0.6066) Acc D Real: 100.000%
Loss D Fake: 0.7476 (0.8384) Acc D Fake: 1.367%
Loss D: 1.334
Loss G: 0.6432 (0.5774) Acc G: 98.621%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.5856 (0.6064) Acc D Real: 100.000%
Loss D Fake: 0.7463 (0.8377) Acc D Fake: 1.381%
Loss D: 1.332
Loss G: 0.6444 (0.5778) Acc G: 98.607%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.5863 (0.6063) Acc D Real: 100.000%
Loss D Fake: 0.7450 (0.8370) Acc D Fake: 1.395%
Loss D: 1.331
Loss G: 0.6455 (0.5783) Acc G: 98.582%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.5843 (0.6061) Acc D Real: 100.000%
Loss D Fake: 0.7437 (0.8364) Acc D Fake: 1.420%
Loss D: 1.328
Loss G: 0.6467 (0.5788) Acc G: 98.556%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.5838 (0.6060) Acc D Real: 100.000%
Loss D Fake: 0.7424 (0.8357) Acc D Fake: 1.445%
Loss D: 1.326
Loss G: 0.6479 (0.5793) Acc G: 98.531%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.5841 (0.6058) Acc D Real: 100.000%
Loss D Fake: 0.7410 (0.8351) Acc D Fake: 1.470%
Loss D: 1.325
Loss G: 0.6491 (0.5798) Acc G: 98.507%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.5828 (0.6057) Acc D Real: 100.000%
Loss D Fake: 0.7396 (0.8344) Acc D Fake: 1.494%
Loss D: 1.322
Loss G: 0.6504 (0.5803) Acc G: 98.471%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.5840 (0.6055) Acc D Real: 100.000%
Loss D Fake: 0.7382 (0.8338) Acc D Fake: 1.553%
Loss D: 1.322
Loss G: 0.6516 (0.5807) Acc G: 98.413%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.5829 (0.6054) Acc D Real: 100.000%
Loss D Fake: 0.7369 (0.8331) Acc D Fake: 1.610%
Loss D: 1.320
Loss G: 0.6529 (0.5812) Acc G: 98.333%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.5826 (0.6052) Acc D Real: 100.000%
Loss D Fake: 0.7355 (0.8324) Acc D Fake: 1.689%
Loss D: 1.318
Loss G: 0.6542 (0.5817) Acc G: 98.255%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.5817 (0.6051) Acc D Real: 100.000%
Loss D Fake: 0.7340 (0.8318) Acc D Fake: 1.767%
Loss D: 1.316
Loss G: 0.6555 (0.5822) Acc G: 98.177%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.5811 (0.6049) Acc D Real: 100.000%
Loss D Fake: 0.7326 (0.8311) Acc D Fake: 1.856%
Loss D: 1.314
Loss G: 0.6568 (0.5827) Acc G: 98.078%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.5804 (0.6047) Acc D Real: 100.000%
Loss D Fake: 0.7312 (0.8305) Acc D Fake: 1.954%
Loss D: 1.312
Loss G: 0.6581 (0.5832) Acc G: 97.980%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.5801 (0.6046) Acc D Real: 100.000%
Loss D Fake: 0.7297 (0.8298) Acc D Fake: 2.061%
Loss D: 1.310
Loss G: 0.6595 (0.5837) Acc G: 97.873%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.5791 (0.6044) Acc D Real: 100.000%
Loss D Fake: 0.7282 (0.8291) Acc D Fake: 2.168%
Loss D: 1.307
Loss G: 0.6609 (0.5842) Acc G: 97.767%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.5802 (0.6043) Acc D Real: 100.000%
Loss D Fake: 0.7267 (0.8285) Acc D Fake: 2.294%
Loss D: 1.307
Loss G: 0.6623 (0.5847) Acc G: 97.641%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.5782 (0.6041) Acc D Real: 100.000%
Loss D Fake: 0.7252 (0.8278) Acc D Fake: 2.419%
Loss D: 1.303
Loss G: 0.6637 (0.5852) Acc G: 97.505%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.5765 (0.6039) Acc D Real: 100.000%
Loss D Fake: 0.7236 (0.8271) Acc D Fake: 2.553%
Loss D: 1.300
Loss G: 0.6652 (0.5858) Acc G: 97.372%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.5777 (0.6037) Acc D Real: 100.000%
Loss D Fake: 0.7220 (0.8265) Acc D Fake: 2.686%
Loss D: 1.300
Loss G: 0.6667 (0.5863) Acc G: 97.229%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.5765 (0.6036) Acc D Real: 100.000%
Loss D Fake: 0.7204 (0.8258) Acc D Fake: 2.838%
Loss D: 1.297
Loss G: 0.6682 (0.5868) Acc G: 97.068%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.5764 (0.6034) Acc D Real: 100.000%
Loss D Fake: 0.7188 (0.8251) Acc D Fake: 2.998%
Loss D: 1.295
Loss G: 0.6698 (0.5873) Acc G: 96.908%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.5772 (0.6032) Acc D Real: 100.000%
Loss D Fake: 0.7172 (0.8244) Acc D Fake: 3.156%
Loss D: 1.294
Loss G: 0.6714 (0.5878) Acc G: 96.750%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.5771 (0.6031) Acc D Real: 100.000%
Loss D Fake: 0.7155 (0.8238) Acc D Fake: 3.313%
Loss D: 1.293
Loss G: 0.6729 (0.5884) Acc G: 96.584%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.5762 (0.6029) Acc D Real: 100.000%
Loss D Fake: 0.7139 (0.8231) Acc D Fake: 3.477%
Loss D: 1.290
Loss G: 0.6745 (0.5889) Acc G: 96.409%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.5773 (0.6027) Acc D Real: 100.000%
Loss D Fake: 0.7122 (0.8224) Acc D Fake: 3.650%
Loss D: 1.290
Loss G: 0.6761 (0.5894) Acc G: 96.237%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.5751 (0.6026) Acc D Real: 100.000%
Loss D Fake: 0.7106 (0.8217) Acc D Fake: 3.821%
Loss D: 1.286
Loss G: 0.6778 (0.5900) Acc G: 96.047%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.5754 (0.6024) Acc D Real: 100.000%
Loss D Fake: 0.7089 (0.8210) Acc D Fake: 4.020%
Loss D: 1.284
Loss G: 0.6794 (0.5905) Acc G: 95.848%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.5718 (0.6022) Acc D Real: 100.000%
Loss D Fake: 0.7072 (0.8204) Acc D Fake: 4.217%
Loss D: 1.279
Loss G: 0.6811 (0.5911) Acc G: 95.653%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.5725 (0.6021) Acc D Real: 100.000%
Loss D Fake: 0.7054 (0.8197) Acc D Fake: 4.421%
Loss D: 1.278
Loss G: 0.6829 (0.5916) Acc G: 95.449%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.5710 (0.6019) Acc D Real: 100.000%
Loss D Fake: 0.7036 (0.8190) Acc D Fake: 4.623%
Loss D: 1.275
Loss G: 0.6847 (0.5922) Acc G: 95.248%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.5723 (0.6017) Acc D Real: 100.000%
Loss D Fake: 0.7018 (0.8183) Acc D Fake: 4.832%
Loss D: 1.274
Loss G: 0.6865 (0.5927) Acc G: 95.039%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.5706 (0.6015) Acc D Real: 100.000%
Loss D Fake: 0.7000 (0.8176) Acc D Fake: 5.039%
Loss D: 1.271
Loss G: 0.6884 (0.5933) Acc G: 94.824%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.5707 (0.6013) Acc D Real: 100.000%
Loss D Fake: 0.6981 (0.8169) Acc D Fake: 5.253%
Loss D: 1.269
Loss G: 0.6903 (0.5939) Acc G: 94.600%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.5692 (0.6011) Acc D Real: 100.000%
Loss D Fake: 0.6962 (0.8162) Acc D Fake: 5.484%
Loss D: 1.265
Loss G: 0.6922 (0.5944) Acc G: 94.360%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.5705 (0.6010) Acc D Real: 100.000%
Loss D Fake: 0.6942 (0.8155) Acc D Fake: 5.723%
Loss D: 1.265
Loss G: 0.6942 (0.5950) Acc G: 94.123%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.5671 (0.6008) Acc D Real: 100.000%
Loss D Fake: 0.6923 (0.8148) Acc D Fake: 5.958%
Loss D: 1.259
Loss G: 0.6963 (0.5956) Acc G: 93.889%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.5672 (0.6006) Acc D Real: 100.000%
Loss D Fake: 0.6902 (0.8141) Acc D Fake: 6.200%
Loss D: 1.257
Loss G: 0.6984 (0.5962) Acc G: 93.629%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.5658 (0.6004) Acc D Real: 100.000%
Loss D Fake: 0.6882 (0.8133) Acc D Fake: 6.458%
Loss D: 1.254
Loss G: 0.7005 (0.5968) Acc G: 93.371%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.5666 (0.6002) Acc D Real: 100.000%
Loss D Fake: 0.6861 (0.8126) Acc D Fake: 6.714%
Loss D: 1.253
Loss G: 0.7027 (0.5974) Acc G: 93.107%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.5661 (0.6000) Acc D Real: 100.000%
Loss D Fake: 0.6839 (0.8119) Acc D Fake: 6.976%
Loss D: 1.250
Loss G: 0.7050 (0.5980) Acc G: 92.828%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.5644 (0.5998) Acc D Real: 100.000%
Loss D Fake: 0.6817 (0.8112) Acc D Fake: 7.253%
Loss D: 1.246
Loss G: 0.7073 (0.5986) Acc G: 92.542%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.5649 (0.5996) Acc D Real: 100.000%
Loss D Fake: 0.6795 (0.8104) Acc D Fake: 7.537%
Loss D: 1.244
Loss G: 0.7096 (0.5992) Acc G: 92.250%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.5641 (0.5994) Acc D Real: 100.000%
Loss D Fake: 0.6773 (0.8097) Acc D Fake: 7.845%
Loss D: 1.241
Loss G: 0.7120 (0.5998) Acc G: 91.934%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.5629 (0.5992) Acc D Real: 100.000%
Loss D Fake: 0.6750 (0.8090) Acc D Fake: 8.168%
Loss D: 1.238
Loss G: 0.7145 (0.6005) Acc G: 91.603%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.5622 (0.5990) Acc D Real: 100.000%
Loss D Fake: 0.6726 (0.8082) Acc D Fake: 8.525%
Loss D: 1.235
Loss G: 0.7170 (0.6011) Acc G: 91.239%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.5614 (0.5988) Acc D Real: 100.000%
Loss D Fake: 0.6702 (0.8075) Acc D Fake: 8.886%
Loss D: 1.232
Loss G: 0.7196 (0.6017) Acc G: 90.870%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.5612 (0.5986) Acc D Real: 100.000%
Loss D Fake: 0.6678 (0.8067) Acc D Fake: 9.261%
Loss D: 1.229
Loss G: 0.7223 (0.6024) Acc G: 90.495%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.5608 (0.5984) Acc D Real: 100.000%
Loss D Fake: 0.6653 (0.8060) Acc D Fake: 9.651%
Loss D: 1.226
Loss G: 0.7250 (0.6030) Acc G: 90.099%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.5582 (0.5982) Acc D Real: 100.000%
Loss D Fake: 0.6628 (0.8052) Acc D Fake: 10.045%
Loss D: 1.221
Loss G: 0.7278 (0.6037) Acc G: 89.697%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.5603 (0.5980) Acc D Real: 100.000%
Loss D Fake: 0.6602 (0.8044) Acc D Fake: 10.443%
Loss D: 1.221
Loss G: 0.7306 (0.6044) Acc G: 89.300%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.5582 (0.5978) Acc D Real: 100.000%
Loss D Fake: 0.6576 (0.8036) Acc D Fake: 10.838%
Loss D: 1.216
Loss G: 0.7336 (0.6051) Acc G: 88.907%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.5576 (0.5976) Acc D Real: 100.000%
Loss D Fake: 0.6549 (0.8029) Acc D Fake: 11.228%
Loss D: 1.213
Loss G: 0.7366 (0.6058) Acc G: 88.518%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.5559 (0.5973) Acc D Real: 100.000%
Loss D Fake: 0.6522 (0.8021) Acc D Fake: 11.614%
Loss D: 1.208
Loss G: 0.7397 (0.6065) Acc G: 88.133%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.5550 (0.5971) Acc D Real: 100.000%
Loss D Fake: 0.6494 (0.8013) Acc D Fake: 11.997%
Loss D: 1.204
Loss G: 0.7429 (0.6072) Acc G: 87.743%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.5542 (0.5969) Acc D Real: 100.000%
Loss D Fake: 0.6465 (0.8005) Acc D Fake: 12.383%
Loss D: 1.201
Loss G: 0.7462 (0.6079) Acc G: 87.358%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.5515 (0.5967) Acc D Real: 100.000%
Loss D Fake: 0.6436 (0.7997) Acc D Fake: 12.766%
Loss D: 1.195
Loss G: 0.7496 (0.6086) Acc G: 86.976%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.5512 (0.5964) Acc D Real: 100.000%
Loss D Fake: 0.6405 (0.7988) Acc D Fake: 13.145%
Loss D: 1.192
Loss G: 0.7531 (0.6094) Acc G: 86.598%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.5519 (0.5962) Acc D Real: 100.000%
Loss D Fake: 0.6375 (0.7980) Acc D Fake: 13.520%
Loss D: 1.189
Loss G: 0.7567 (0.6101) Acc G: 86.224%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.5519 (0.5960) Acc D Real: 100.000%
Loss D Fake: 0.6343 (0.7972) Acc D Fake: 13.892%
Loss D: 1.186
Loss G: 0.7604 (0.6109) Acc G: 85.854%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.5489 (0.5957) Acc D Real: 100.000%
Loss D Fake: 0.6311 (0.7964) Acc D Fake: 14.259%
Loss D: 1.180
Loss G: 0.7642 (0.6117) Acc G: 85.488%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.5497 (0.5955) Acc D Real: 100.000%
Loss D Fake: 0.6278 (0.7955) Acc D Fake: 14.623%
Loss D: 1.178
Loss G: 0.7681 (0.6124) Acc G: 85.117%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.5471 (0.5953) Acc D Real: 100.000%
Loss D Fake: 0.6245 (0.7947) Acc D Fake: 14.992%
Loss D: 1.172
Loss G: 0.7722 (0.6132) Acc G: 84.750%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.5483 (0.5950) Acc D Real: 100.000%
Loss D Fake: 0.6211 (0.7938) Acc D Fake: 15.357%
Loss D: 1.169
Loss G: 0.7763 (0.6140) Acc G: 84.386%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.5474 (0.5948) Acc D Real: 100.000%
Loss D Fake: 0.6176 (0.7929) Acc D Fake: 15.718%
Loss D: 1.165
Loss G: 0.7805 (0.6149) Acc G: 84.026%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.5475 (0.5946) Acc D Real: 100.000%
Loss D Fake: 0.6141 (0.7920) Acc D Fake: 16.076%
Loss D: 1.162
Loss G: 0.7849 (0.6157) Acc G: 83.670%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.5450 (0.5943) Acc D Real: 100.000%
Loss D Fake: 0.6105 (0.7911) Acc D Fake: 16.430%
Loss D: 1.155
Loss G: 0.7893 (0.6166) Acc G: 83.317%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.5403 (0.5941) Acc D Real: 100.000%
Loss D Fake: 0.6069 (0.7902) Acc D Fake: 16.780%
Loss D: 1.147
Loss G: 0.7939 (0.6174) Acc G: 82.967%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.5430 (0.5938) Acc D Real: 100.000%
Loss D Fake: 0.6031 (0.7893) Acc D Fake: 17.128%
Loss D: 1.146
Loss G: 0.7986 (0.6183) Acc G: 82.621%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.5401 (0.5935) Acc D Real: 100.000%
Loss D Fake: 0.5994 (0.7884) Acc D Fake: 17.472%
Loss D: 1.139
Loss G: 0.8035 (0.6192) Acc G: 82.279%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.5397 (0.5933) Acc D Real: 100.000%
Loss D Fake: 0.5955 (0.7875) Acc D Fake: 17.812%
Loss D: 1.135
Loss G: 0.8085 (0.6201) Acc G: 81.939%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.5406 (0.5930) Acc D Real: 100.000%
Loss D Fake: 0.5916 (0.7866) Acc D Fake: 18.150%
Loss D: 1.132
Loss G: 0.8135 (0.6210) Acc G: 81.595%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.5341 (0.5928) Acc D Real: 100.000%
Loss D Fake: 0.5876 (0.7856) Acc D Fake: 18.493%
Loss D: 1.122
Loss G: 0.8188 (0.6220) Acc G: 81.254%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.5332 (0.5925) Acc D Real: 100.000%
Loss D Fake: 0.5836 (0.7847) Acc D Fake: 18.831%
Loss D: 1.117
Loss G: 0.8242 (0.6229) Acc G: 80.916%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.5345 (0.5922) Acc D Real: 100.000%
Loss D Fake: 0.5795 (0.7837) Acc D Fake: 19.167%
Loss D: 1.114
Loss G: 0.8297 (0.6239) Acc G: 80.582%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.5300 (0.5919) Acc D Real: 100.000%
Loss D Fake: 0.5753 (0.7827) Acc D Fake: 19.500%
Loss D: 1.105
Loss G: 0.8353 (0.6249) Acc G: 80.250%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.5318 (0.5916) Acc D Real: 100.000%
Loss D Fake: 0.5711 (0.7817) Acc D Fake: 19.829%
Loss D: 1.103
Loss G: 0.8411 (0.6259) Acc G: 79.922%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.5277 (0.5913) Acc D Real: 100.000%
Loss D Fake: 0.5669 (0.7807) Acc D Fake: 20.156%
Loss D: 1.095
Loss G: 0.8470 (0.6269) Acc G: 79.597%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.5277 (0.5910) Acc D Real: 100.000%
Loss D Fake: 0.5626 (0.7797) Acc D Fake: 20.479%
Loss D: 1.090
Loss G: 0.8531 (0.6280) Acc G: 79.275%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.5275 (0.5907) Acc D Real: 100.000%
Loss D Fake: 0.5582 (0.7787) Acc D Fake: 20.799%
Loss D: 1.086
Loss G: 0.8592 (0.6291) Acc G: 78.955%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.5196 (0.5904) Acc D Real: 100.000%
Loss D Fake: 0.5539 (0.7777) Acc D Fake: 21.117%
Loss D: 1.073
Loss G: 0.8655 (0.6301) Acc G: 78.639%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.5197 (0.5901) Acc D Real: 100.000%
Loss D Fake: 0.5494 (0.7766) Acc D Fake: 21.431%
Loss D: 1.069
Loss G: 0.8720 (0.6312) Acc G: 78.326%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.5201 (0.5898) Acc D Real: 100.000%
Loss D Fake: 0.5450 (0.7756) Acc D Fake: 21.743%
Loss D: 1.065
Loss G: 0.8786 (0.6324) Acc G: 78.015%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.5172 (0.5894) Acc D Real: 100.000%
Loss D Fake: 0.5405 (0.7745) Acc D Fake: 22.052%
Loss D: 1.058
Loss G: 0.8853 (0.6335) Acc G: 77.707%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.5151 (0.5891) Acc D Real: 100.000%
Loss D Fake: 0.5359 (0.7734) Acc D Fake: 22.358%
Loss D: 1.051
Loss G: 0.8922 (0.6347) Acc G: 77.402%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.5182 (0.5888) Acc D Real: 100.000%
Loss D Fake: 0.5313 (0.7723) Acc D Fake: 22.661%
Loss D: 1.050
Loss G: 0.8992 (0.6359) Acc G: 77.100%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.5128 (0.5885) Acc D Real: 100.000%
Loss D Fake: 0.5268 (0.7712) Acc D Fake: 22.962%
Loss D: 1.040
Loss G: 0.9064 (0.6371) Acc G: 76.801%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.5114 (0.5881) Acc D Real: 100.000%
Loss D Fake: 0.5222 (0.7701) Acc D Fake: 23.260%
Loss D: 1.034
Loss G: 0.9137 (0.6383) Acc G: 76.504%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.5078 (0.5878) Acc D Real: 100.000%
Loss D Fake: 0.5175 (0.7690) Acc D Fake: 23.334%
Loss D: 1.025
Loss G: 0.9211 (0.6396) Acc G: 76.430%
LR: 2.000e-04
Epoch: 3/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.5066 (0.5065) Acc D Real: 100.000%
Loss D Fake: 0.5081 (0.5104) Acc D Fake: 90.833%
Loss D: 1.015
Loss G: 0.9366 (0.9327) Acc G: 9.167%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.5016 (0.5049) Acc D Real: 100.000%
Loss D Fake: 0.5033 (0.5081) Acc D Fake: 91.111%
Loss D: 1.005
Loss G: 0.9446 (0.9367) Acc G: 8.889%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4959 (0.5026) Acc D Real: 100.000%
Loss D Fake: 0.4985 (0.5057) Acc D Fake: 91.250%
Loss D: 0.994
Loss G: 0.9529 (0.9407) Acc G: 8.750%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4907 (0.5002) Acc D Real: 100.000%
Loss D Fake: 0.4936 (0.5032) Acc D Fake: 91.333%
Loss D: 0.984
Loss G: 0.9614 (0.9449) Acc G: 8.667%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4956 (0.4995) Acc D Real: 100.000%
Loss D Fake: 0.4886 (0.5008) Acc D Fake: 91.389%
Loss D: 0.984
Loss G: 0.9702 (0.9491) Acc G: 8.611%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4882 (0.4979) Acc D Real: 100.000%
Loss D Fake: 0.4835 (0.4983) Acc D Fake: 91.429%
Loss D: 0.972
Loss G: 0.9793 (0.9534) Acc G: 8.571%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4891 (0.4968) Acc D Real: 100.000%
Loss D Fake: 0.4784 (0.4958) Acc D Fake: 91.458%
Loss D: 0.967
Loss G: 0.9887 (0.9578) Acc G: 8.542%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4824 (0.4952) Acc D Real: 100.000%
Loss D Fake: 0.4732 (0.4933) Acc D Fake: 91.481%
Loss D: 0.956
Loss G: 0.9984 (0.9623) Acc G: 8.519%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4773 (0.4934) Acc D Real: 100.000%
Loss D Fake: 0.4679 (0.4908) Acc D Fake: 91.500%
Loss D: 0.945
Loss G: 1.0085 (0.9669) Acc G: 8.500%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4729 (0.4915) Acc D Real: 100.000%
Loss D Fake: 0.4624 (0.4882) Acc D Fake: 91.515%
Loss D: 0.935
Loss G: 1.0189 (0.9717) Acc G: 8.485%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4728 (0.4900) Acc D Real: 100.000%
Loss D Fake: 0.4569 (0.4856) Acc D Fake: 91.528%
Loss D: 0.930
Loss G: 1.0298 (0.9765) Acc G: 8.472%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4699 (0.4884) Acc D Real: 100.000%
Loss D Fake: 0.4513 (0.4830) Acc D Fake: 91.538%
Loss D: 0.921
Loss G: 1.0411 (0.9815) Acc G: 8.462%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4691 (0.4870) Acc D Real: 100.000%
Loss D Fake: 0.4455 (0.4803) Acc D Fake: 91.548%
Loss D: 0.915
Loss G: 1.0529 (0.9866) Acc G: 8.452%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4627 (0.4854) Acc D Real: 100.000%
Loss D Fake: 0.4397 (0.4776) Acc D Fake: 91.556%
Loss D: 0.902
Loss G: 1.0652 (0.9918) Acc G: 8.444%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4551 (0.4835) Acc D Real: 100.000%
Loss D Fake: 0.4337 (0.4748) Acc D Fake: 91.562%
Loss D: 0.889
Loss G: 1.0780 (0.9972) Acc G: 8.438%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4563 (0.4819) Acc D Real: 100.000%
Loss D Fake: 0.4276 (0.4721) Acc D Fake: 91.569%
Loss D: 0.884
Loss G: 1.0915 (1.0028) Acc G: 8.431%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4474 (0.4800) Acc D Real: 100.000%
Loss D Fake: 0.4213 (0.4692) Acc D Fake: 91.574%
Loss D: 0.869
Loss G: 1.1057 (1.0085) Acc G: 8.426%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4412 (0.4780) Acc D Real: 100.000%
Loss D Fake: 0.4148 (0.4664) Acc D Fake: 91.579%
Loss D: 0.856
Loss G: 1.1207 (1.0144) Acc G: 8.421%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4416 (0.4761) Acc D Real: 100.000%
Loss D Fake: 0.4081 (0.4635) Acc D Fake: 91.583%
Loss D: 0.850
Loss G: 1.1367 (1.0205) Acc G: 8.417%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4376 (0.4743) Acc D Real: 100.000%
Loss D Fake: 0.4011 (0.4605) Acc D Fake: 91.587%
Loss D: 0.839
Loss G: 1.1538 (1.0268) Acc G: 8.413%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4294 (0.4723) Acc D Real: 100.000%
Loss D Fake: 0.3939 (0.4575) Acc D Fake: 91.591%
Loss D: 0.823
Loss G: 1.1722 (1.0335) Acc G: 8.409%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4251 (0.4702) Acc D Real: 100.000%
Loss D Fake: 0.3863 (0.4544) Acc D Fake: 91.594%
Loss D: 0.811
Loss G: 1.1923 (1.0404) Acc G: 8.406%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4185 (0.4681) Acc D Real: 100.000%
Loss D Fake: 0.3782 (0.4512) Acc D Fake: 91.597%
Loss D: 0.797
Loss G: 1.2145 (1.0476) Acc G: 8.403%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4193 (0.4661) Acc D Real: 100.000%
Loss D Fake: 0.3696 (0.4479) Acc D Fake: 91.600%
Loss D: 0.789
Loss G: 1.2393 (1.0553) Acc G: 8.400%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4142 (0.4641) Acc D Real: 100.000%
Loss D Fake: 0.3603 (0.4446) Acc D Fake: 91.603%
Loss D: 0.774
Loss G: 1.2676 (1.0635) Acc G: 8.397%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4024 (0.4618) Acc D Real: 100.000%
Loss D Fake: 0.3502 (0.4411) Acc D Fake: 91.605%
Loss D: 0.753
Loss G: 1.3000 (1.0722) Acc G: 8.395%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4033 (0.4597) Acc D Real: 100.000%
Loss D Fake: 0.3391 (0.4374) Acc D Fake: 91.607%
Loss D: 0.742
Loss G: 1.3370 (1.0817) Acc G: 8.393%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.3952 (0.4575) Acc D Real: 100.000%
Loss D Fake: 0.3275 (0.4336) Acc D Fake: 91.609%
Loss D: 0.723
Loss G: 1.3774 (1.0919) Acc G: 8.391%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.3915 (0.4553) Acc D Real: 100.000%
Loss D Fake: 0.3161 (0.4297) Acc D Fake: 91.611%
Loss D: 0.708
Loss G: 1.4180 (1.1027) Acc G: 8.389%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.3834 (0.4530) Acc D Real: 100.000%
Loss D Fake: 0.3058 (0.4257) Acc D Fake: 91.613%
Loss D: 0.689
Loss G: 1.4550 (1.1141) Acc G: 8.387%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.3789 (0.4507) Acc D Real: 100.000%
Loss D Fake: 0.2973 (0.4217) Acc D Fake: 91.615%
Loss D: 0.676
Loss G: 1.4861 (1.1257) Acc G: 8.385%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.3716 (0.4483) Acc D Real: 100.000%
Loss D Fake: 0.2905 (0.4177) Acc D Fake: 91.616%
Loss D: 0.662
Loss G: 1.5117 (1.1374) Acc G: 8.384%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.3638 (0.4458) Acc D Real: 100.000%
Loss D Fake: 0.2851 (0.4138) Acc D Fake: 91.618%
Loss D: 0.649
Loss G: 1.5333 (1.1491) Acc G: 8.382%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.3571 (0.4433) Acc D Real: 100.000%
Loss D Fake: 0.2805 (0.4100) Acc D Fake: 91.619%
Loss D: 0.638
Loss G: 1.5526 (1.1606) Acc G: 8.381%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.3505 (0.4407) Acc D Real: 100.000%
Loss D Fake: 0.2764 (0.4063) Acc D Fake: 91.620%
Loss D: 0.627
Loss G: 1.5706 (1.1720) Acc G: 8.380%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.3493 (0.4382) Acc D Real: 100.000%
Loss D Fake: 0.2725 (0.4027) Acc D Fake: 91.622%
Loss D: 0.622
Loss G: 1.5883 (1.1832) Acc G: 8.378%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.3450 (0.4358) Acc D Real: 100.000%
Loss D Fake: 0.2688 (0.3992) Acc D Fake: 91.623%
Loss D: 0.614
Loss G: 1.6060 (1.1944) Acc G: 8.377%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.3412 (0.4333) Acc D Real: 100.000%
Loss D Fake: 0.2652 (0.3957) Acc D Fake: 91.624%
Loss D: 0.606
Loss G: 1.6239 (1.2054) Acc G: 8.376%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.3294 (0.4307) Acc D Real: 100.000%
Loss D Fake: 0.2616 (0.3924) Acc D Fake: 91.625%
Loss D: 0.591
Loss G: 1.6420 (1.2163) Acc G: 8.375%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.3270 (0.4282) Acc D Real: 100.000%
Loss D Fake: 0.2582 (0.3891) Acc D Fake: 91.626%
Loss D: 0.585
Loss G: 1.6603 (1.2271) Acc G: 8.374%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.3203 (0.4256) Acc D Real: 100.000%
Loss D Fake: 0.2548 (0.3859) Acc D Fake: 91.627%
Loss D: 0.575
Loss G: 1.6787 (1.2379) Acc G: 8.373%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.3146 (0.4231) Acc D Real: 100.000%
Loss D Fake: 0.2515 (0.3828) Acc D Fake: 91.628%
Loss D: 0.566
Loss G: 1.6970 (1.2486) Acc G: 8.372%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.3062 (0.4204) Acc D Real: 100.000%
Loss D Fake: 0.2483 (0.3797) Acc D Fake: 91.629%
Loss D: 0.555
Loss G: 1.7153 (1.2592) Acc G: 8.371%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.3020 (0.4178) Acc D Real: 100.000%
Loss D Fake: 0.2452 (0.3767) Acc D Fake: 91.630%
Loss D: 0.547
Loss G: 1.7333 (1.2697) Acc G: 8.370%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.2940 (0.4151) Acc D Real: 100.000%
Loss D Fake: 0.2422 (0.3738) Acc D Fake: 91.630%
Loss D: 0.536
Loss G: 1.7512 (1.2802) Acc G: 8.370%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.2929 (0.4125) Acc D Real: 100.000%
Loss D Fake: 0.2394 (0.3710) Acc D Fake: 91.631%
Loss D: 0.532
Loss G: 1.7688 (1.2906) Acc G: 8.369%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.2828 (0.4098) Acc D Real: 100.000%
Loss D Fake: 0.2367 (0.3682) Acc D Fake: 91.632%
Loss D: 0.519
Loss G: 1.7861 (1.3009) Acc G: 8.368%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.2743 (0.4070) Acc D Real: 100.000%
Loss D Fake: 0.2341 (0.3654) Acc D Fake: 91.633%
Loss D: 0.508
Loss G: 1.8031 (1.3111) Acc G: 8.367%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.2717 (0.4043) Acc D Real: 100.000%
Loss D Fake: 0.2317 (0.3627) Acc D Fake: 91.633%
Loss D: 0.503
Loss G: 1.8199 (1.3213) Acc G: 8.367%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.2682 (0.4016) Acc D Real: 100.000%
Loss D Fake: 0.2293 (0.3601) Acc D Fake: 91.634%
Loss D: 0.497
Loss G: 1.8362 (1.3314) Acc G: 8.366%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.2630 (0.3990) Acc D Real: 100.000%
Loss D Fake: 0.2271 (0.3576) Acc D Fake: 91.635%
Loss D: 0.490
Loss G: 1.8523 (1.3414) Acc G: 8.365%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.2540 (0.3962) Acc D Real: 100.000%
Loss D Fake: 0.2250 (0.3551) Acc D Fake: 91.635%
Loss D: 0.479
Loss G: 1.8679 (1.3514) Acc G: 8.365%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.2513 (0.3935) Acc D Real: 100.000%
Loss D Fake: 0.2230 (0.3526) Acc D Fake: 91.636%
Loss D: 0.474
Loss G: 1.8833 (1.3612) Acc G: 8.364%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.2440 (0.3908) Acc D Real: 100.000%
Loss D Fake: 0.2211 (0.3502) Acc D Fake: 91.636%
Loss D: 0.465
Loss G: 1.8982 (1.3710) Acc G: 8.364%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.2399 (0.3881) Acc D Real: 100.000%
Loss D Fake: 0.2193 (0.3479) Acc D Fake: 91.637%
Loss D: 0.459
Loss G: 1.9128 (1.3806) Acc G: 8.363%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.2339 (0.3854) Acc D Real: 100.000%
Loss D Fake: 0.2177 (0.3456) Acc D Fake: 91.637%
Loss D: 0.452
Loss G: 1.9269 (1.3902) Acc G: 8.363%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.2285 (0.3827) Acc D Real: 100.000%
Loss D Fake: 0.2162 (0.3434) Acc D Fake: 91.638%
Loss D: 0.445
Loss G: 1.9407 (1.3997) Acc G: 8.362%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.2215 (0.3800) Acc D Real: 100.000%
Loss D Fake: 0.2148 (0.3412) Acc D Fake: 91.638%
Loss D: 0.436
Loss G: 1.9540 (1.4091) Acc G: 8.362%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.2167 (0.3773) Acc D Real: 100.000%
Loss D Fake: 0.2135 (0.3391) Acc D Fake: 91.639%
Loss D: 0.430
Loss G: 1.9668 (1.4184) Acc G: 8.361%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.2139 (0.3746) Acc D Real: 100.000%
Loss D Fake: 0.2123 (0.3370) Acc D Fake: 91.639%
Loss D: 0.426
Loss G: 1.9790 (1.4276) Acc G: 8.361%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.2093 (0.3719) Acc D Real: 100.000%
Loss D Fake: 0.2113 (0.3350) Acc D Fake: 91.640%
Loss D: 0.421
Loss G: 1.9906 (1.4367) Acc G: 8.360%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.2045 (0.3693) Acc D Real: 100.000%
Loss D Fake: 0.2105 (0.3330) Acc D Fake: 91.614%
Loss D: 0.415
Loss G: 2.0016 (1.4456) Acc G: 8.386%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.2013 (0.3666) Acc D Real: 100.000%
Loss D Fake: 0.2098 (0.3311) Acc D Fake: 91.589%
Loss D: 0.411
Loss G: 2.0117 (1.4545) Acc G: 8.411%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.2005 (0.3641) Acc D Real: 100.000%
Loss D Fake: 0.2093 (0.3292) Acc D Fake: 91.564%
Loss D: 0.410
Loss G: 2.0208 (1.4632) Acc G: 8.436%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.1920 (0.3615) Acc D Real: 100.000%
Loss D Fake: 0.2090 (0.3274) Acc D Fake: 91.540%
Loss D: 0.401
Loss G: 2.0288 (1.4718) Acc G: 8.460%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.1898 (0.3589) Acc D Real: 100.000%
Loss D Fake: 0.2090 (0.3256) Acc D Fake: 91.517%
Loss D: 0.399
Loss G: 2.0355 (1.4802) Acc G: 8.483%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.1847 (0.3564) Acc D Real: 100.000%
Loss D Fake: 0.2093 (0.3239) Acc D Fake: 91.495%
Loss D: 0.394
Loss G: 2.0404 (1.4884) Acc G: 8.505%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.1825 (0.3538) Acc D Real: 100.000%
Loss D Fake: 0.2100 (0.3222) Acc D Fake: 91.473%
Loss D: 0.393
Loss G: 2.0432 (1.4965) Acc G: 8.527%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.1786 (0.3513) Acc D Real: 100.000%
Loss D Fake: 0.2112 (0.3207) Acc D Fake: 91.452%
Loss D: 0.390
Loss G: 2.0432 (1.5043) Acc G: 8.548%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.1757 (0.3489) Acc D Real: 100.000%
Loss D Fake: 0.2131 (0.3191) Acc D Fake: 91.432%
Loss D: 0.389
Loss G: 2.0393 (1.5118) Acc G: 8.568%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.1711 (0.3464) Acc D Real: 100.000%
Loss D Fake: 0.2158 (0.3177) Acc D Fake: 91.412%
Loss D: 0.387
Loss G: 2.0302 (1.5190) Acc G: 8.588%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.1695 (0.3440) Acc D Real: 100.000%
Loss D Fake: 0.2197 (0.3164) Acc D Fake: 91.370%
Loss D: 0.389
Loss G: 2.0137 (1.5258) Acc G: 8.630%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.1664 (0.3416) Acc D Real: 100.000%
Loss D Fake: 0.2255 (0.3151) Acc D Fake: 91.329%
Loss D: 0.392
Loss G: 1.9864 (1.5320) Acc G: 8.671%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.1608 (0.3392) Acc D Real: 100.000%
Loss D Fake: 0.2340 (0.3141) Acc D Fake: 91.289%
Loss D: 0.395
Loss G: 1.9431 (1.5375) Acc G: 8.711%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.1608 (0.3368) Acc D Real: 100.000%
Loss D Fake: 0.2468 (0.3132) Acc D Fake: 91.250%
Loss D: 0.408
Loss G: 1.8772 (1.5420) Acc G: 8.750%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.1566 (0.3345) Acc D Real: 100.000%
Loss D Fake: 0.2657 (0.3126) Acc D Fake: 91.190%
Loss D: 0.422
Loss G: 1.7832 (1.5451) Acc G: 8.810%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.1551 (0.3322) Acc D Real: 100.000%
Loss D Fake: 0.2918 (0.3123) Acc D Fake: 91.132%
Loss D: 0.447
Loss G: 1.6635 (1.5466) Acc G: 8.868%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.1538 (0.3299) Acc D Real: 100.000%
Loss D Fake: 0.3248 (0.3124) Acc D Fake: 91.055%
Loss D: 0.479
Loss G: 1.5298 (1.5464) Acc G: 8.945%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.1500 (0.3277) Acc D Real: 100.000%
Loss D Fake: 0.3653 (0.3131) Acc D Fake: 90.979%
Loss D: 0.515
Loss G: 1.3944 (1.5445) Acc G: 9.021%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.1460 (0.3254) Acc D Real: 100.000%
Loss D Fake: 0.4145 (0.3144) Acc D Fake: 90.885%
Loss D: 0.560
Loss G: 1.2745 (1.5412) Acc G: 9.095%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.1465 (0.3232) Acc D Real: 100.000%
Loss D Fake: 0.4617 (0.3162) Acc D Fake: 90.793%
Loss D: 0.608
Loss G: 1.2030 (1.5370) Acc G: 9.187%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.1465 (0.3211) Acc D Real: 100.000%
Loss D Fake: 0.4681 (0.3180) Acc D Fake: 90.703%
Loss D: 0.615
Loss G: 1.1872 (1.5328) Acc G: 9.257%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.1466 (0.3190) Acc D Real: 100.000%
Loss D Fake: 0.4495 (0.3195) Acc D Fake: 90.615%
Loss D: 0.596
Loss G: 1.1979 (1.5288) Acc G: 9.325%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.1447 (0.3170) Acc D Real: 100.000%
Loss D Fake: 0.4319 (0.3209) Acc D Fake: 90.549%
Loss D: 0.577
Loss G: 1.2156 (1.5252) Acc G: 9.392%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.1430 (0.3150) Acc D Real: 100.000%
Loss D Fake: 0.4179 (0.3220) Acc D Fake: 90.484%
Loss D: 0.561
Loss G: 1.2351 (1.5218) Acc G: 9.457%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.1510 (0.3131) Acc D Real: 100.000%
Loss D Fake: 0.4067 (0.3230) Acc D Fake: 90.421%
Loss D: 0.558
Loss G: 1.2546 (1.5187) Acc G: 9.521%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.1441 (0.3112) Acc D Real: 100.000%
Loss D Fake: 0.3976 (0.3238) Acc D Fake: 90.360%
Loss D: 0.542
Loss G: 1.2738 (1.5159) Acc G: 9.564%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.1574 (0.3094) Acc D Real: 99.994%
Loss D Fake: 0.3904 (0.3246) Acc D Fake: 90.300%
Loss D: 0.548
Loss G: 1.2905 (1.5134) Acc G: 9.607%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.1725 (0.3079) Acc D Real: 99.963%
Loss D Fake: 0.3857 (0.3252) Acc D Fake: 90.258%
Loss D: 0.558
Loss G: 1.3014 (1.5110) Acc G: 9.648%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.1445 (0.3061) Acc D Real: 99.963%
Loss D Fake: 0.3835 (0.3259) Acc D Fake: 90.211%
Loss D: 0.528
Loss G: 1.3097 (1.5088) Acc G: 9.689%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.1432 (0.3043) Acc D Real: 99.964%
Loss D Fake: 0.3825 (0.3265) Acc D Fake: 90.154%
Loss D: 0.526
Loss G: 1.3156 (1.5067) Acc G: 9.728%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.1507 (0.3027) Acc D Real: 99.964%
Loss D Fake: 0.3830 (0.3271) Acc D Fake: 90.099%
Loss D: 0.534
Loss G: 1.3169 (1.5047) Acc G: 9.767%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.1605 (0.3012) Acc D Real: 99.963%
Loss D Fake: 0.3876 (0.3278) Acc D Fake: 90.044%
Loss D: 0.548
Loss G: 1.2974 (1.5025) Acc G: 9.823%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.1699 (0.2998) Acc D Real: 99.931%
Loss D Fake: 0.4027 (0.3285) Acc D Fake: 89.991%
Loss D: 0.573
Loss G: 1.2538 (1.4999) Acc G: 9.877%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.1393 (0.2981) Acc D Real: 99.932%
Loss D Fake: 0.4284 (0.3296) Acc D Fake: 89.939%
Loss D: 0.568
Loss G: 1.1975 (1.4967) Acc G: 9.931%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.1509 (0.2966) Acc D Real: 99.931%
Loss D Fake: 0.4661 (0.3310) Acc D Fake: 89.871%
Loss D: 0.617
Loss G: 1.1302 (1.4929) Acc G: 10.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.1361 (0.2950) Acc D Real: 99.932%
Loss D Fake: 0.5257 (0.3330) Acc D Fake: 89.787%
Loss D: 0.662
Loss G: 1.0960 (1.4889) Acc G: 10.068%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.1545 (0.2935) Acc D Real: 99.926%
Loss D Fake: 0.5347 (0.3350) Acc D Fake: 89.705%
Loss D: 0.689
Loss G: 1.1084 (1.4850) Acc G: 10.135%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.2191 (0.2928) Acc D Real: 99.874%
Loss D Fake: 0.5078 (0.3367) Acc D Fake: 89.642%
Loss D: 0.727
Loss G: 1.1188 (1.4814) Acc G: 10.200%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.2724 (0.2926) Acc D Real: 99.796%
Loss D Fake: 0.5027 (0.3384) Acc D Fake: 89.579%
Loss D: 0.775
Loss G: 1.1017 (1.4776) Acc G: 10.248%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.2539 (0.2922) Acc D Real: 99.742%
Loss D Fake: 0.5211 (0.3402) Acc D Fake: 89.518%
Loss D: 0.775
Loss G: 1.0550 (1.4735) Acc G: 10.294%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4764 (0.2940) Acc D Real: 99.542%
Loss D Fake: 0.5928 (0.3426) Acc D Fake: 89.458%
Loss D: 1.069
Loss G: 0.9914 (1.4688) Acc G: 10.340%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.5247 (0.2962) Acc D Real: 99.333%
Loss D Fake: 1.1786 (0.3507) Acc D Fake: 88.854%
Loss D: 1.703
Loss G: 1.0115 (1.4644) Acc G: 10.385%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.9488 (0.3024) Acc D Real: 98.909%
Loss D Fake: 0.5144 (0.3522) Acc D Fake: 88.817%
Loss D: 1.463
Loss G: 1.0515 (1.4605) Acc G: 10.413%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 1.0306 (0.3093) Acc D Real: 98.445%
Loss D Fake: 0.4960 (0.3536) Acc D Fake: 88.781%
Loss D: 1.527
Loss G: 1.0299 (1.4564) Acc G: 10.440%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 1.2384 (0.3180) Acc D Real: 97.898%
Loss D Fake: 0.5050 (0.3550) Acc D Fake: 88.746%
Loss D: 1.743
Loss G: 0.9926 (1.4521) Acc G: 10.467%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 1.2290 (0.3264) Acc D Real: 97.377%
Loss D Fake: 0.5214 (0.3565) Acc D Fake: 88.711%
Loss D: 1.750
Loss G: 0.9531 (1.4475) Acc G: 10.509%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 1.7081 (0.3391) Acc D Real: 96.642%
Loss D Fake: 0.5493 (0.3583) Acc D Fake: 88.662%
Loss D: 2.257
Loss G: 0.8965 (1.4424) Acc G: 10.566%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 1.3116 (0.3479) Acc D Real: 96.048%
Loss D Fake: 0.6245 (0.3607) Acc D Fake: 88.598%
Loss D: 1.936
Loss G: 0.8254 (1.4368) Acc G: 10.636%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 1.5414 (0.3587) Acc D Real: 95.369%
Loss D Fake: 1.5183 (0.3712) Acc D Fake: 87.905%
Loss D: 3.060
Loss G: 0.8779 (1.4318) Acc G: 10.706%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 1.5387 (0.3692) Acc D Real: 94.649%
Loss D Fake: 0.5419 (0.3727) Acc D Fake: 87.850%
Loss D: 2.081
Loss G: 0.9457 (1.4274) Acc G: 10.759%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 1.5267 (0.3795) Acc D Real: 93.951%
Loss D Fake: 0.5120 (0.3739) Acc D Fake: 87.810%
Loss D: 2.039
Loss G: 0.9688 (1.4234) Acc G: 10.811%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 1.5004 (0.3893) Acc D Real: 93.242%
Loss D Fake: 0.5024 (0.3750) Acc D Fake: 87.770%
Loss D: 2.003
Loss G: 0.9736 (1.4194) Acc G: 10.863%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 1.3930 (0.3980) Acc D Real: 92.566%
Loss D Fake: 0.5013 (0.3761) Acc D Fake: 87.732%
Loss D: 1.894
Loss G: 0.9691 (1.4155) Acc G: 10.913%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 1.3567 (0.4063) Acc D Real: 91.878%
Loss D Fake: 0.5046 (0.3772) Acc D Fake: 87.694%
Loss D: 1.861
Loss G: 0.9597 (1.4116) Acc G: 10.963%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 1.2675 (0.4137) Acc D Real: 91.205%
Loss D Fake: 0.5103 (0.3784) Acc D Fake: 87.657%
Loss D: 1.778
Loss G: 0.9479 (1.4076) Acc G: 11.011%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 1.2514 (0.4208) Acc D Real: 90.539%
Loss D Fake: 0.5172 (0.3796) Acc D Fake: 87.620%
Loss D: 1.769
Loss G: 0.9350 (1.4036) Acc G: 11.059%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 1.2068 (0.4274) Acc D Real: 89.884%
Loss D Fake: 0.5249 (0.3808) Acc D Fake: 87.584%
Loss D: 1.732
Loss G: 0.9218 (1.3995) Acc G: 11.106%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 1.1890 (0.4337) Acc D Real: 89.240%
Loss D Fake: 0.5329 (0.3820) Acc D Fake: 87.549%
Loss D: 1.722
Loss G: 0.9087 (1.3955) Acc G: 11.153%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 1.1569 (0.4397) Acc D Real: 88.609%
Loss D Fake: 0.5410 (0.3834) Acc D Fake: 87.514%
Loss D: 1.698
Loss G: 0.8959 (1.3913) Acc G: 11.198%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 1.1316 (0.4454) Acc D Real: 87.987%
Loss D Fake: 0.5491 (0.3847) Acc D Fake: 87.480%
Loss D: 1.681
Loss G: 0.8836 (1.3872) Acc G: 11.243%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 1.1125 (0.4508) Acc D Real: 87.376%
Loss D Fake: 0.5570 (0.3861) Acc D Fake: 87.446%
Loss D: 1.670
Loss G: 0.8718 (1.3830) Acc G: 11.300%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 1.0898 (0.4559) Acc D Real: 86.777%
Loss D Fake: 0.5648 (0.3876) Acc D Fake: 87.399%
Loss D: 1.655
Loss G: 0.8605 (1.3788) Acc G: 11.357%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 1.0970 (0.4611) Acc D Real: 86.179%
Loss D Fake: 0.5724 (0.3890) Acc D Fake: 87.353%
Loss D: 1.669
Loss G: 0.8499 (1.3745) Acc G: 11.413%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 1.0596 (0.4658) Acc D Real: 85.597%
Loss D Fake: 0.5798 (0.3906) Acc D Fake: 87.308%
Loss D: 1.639
Loss G: 0.8397 (1.3703) Acc G: 11.468%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 1.0365 (0.4703) Acc D Real: 85.029%
Loss D Fake: 0.5869 (0.3921) Acc D Fake: 87.264%
Loss D: 1.623
Loss G: 0.8301 (1.3660) Acc G: 11.522%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 1.0450 (0.4748) Acc D Real: 84.462%
Loss D Fake: 0.5937 (0.3937) Acc D Fake: 87.220%
Loss D: 1.639
Loss G: 0.8210 (1.3618) Acc G: 11.575%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 1.0120 (0.4790) Acc D Real: 83.911%
Loss D Fake: 0.6004 (0.3953) Acc D Fake: 87.177%
Loss D: 1.612
Loss G: 0.8124 (1.3575) Acc G: 11.628%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.9965 (0.4829) Acc D Real: 83.369%
Loss D Fake: 0.6068 (0.3969) Acc D Fake: 87.122%
Loss D: 1.603
Loss G: 0.8042 (1.3533) Acc G: 11.692%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.9995 (0.4869) Acc D Real: 82.834%
Loss D Fake: 0.6129 (0.3986) Acc D Fake: 87.067%
Loss D: 1.612
Loss G: 0.7964 (1.3490) Acc G: 11.755%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.9817 (0.4906) Acc D Real: 82.309%
Loss D Fake: 0.6189 (0.4002) Acc D Fake: 87.014%
Loss D: 1.601
Loss G: 0.7890 (1.3448) Acc G: 11.818%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.9787 (0.4943) Acc D Real: 81.790%
Loss D Fake: 0.6246 (0.4019) Acc D Fake: 86.961%
Loss D: 1.603
Loss G: 0.7820 (1.3405) Acc G: 11.879%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.9717 (0.4979) Acc D Real: 81.281%
Loss D Fake: 0.6301 (0.4036) Acc D Fake: 86.909%
Loss D: 1.602
Loss G: 0.7753 (1.3363) Acc G: 11.940%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.9584 (0.5013) Acc D Real: 80.782%
Loss D Fake: 0.6354 (0.4053) Acc D Fake: 86.858%
Loss D: 1.594
Loss G: 0.7689 (1.3321) Acc G: 12.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.9511 (0.5046) Acc D Real: 80.291%
Loss D Fake: 0.6405 (0.4071) Acc D Fake: 86.795%
Loss D: 1.592
Loss G: 0.7629 (1.3279) Acc G: 12.071%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.9356 (0.5077) Acc D Real: 79.808%
Loss D Fake: 0.6455 (0.4088) Acc D Fake: 86.734%
Loss D: 1.581
Loss G: 0.7571 (1.3238) Acc G: 12.141%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.9457 (0.5109) Acc D Real: 79.327%
Loss D Fake: 0.6503 (0.4105) Acc D Fake: 86.673%
Loss D: 1.596
Loss G: 0.7516 (1.3196) Acc G: 12.210%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.9262 (0.5139) Acc D Real: 78.858%
Loss D Fake: 0.6549 (0.4123) Acc D Fake: 86.613%
Loss D: 1.581
Loss G: 0.7463 (1.3155) Acc G: 12.278%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.9142 (0.5168) Acc D Real: 78.399%
Loss D Fake: 0.6594 (0.4141) Acc D Fake: 86.554%
Loss D: 1.574
Loss G: 0.7412 (1.3114) Acc G: 12.345%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.9045 (0.5195) Acc D Real: 77.946%
Loss D Fake: 0.6637 (0.4158) Acc D Fake: 86.495%
Loss D: 1.568
Loss G: 0.7363 (1.3073) Acc G: 12.411%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.9114 (0.5223) Acc D Real: 77.496%
Loss D Fake: 0.6680 (0.4176) Acc D Fake: 86.429%
Loss D: 1.579
Loss G: 0.7315 (1.3033) Acc G: 12.488%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.8938 (0.5249) Acc D Real: 77.056%
Loss D Fake: 0.6721 (0.4194) Acc D Fake: 86.361%
Loss D: 1.566
Loss G: 0.7270 (1.2992) Acc G: 12.564%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.8880 (0.5274) Acc D Real: 76.623%
Loss D Fake: 0.6760 (0.4212) Acc D Fake: 86.293%
Loss D: 1.564
Loss G: 0.7227 (1.2952) Acc G: 12.639%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.8833 (0.5298) Acc D Real: 76.196%
Loss D Fake: 0.6799 (0.4230) Acc D Fake: 86.227%
Loss D: 1.563
Loss G: 0.7184 (1.2912) Acc G: 12.712%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.8795 (0.5322) Acc D Real: 75.775%
Loss D Fake: 0.6837 (0.4247) Acc D Fake: 86.162%
Loss D: 1.563
Loss G: 0.7144 (1.2873) Acc G: 12.785%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.8765 (0.5346) Acc D Real: 75.359%
Loss D Fake: 0.6874 (0.4265) Acc D Fake: 86.097%
Loss D: 1.564
Loss G: 0.7104 (1.2834) Acc G: 12.857%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.8621 (0.5368) Acc D Real: 74.952%
Loss D Fake: 0.6910 (0.4283) Acc D Fake: 86.022%
Loss D: 1.553
Loss G: 0.7066 (1.2795) Acc G: 12.939%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.8450 (0.5389) Acc D Real: 74.555%
Loss D Fake: 0.6945 (0.4301) Acc D Fake: 85.948%
Loss D: 1.539
Loss G: 0.7028 (1.2756) Acc G: 13.020%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.8636 (0.5410) Acc D Real: 74.158%
Loss D Fake: 0.6980 (0.4319) Acc D Fake: 85.875%
Loss D: 1.562
Loss G: 0.6991 (1.2718) Acc G: 13.100%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.8526 (0.5431) Acc D Real: 73.767%
Loss D Fake: 0.7015 (0.4337) Acc D Fake: 85.803%
Loss D: 1.554
Loss G: 0.6955 (1.2679) Acc G: 13.178%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.8390 (0.5450) Acc D Real: 73.385%
Loss D Fake: 0.7049 (0.4355) Acc D Fake: 85.732%
Loss D: 1.544
Loss G: 0.6920 (1.2642) Acc G: 13.267%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.8547 (0.5471) Acc D Real: 73.003%
Loss D Fake: 0.7082 (0.4372) Acc D Fake: 85.651%
Loss D: 1.563
Loss G: 0.6886 (1.2604) Acc G: 13.355%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.8240 (0.5489) Acc D Real: 72.633%
Loss D Fake: 0.7114 (0.4390) Acc D Fake: 85.571%
Loss D: 1.535
Loss G: 0.6853 (1.2567) Acc G: 13.441%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.8354 (0.5507) Acc D Real: 72.265%
Loss D Fake: 0.7146 (0.4408) Acc D Fake: 85.492%
Loss D: 1.550
Loss G: 0.6821 (1.2530) Acc G: 13.527%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.8389 (0.5526) Acc D Real: 71.898%
Loss D Fake: 0.7178 (0.4426) Acc D Fake: 85.414%
Loss D: 1.557
Loss G: 0.6789 (1.2493) Acc G: 13.621%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.8153 (0.5542) Acc D Real: 71.542%
Loss D Fake: 0.7209 (0.4444) Acc D Fake: 85.326%
Loss D: 1.536
Loss G: 0.6758 (1.2456) Acc G: 13.715%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.7978 (0.5558) Acc D Real: 71.200%
Loss D Fake: 0.7241 (0.4461) Acc D Fake: 85.240%
Loss D: 1.522
Loss G: 0.6724 (1.2420) Acc G: 13.808%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.8107 (0.5574) Acc D Real: 70.853%
Loss D Fake: 0.7276 (0.4479) Acc D Fake: 85.144%
Loss D: 1.538
Loss G: 0.6691 (1.2384) Acc G: 13.910%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.8170 (0.5590) Acc D Real: 70.507%
Loss D Fake: 0.7309 (0.4497) Acc D Fake: 85.049%
Loss D: 1.548
Loss G: 0.6658 (1.2348) Acc G: 14.021%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.8099 (0.5605) Acc D Real: 70.168%
Loss D Fake: 0.7341 (0.4514) Acc D Fake: 84.946%
Loss D: 1.544
Loss G: 0.6627 (1.2313) Acc G: 14.130%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.8003 (0.5620) Acc D Real: 69.835%
Loss D Fake: 0.7373 (0.4532) Acc D Fake: 84.833%
Loss D: 1.538
Loss G: 0.6597 (1.2277) Acc G: 14.259%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.8056 (0.5635) Acc D Real: 69.503%
Loss D Fake: 0.7404 (0.4550) Acc D Fake: 84.701%
Loss D: 1.546
Loss G: 0.6567 (1.2242) Acc G: 14.396%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.7831 (0.5649) Acc D Real: 69.183%
Loss D Fake: 0.7435 (0.4567) Acc D Fake: 84.551%
Loss D: 1.527
Loss G: 0.6538 (1.2207) Acc G: 14.563%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.7966 (0.5663) Acc D Real: 68.867%
Loss D Fake: 0.7465 (0.4585) Acc D Fake: 84.382%
Loss D: 1.543
Loss G: 0.6509 (1.2173) Acc G: 14.757%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.7771 (0.5675) Acc D Real: 68.557%
Loss D Fake: 0.7495 (0.4602) Acc D Fake: 84.185%
Loss D: 1.527
Loss G: 0.6481 (1.2139) Acc G: 14.970%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.7858 (0.5688) Acc D Real: 68.245%
Loss D Fake: 0.7524 (0.4620) Acc D Fake: 83.970%
Loss D: 1.538
Loss G: 0.6454 (1.2105) Acc G: 15.209%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.7762 (0.5701) Acc D Real: 67.940%
Loss D Fake: 0.7553 (0.4637) Acc D Fake: 83.728%
Loss D: 1.532
Loss G: 0.6426 (1.2071) Acc G: 15.477%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.7445 (0.5711) Acc D Real: 67.657%
Loss D Fake: 0.7583 (0.4655) Acc D Fake: 83.429%
Loss D: 1.503
Loss G: 0.6398 (1.2037) Acc G: 15.938%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.7698 (0.5723) Acc D Real: 67.359%
Loss D Fake: 0.7613 (0.4672) Acc D Fake: 82.939%
Loss D: 1.531
Loss G: 0.6371 (1.2004) Acc G: 16.433%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.7559 (0.5734) Acc D Real: 67.070%
Loss D Fake: 0.7643 (0.4689) Acc D Fake: 82.454%
Loss D: 1.520
Loss G: 0.6343 (1.1971) Acc G: 16.921%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.7492 (0.5744) Acc D Real: 66.787%
Loss D Fake: 0.7673 (0.4707) Acc D Fake: 81.974%
Loss D: 1.516
Loss G: 0.6316 (1.1938) Acc G: 17.404%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.7479 (0.5754) Acc D Real: 66.507%
Loss D Fake: 0.7702 (0.4724) Acc D Fake: 81.500%
Loss D: 1.518
Loss G: 0.6290 (1.1905) Acc G: 17.882%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.7536 (0.5764) Acc D Real: 66.228%
Loss D Fake: 0.7732 (0.4741) Acc D Fake: 81.032%
Loss D: 1.527
Loss G: 0.6264 (1.1873) Acc G: 18.354%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.7400 (0.5773) Acc D Real: 65.957%
Loss D Fake: 0.7760 (0.4759) Acc D Fake: 80.569%
Loss D: 1.516
Loss G: 0.6238 (1.1841) Acc G: 18.820%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.7379 (0.5782) Acc D Real: 65.700%
Loss D Fake: 0.7789 (0.4776) Acc D Fake: 80.111%
Loss D: 1.517
Loss G: 0.6212 (1.1809) Acc G: 19.281%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.7338 (0.5791) Acc D Real: 65.439%
Loss D Fake: 0.7818 (0.4793) Acc D Fake: 79.659%
Loss D: 1.516
Loss G: 0.6186 (1.1777) Acc G: 19.738%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.7376 (0.5800) Acc D Real: 65.179%
Loss D Fake: 0.7847 (0.4810) Acc D Fake: 79.211%
Loss D: 1.522
Loss G: 0.6160 (1.1745) Acc G: 20.188%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.7259 (0.5808) Acc D Real: 64.926%
Loss D Fake: 0.7876 (0.4827) Acc D Fake: 78.769%
Loss D: 1.514
Loss G: 0.6135 (1.1714) Acc G: 20.634%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.7321 (0.5817) Acc D Real: 64.670%
Loss D Fake: 0.7905 (0.4844) Acc D Fake: 78.331%
Loss D: 1.523
Loss G: 0.6110 (1.1683) Acc G: 21.075%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.7181 (0.5824) Acc D Real: 64.424%
Loss D Fake: 0.7934 (0.4861) Acc D Fake: 77.898%
Loss D: 1.511
Loss G: 0.6085 (1.1652) Acc G: 21.511%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.7172 (0.5832) Acc D Real: 64.182%
Loss D Fake: 0.7963 (0.4879) Acc D Fake: 77.470%
Loss D: 1.513
Loss G: 0.6060 (1.1621) Acc G: 21.943%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.7173 (0.5839) Acc D Real: 63.940%
Loss D Fake: 0.7992 (0.4896) Acc D Fake: 77.047%
Loss D: 1.517
Loss G: 0.6034 (1.1591) Acc G: 22.369%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.7144 (0.5846) Acc D Real: 63.704%
Loss D Fake: 0.8021 (0.4913) Acc D Fake: 76.628%
Loss D: 1.517
Loss G: 0.6009 (1.1560) Acc G: 22.791%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.7084 (0.5853) Acc D Real: 63.484%
Loss D Fake: 0.8051 (0.4929) Acc D Fake: 76.214%
Loss D: 1.513
Loss G: 0.5985 (1.1530) Acc G: 23.208%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.6949 (0.5859) Acc D Real: 63.275%
Loss D Fake: 0.8080 (0.4946) Acc D Fake: 75.804%
Loss D: 1.503
Loss G: 0.5960 (1.1500) Acc G: 23.621%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.7012 (0.5865) Acc D Real: 63.054%
Loss D Fake: 0.8110 (0.4963) Acc D Fake: 75.399%
Loss D: 1.512
Loss G: 0.5935 (1.1471) Acc G: 24.030%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.6941 (0.5871) Acc D Real: 62.845%
Loss D Fake: 0.8139 (0.4980) Acc D Fake: 74.998%
Loss D: 1.508
Loss G: 0.5910 (1.1441) Acc G: 24.434%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.6944 (0.5876) Acc D Real: 62.652%
Loss D Fake: 0.8169 (0.4997) Acc D Fake: 74.601%
Loss D: 1.511
Loss G: 0.5885 (1.1412) Acc G: 24.834%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.6856 (0.5881) Acc D Real: 62.477%
Loss D Fake: 0.8199 (0.5014) Acc D Fake: 74.208%
Loss D: 1.505
Loss G: 0.5860 (1.1382) Acc G: 25.229%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.6811 (0.5886) Acc D Real: 62.323%
Loss D Fake: 0.8229 (0.5031) Acc D Fake: 73.820%
Loss D: 1.504
Loss G: 0.5836 (1.1353) Acc G: 25.621%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.6814 (0.5891) Acc D Real: 62.180%
Loss D Fake: 0.8259 (0.5048) Acc D Fake: 73.435%
Loss D: 1.507
Loss G: 0.5811 (1.1324) Acc G: 26.008%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.6782 (0.5896) Acc D Real: 62.059%
Loss D Fake: 0.8290 (0.5064) Acc D Fake: 73.055%
Loss D: 1.507
Loss G: 0.5786 (1.1296) Acc G: 26.391%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.6661 (0.5900) Acc D Real: 62.008%
Loss D Fake: 0.8320 (0.5081) Acc D Fake: 72.678%
Loss D: 1.498
Loss G: 0.5762 (1.1267) Acc G: 26.771%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.6683 (0.5904) Acc D Real: 61.954%
Loss D Fake: 0.8351 (0.5098) Acc D Fake: 72.306%
Loss D: 1.503
Loss G: 0.5737 (1.1239) Acc G: 27.146%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.6639 (0.5907) Acc D Real: 61.910%
Loss D Fake: 0.8382 (0.5115) Acc D Fake: 71.937%
Loss D: 1.502
Loss G: 0.5712 (1.1211) Acc G: 27.518%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.6535 (0.5911) Acc D Real: 61.947%
Loss D Fake: 0.8413 (0.5131) Acc D Fake: 71.571%
Loss D: 1.495
Loss G: 0.5688 (1.1183) Acc G: 27.886%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.6560 (0.5914) Acc D Real: 61.956%
Loss D Fake: 0.8444 (0.5148) Acc D Fake: 71.210%
Loss D: 1.500
Loss G: 0.5663 (1.1155) Acc G: 28.250%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.6518 (0.5917) Acc D Real: 61.978%
Loss D Fake: 0.8475 (0.5165) Acc D Fake: 70.852%
Loss D: 1.499
Loss G: 0.5639 (1.1127) Acc G: 28.611%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.6495 (0.5920) Acc D Real: 62.033%
Loss D Fake: 0.8507 (0.5182) Acc D Fake: 70.498%
Loss D: 1.500
Loss G: 0.5614 (1.1099) Acc G: 28.968%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.6443 (0.5922) Acc D Real: 62.112%
Loss D Fake: 0.8538 (0.5198) Acc D Fake: 70.147%
Loss D: 1.498
Loss G: 0.5590 (1.1072) Acc G: 29.321%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.6478 (0.5925) Acc D Real: 62.187%
Loss D Fake: 0.8570 (0.5215) Acc D Fake: 69.800%
Loss D: 1.505
Loss G: 0.5566 (1.1045) Acc G: 29.671%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.6383 (0.5927) Acc D Real: 62.310%
Loss D Fake: 0.8601 (0.5232) Acc D Fake: 69.456%
Loss D: 1.498
Loss G: 0.5541 (1.1018) Acc G: 30.017%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.6384 (0.5930) Acc D Real: 62.436%
Loss D Fake: 0.8633 (0.5248) Acc D Fake: 69.116%
Loss D: 1.502
Loss G: 0.5517 (1.0991) Acc G: 30.360%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.6349 (0.5932) Acc D Real: 62.570%
Loss D Fake: 0.8665 (0.5265) Acc D Fake: 68.778%
Loss D: 1.501
Loss G: 0.5493 (1.0964) Acc G: 30.700%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.6249 (0.5933) Acc D Real: 62.717%
Loss D Fake: 0.8697 (0.5282) Acc D Fake: 68.445%
Loss D: 1.495
Loss G: 0.5469 (1.0937) Acc G: 31.037%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.6323 (0.5935) Acc D Real: 62.829%
Loss D Fake: 0.8730 (0.5298) Acc D Fake: 68.114%
Loss D: 1.505
Loss G: 0.5445 (1.0911) Acc G: 31.370%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.6258 (0.5937) Acc D Real: 62.986%
Loss D Fake: 0.8762 (0.5315) Acc D Fake: 67.786%
Loss D: 1.502
Loss G: 0.5421 (1.0884) Acc G: 31.700%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.6161 (0.5938) Acc D Real: 63.158%
Loss D Fake: 0.8794 (0.5332) Acc D Fake: 67.462%
Loss D: 1.496
Loss G: 0.5397 (1.0858) Acc G: 32.027%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.6154 (0.5939) Acc D Real: 63.332%
Loss D Fake: 0.8826 (0.5348) Acc D Fake: 67.141%
Loss D: 1.498
Loss G: 0.5373 (1.0832) Acc G: 32.350%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.6132 (0.5940) Acc D Real: 63.481%
Loss D Fake: 0.8859 (0.5365) Acc D Fake: 66.823%
Loss D: 1.499
Loss G: 0.5350 (1.0806) Acc G: 32.671%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.6088 (0.5940) Acc D Real: 63.636%
Loss D Fake: 0.8892 (0.5382) Acc D Fake: 66.507%
Loss D: 1.498
Loss G: 0.5326 (1.0780) Acc G: 32.988%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.6026 (0.5941) Acc D Real: 63.801%
Loss D Fake: 0.8924 (0.5398) Acc D Fake: 66.195%
Loss D: 1.495
Loss G: 0.5303 (1.0754) Acc G: 33.303%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.6064 (0.5941) Acc D Real: 63.971%
Loss D Fake: 0.8957 (0.5415) Acc D Fake: 65.886%
Loss D: 1.502
Loss G: 0.5280 (1.0729) Acc G: 33.615%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.6036 (0.5942) Acc D Real: 64.138%
Loss D Fake: 0.8989 (0.5431) Acc D Fake: 65.579%
Loss D: 1.503
Loss G: 0.5256 (1.0703) Acc G: 33.923%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.6055 (0.5942) Acc D Real: 64.304%
Loss D Fake: 0.9022 (0.5448) Acc D Fake: 65.276%
Loss D: 1.508
Loss G: 0.5233 (1.0678) Acc G: 34.229%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.5980 (0.5943) Acc D Real: 64.469%
Loss D Fake: 0.9055 (0.5465) Acc D Fake: 64.975%
Loss D: 1.503
Loss G: 0.5210 (1.0653) Acc G: 34.532%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.5938 (0.5942) Acc D Real: 64.632%
Loss D Fake: 0.9088 (0.5481) Acc D Fake: 64.677%
Loss D: 1.503
Loss G: 0.5187 (1.0628) Acc G: 34.833%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.5963 (0.5943) Acc D Real: 64.793%
Loss D Fake: 0.9120 (0.5498) Acc D Fake: 64.382%
Loss D: 1.508
Loss G: 0.5165 (1.0603) Acc G: 35.130%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.5807 (0.5942) Acc D Real: 64.953%
Loss D Fake: 0.9153 (0.5515) Acc D Fake: 64.089%
Loss D: 1.496
Loss G: 0.5142 (1.0578) Acc G: 35.425%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.5811 (0.5941) Acc D Real: 65.112%
Loss D Fake: 0.9186 (0.5531) Acc D Fake: 63.799%
Loss D: 1.500
Loss G: 0.5120 (1.0553) Acc G: 35.717%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.5830 (0.5941) Acc D Real: 65.269%
Loss D Fake: 0.9219 (0.5548) Acc D Fake: 63.512%
Loss D: 1.505
Loss G: 0.5097 (1.0529) Acc G: 36.007%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.5755 (0.5940) Acc D Real: 65.425%
Loss D Fake: 0.9251 (0.5564) Acc D Fake: 63.227%
Loss D: 1.501
Loss G: 0.5075 (1.0504) Acc G: 36.294%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.5754 (0.5939) Acc D Real: 65.579%
Loss D Fake: 0.9284 (0.5581) Acc D Fake: 62.945%
Loss D: 1.504
Loss G: 0.5053 (1.0480) Acc G: 36.578%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.5644 (0.5938) Acc D Real: 65.732%
Loss D Fake: 0.9317 (0.5598) Acc D Fake: 62.665%
Loss D: 1.496
Loss G: 0.5032 (1.0456) Acc G: 36.860%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.5725 (0.5937) Acc D Real: 65.770%
Loss D Fake: 0.9349 (0.5614) Acc D Fake: 62.595%
Loss D: 1.507
Loss G: 0.5010 (1.0432) Acc G: 36.930%
LR: 2.000e-04
Epoch: 4/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.5648 (0.5645) Acc D Real: 100.000%
Loss D Fake: 0.9414 (0.9398) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4967 (0.4978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.5543 (0.5611) Acc D Real: 100.000%
Loss D Fake: 0.9446 (0.9414) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4946 (0.4967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.5580 (0.5603) Acc D Real: 100.000%
Loss D Fake: 0.9479 (0.9430) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4925 (0.4957) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.5522 (0.5587) Acc D Real: 100.000%
Loss D Fake: 0.9511 (0.9446) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4905 (0.4946) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.5488 (0.5570) Acc D Real: 100.000%
Loss D Fake: 0.9543 (0.9462) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4884 (0.4936) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.5545 (0.5567) Acc D Real: 100.000%
Loss D Fake: 0.9574 (0.9478) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4864 (0.4926) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.5445 (0.5551) Acc D Real: 100.000%
Loss D Fake: 0.9606 (0.9494) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4844 (0.4916) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.5439 (0.5539) Acc D Real: 100.000%
Loss D Fake: 0.9638 (0.9510) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4824 (0.4905) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.5351 (0.5520) Acc D Real: 100.000%
Loss D Fake: 0.9669 (0.9526) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4804 (0.4895) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.5335 (0.5503) Acc D Real: 100.000%
Loss D Fake: 0.9700 (0.9542) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4785 (0.4885) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.5320 (0.5488) Acc D Real: 100.000%
Loss D Fake: 0.9731 (0.9558) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4766 (0.4875) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.5289 (0.5473) Acc D Real: 100.000%
Loss D Fake: 0.9762 (0.9573) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4747 (0.4865) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.5286 (0.5459) Acc D Real: 100.000%
Loss D Fake: 0.9792 (0.9589) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4728 (0.4856) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.5280 (0.5447) Acc D Real: 100.000%
Loss D Fake: 0.9822 (0.9605) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4710 (0.4846) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.5214 (0.5433) Acc D Real: 100.000%
Loss D Fake: 0.9852 (0.9620) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4692 (0.4836) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.5253 (0.5422) Acc D Real: 100.000%
Loss D Fake: 0.9882 (0.9636) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4674 (0.4827) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.5205 (0.5410) Acc D Real: 100.000%
Loss D Fake: 0.9912 (0.9651) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4656 (0.4817) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.5146 (0.5396) Acc D Real: 100.000%
Loss D Fake: 0.9941 (0.9666) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4639 (0.4808) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.5112 (0.5382) Acc D Real: 100.000%
Loss D Fake: 0.9970 (0.9681) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4622 (0.4799) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.5130 (0.5370) Acc D Real: 100.000%
Loss D Fake: 0.9999 (0.9696) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4605 (0.4789) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.5105 (0.5358) Acc D Real: 100.000%
Loss D Fake: 1.0027 (0.9711) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4588 (0.4780) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.5071 (0.5345) Acc D Real: 100.000%
Loss D Fake: 1.0055 (0.9726) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4572 (0.4771) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.5036 (0.5333) Acc D Real: 100.000%
Loss D Fake: 1.0083 (0.9741) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4556 (0.4762) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.5045 (0.5321) Acc D Real: 100.000%
Loss D Fake: 1.0111 (0.9756) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4540 (0.4753) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.5012 (0.5309) Acc D Real: 100.000%
Loss D Fake: 1.0138 (0.9771) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4524 (0.4744) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4934 (0.5295) Acc D Real: 100.000%
Loss D Fake: 1.0165 (0.9785) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4509 (0.4736) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4995 (0.5285) Acc D Real: 100.000%
Loss D Fake: 1.0191 (0.9800) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4494 (0.4727) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4929 (0.5272) Acc D Real: 100.000%
Loss D Fake: 1.0217 (0.9814) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4479 (0.4719) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4881 (0.5259) Acc D Real: 100.000%
Loss D Fake: 1.0243 (0.9829) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4464 (0.4710) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4865 (0.5247) Acc D Real: 100.000%
Loss D Fake: 1.0269 (0.9843) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4450 (0.4702) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4876 (0.5235) Acc D Real: 100.000%
Loss D Fake: 1.0294 (0.9857) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4436 (0.4693) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4821 (0.5222) Acc D Real: 100.000%
Loss D Fake: 1.0318 (0.9871) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4422 (0.4685) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4859 (0.5212) Acc D Real: 100.000%
Loss D Fake: 1.0343 (0.9885) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4409 (0.4677) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4780 (0.5199) Acc D Real: 100.000%
Loss D Fake: 1.0366 (0.9898) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4396 (0.4669) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4779 (0.5188) Acc D Real: 100.000%
Loss D Fake: 1.0390 (0.9912) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4383 (0.4661) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4774 (0.5177) Acc D Real: 100.000%
Loss D Fake: 1.0413 (0.9926) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4370 (0.4653) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4747 (0.5165) Acc D Real: 100.000%
Loss D Fake: 1.0436 (0.9939) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4358 (0.4645) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4733 (0.5154) Acc D Real: 100.000%
Loss D Fake: 1.0458 (0.9952) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4346 (0.4638) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4734 (0.5144) Acc D Real: 100.000%
Loss D Fake: 1.0480 (0.9966) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4334 (0.4630) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4692 (0.5133) Acc D Real: 100.000%
Loss D Fake: 1.0502 (0.9979) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4322 (0.4623) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4678 (0.5122) Acc D Real: 100.000%
Loss D Fake: 1.0523 (0.9992) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4311 (0.4615) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4656 (0.5111) Acc D Real: 100.000%
Loss D Fake: 1.0544 (1.0004) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4300 (0.4608) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4624 (0.5100) Acc D Real: 100.000%
Loss D Fake: 1.0564 (1.0017) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4289 (0.4601) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4658 (0.5090) Acc D Real: 100.000%
Loss D Fake: 1.0584 (1.0030) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4278 (0.4593) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4627 (0.5080) Acc D Real: 100.000%
Loss D Fake: 1.0603 (1.0042) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4268 (0.4586) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4605 (0.5070) Acc D Real: 100.000%
Loss D Fake: 1.0623 (1.0055) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4258 (0.4579) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4551 (0.5059) Acc D Real: 100.000%
Loss D Fake: 1.0641 (1.0067) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4248 (0.4572) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4543 (0.5049) Acc D Real: 100.000%
Loss D Fake: 1.0660 (1.0079) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4239 (0.4566) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4575 (0.5039) Acc D Real: 100.000%
Loss D Fake: 1.0678 (1.0091) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4229 (0.4559) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4546 (0.5029) Acc D Real: 100.000%
Loss D Fake: 1.0695 (1.0103) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4220 (0.4552) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4505 (0.5019) Acc D Real: 100.000%
Loss D Fake: 1.0712 (1.0114) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4211 (0.4546) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4519 (0.5010) Acc D Real: 100.000%
Loss D Fake: 1.0729 (1.0126) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4202 (0.4539) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4484 (0.5000) Acc D Real: 100.000%
Loss D Fake: 1.0746 (1.0138) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4194 (0.4533) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4490 (0.4991) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.0149) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4186 (0.4527) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4461 (0.4981) Acc D Real: 100.000%
Loss D Fake: 1.0777 (1.0160) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4178 (0.4520) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4467 (0.4972) Acc D Real: 100.000%
Loss D Fake: 1.0792 (1.0171) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4170 (0.4514) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4438 (0.4963) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.0182) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4162 (0.4508) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4432 (0.4954) Acc D Real: 100.000%
Loss D Fake: 1.0822 (1.0193) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4155 (0.4502) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4418 (0.4945) Acc D Real: 100.000%
Loss D Fake: 1.0836 (1.0204) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4148 (0.4496) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4403 (0.4936) Acc D Real: 100.000%
Loss D Fake: 1.0850 (1.0214) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4141 (0.4490) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4381 (0.4927) Acc D Real: 100.000%
Loss D Fake: 1.0863 (1.0225) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4134 (0.4485) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4381 (0.4919) Acc D Real: 100.000%
Loss D Fake: 1.0876 (1.0235) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4127 (0.4479) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4374 (0.4910) Acc D Real: 100.000%
Loss D Fake: 1.0889 (1.0245) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4121 (0.4473) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4375 (0.4902) Acc D Real: 100.000%
Loss D Fake: 1.0901 (1.0255) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4115 (0.4468) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4326 (0.4893) Acc D Real: 100.000%
Loss D Fake: 1.0914 (1.0265) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4109 (0.4462) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4353 (0.4885) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.0275) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4103 (0.4457) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4329 (0.4877) Acc D Real: 100.000%
Loss D Fake: 1.0937 (1.0285) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4097 (0.4452) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4335 (0.4869) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.0295) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4092 (0.4447) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4311 (0.4861) Acc D Real: 100.000%
Loss D Fake: 1.0959 (1.0304) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4086 (0.4441) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4285 (0.4853) Acc D Real: 100.000%
Loss D Fake: 1.0969 (1.0313) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4081 (0.4436) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4305 (0.4845) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.0323) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4076 (0.4431) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4278 (0.4838) Acc D Real: 100.000%
Loss D Fake: 1.0989 (1.0332) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4071 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4279 (0.4830) Acc D Real: 100.000%
Loss D Fake: 1.0999 (1.0341) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4066 (0.4422) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4274 (0.4823) Acc D Real: 100.000%
Loss D Fake: 1.1009 (1.0350) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4062 (0.4417) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4264 (0.4815) Acc D Real: 100.000%
Loss D Fake: 1.1018 (1.0359) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4057 (0.4412) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4251 (0.4808) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.0367) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4053 (0.4407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4254 (0.4801) Acc D Real: 100.000%
Loss D Fake: 1.1036 (1.0376) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4048 (0.4403) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4244 (0.4794) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.0384) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4044 (0.4398) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4227 (0.4787) Acc D Real: 100.000%
Loss D Fake: 1.1053 (1.0393) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4040 (0.4394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4230 (0.4780) Acc D Real: 100.000%
Loss D Fake: 1.1061 (1.0401) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4036 (0.4389) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4205 (0.4773) Acc D Real: 100.000%
Loss D Fake: 1.1069 (1.0409) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4032 (0.4385) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4202 (0.4766) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.0417) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4028 (0.4381) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4194 (0.4759) Acc D Real: 100.000%
Loss D Fake: 1.1084 (1.0425) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4025 (0.4376) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4183 (0.4752) Acc D Real: 100.000%
Loss D Fake: 1.1091 (1.0433) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4021 (0.4372) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4175 (0.4746) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.0441) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4018 (0.4368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4163 (0.4739) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.0448) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4015 (0.4364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4169 (0.4733) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.0456) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4011 (0.4360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4168 (0.4726) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.0463) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4008 (0.4356) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4135 (0.4720) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.0470) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4005 (0.4352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4145 (0.4713) Acc D Real: 100.000%
Loss D Fake: 1.1130 (1.0478) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4003 (0.4348) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4139 (0.4707) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.0485) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4000 (0.4345) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4129 (0.4701) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.0492) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3997 (0.4341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4124 (0.4695) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.0499) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3995 (0.4337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4118 (0.4689) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.0506) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3992 (0.4333) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4117 (0.4683) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.0513) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3990 (0.4330) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4099 (0.4677) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.0519) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3987 (0.4326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4091 (0.4671) Acc D Real: 100.000%
Loss D Fake: 1.1166 (1.0526) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3985 (0.4323) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4102 (0.4665) Acc D Real: 100.000%
Loss D Fake: 1.1170 (1.0532) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3983 (0.4319) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4078 (0.4659) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.0539) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3981 (0.4316) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4082 (0.4653) Acc D Real: 100.000%
Loss D Fake: 1.1179 (1.0545) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3979 (0.4313) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4075 (0.4648) Acc D Real: 100.000%
Loss D Fake: 1.1183 (1.0551) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3977 (0.4309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4066 (0.4642) Acc D Real: 100.000%
Loss D Fake: 1.1187 (1.0558) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3975 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4064 (0.4637) Acc D Real: 100.000%
Loss D Fake: 1.1191 (1.0564) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3973 (0.4303) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4053 (0.4631) Acc D Real: 100.000%
Loss D Fake: 1.1195 (1.0570) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3971 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4046 (0.4625) Acc D Real: 100.000%
Loss D Fake: 1.1198 (1.0576) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3969 (0.4297) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4046 (0.4620) Acc D Real: 100.000%
Loss D Fake: 1.1202 (1.0581) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3968 (0.4294) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4043 (0.4615) Acc D Real: 100.000%
Loss D Fake: 1.1205 (1.0587) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3966 (0.4291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4039 (0.4609) Acc D Real: 100.000%
Loss D Fake: 1.1209 (1.0593) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3965 (0.4288) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4035 (0.4604) Acc D Real: 100.000%
Loss D Fake: 1.1212 (1.0599) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3963 (0.4285) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4020 (0.4599) Acc D Real: 100.000%
Loss D Fake: 1.1215 (1.0604) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3961 (0.4282) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4022 (0.4594) Acc D Real: 100.000%
Loss D Fake: 1.1219 (1.0610) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3960 (0.4279) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4014 (0.4589) Acc D Real: 100.000%
Loss D Fake: 1.1222 (1.0615) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3958 (0.4276) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4012 (0.4584) Acc D Real: 100.000%
Loss D Fake: 1.1225 (1.0620) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3957 (0.4273) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4003 (0.4579) Acc D Real: 100.000%
Loss D Fake: 1.1228 (1.0626) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3955 (0.4270) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.3995 (0.4574) Acc D Real: 100.000%
Loss D Fake: 1.1230 (1.0631) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3954 (0.4268) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.3993 (0.4569) Acc D Real: 100.000%
Loss D Fake: 1.1233 (1.0636) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3953 (0.4265) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.3985 (0.4564) Acc D Real: 100.000%
Loss D Fake: 1.1236 (1.0641) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3952 (0.4262) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.3982 (0.4559) Acc D Real: 100.000%
Loss D Fake: 1.1238 (1.0646) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3951 (0.4260) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.3976 (0.4554) Acc D Real: 100.000%
Loss D Fake: 1.1240 (1.0651) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3949 (0.4257) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.3975 (0.4549) Acc D Real: 100.000%
Loss D Fake: 1.1243 (1.0656) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3948 (0.4255) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.3965 (0.4544) Acc D Real: 100.000%
Loss D Fake: 1.1245 (1.0661) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3947 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.3960 (0.4540) Acc D Real: 100.000%
Loss D Fake: 1.1247 (1.0666) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3946 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.3957 (0.4535) Acc D Real: 100.000%
Loss D Fake: 1.1249 (1.0670) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3945 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.3954 (0.4530) Acc D Real: 100.000%
Loss D Fake: 1.1251 (1.0675) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3945 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.3948 (0.4526) Acc D Real: 100.000%
Loss D Fake: 1.1252 (1.0679) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3944 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.3943 (0.4521) Acc D Real: 100.000%
Loss D Fake: 1.1254 (1.0684) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3943 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.3940 (0.4516) Acc D Real: 100.000%
Loss D Fake: 1.1256 (1.0688) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3942 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.3935 (0.4512) Acc D Real: 100.000%
Loss D Fake: 1.1258 (1.0693) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3941 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.3930 (0.4507) Acc D Real: 100.000%
Loss D Fake: 1.1259 (1.0697) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3941 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.3924 (0.4503) Acc D Real: 100.000%
Loss D Fake: 1.1260 (1.0701) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3940 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.3919 (0.4499) Acc D Real: 100.000%
Loss D Fake: 1.1262 (1.0706) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3939 (0.4229) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.3913 (0.4494) Acc D Real: 100.000%
Loss D Fake: 1.1263 (1.0710) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3938 (0.4226) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.3910 (0.4490) Acc D Real: 100.000%
Loss D Fake: 1.1265 (1.0714) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3938 (0.4224) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.3905 (0.4485) Acc D Real: 100.000%
Loss D Fake: 1.1266 (1.0718) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3937 (0.4222) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.3906 (0.4481) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0722) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3936 (0.4220) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.3895 (0.4477) Acc D Real: 100.000%
Loss D Fake: 1.1269 (1.0726) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3935 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.3893 (0.4473) Acc D Real: 100.000%
Loss D Fake: 1.1271 (1.0730) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3935 (0.4216) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.3886 (0.4468) Acc D Real: 100.000%
Loss D Fake: 1.1272 (1.0734) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3934 (0.4214) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.3888 (0.4464) Acc D Real: 100.000%
Loss D Fake: 1.1274 (1.0738) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3933 (0.4212) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.3875 (0.4460) Acc D Real: 100.000%
Loss D Fake: 1.1275 (1.0742) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3933 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.3871 (0.4456) Acc D Real: 100.000%
Loss D Fake: 1.1276 (1.0745) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3932 (0.4208) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.3870 (0.4452) Acc D Real: 100.000%
Loss D Fake: 1.1278 (1.0749) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3932 (0.4206) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.3866 (0.4448) Acc D Real: 100.000%
Loss D Fake: 1.1279 (1.0753) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3931 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.3856 (0.4444) Acc D Real: 100.000%
Loss D Fake: 1.1280 (1.0757) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3930 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.3854 (0.4440) Acc D Real: 100.000%
Loss D Fake: 1.1281 (1.0760) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3930 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.3846 (0.4436) Acc D Real: 100.000%
Loss D Fake: 1.1282 (1.0764) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.3929 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.3844 (0.4432) Acc D Real: 100.000%
Loss D Fake: 1.1283 (1.0767) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.3929 (0.4197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.3829 (0.4428) Acc D Real: 100.000%
Loss D Fake: 1.1285 (1.0771) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.3928 (0.4195) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.3837 (0.4424) Acc D Real: 100.000%
Loss D Fake: 1.1286 (1.0774) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.3927 (0.4193) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.3838 (0.4420) Acc D Real: 100.000%
Loss D Fake: 1.1287 (1.0777) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.3927 (0.4191) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.3822 (0.4416) Acc D Real: 100.000%
Loss D Fake: 1.1288 (1.0781) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.3926 (0.4190) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.3812 (0.4412) Acc D Real: 100.000%
Loss D Fake: 1.1290 (1.0784) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.3926 (0.4188) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.3811 (0.4408) Acc D Real: 100.000%
Loss D Fake: 1.1291 (1.0787) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.3925 (0.4186) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.3798 (0.4404) Acc D Real: 100.000%
Loss D Fake: 1.1292 (1.0791) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.3924 (0.4185) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.3805 (0.4400) Acc D Real: 100.000%
Loss D Fake: 1.1294 (1.0794) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.3924 (0.4183) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.3785 (0.4396) Acc D Real: 100.000%
Loss D Fake: 1.1295 (1.0797) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.3923 (0.4181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.3797 (0.4393) Acc D Real: 100.000%
Loss D Fake: 1.1296 (1.0800) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.3922 (0.4180) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.3779 (0.4389) Acc D Real: 100.000%
Loss D Fake: 1.1298 (1.0803) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.3922 (0.4178) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.3771 (0.4385) Acc D Real: 100.000%
Loss D Fake: 1.1299 (1.0807) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.3921 (0.4176) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.3776 (0.4381) Acc D Real: 100.000%
Loss D Fake: 1.1301 (1.0810) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.3920 (0.4175) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.3757 (0.4377) Acc D Real: 100.000%
Loss D Fake: 1.1302 (1.0813) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.3920 (0.4173) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.3772 (0.4373) Acc D Real: 100.000%
Loss D Fake: 1.1304 (1.0816) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.3919 (0.4172) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.3764 (0.4370) Acc D Real: 100.000%
Loss D Fake: 1.1305 (1.0819) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.3918 (0.4170) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3746 (0.4366) Acc D Real: 100.000%
Loss D Fake: 1.1307 (1.0822) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.3917 (0.4169) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.3736 (0.4362) Acc D Real: 100.000%
Loss D Fake: 1.1308 (1.0825) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.3917 (0.4167) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.3743 (0.4358) Acc D Real: 100.000%
Loss D Fake: 1.1310 (1.0827) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.3916 (0.4166) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.3711 (0.4355) Acc D Real: 100.000%
Loss D Fake: 1.1312 (1.0830) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.3915 (0.4164) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.3728 (0.4351) Acc D Real: 100.000%
Loss D Fake: 1.1314 (1.0833) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.3914 (0.4163) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.3723 (0.4347) Acc D Real: 100.000%
Loss D Fake: 1.1315 (1.0836) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.3913 (0.4161) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.3704 (0.4343) Acc D Real: 100.000%
Loss D Fake: 1.1317 (1.0839) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.3912 (0.4160) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.3680 (0.4340) Acc D Real: 100.000%
Loss D Fake: 1.1319 (1.0842) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.3911 (0.4158) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.3698 (0.4336) Acc D Real: 100.000%
Loss D Fake: 1.1321 (1.0844) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.3910 (0.4157) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.3701 (0.4332) Acc D Real: 100.000%
Loss D Fake: 1.1323 (1.0847) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.3909 (0.4155) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.3686 (0.4329) Acc D Real: 100.000%
Loss D Fake: 1.1326 (1.0850) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.3908 (0.4154) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.3685 (0.4325) Acc D Real: 100.000%
Loss D Fake: 1.1328 (1.0853) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.3907 (0.4153) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.3682 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.1330 (1.0855) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.3906 (0.4151) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.3651 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.1332 (1.0858) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.3905 (0.4150) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.3665 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.1334 (1.0861) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.3904 (0.4148) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.3616 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.1336 (1.0863) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.3903 (0.4147) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.3636 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.1338 (1.0866) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.3902 (0.4146) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.3645 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.1341 (1.0868) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.3901 (0.4144) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.3637 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.1343 (1.0871) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.3900 (0.4143) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.3595 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.1346 (1.0874) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.3898 (0.4142) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.3606 (0.4291) Acc D Real: 100.000%
Loss D Fake: 1.1349 (1.0876) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.3897 (0.4140) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.3615 (0.4288) Acc D Real: 100.000%
Loss D Fake: 1.1352 (1.0879) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.3896 (0.4139) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.3587 (0.4284) Acc D Real: 100.000%
Loss D Fake: 1.1355 (1.0881) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.3894 (0.4138) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.3594 (0.4280) Acc D Real: 100.000%
Loss D Fake: 1.1358 (1.0884) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.3893 (0.4136) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.3547 (0.4277) Acc D Real: 100.000%
Loss D Fake: 1.1361 (1.0886) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.3891 (0.4135) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.3543 (0.4273) Acc D Real: 100.000%
Loss D Fake: 1.1364 (1.0889) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.3890 (0.4134) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.3532 (0.4269) Acc D Real: 100.000%
Loss D Fake: 1.1368 (1.0891) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.3888 (0.4133) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.3537 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.1372 (1.0894) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.3886 (0.4131) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.3509 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.1376 (1.0896) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.3884 (0.4130) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.3563 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.1381 (1.0899) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.3882 (0.4129) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.3481 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.1385 (1.0901) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.3880 (0.4127) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.3462 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.1390 (1.0904) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.3877 (0.4126) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.3431 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.1395 (1.0906) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.3875 (0.4125) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.3394 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.1400 (1.0909) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.3872 (0.4124) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.3444 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.1406 (1.0911) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.3869 (0.4122) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.3407 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.1412 (1.0914) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.3866 (0.4121) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.3378 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.1419 (1.0916) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.3863 (0.4120) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.3373 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.1426 (1.0919) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.3860 (0.4118) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.3343 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.1434 (1.0921) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.3856 (0.4117) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.3347 (0.4216) Acc D Real: 100.000%
Loss D Fake: 1.1442 (1.0924) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.3852 (0.4116) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.3325 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.1450 (1.0927) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.3848 (0.4115) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.3273 (0.4207) Acc D Real: 100.000%
Loss D Fake: 1.1460 (1.0929) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.3844 (0.4113) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3294 (0.4202) Acc D Real: 100.000%
Loss D Fake: 1.1470 (1.0932) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.3839 (0.4112) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.3240 (0.4198) Acc D Real: 100.000%
Loss D Fake: 1.1481 (1.0934) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.3834 (0.4111) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.3199 (0.4193) Acc D Real: 100.000%
Loss D Fake: 1.1493 (1.0937) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.3828 (0.4109) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.3177 (0.4188) Acc D Real: 100.000%
Loss D Fake: 1.1506 (1.0940) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.3822 (0.4108) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.3148 (0.4183) Acc D Real: 100.000%
Loss D Fake: 1.1520 (1.0943) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.3815 (0.4106) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3091 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.1535 (1.0945) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.3808 (0.4105) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.3052 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.1552 (1.0948) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.3800 (0.4104) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.2992 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.1571 (1.0951) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.3791 (0.4102) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.3029 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.1593 (1.0954) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.3781 (0.4101) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.2935 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.1617 (1.0957) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.3769 (0.4099) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.2762 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.1644 (1.0960) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.3757 (0.4098) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.2702 (0.4143) Acc D Real: 100.000%
Loss D Fake: 1.1672 (1.0964) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.3745 (0.4096) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.2664 (0.4136) Acc D Real: 100.000%
Loss D Fake: 1.1700 (1.0967) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.3734 (0.4094) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.2441 (0.4129) Acc D Real: 100.000%
Loss D Fake: 1.1725 (1.0970) Acc D Fake: 0.000%
Loss D: 1.417
Loss G: 0.3726 (0.4093) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.2483 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.1737 (1.0974) Acc D Fake: 0.000%
Loss D: 1.422
Loss G: 0.3724 (0.4091) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.2474 (0.4114) Acc D Real: 100.000%
Loss D Fake: 1.1739 (1.0977) Acc D Fake: 0.000%
Loss D: 1.421
Loss G: 0.3724 (0.4089) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.2276 (0.4106) Acc D Real: 100.000%
Loss D Fake: 1.1731 (1.0981) Acc D Fake: 0.000%
Loss D: 1.401
Loss G: 0.3735 (0.4088) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.2166 (0.4097) Acc D Real: 100.000%
Loss D Fake: 1.1691 (1.0984) Acc D Fake: 0.000%
Loss D: 1.386
Loss G: 0.3761 (0.4086) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.2097 (0.4088) Acc D Real: 100.000%
Loss D Fake: 1.1610 (1.0987) Acc D Fake: 0.000%
Loss D: 1.371
Loss G: 0.3807 (0.4085) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.2083 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1489 (1.0989) Acc D Fake: 0.000%
Loss D: 1.357
Loss G: 0.3868 (0.4084) Acc G: 100.000%
LR: 2.000e-04
Best Loss 0.983 to 0.958
Epoch: 5/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.2096 (0.2137) Acc D Real: 100.000%
Loss D Fake: 1.1206 (1.1277) Acc D Fake: 0.000%
Loss D: 1.330
Loss G: 0.4001 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.2098 (0.2124) Acc D Real: 100.000%
Loss D Fake: 1.1061 (1.1205) Acc D Fake: 0.000%
Loss D: 1.316
Loss G: 0.4072 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.2239 (0.2153) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1134) Acc D Fake: 0.000%
Loss D: 1.316
Loss G: 0.4135 (0.4036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.2052 (0.2132) Acc D Real: 100.000%
Loss D Fake: 1.0804 (1.1068) Acc D Fake: 0.000%
Loss D: 1.286
Loss G: 0.4194 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.2123 (0.2131) Acc D Real: 100.000%
Loss D Fake: 1.0693 (1.1006) Acc D Fake: 0.000%
Loss D: 1.282
Loss G: 0.4248 (0.4097) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.2186 (0.2139) Acc D Real: 100.000%
Loss D Fake: 1.0597 (1.0947) Acc D Fake: 0.000%
Loss D: 1.278
Loss G: 0.4295 (0.4126) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.2131 (0.2138) Acc D Real: 100.000%
Loss D Fake: 1.0520 (1.0894) Acc D Fake: 0.000%
Loss D: 1.265
Loss G: 0.4330 (0.4151) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.2042 (0.2127) Acc D Real: 100.000%
Loss D Fake: 1.0462 (1.0846) Acc D Fake: 0.000%
Loss D: 1.250
Loss G: 0.4360 (0.4174) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.1921 (0.2107) Acc D Real: 100.000%
Loss D Fake: 1.0404 (1.0802) Acc D Fake: 0.000%
Loss D: 1.233
Loss G: 0.4394 (0.4196) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.1924 (0.2090) Acc D Real: 100.000%
Loss D Fake: 1.0338 (1.0759) Acc D Fake: 0.000%
Loss D: 1.226
Loss G: 0.4433 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.1986 (0.2081) Acc D Real: 100.000%
Loss D Fake: 1.0269 (1.0719) Acc D Fake: 0.000%
Loss D: 1.226
Loss G: 0.4469 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.1940 (0.2070) Acc D Real: 100.000%
Loss D Fake: 1.0207 (1.0679) Acc D Fake: 0.000%
Loss D: 1.215
Loss G: 0.4503 (0.4259) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.1923 (0.2060) Acc D Real: 100.000%
Loss D Fake: 1.0149 (1.0641) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.4536 (0.4279) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.1980 (0.2055) Acc D Real: 100.000%
Loss D Fake: 1.0097 (1.0605) Acc D Fake: 0.000%
Loss D: 1.208
Loss G: 0.4563 (0.4298) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.1951 (0.2048) Acc D Real: 100.000%
Loss D Fake: 1.0056 (1.0571) Acc D Fake: 0.000%
Loss D: 1.201
Loss G: 0.4585 (0.4316) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.2051 (0.2048) Acc D Real: 100.000%
Loss D Fake: 1.0023 (1.0539) Acc D Fake: 0.000%
Loss D: 1.207
Loss G: 0.4601 (0.4333) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.1812 (0.2035) Acc D Real: 100.000%
Loss D Fake: 0.9996 (1.0508) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.4620 (0.4349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.1875 (0.2027) Acc D Real: 100.000%
Loss D Fake: 0.9962 (1.0480) Acc D Fake: 0.000%
Loss D: 1.184
Loss G: 0.4640 (0.4364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.1746 (0.2013) Acc D Real: 100.000%
Loss D Fake: 0.9924 (1.0452) Acc D Fake: 0.000%
Loss D: 1.167
Loss G: 0.4667 (0.4379) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.1723 (0.1999) Acc D Real: 100.000%
Loss D Fake: 0.9873 (1.0424) Acc D Fake: 0.000%
Loss D: 1.160
Loss G: 0.4702 (0.4394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.1817 (0.1991) Acc D Real: 100.000%
Loss D Fake: 0.9814 (1.0397) Acc D Fake: 0.000%
Loss D: 1.163
Loss G: 0.4739 (0.4410) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.1734 (0.1980) Acc D Real: 100.000%
Loss D Fake: 0.9753 (1.0369) Acc D Fake: 0.000%
Loss D: 1.149
Loss G: 0.4777 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.1842 (0.1974) Acc D Real: 100.000%
Loss D Fake: 0.9695 (1.0340) Acc D Fake: 0.000%
Loss D: 1.154
Loss G: 0.4809 (0.4442) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.1701 (0.1963) Acc D Real: 100.000%
Loss D Fake: 0.9647 (1.0313) Acc D Fake: 0.000%
Loss D: 1.135
Loss G: 0.4840 (0.4458) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.1686 (0.1952) Acc D Real: 100.000%
Loss D Fake: 0.9595 (1.0285) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.4874 (0.4474) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.1681 (0.1942) Acc D Real: 100.000%
Loss D Fake: 0.9542 (1.0258) Acc D Fake: 0.000%
Loss D: 1.122
Loss G: 0.4908 (0.4490) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.1645 (0.1932) Acc D Real: 100.000%
Loss D Fake: 0.9490 (1.0230) Acc D Fake: 0.000%
Loss D: 1.114
Loss G: 0.4942 (0.4506) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.1734 (0.1925) Acc D Real: 100.000%
Loss D Fake: 0.9439 (1.0203) Acc D Fake: 0.000%
Loss D: 1.117
Loss G: 0.4976 (0.4522) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.1883 (0.1923) Acc D Real: 100.000%
Loss D Fake: 0.9392 (1.0176) Acc D Fake: 0.000%
Loss D: 1.128
Loss G: 0.5002 (0.4538) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.1732 (0.1917) Acc D Real: 100.000%
Loss D Fake: 0.9361 (1.0150) Acc D Fake: 0.000%
Loss D: 1.109
Loss G: 0.5019 (0.4554) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.1816 (0.1914) Acc D Real: 100.000%
Loss D Fake: 0.9340 (1.0124) Acc D Fake: 0.000%
Loss D: 1.116
Loss G: 0.5031 (0.4569) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.1656 (0.1906) Acc D Real: 100.000%
Loss D Fake: 0.9324 (1.0100) Acc D Fake: 0.000%
Loss D: 1.098
Loss G: 0.5043 (0.4583) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.1710 (0.1900) Acc D Real: 100.000%
Loss D Fake: 0.9307 (1.0077) Acc D Fake: 0.000%
Loss D: 1.102
Loss G: 0.5054 (0.4597) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.1691 (0.1894) Acc D Real: 100.000%
Loss D Fake: 0.9290 (1.0054) Acc D Fake: 0.000%
Loss D: 1.098
Loss G: 0.5066 (0.4610) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.1662 (0.1888) Acc D Real: 100.000%
Loss D Fake: 0.9274 (1.0033) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.5077 (0.4623) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.1559 (0.1879) Acc D Real: 100.000%
Loss D Fake: 0.9258 (1.0012) Acc D Fake: 0.000%
Loss D: 1.082
Loss G: 0.5090 (0.4636) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.1479 (0.1869) Acc D Real: 100.000%
Loss D Fake: 0.9235 (0.9991) Acc D Fake: 0.000%
Loss D: 1.071
Loss G: 0.5111 (0.4648) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.1597 (0.1862) Acc D Real: 100.000%
Loss D Fake: 0.9203 (0.9971) Acc D Fake: 0.000%
Loss D: 1.080
Loss G: 0.5132 (0.4661) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.1501 (0.1853) Acc D Real: 100.000%
Loss D Fake: 0.9171 (0.9951) Acc D Fake: 0.000%
Loss D: 1.067
Loss G: 0.5156 (0.4673) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.1553 (0.1845) Acc D Real: 100.000%
Loss D Fake: 0.9136 (0.9931) Acc D Fake: 0.000%
Loss D: 1.069
Loss G: 0.5181 (0.4686) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.1500 (0.1837) Acc D Real: 100.000%
Loss D Fake: 0.9102 (0.9911) Acc D Fake: 0.000%
Loss D: 1.060
Loss G: 0.5205 (0.4698) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.1429 (0.1828) Acc D Real: 100.000%
Loss D Fake: 0.9067 (0.9892) Acc D Fake: 0.000%
Loss D: 1.050
Loss G: 0.5233 (0.4710) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.1449 (0.1819) Acc D Real: 100.000%
Loss D Fake: 0.9024 (0.9872) Acc D Fake: 0.000%
Loss D: 1.047
Loss G: 0.5266 (0.4723) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.1594 (0.1814) Acc D Real: 100.000%
Loss D Fake: 0.8980 (0.9852) Acc D Fake: 0.000%
Loss D: 1.057
Loss G: 0.5294 (0.4736) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.1427 (0.1806) Acc D Real: 100.000%
Loss D Fake: 0.8942 (0.9832) Acc D Fake: 0.000%
Loss D: 1.037
Loss G: 0.5324 (0.4749) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.1552 (0.1800) Acc D Real: 100.000%
Loss D Fake: 0.8902 (0.9813) Acc D Fake: 0.000%
Loss D: 1.045
Loss G: 0.5353 (0.4761) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.1404 (0.1792) Acc D Real: 100.000%
Loss D Fake: 0.8863 (0.9793) Acc D Fake: 0.000%
Loss D: 1.027
Loss G: 0.5381 (0.4774) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.1351 (0.1783) Acc D Real: 100.000%
Loss D Fake: 0.8824 (0.9773) Acc D Fake: 0.000%
Loss D: 1.017
Loss G: 0.5412 (0.4787) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.1407 (0.1775) Acc D Real: 100.000%
Loss D Fake: 0.8783 (0.9753) Acc D Fake: 0.000%
Loss D: 1.019
Loss G: 0.5442 (0.4800) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.1614 (0.1772) Acc D Real: 100.000%
Loss D Fake: 0.8747 (0.9734) Acc D Fake: 0.000%
Loss D: 1.036
Loss G: 0.5466 (0.4813) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.1378 (0.1765) Acc D Real: 100.000%
Loss D Fake: 0.8717 (0.9714) Acc D Fake: 0.000%
Loss D: 1.009
Loss G: 0.5490 (0.4826) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.1418 (0.1758) Acc D Real: 100.000%
Loss D Fake: 0.8687 (0.9695) Acc D Fake: 0.000%
Loss D: 1.010
Loss G: 0.5512 (0.4839) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.1348 (0.1751) Acc D Real: 100.000%
Loss D Fake: 0.8659 (0.9675) Acc D Fake: 0.000%
Loss D: 1.001
Loss G: 0.5535 (0.4852) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.1364 (0.1744) Acc D Real: 100.000%
Loss D Fake: 0.8629 (0.9656) Acc D Fake: 0.000%
Loss D: 0.999
Loss G: 0.5558 (0.4865) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.1297 (0.1736) Acc D Real: 100.000%
Loss D Fake: 0.8598 (0.9638) Acc D Fake: 0.000%
Loss D: 0.990
Loss G: 0.5583 (0.4878) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.1322 (0.1728) Acc D Real: 100.000%
Loss D Fake: 0.8566 (0.9619) Acc D Fake: 0.000%
Loss D: 0.989
Loss G: 0.5609 (0.4891) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.1453 (0.1724) Acc D Real: 100.000%
Loss D Fake: 0.8535 (0.9600) Acc D Fake: 0.000%
Loss D: 0.999
Loss G: 0.5632 (0.4904) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.1384 (0.1718) Acc D Real: 100.000%
Loss D Fake: 0.8508 (0.9582) Acc D Fake: 0.000%
Loss D: 0.989
Loss G: 0.5652 (0.4916) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.1372 (0.1712) Acc D Real: 100.000%
Loss D Fake: 0.8486 (0.9563) Acc D Fake: 0.000%
Loss D: 0.986
Loss G: 0.5669 (0.4929) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.1325 (0.1706) Acc D Real: 100.000%
Loss D Fake: 0.8466 (0.9545) Acc D Fake: 0.000%
Loss D: 0.979
Loss G: 0.5686 (0.4941) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.1278 (0.1699) Acc D Real: 100.000%
Loss D Fake: 0.8445 (0.9528) Acc D Fake: 0.000%
Loss D: 0.972
Loss G: 0.5704 (0.4953) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.1313 (0.1693) Acc D Real: 100.000%
Loss D Fake: 0.8423 (0.9510) Acc D Fake: 0.000%
Loss D: 0.974
Loss G: 0.5722 (0.4966) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.1277 (0.1686) Acc D Real: 100.000%
Loss D Fake: 0.8400 (0.9493) Acc D Fake: 0.000%
Loss D: 0.968
Loss G: 0.5742 (0.4978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.1262 (0.1680) Acc D Real: 100.000%
Loss D Fake: 0.8377 (0.9475) Acc D Fake: 0.000%
Loss D: 0.964
Loss G: 0.5762 (0.4990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.1268 (0.1673) Acc D Real: 100.000%
Loss D Fake: 0.8353 (0.9458) Acc D Fake: 0.000%
Loss D: 0.962
Loss G: 0.5781 (0.5002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.1252 (0.1667) Acc D Real: 100.000%
Loss D Fake: 0.8331 (0.9442) Acc D Fake: 0.000%
Loss D: 0.958
Loss G: 0.5799 (0.5014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.1289 (0.1662) Acc D Real: 100.000%
Loss D Fake: 0.8309 (0.9425) Acc D Fake: 0.000%
Loss D: 0.960
Loss G: 0.5818 (0.5026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.1258 (0.1656) Acc D Real: 100.000%
Loss D Fake: 0.8287 (0.9408) Acc D Fake: 0.000%
Loss D: 0.955
Loss G: 0.5836 (0.5037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.1224 (0.1650) Acc D Real: 100.000%
Loss D Fake: 0.8266 (0.9392) Acc D Fake: 0.000%
Loss D: 0.949
Loss G: 0.5854 (0.5049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.1223 (0.1644) Acc D Real: 100.000%
Loss D Fake: 0.8245 (0.9376) Acc D Fake: 0.000%
Loss D: 0.947
Loss G: 0.5872 (0.5061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.1256 (0.1638) Acc D Real: 100.000%
Loss D Fake: 0.8224 (0.9360) Acc D Fake: 0.000%
Loss D: 0.948
Loss G: 0.5890 (0.5072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.1341 (0.1634) Acc D Real: 100.000%
Loss D Fake: 0.8204 (0.9344) Acc D Fake: 0.000%
Loss D: 0.954
Loss G: 0.5908 (0.5084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.1240 (0.1629) Acc D Real: 100.000%
Loss D Fake: 0.8183 (0.9328) Acc D Fake: 0.000%
Loss D: 0.942
Loss G: 0.5925 (0.5095) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.1201 (0.1623) Acc D Real: 100.000%
Loss D Fake: 0.8163 (0.9313) Acc D Fake: 0.000%
Loss D: 0.936
Loss G: 0.5944 (0.5106) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.1339 (0.1619) Acc D Real: 100.000%
Loss D Fake: 0.8142 (0.9298) Acc D Fake: 0.000%
Loss D: 0.948
Loss G: 0.5962 (0.5118) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.1194 (0.1614) Acc D Real: 100.000%
Loss D Fake: 0.8122 (0.9282) Acc D Fake: 0.000%
Loss D: 0.932
Loss G: 0.5980 (0.5129) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.1188 (0.1608) Acc D Real: 100.000%
Loss D Fake: 0.8101 (0.9267) Acc D Fake: 0.000%
Loss D: 0.929
Loss G: 0.5999 (0.5140) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.1181 (0.1603) Acc D Real: 100.000%
Loss D Fake: 0.8079 (0.9252) Acc D Fake: 0.000%
Loss D: 0.926
Loss G: 0.6018 (0.5151) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.1148 (0.1597) Acc D Real: 100.000%
Loss D Fake: 0.8058 (0.9237) Acc D Fake: 0.000%
Loss D: 0.921
Loss G: 0.6037 (0.5162) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.1142 (0.1592) Acc D Real: 100.000%
Loss D Fake: 0.8035 (0.9222) Acc D Fake: 0.021%
Loss D: 0.918
Loss G: 0.6057 (0.5173) Acc G: 99.938%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.1207 (0.1587) Acc D Real: 100.000%
Loss D Fake: 0.8016 (0.9208) Acc D Fake: 0.081%
Loss D: 0.922
Loss G: 0.6070 (0.5184) Acc G: 99.878%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.1150 (0.1582) Acc D Real: 100.000%
Loss D Fake: 0.8004 (0.9193) Acc D Fake: 0.161%
Loss D: 0.915
Loss G: 0.6082 (0.5195) Acc G: 99.779%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.1458 (0.1580) Acc D Real: 100.000%
Loss D Fake: 0.7991 (0.9179) Acc D Fake: 0.258%
Loss D: 0.945
Loss G: 0.6094 (0.5206) Acc G: 99.683%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.1175 (0.1575) Acc D Real: 100.000%
Loss D Fake: 0.7979 (0.9165) Acc D Fake: 0.373%
Loss D: 0.915
Loss G: 0.6106 (0.5216) Acc G: 99.569%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.1120 (0.1570) Acc D Real: 100.000%
Loss D Fake: 0.7966 (0.9151) Acc D Fake: 0.484%
Loss D: 0.909
Loss G: 0.6120 (0.5227) Acc G: 99.457%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.1274 (0.1567) Acc D Real: 99.998%
Loss D Fake: 0.7949 (0.9137) Acc D Fake: 0.594%
Loss D: 0.922
Loss G: 0.6136 (0.5237) Acc G: 99.330%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.1123 (0.1562) Acc D Real: 99.998%
Loss D Fake: 0.7931 (0.9123) Acc D Fake: 0.720%
Loss D: 0.905
Loss G: 0.6153 (0.5248) Acc G: 99.186%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.1136 (0.1557) Acc D Real: 99.998%
Loss D Fake: 0.7911 (0.9110) Acc D Fake: 0.861%
Loss D: 0.905
Loss G: 0.6172 (0.5258) Acc G: 99.045%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.1132 (0.1552) Acc D Real: 99.998%
Loss D Fake: 0.7890 (0.9096) Acc D Fake: 1.000%
Loss D: 0.902
Loss G: 0.6192 (0.5268) Acc G: 98.907%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.1169 (0.1548) Acc D Real: 99.998%
Loss D Fake: 0.7868 (0.9083) Acc D Fake: 1.154%
Loss D: 0.904
Loss G: 0.6211 (0.5279) Acc G: 98.755%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.1265 (0.1545) Acc D Real: 99.994%
Loss D Fake: 0.7848 (0.9069) Acc D Fake: 1.304%
Loss D: 0.911
Loss G: 0.6229 (0.5289) Acc G: 98.587%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.1135 (0.1541) Acc D Real: 99.994%
Loss D Fake: 0.7829 (0.9056) Acc D Fake: 1.470%
Loss D: 0.896
Loss G: 0.6248 (0.5299) Acc G: 98.423%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.1116 (0.1536) Acc D Real: 99.994%
Loss D Fake: 0.7809 (0.9043) Acc D Fake: 1.631%
Loss D: 0.892
Loss G: 0.6266 (0.5310) Acc G: 98.262%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.1141 (0.1532) Acc D Real: 99.994%
Loss D Fake: 0.7789 (0.9029) Acc D Fake: 1.807%
Loss D: 0.893
Loss G: 0.6285 (0.5320) Acc G: 98.088%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.1124 (0.1528) Acc D Real: 99.994%
Loss D Fake: 0.7769 (0.9016) Acc D Fake: 1.979%
Loss D: 0.889
Loss G: 0.6304 (0.5330) Acc G: 97.917%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.1125 (0.1523) Acc D Real: 99.994%
Loss D Fake: 0.7749 (0.9003) Acc D Fake: 2.148%
Loss D: 0.887
Loss G: 0.6322 (0.5340) Acc G: 97.742%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.1090 (0.1519) Acc D Real: 99.994%
Loss D Fake: 0.7730 (0.8990) Acc D Fake: 2.330%
Loss D: 0.882
Loss G: 0.6341 (0.5351) Acc G: 97.561%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.1097 (0.1515) Acc D Real: 99.994%
Loss D Fake: 0.7710 (0.8977) Acc D Fake: 2.508%
Loss D: 0.881
Loss G: 0.6360 (0.5361) Acc G: 97.383%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.1070 (0.1510) Acc D Real: 99.994%
Loss D Fake: 0.7689 (0.8964) Acc D Fake: 2.717%
Loss D: 0.876
Loss G: 0.6380 (0.5371) Acc G: 97.076%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.1061 (0.1506) Acc D Real: 99.994%
Loss D Fake: 0.7667 (0.8952) Acc D Fake: 3.069%
Loss D: 0.873
Loss G: 0.6401 (0.5381) Acc G: 96.692%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.1149 (0.1502) Acc D Real: 99.994%
Loss D Fake: 0.7647 (0.8939) Acc D Fake: 3.464%
Loss D: 0.880
Loss G: 0.6418 (0.5391) Acc G: 96.300%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.1144 (0.1499) Acc D Real: 99.994%
Loss D Fake: 0.7631 (0.8926) Acc D Fake: 3.867%
Loss D: 0.877
Loss G: 0.6433 (0.5401) Acc G: 95.899%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.1079 (0.1495) Acc D Real: 99.994%
Loss D Fake: 0.7617 (0.8913) Acc D Fake: 4.263%
Loss D: 0.870
Loss G: 0.6448 (0.5411) Acc G: 95.474%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.1049 (0.1491) Acc D Real: 99.995%
Loss D Fake: 0.7601 (0.8901) Acc D Fake: 4.683%
Loss D: 0.865
Loss G: 0.6465 (0.5421) Acc G: 95.041%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.1062 (0.1487) Acc D Real: 99.995%
Loss D Fake: 0.7584 (0.8889) Acc D Fake: 5.110%
Loss D: 0.865
Loss G: 0.6483 (0.5431) Acc G: 94.616%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.1048 (0.1482) Acc D Real: 99.995%
Loss D Fake: 0.7565 (0.8876) Acc D Fake: 5.561%
Loss D: 0.861
Loss G: 0.6502 (0.5442) Acc G: 94.168%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.1070 (0.1479) Acc D Real: 99.995%
Loss D Fake: 0.7545 (0.8864) Acc D Fake: 6.034%
Loss D: 0.861
Loss G: 0.6522 (0.5452) Acc G: 93.697%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.1077 (0.1475) Acc D Real: 99.995%
Loss D Fake: 0.7525 (0.8852) Acc D Fake: 6.498%
Loss D: 0.860
Loss G: 0.6541 (0.5462) Acc G: 93.220%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.1072 (0.1471) Acc D Real: 99.995%
Loss D Fake: 0.7505 (0.8839) Acc D Fake: 6.970%
Loss D: 0.858
Loss G: 0.6561 (0.5471) Acc G: 92.751%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.1037 (0.1467) Acc D Real: 99.995%
Loss D Fake: 0.7485 (0.8827) Acc D Fake: 7.447%
Loss D: 0.852
Loss G: 0.6581 (0.5481) Acc G: 92.261%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.1064 (0.1464) Acc D Real: 99.995%
Loss D Fake: 0.7464 (0.8815) Acc D Fake: 7.932%
Loss D: 0.853
Loss G: 0.6602 (0.5491) Acc G: 91.764%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.1082 (0.1460) Acc D Real: 99.995%
Loss D Fake: 0.7444 (0.8803) Acc D Fake: 8.422%
Loss D: 0.853
Loss G: 0.6620 (0.5501) Acc G: 91.247%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.1066 (0.1457) Acc D Real: 99.995%
Loss D Fake: 0.7427 (0.8791) Acc D Fake: 8.933%
Loss D: 0.849
Loss G: 0.6638 (0.5511) Acc G: 90.710%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.1051 (0.1453) Acc D Real: 99.995%
Loss D Fake: 0.7409 (0.8779) Acc D Fake: 9.478%
Loss D: 0.846
Loss G: 0.6657 (0.5521) Acc G: 90.168%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.1206 (0.1451) Acc D Real: 99.988%
Loss D Fake: 0.7392 (0.8767) Acc D Fake: 10.014%
Loss D: 0.860
Loss G: 0.6675 (0.5531) Acc G: 89.635%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.1065 (0.1448) Acc D Real: 99.988%
Loss D Fake: 0.7374 (0.8755) Acc D Fake: 10.541%
Loss D: 0.844
Loss G: 0.6694 (0.5541) Acc G: 89.111%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.1022 (0.1444) Acc D Real: 99.988%
Loss D Fake: 0.7355 (0.8743) Acc D Fake: 11.059%
Loss D: 0.838
Loss G: 0.6713 (0.5551) Acc G: 88.581%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.1018 (0.1441) Acc D Real: 99.988%
Loss D Fake: 0.7335 (0.8731) Acc D Fake: 11.583%
Loss D: 0.835
Loss G: 0.6734 (0.5561) Acc G: 88.061%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.1038 (0.1437) Acc D Real: 99.988%
Loss D Fake: 0.7315 (0.8719) Acc D Fake: 12.097%
Loss D: 0.835
Loss G: 0.6755 (0.5571) Acc G: 87.549%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.1017 (0.1434) Acc D Real: 99.988%
Loss D Fake: 0.7295 (0.8708) Acc D Fake: 12.603%
Loss D: 0.831
Loss G: 0.6776 (0.5581) Acc G: 87.046%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.1023 (0.1431) Acc D Real: 99.988%
Loss D Fake: 0.7274 (0.8696) Acc D Fake: 13.101%
Loss D: 0.830
Loss G: 0.6797 (0.5591) Acc G: 86.551%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.1035 (0.1427) Acc D Real: 99.989%
Loss D Fake: 0.7254 (0.8684) Acc D Fake: 13.591%
Loss D: 0.829
Loss G: 0.6819 (0.5601) Acc G: 86.065%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.1023 (0.1424) Acc D Real: 99.989%
Loss D Fake: 0.7233 (0.8672) Acc D Fake: 14.073%
Loss D: 0.826
Loss G: 0.6840 (0.5611) Acc G: 85.586%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.1242 (0.1423) Acc D Real: 99.974%
Loss D Fake: 0.7214 (0.8661) Acc D Fake: 14.547%
Loss D: 0.846
Loss G: 0.6859 (0.5621) Acc G: 85.114%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.1044 (0.1420) Acc D Real: 99.974%
Loss D Fake: 0.7197 (0.8649) Acc D Fake: 15.013%
Loss D: 0.824
Loss G: 0.6877 (0.5631) Acc G: 84.650%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.1038 (0.1417) Acc D Real: 99.975%
Loss D Fake: 0.7181 (0.8638) Acc D Fake: 15.472%
Loss D: 0.822
Loss G: 0.6895 (0.5641) Acc G: 84.194%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.1049 (0.1414) Acc D Real: 99.975%
Loss D Fake: 0.7165 (0.8626) Acc D Fake: 15.924%
Loss D: 0.821
Loss G: 0.6914 (0.5651) Acc G: 83.744%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.1022 (0.1411) Acc D Real: 99.975%
Loss D Fake: 0.7148 (0.8615) Acc D Fake: 16.370%
Loss D: 0.817
Loss G: 0.6932 (0.5661) Acc G: 83.302%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.0967 (0.1407) Acc D Real: 99.975%
Loss D Fake: 0.7131 (0.8603) Acc D Fake: 16.808%
Loss D: 0.810
Loss G: 0.6953 (0.5671) Acc G: 82.866%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.1185 (0.1406) Acc D Real: 99.959%
Loss D Fake: 0.7111 (0.8592) Acc D Fake: 17.239%
Loss D: 0.830
Loss G: 0.6974 (0.5681) Acc G: 82.437%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.0975 (0.1402) Acc D Real: 99.959%
Loss D Fake: 0.7092 (0.8580) Acc D Fake: 17.664%
Loss D: 0.807
Loss G: 0.6996 (0.5691) Acc G: 82.015%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.1005 (0.1399) Acc D Real: 99.960%
Loss D Fake: 0.7071 (0.8569) Acc D Fake: 18.083%
Loss D: 0.808
Loss G: 0.7019 (0.5701) Acc G: 81.586%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.1360 (0.1399) Acc D Real: 99.927%
Loss D Fake: 0.7049 (0.8558) Acc D Fake: 18.507%
Loss D: 0.841
Loss G: 0.7042 (0.5711) Acc G: 81.164%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.1018 (0.1396) Acc D Real: 99.927%
Loss D Fake: 0.7030 (0.8546) Acc D Fake: 18.926%
Loss D: 0.805
Loss G: 0.7063 (0.5721) Acc G: 80.748%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.0979 (0.1393) Acc D Real: 99.928%
Loss D Fake: 0.7011 (0.8535) Acc D Fake: 19.338%
Loss D: 0.799
Loss G: 0.7084 (0.5731) Acc G: 80.338%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.1011 (0.1390) Acc D Real: 99.928%
Loss D Fake: 0.6992 (0.8524) Acc D Fake: 19.745%
Loss D: 0.800
Loss G: 0.7106 (0.5741) Acc G: 79.934%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.0994 (0.1388) Acc D Real: 99.929%
Loss D Fake: 0.6972 (0.8513) Acc D Fake: 20.145%
Loss D: 0.797
Loss G: 0.7128 (0.5751) Acc G: 79.536%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.0994 (0.1385) Acc D Real: 99.929%
Loss D Fake: 0.6952 (0.8501) Acc D Fake: 20.540%
Loss D: 0.795
Loss G: 0.7151 (0.5761) Acc G: 79.143%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.1024 (0.1382) Acc D Real: 99.930%
Loss D Fake: 0.6931 (0.8490) Acc D Fake: 20.929%
Loss D: 0.796
Loss G: 0.7174 (0.5771) Acc G: 78.757%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.0992 (0.1379) Acc D Real: 99.930%
Loss D Fake: 0.6912 (0.8479) Acc D Fake: 21.312%
Loss D: 0.790
Loss G: 0.7196 (0.5781) Acc G: 78.375%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.0957 (0.1376) Acc D Real: 99.931%
Loss D Fake: 0.6892 (0.8468) Acc D Fake: 21.690%
Loss D: 0.785
Loss G: 0.7220 (0.5791) Acc G: 78.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.1178 (0.1375) Acc D Real: 99.916%
Loss D Fake: 0.6871 (0.8457) Acc D Fake: 22.063%
Loss D: 0.805
Loss G: 0.7243 (0.5801) Acc G: 77.629%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.1179 (0.1374) Acc D Real: 99.901%
Loss D Fake: 0.6851 (0.8445) Acc D Fake: 22.431%
Loss D: 0.803
Loss G: 0.7266 (0.5812) Acc G: 77.263%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.0981 (0.1371) Acc D Real: 99.902%
Loss D Fake: 0.6831 (0.8434) Acc D Fake: 22.793%
Loss D: 0.781
Loss G: 0.7289 (0.5822) Acc G: 76.903%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.0962 (0.1368) Acc D Real: 99.903%
Loss D Fake: 0.6811 (0.8423) Acc D Fake: 23.151%
Loss D: 0.777
Loss G: 0.7314 (0.5832) Acc G: 76.548%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.0976 (0.1365) Acc D Real: 99.903%
Loss D Fake: 0.6790 (0.8412) Acc D Fake: 23.503%
Loss D: 0.777
Loss G: 0.7339 (0.5842) Acc G: 76.197%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.1160 (0.1364) Acc D Real: 99.890%
Loss D Fake: 0.6768 (0.8401) Acc D Fake: 23.851%
Loss D: 0.793
Loss G: 0.7363 (0.5852) Acc G: 75.840%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.1175 (0.1363) Acc D Real: 99.875%
Loss D Fake: 0.6748 (0.8390) Acc D Fake: 24.206%
Loss D: 0.792
Loss G: 0.7386 (0.5863) Acc G: 75.488%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.0996 (0.1360) Acc D Real: 99.875%
Loss D Fake: 0.6728 (0.8379) Acc D Fake: 24.556%
Loss D: 0.772
Loss G: 0.7410 (0.5873) Acc G: 75.140%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.0997 (0.1358) Acc D Real: 99.876%
Loss D Fake: 0.6708 (0.8368) Acc D Fake: 24.901%
Loss D: 0.771
Loss G: 0.7434 (0.5883) Acc G: 74.797%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.0960 (0.1355) Acc D Real: 99.877%
Loss D Fake: 0.6688 (0.8357) Acc D Fake: 25.241%
Loss D: 0.765
Loss G: 0.7459 (0.5894) Acc G: 74.458%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.0956 (0.1353) Acc D Real: 99.878%
Loss D Fake: 0.6667 (0.8346) Acc D Fake: 25.577%
Loss D: 0.762
Loss G: 0.7484 (0.5904) Acc G: 74.124%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.1143 (0.1351) Acc D Real: 99.863%
Loss D Fake: 0.6646 (0.8335) Acc D Fake: 25.909%
Loss D: 0.779
Loss G: 0.7510 (0.5915) Acc G: 73.794%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.0963 (0.1349) Acc D Real: 99.864%
Loss D Fake: 0.6624 (0.8324) Acc D Fake: 26.237%
Loss D: 0.759
Loss G: 0.7536 (0.5925) Acc G: 73.469%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.0942 (0.1346) Acc D Real: 99.865%
Loss D Fake: 0.6603 (0.8313) Acc D Fake: 26.560%
Loss D: 0.754
Loss G: 0.7563 (0.5936) Acc G: 73.147%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.0970 (0.1344) Acc D Real: 99.866%
Loss D Fake: 0.6580 (0.8302) Acc D Fake: 26.879%
Loss D: 0.755
Loss G: 0.7590 (0.5946) Acc G: 72.830%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.0973 (0.1341) Acc D Real: 99.866%
Loss D Fake: 0.6559 (0.8291) Acc D Fake: 27.194%
Loss D: 0.753
Loss G: 0.7616 (0.5957) Acc G: 72.517%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.0938 (0.1339) Acc D Real: 99.867%
Loss D Fake: 0.6537 (0.8280) Acc D Fake: 27.505%
Loss D: 0.748
Loss G: 0.7643 (0.5967) Acc G: 72.207%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.0960 (0.1337) Acc D Real: 99.868%
Loss D Fake: 0.6516 (0.8268) Acc D Fake: 27.812%
Loss D: 0.748
Loss G: 0.7668 (0.5978) Acc G: 71.902%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.1143 (0.1335) Acc D Real: 99.855%
Loss D Fake: 0.6498 (0.8257) Acc D Fake: 28.116%
Loss D: 0.764
Loss G: 0.7693 (0.5989) Acc G: 71.600%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.0978 (0.1333) Acc D Real: 99.856%
Loss D Fake: 0.6479 (0.8247) Acc D Fake: 28.416%
Loss D: 0.746
Loss G: 0.7717 (0.5999) Acc G: 71.302%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.1131 (0.1332) Acc D Real: 99.849%
Loss D Fake: 0.6471 (0.8236) Acc D Fake: 28.712%
Loss D: 0.760
Loss G: 0.7709 (0.6010) Acc G: 71.008%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.0951 (0.1330) Acc D Real: 99.850%
Loss D Fake: 0.6502 (0.8225) Acc D Fake: 28.994%
Loss D: 0.745
Loss G: 0.7687 (0.6020) Acc G: 70.728%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.0921 (0.1327) Acc D Real: 99.851%
Loss D Fake: 0.6531 (0.8215) Acc D Fake: 29.273%
Loss D: 0.745
Loss G: 0.7669 (0.6030) Acc G: 70.461%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.0940 (0.1325) Acc D Real: 99.852%
Loss D Fake: 0.6553 (0.8205) Acc D Fake: 29.538%
Loss D: 0.749
Loss G: 0.7662 (0.6040) Acc G: 70.197%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.0912 (0.1322) Acc D Real: 99.853%
Loss D Fake: 0.6560 (0.8195) Acc D Fake: 29.800%
Loss D: 0.747
Loss G: 0.7673 (0.6050) Acc G: 69.936%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.0894 (0.1320) Acc D Real: 99.854%
Loss D Fake: 0.6544 (0.8185) Acc D Fake: 30.060%
Loss D: 0.744
Loss G: 0.7705 (0.6059) Acc G: 69.679%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.0899 (0.1317) Acc D Real: 99.855%
Loss D Fake: 0.6508 (0.8175) Acc D Fake: 30.316%
Loss D: 0.741
Loss G: 0.7753 (0.6069) Acc G: 69.424%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.0911 (0.1315) Acc D Real: 99.855%
Loss D Fake: 0.6459 (0.8165) Acc D Fake: 30.569%
Loss D: 0.737
Loss G: 0.7810 (0.6080) Acc G: 69.163%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.0917 (0.1313) Acc D Real: 99.856%
Loss D Fake: 0.6406 (0.8155) Acc D Fake: 30.828%
Loss D: 0.732
Loss G: 0.7868 (0.6090) Acc G: 68.904%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.0921 (0.1310) Acc D Real: 99.857%
Loss D Fake: 0.6354 (0.8144) Acc D Fake: 31.085%
Loss D: 0.727
Loss G: 0.7924 (0.6101) Acc G: 68.639%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.0926 (0.1308) Acc D Real: 99.858%
Loss D Fake: 0.6305 (0.8134) Acc D Fake: 31.349%
Loss D: 0.723
Loss G: 0.7977 (0.6112) Acc G: 68.378%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.0943 (0.1306) Acc D Real: 99.859%
Loss D Fake: 0.6261 (0.8123) Acc D Fake: 31.609%
Loss D: 0.720
Loss G: 0.8026 (0.6123) Acc G: 68.119%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.1111 (0.1305) Acc D Real: 99.850%
Loss D Fake: 0.6224 (0.8112) Acc D Fake: 31.867%
Loss D: 0.734
Loss G: 0.8063 (0.6134) Acc G: 67.853%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.0946 (0.1303) Acc D Real: 99.851%
Loss D Fake: 0.6198 (0.8101) Acc D Fake: 32.131%
Loss D: 0.714
Loss G: 0.8096 (0.6145) Acc G: 67.591%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.0937 (0.1301) Acc D Real: 99.852%
Loss D Fake: 0.6172 (0.8090) Acc D Fake: 32.392%
Loss D: 0.711
Loss G: 0.8130 (0.6156) Acc G: 67.331%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.1145 (0.1300) Acc D Real: 99.839%
Loss D Fake: 0.6146 (0.8079) Acc D Fake: 32.650%
Loss D: 0.729
Loss G: 0.8164 (0.6167) Acc G: 67.075%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.0923 (0.1298) Acc D Real: 99.840%
Loss D Fake: 0.6121 (0.8068) Acc D Fake: 32.905%
Loss D: 0.704
Loss G: 0.8199 (0.6179) Acc G: 66.821%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.0946 (0.1296) Acc D Real: 99.841%
Loss D Fake: 0.6095 (0.8057) Acc D Fake: 33.157%
Loss D: 0.704
Loss G: 0.8233 (0.6190) Acc G: 66.570%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.0908 (0.1294) Acc D Real: 99.841%
Loss D Fake: 0.6070 (0.8046) Acc D Fake: 33.407%
Loss D: 0.698
Loss G: 0.8267 (0.6202) Acc G: 66.322%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.0976 (0.1292) Acc D Real: 99.842%
Loss D Fake: 0.6045 (0.8035) Acc D Fake: 33.654%
Loss D: 0.702
Loss G: 0.8299 (0.6213) Acc G: 66.077%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.0945 (0.1290) Acc D Real: 99.843%
Loss D Fake: 0.6024 (0.8025) Acc D Fake: 33.898%
Loss D: 0.697
Loss G: 0.8330 (0.6225) Acc G: 65.834%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.0956 (0.1288) Acc D Real: 99.844%
Loss D Fake: 0.6003 (0.8014) Acc D Fake: 34.139%
Loss D: 0.696
Loss G: 0.8361 (0.6236) Acc G: 65.594%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.0946 (0.1286) Acc D Real: 99.845%
Loss D Fake: 0.5982 (0.8003) Acc D Fake: 34.378%
Loss D: 0.693
Loss G: 0.8392 (0.6248) Acc G: 65.357%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.0931 (0.1284) Acc D Real: 99.846%
Loss D Fake: 0.5960 (0.7992) Acc D Fake: 34.615%
Loss D: 0.689
Loss G: 0.8424 (0.6260) Acc G: 65.122%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.0909 (0.1282) Acc D Real: 99.847%
Loss D Fake: 0.5938 (0.7981) Acc D Fake: 34.848%
Loss D: 0.685
Loss G: 0.8457 (0.6271) Acc G: 64.889%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.0924 (0.1281) Acc D Real: 99.847%
Loss D Fake: 0.5915 (0.7970) Acc D Fake: 35.080%
Loss D: 0.684
Loss G: 0.8491 (0.6283) Acc G: 64.660%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.0939 (0.1279) Acc D Real: 99.848%
Loss D Fake: 0.5892 (0.7959) Acc D Fake: 35.309%
Loss D: 0.683
Loss G: 0.8525 (0.6295) Acc G: 64.432%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.0933 (0.1277) Acc D Real: 99.849%
Loss D Fake: 0.5869 (0.7948) Acc D Fake: 35.544%
Loss D: 0.680
Loss G: 0.8559 (0.6307) Acc G: 64.198%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.0937 (0.1275) Acc D Real: 99.850%
Loss D Fake: 0.5847 (0.7937) Acc D Fake: 35.777%
Loss D: 0.678
Loss G: 0.8594 (0.6319) Acc G: 63.967%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.0930 (0.1273) Acc D Real: 99.851%
Loss D Fake: 0.5825 (0.7926) Acc D Fake: 36.007%
Loss D: 0.675
Loss G: 0.8627 (0.6331) Acc G: 63.738%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.0951 (0.1272) Acc D Real: 99.851%
Loss D Fake: 0.5803 (0.7915) Acc D Fake: 36.235%
Loss D: 0.675
Loss G: 0.8661 (0.6343) Acc G: 63.511%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.0976 (0.1270) Acc D Real: 99.852%
Loss D Fake: 0.5783 (0.7904) Acc D Fake: 36.460%
Loss D: 0.676
Loss G: 0.8690 (0.6355) Acc G: 63.287%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.1375 (0.1271) Acc D Real: 99.828%
Loss D Fake: 0.5768 (0.7893) Acc D Fake: 36.684%
Loss D: 0.714
Loss G: 0.8717 (0.6367) Acc G: 63.065%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.0929 (0.1269) Acc D Real: 99.829%
Loss D Fake: 0.5752 (0.7882) Acc D Fake: 36.905%
Loss D: 0.668
Loss G: 0.8746 (0.6379) Acc G: 62.845%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.1153 (0.1268) Acc D Real: 99.817%
Loss D Fake: 0.5735 (0.7871) Acc D Fake: 37.124%
Loss D: 0.689
Loss G: 0.8776 (0.6392) Acc G: 62.628%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.0902 (0.1267) Acc D Real: 99.818%
Loss D Fake: 0.5717 (0.7860) Acc D Fake: 37.340%
Loss D: 0.662
Loss G: 0.8808 (0.6404) Acc G: 62.412%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.0899 (0.1265) Acc D Real: 99.819%
Loss D Fake: 0.5697 (0.7849) Acc D Fake: 37.554%
Loss D: 0.660
Loss G: 0.8843 (0.6416) Acc G: 62.199%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.0910 (0.1263) Acc D Real: 99.820%
Loss D Fake: 0.5674 (0.7838) Acc D Fake: 37.767%
Loss D: 0.658
Loss G: 0.8879 (0.6428) Acc G: 61.988%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.0909 (0.1261) Acc D Real: 99.821%
Loss D Fake: 0.5651 (0.7827) Acc D Fake: 37.977%
Loss D: 0.656
Loss G: 0.8918 (0.6441) Acc G: 61.779%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.0885 (0.1259) Acc D Real: 99.822%
Loss D Fake: 0.5626 (0.7816) Acc D Fake: 38.185%
Loss D: 0.651
Loss G: 0.8958 (0.6453) Acc G: 61.573%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.1097 (0.1258) Acc D Real: 99.815%
Loss D Fake: 0.5605 (0.7806) Acc D Fake: 38.391%
Loss D: 0.670
Loss G: 0.8983 (0.6466) Acc G: 61.368%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.0869 (0.1257) Acc D Real: 99.815%
Loss D Fake: 0.5597 (0.7795) Acc D Fake: 38.595%
Loss D: 0.647
Loss G: 0.9007 (0.6478) Acc G: 61.165%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.0905 (0.1255) Acc D Real: 99.816%
Loss D Fake: 0.5584 (0.7784) Acc D Fake: 38.796%
Loss D: 0.649
Loss G: 0.9036 (0.6491) Acc G: 60.972%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.0906 (0.1253) Acc D Real: 99.817%
Loss D Fake: 0.5568 (0.7773) Acc D Fake: 38.988%
Loss D: 0.647
Loss G: 0.9069 (0.6503) Acc G: 60.781%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.1107 (0.1252) Acc D Real: 99.806%
Loss D Fake: 0.5548 (0.7762) Acc D Fake: 39.178%
Loss D: 0.665
Loss G: 0.9106 (0.6516) Acc G: 60.584%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.0867 (0.1251) Acc D Real: 99.807%
Loss D Fake: 0.5523 (0.7752) Acc D Fake: 39.374%
Loss D: 0.639
Loss G: 0.9149 (0.6528) Acc G: 60.389%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.0866 (0.1249) Acc D Real: 99.808%
Loss D Fake: 0.5495 (0.7741) Acc D Fake: 39.569%
Loss D: 0.636
Loss G: 0.9195 (0.6541) Acc G: 60.195%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.0875 (0.1247) Acc D Real: 99.809%
Loss D Fake: 0.5464 (0.7730) Acc D Fake: 39.761%
Loss D: 0.634
Loss G: 0.9244 (0.6554) Acc G: 60.004%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.0901 (0.1245) Acc D Real: 99.810%
Loss D Fake: 0.5433 (0.7719) Acc D Fake: 39.952%
Loss D: 0.633
Loss G: 0.9292 (0.6567) Acc G: 59.814%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.0909 (0.1244) Acc D Real: 99.811%
Loss D Fake: 0.5403 (0.7708) Acc D Fake: 40.141%
Loss D: 0.631
Loss G: 0.9339 (0.6580) Acc G: 59.627%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.0870 (0.1242) Acc D Real: 99.812%
Loss D Fake: 0.5374 (0.7697) Acc D Fake: 40.328%
Loss D: 0.624
Loss G: 0.9387 (0.6593) Acc G: 59.441%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.0888 (0.1240) Acc D Real: 99.813%
Loss D Fake: 0.5344 (0.7686) Acc D Fake: 40.514%
Loss D: 0.623
Loss G: 0.9436 (0.6606) Acc G: 59.256%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.0878 (0.1239) Acc D Real: 99.813%
Loss D Fake: 0.5314 (0.7675) Acc D Fake: 40.697%
Loss D: 0.619
Loss G: 0.9485 (0.6620) Acc G: 59.074%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.1141 (0.1238) Acc D Real: 99.803%
Loss D Fake: 0.5285 (0.7664) Acc D Fake: 40.879%
Loss D: 0.643
Loss G: 0.9533 (0.6633) Acc G: 58.893%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.1161 (0.1238) Acc D Real: 99.793%
Loss D Fake: 0.5258 (0.7653) Acc D Fake: 41.067%
Loss D: 0.642
Loss G: 0.9579 (0.6647) Acc G: 58.706%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.0907 (0.1236) Acc D Real: 99.794%
Loss D Fake: 0.5232 (0.7642) Acc D Fake: 41.253%
Loss D: 0.614
Loss G: 0.9624 (0.6661) Acc G: 58.521%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.0885 (0.1235) Acc D Real: 99.795%
Loss D Fake: 0.5206 (0.7631) Acc D Fake: 41.438%
Loss D: 0.609
Loss G: 0.9669 (0.6674) Acc G: 58.337%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.0892 (0.1233) Acc D Real: 99.795%
Loss D Fake: 0.5182 (0.7620) Acc D Fake: 41.621%
Loss D: 0.607
Loss G: 0.9714 (0.6688) Acc G: 58.155%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.0901 (0.1232) Acc D Real: 99.796%
Loss D Fake: 0.5157 (0.7609) Acc D Fake: 41.802%
Loss D: 0.606
Loss G: 0.9759 (0.6702) Acc G: 57.975%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.0880 (0.1230) Acc D Real: 99.797%
Loss D Fake: 0.5134 (0.7597) Acc D Fake: 41.982%
Loss D: 0.601
Loss G: 0.9804 (0.6716) Acc G: 57.797%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.0877 (0.1228) Acc D Real: 99.798%
Loss D Fake: 0.5109 (0.7586) Acc D Fake: 42.159%
Loss D: 0.599
Loss G: 0.9850 (0.6730) Acc G: 57.620%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.0893 (0.1227) Acc D Real: 99.799%
Loss D Fake: 0.5085 (0.7575) Acc D Fake: 42.336%
Loss D: 0.598
Loss G: 0.9897 (0.6744) Acc G: 57.444%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.0914 (0.1226) Acc D Real: 99.800%
Loss D Fake: 0.5061 (0.7564) Acc D Fake: 42.511%
Loss D: 0.598
Loss G: 0.9943 (0.6758) Acc G: 57.270%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.0859 (0.1224) Acc D Real: 99.800%
Loss D Fake: 0.5037 (0.7553) Acc D Fake: 42.554%
Loss D: 0.590
Loss G: 0.9990 (0.6773) Acc G: 57.227%
LR: 2.000e-04
Best Loss 0.958 to 0.777
Epoch: 6/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.1161 (0.1274) Acc D Real: 96.562%
Loss D Fake: 0.5001 (0.5008) Acc D Fake: 81.667%
Loss D: 0.616
Loss G: 1.0065 (1.0047) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.0877 (0.1142) Acc D Real: 97.708%
Loss D Fake: 0.4986 (0.5001) Acc D Fake: 81.667%
Loss D: 0.586
Loss G: 1.0103 (1.0066) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.0862 (0.1072) Acc D Real: 98.281%
Loss D Fake: 0.4969 (0.4993) Acc D Fake: 81.667%
Loss D: 0.583
Loss G: 1.0144 (1.0085) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.0871 (0.1032) Acc D Real: 98.625%
Loss D Fake: 0.4949 (0.4984) Acc D Fake: 81.667%
Loss D: 0.582
Loss G: 1.0189 (1.0106) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.0860 (0.1003) Acc D Real: 98.854%
Loss D Fake: 0.4928 (0.4975) Acc D Fake: 81.667%
Loss D: 0.579
Loss G: 1.0236 (1.0128) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.0876 (0.0985) Acc D Real: 99.018%
Loss D Fake: 0.4904 (0.4965) Acc D Fake: 81.667%
Loss D: 0.578
Loss G: 1.0285 (1.0150) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.0899 (0.0974) Acc D Real: 99.141%
Loss D Fake: 0.4882 (0.4954) Acc D Fake: 81.667%
Loss D: 0.578
Loss G: 1.0329 (1.0172) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.1142 (0.0993) Acc D Real: 98.947%
Loss D Fake: 0.4865 (0.4944) Acc D Fake: 81.667%
Loss D: 0.601
Loss G: 1.0372 (1.0195) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.0832 (0.0977) Acc D Real: 99.052%
Loss D Fake: 0.4845 (0.4934) Acc D Fake: 81.667%
Loss D: 0.568
Loss G: 1.0420 (1.0217) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.0847 (0.0965) Acc D Real: 99.138%
Loss D Fake: 0.4822 (0.4924) Acc D Fake: 81.667%
Loss D: 0.567
Loss G: 1.0472 (1.0240) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.0842 (0.0955) Acc D Real: 99.210%
Loss D Fake: 0.4796 (0.4914) Acc D Fake: 81.667%
Loss D: 0.564
Loss G: 1.0527 (1.0264) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.0812 (0.0944) Acc D Real: 99.271%
Loss D Fake: 0.4768 (0.4902) Acc D Fake: 81.667%
Loss D: 0.558
Loss G: 1.0586 (1.0289) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.0848 (0.0937) Acc D Real: 99.323%
Loss D Fake: 0.4738 (0.4891) Acc D Fake: 81.667%
Loss D: 0.559
Loss G: 1.0647 (1.0314) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.1138 (0.0950) Acc D Real: 99.250%
Loss D Fake: 0.4718 (0.4879) Acc D Fake: 81.667%
Loss D: 0.586
Loss G: 1.0670 (1.0338) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.0867 (0.0945) Acc D Real: 99.297%
Loss D Fake: 0.4727 (0.4870) Acc D Fake: 81.667%
Loss D: 0.559
Loss G: 1.0683 (1.0360) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.0838 (0.0939) Acc D Real: 99.338%
Loss D Fake: 0.4732 (0.4861) Acc D Fake: 81.667%
Loss D: 0.557
Loss G: 1.0706 (1.0380) Acc G: 18.431%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.1107 (0.0948) Acc D Real: 99.256%
Loss D Fake: 0.4731 (0.4854) Acc D Fake: 81.574%
Loss D: 0.584
Loss G: 1.0728 (1.0399) Acc G: 18.519%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.1437 (0.0974) Acc D Real: 99.038%
Loss D Fake: 0.4730 (0.4848) Acc D Fake: 81.491%
Loss D: 0.617
Loss G: 1.0757 (1.0418) Acc G: 18.596%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.0810 (0.0966) Acc D Real: 99.086%
Loss D Fake: 0.4720 (0.4841) Acc D Fake: 81.417%
Loss D: 0.553
Loss G: 1.0803 (1.0437) Acc G: 18.667%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.0826 (0.0959) Acc D Real: 99.129%
Loss D Fake: 0.4694 (0.4834) Acc D Fake: 81.349%
Loss D: 0.552
Loss G: 1.0867 (1.0458) Acc G: 18.730%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.0804 (0.0952) Acc D Real: 99.169%
Loss D Fake: 0.4656 (0.4826) Acc D Fake: 81.288%
Loss D: 0.546
Loss G: 1.0945 (1.0480) Acc G: 18.788%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.0824 (0.0946) Acc D Real: 99.205%
Loss D Fake: 0.4612 (0.4817) Acc D Fake: 81.304%
Loss D: 0.544
Loss G: 1.1029 (1.0504) Acc G: 18.768%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.0835 (0.0942) Acc D Real: 99.238%
Loss D Fake: 0.4566 (0.4806) Acc D Fake: 81.319%
Loss D: 0.540
Loss G: 1.1114 (1.0529) Acc G: 18.750%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.0840 (0.0938) Acc D Real: 99.269%
Loss D Fake: 0.4520 (0.4795) Acc D Fake: 81.333%
Loss D: 0.536
Loss G: 1.1199 (1.0556) Acc G: 18.733%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.0819 (0.0933) Acc D Real: 99.297%
Loss D Fake: 0.4476 (0.4783) Acc D Fake: 81.346%
Loss D: 0.529
Loss G: 1.1283 (1.0584) Acc G: 18.718%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.0870 (0.0931) Acc D Real: 99.323%
Loss D Fake: 0.4434 (0.4770) Acc D Fake: 81.358%
Loss D: 0.530
Loss G: 1.1362 (1.0613) Acc G: 18.704%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.1176 (0.0940) Acc D Real: 99.256%
Loss D Fake: 0.4397 (0.4756) Acc D Fake: 81.429%
Loss D: 0.557
Loss G: 1.1437 (1.0642) Acc G: 18.631%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.1184 (0.0948) Acc D Real: 99.194%
Loss D Fake: 0.4363 (0.4743) Acc D Fake: 81.494%
Loss D: 0.555
Loss G: 1.1507 (1.0672) Acc G: 18.563%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.1150 (0.0955) Acc D Real: 99.141%
Loss D Fake: 0.4334 (0.4729) Acc D Fake: 81.556%
Loss D: 0.548
Loss G: 1.1570 (1.0702) Acc G: 18.500%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.0845 (0.0951) Acc D Real: 99.168%
Loss D Fake: 0.4309 (0.4716) Acc D Fake: 81.613%
Loss D: 0.515
Loss G: 1.1632 (1.0732) Acc G: 18.441%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.1171 (0.0958) Acc D Real: 99.113%
Loss D Fake: 0.4284 (0.4702) Acc D Fake: 81.667%
Loss D: 0.545
Loss G: 1.1693 (1.0762) Acc G: 18.385%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.0823 (0.0954) Acc D Real: 99.140%
Loss D Fake: 0.4259 (0.4689) Acc D Fake: 81.717%
Loss D: 0.508
Loss G: 1.1756 (1.0792) Acc G: 18.333%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.0841 (0.0951) Acc D Real: 99.165%
Loss D Fake: 0.4234 (0.4675) Acc D Fake: 81.765%
Loss D: 0.507
Loss G: 1.1821 (1.0822) Acc G: 18.284%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.0871 (0.0948) Acc D Real: 99.189%
Loss D Fake: 0.4209 (0.4662) Acc D Fake: 81.810%
Loss D: 0.508
Loss G: 1.1885 (1.0853) Acc G: 18.238%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.0841 (0.0945) Acc D Real: 99.212%
Loss D Fake: 0.4185 (0.4649) Acc D Fake: 81.852%
Loss D: 0.503
Loss G: 1.1949 (1.0883) Acc G: 18.194%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.1206 (0.0952) Acc D Real: 99.169%
Loss D Fake: 0.4164 (0.4636) Acc D Fake: 81.892%
Loss D: 0.537
Loss G: 1.2002 (1.0914) Acc G: 18.153%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.0855 (0.0950) Acc D Real: 99.191%
Loss D Fake: 0.4150 (0.4623) Acc D Fake: 81.930%
Loss D: 0.501
Loss G: 1.2054 (1.0944) Acc G: 18.114%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.0812 (0.0946) Acc D Real: 99.212%
Loss D Fake: 0.4135 (0.4610) Acc D Fake: 81.966%
Loss D: 0.495
Loss G: 1.2109 (1.0973) Acc G: 18.077%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.1200 (0.0953) Acc D Real: 99.167%
Loss D Fake: 0.4119 (0.4598) Acc D Fake: 82.000%
Loss D: 0.532
Loss G: 1.2163 (1.1003) Acc G: 18.042%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.1170 (0.0958) Acc D Real: 99.129%
Loss D Fake: 0.4106 (0.4586) Acc D Fake: 82.033%
Loss D: 0.528
Loss G: 1.2210 (1.1033) Acc G: 18.008%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.0799 (0.0954) Acc D Real: 99.149%
Loss D Fake: 0.4095 (0.4574) Acc D Fake: 82.063%
Loss D: 0.489
Loss G: 1.2262 (1.1062) Acc G: 17.976%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.0816 (0.0951) Acc D Real: 99.169%
Loss D Fake: 0.4080 (0.4563) Acc D Fake: 82.093%
Loss D: 0.490
Loss G: 1.2321 (1.1091) Acc G: 17.946%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.0833 (0.0948) Acc D Real: 99.188%
Loss D Fake: 0.4060 (0.4552) Acc D Fake: 82.121%
Loss D: 0.489
Loss G: 1.2385 (1.1121) Acc G: 17.917%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.0847 (0.0946) Acc D Real: 99.206%
Loss D Fake: 0.4039 (0.4540) Acc D Fake: 82.148%
Loss D: 0.489
Loss G: 1.2452 (1.1150) Acc G: 17.889%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.0833 (0.0944) Acc D Real: 99.223%
Loss D Fake: 0.4016 (0.4529) Acc D Fake: 82.174%
Loss D: 0.485
Loss G: 1.2522 (1.1180) Acc G: 17.862%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.0827 (0.0941) Acc D Real: 99.240%
Loss D Fake: 0.3991 (0.4517) Acc D Fake: 82.199%
Loss D: 0.482
Loss G: 1.2595 (1.1210) Acc G: 17.837%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.0807 (0.0938) Acc D Real: 99.256%
Loss D Fake: 0.3965 (0.4506) Acc D Fake: 82.222%
Loss D: 0.477
Loss G: 1.2672 (1.1241) Acc G: 17.812%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.1545 (0.0951) Acc D Real: 99.163%
Loss D Fake: 0.3938 (0.4494) Acc D Fake: 82.245%
Loss D: 0.548
Loss G: 1.2747 (1.1271) Acc G: 17.789%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.1183 (0.0955) Acc D Real: 99.128%
Loss D Fake: 0.3912 (0.4483) Acc D Fake: 82.267%
Loss D: 0.509
Loss G: 1.2821 (1.1302) Acc G: 17.767%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.0790 (0.0952) Acc D Real: 99.145%
Loss D Fake: 0.3885 (0.4471) Acc D Fake: 82.288%
Loss D: 0.468
Loss G: 1.2897 (1.1334) Acc G: 17.745%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.0825 (0.0950) Acc D Real: 99.162%
Loss D Fake: 0.3858 (0.4459) Acc D Fake: 82.308%
Loss D: 0.468
Loss G: 1.2975 (1.1365) Acc G: 17.724%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.0835 (0.0947) Acc D Real: 99.177%
Loss D Fake: 0.3831 (0.4447) Acc D Fake: 82.327%
Loss D: 0.467
Loss G: 1.3053 (1.1397) Acc G: 17.704%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.1199 (0.0952) Acc D Real: 99.147%
Loss D Fake: 0.3807 (0.4435) Acc D Fake: 82.346%
Loss D: 0.501
Loss G: 1.3122 (1.1429) Acc G: 17.685%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.0840 (0.0950) Acc D Real: 99.163%
Loss D Fake: 0.3789 (0.4424) Acc D Fake: 82.364%
Loss D: 0.463
Loss G: 1.3188 (1.1461) Acc G: 17.667%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.0832 (0.0948) Acc D Real: 99.178%
Loss D Fake: 0.3771 (0.4412) Acc D Fake: 82.381%
Loss D: 0.460
Loss G: 1.3255 (1.1493) Acc G: 17.649%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.0800 (0.0945) Acc D Real: 99.192%
Loss D Fake: 0.3753 (0.4400) Acc D Fake: 82.398%
Loss D: 0.455
Loss G: 1.3326 (1.1525) Acc G: 17.632%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.0820 (0.0943) Acc D Real: 99.206%
Loss D Fake: 0.3732 (0.4389) Acc D Fake: 82.414%
Loss D: 0.455
Loss G: 1.3399 (1.1557) Acc G: 17.615%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.0809 (0.0941) Acc D Real: 99.220%
Loss D Fake: 0.3711 (0.4377) Acc D Fake: 82.429%
Loss D: 0.452
Loss G: 1.3476 (1.1590) Acc G: 17.599%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.1226 (0.0946) Acc D Real: 99.193%
Loss D Fake: 0.3692 (0.4366) Acc D Fake: 82.444%
Loss D: 0.492
Loss G: 1.3540 (1.1622) Acc G: 17.583%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.1182 (0.0950) Acc D Real: 99.164%
Loss D Fake: 0.3680 (0.4355) Acc D Fake: 82.459%
Loss D: 0.486
Loss G: 1.3601 (1.1655) Acc G: 17.568%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.1193 (0.0953) Acc D Real: 99.136%
Loss D Fake: 0.3666 (0.4344) Acc D Fake: 82.473%
Loss D: 0.486
Loss G: 1.3665 (1.1687) Acc G: 17.554%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.0824 (0.0951) Acc D Real: 99.149%
Loss D Fake: 0.3651 (0.4333) Acc D Fake: 82.487%
Loss D: 0.447
Loss G: 1.3732 (1.1720) Acc G: 17.540%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.0809 (0.0949) Acc D Real: 99.163%
Loss D Fake: 0.3633 (0.4322) Acc D Fake: 82.500%
Loss D: 0.444
Loss G: 1.3805 (1.1752) Acc G: 17.526%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.0792 (0.0947) Acc D Real: 99.175%
Loss D Fake: 0.3613 (0.4311) Acc D Fake: 82.513%
Loss D: 0.440
Loss G: 1.3884 (1.1785) Acc G: 17.513%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.0829 (0.0945) Acc D Real: 99.188%
Loss D Fake: 0.3592 (0.4300) Acc D Fake: 82.525%
Loss D: 0.442
Loss G: 1.3957 (1.1818) Acc G: 17.500%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.0786 (0.0943) Acc D Real: 99.200%
Loss D Fake: 0.3576 (0.4289) Acc D Fake: 82.537%
Loss D: 0.436
Loss G: 1.4030 (1.1851) Acc G: 17.488%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.0795 (0.0940) Acc D Real: 99.212%
Loss D Fake: 0.3557 (0.4278) Acc D Fake: 82.549%
Loss D: 0.435
Loss G: 1.4111 (1.1884) Acc G: 17.475%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.0804 (0.0938) Acc D Real: 99.223%
Loss D Fake: 0.3535 (0.4268) Acc D Fake: 82.560%
Loss D: 0.434
Loss G: 1.4195 (1.1918) Acc G: 17.464%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.0796 (0.0936) Acc D Real: 99.234%
Loss D Fake: 0.3511 (0.4257) Acc D Fake: 82.571%
Loss D: 0.431
Loss G: 1.4284 (1.1952) Acc G: 17.452%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.0822 (0.0935) Acc D Real: 99.245%
Loss D Fake: 0.3486 (0.4246) Acc D Fake: 82.582%
Loss D: 0.431
Loss G: 1.4372 (1.1986) Acc G: 17.441%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.1175 (0.0938) Acc D Real: 99.223%
Loss D Fake: 0.3466 (0.4235) Acc D Fake: 82.593%
Loss D: 0.464
Loss G: 1.4445 (1.2020) Acc G: 17.431%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.1626 (0.0948) Acc D Real: 99.164%
Loss D Fake: 0.3456 (0.4224) Acc D Fake: 82.603%
Loss D: 0.508
Loss G: 1.4501 (1.2054) Acc G: 17.420%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.1193 (0.0951) Acc D Real: 99.142%
Loss D Fake: 0.3451 (0.4214) Acc D Fake: 82.613%
Loss D: 0.464
Loss G: 1.4555 (1.2088) Acc G: 17.410%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.0804 (0.0949) Acc D Real: 99.153%
Loss D Fake: 0.3444 (0.4204) Acc D Fake: 82.622%
Loss D: 0.425
Loss G: 1.4617 (1.2121) Acc G: 17.400%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.0774 (0.0947) Acc D Real: 99.165%
Loss D Fake: 0.3430 (0.4193) Acc D Fake: 82.632%
Loss D: 0.420
Loss G: 1.4693 (1.2155) Acc G: 17.390%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.0779 (0.0944) Acc D Real: 99.175%
Loss D Fake: 0.3409 (0.4183) Acc D Fake: 82.641%
Loss D: 0.419
Loss G: 1.4779 (1.2189) Acc G: 17.381%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.0805 (0.0943) Acc D Real: 99.186%
Loss D Fake: 0.3385 (0.4173) Acc D Fake: 82.650%
Loss D: 0.419
Loss G: 1.4871 (1.2224) Acc G: 17.372%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.0755 (0.0940) Acc D Real: 99.196%
Loss D Fake: 0.3359 (0.4163) Acc D Fake: 82.658%
Loss D: 0.411
Loss G: 1.4969 (1.2258) Acc G: 17.363%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.0809 (0.0939) Acc D Real: 99.206%
Loss D Fake: 0.3329 (0.4152) Acc D Fake: 82.667%
Loss D: 0.414
Loss G: 1.5070 (1.2293) Acc G: 17.354%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.0775 (0.0937) Acc D Real: 99.216%
Loss D Fake: 0.3300 (0.4142) Acc D Fake: 82.675%
Loss D: 0.408
Loss G: 1.5174 (1.2329) Acc G: 17.346%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.1213 (0.0940) Acc D Real: 99.196%
Loss D Fake: 0.3272 (0.4131) Acc D Fake: 82.683%
Loss D: 0.448
Loss G: 1.5268 (1.2365) Acc G: 17.337%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.0778 (0.0938) Acc D Real: 99.206%
Loss D Fake: 0.3249 (0.4121) Acc D Fake: 82.691%
Loss D: 0.403
Loss G: 1.5363 (1.2401) Acc G: 17.329%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.1276 (0.0942) Acc D Real: 99.184%
Loss D Fake: 0.3225 (0.4110) Acc D Fake: 82.698%
Loss D: 0.450
Loss G: 1.5450 (1.2437) Acc G: 17.321%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.1279 (0.0946) Acc D Real: 99.162%
Loss D Fake: 0.3211 (0.4099) Acc D Fake: 82.706%
Loss D: 0.449
Loss G: 1.5510 (1.2473) Acc G: 17.314%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.1253 (0.0950) Acc D Real: 99.141%
Loss D Fake: 0.3209 (0.4089) Acc D Fake: 82.713%
Loss D: 0.446
Loss G: 1.5564 (1.2509) Acc G: 17.306%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.0812 (0.0948) Acc D Real: 99.151%
Loss D Fake: 0.3204 (0.4079) Acc D Fake: 82.720%
Loss D: 0.402
Loss G: 1.5625 (1.2545) Acc G: 17.299%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.0810 (0.0946) Acc D Real: 99.161%
Loss D Fake: 0.3196 (0.4069) Acc D Fake: 82.727%
Loss D: 0.401
Loss G: 1.5695 (1.2581) Acc G: 17.292%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.0803 (0.0945) Acc D Real: 99.170%
Loss D Fake: 0.3185 (0.4059) Acc D Fake: 82.734%
Loss D: 0.399
Loss G: 1.5769 (1.2617) Acc G: 17.285%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.0770 (0.0943) Acc D Real: 99.179%
Loss D Fake: 0.3172 (0.4049) Acc D Fake: 82.741%
Loss D: 0.394
Loss G: 1.5853 (1.2653) Acc G: 17.278%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.0774 (0.0941) Acc D Real: 99.188%
Loss D Fake: 0.3152 (0.4039) Acc D Fake: 82.747%
Loss D: 0.393
Loss G: 1.5947 (1.2689) Acc G: 17.271%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.0796 (0.0939) Acc D Real: 99.197%
Loss D Fake: 0.3132 (0.4029) Acc D Fake: 82.754%
Loss D: 0.393
Loss G: 1.6030 (1.2725) Acc G: 17.264%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.0764 (0.0938) Acc D Real: 99.206%
Loss D Fake: 0.3119 (0.4019) Acc D Fake: 82.760%
Loss D: 0.388
Loss G: 1.6118 (1.2762) Acc G: 17.258%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.0870 (0.0937) Acc D Real: 99.214%
Loss D Fake: 0.3118 (0.4010) Acc D Fake: 82.766%
Loss D: 0.399
Loss G: 1.6113 (1.2797) Acc G: 17.252%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.0776 (0.0935) Acc D Real: 99.223%
Loss D Fake: 0.3172 (0.4001) Acc D Fake: 82.772%
Loss D: 0.395
Loss G: 1.6084 (1.2832) Acc G: 17.253%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.0756 (0.0933) Acc D Real: 99.231%
Loss D Fake: 0.3214 (0.3993) Acc D Fake: 82.760%
Loss D: 0.397
Loss G: 1.6093 (1.2866) Acc G: 17.265%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.1227 (0.0936) Acc D Real: 99.212%
Loss D Fake: 0.3227 (0.3985) Acc D Fake: 82.749%
Loss D: 0.445
Loss G: 1.6157 (1.2900) Acc G: 17.276%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.0746 (0.0934) Acc D Real: 99.220%
Loss D Fake: 0.3204 (0.3977) Acc D Fake: 82.738%
Loss D: 0.395
Loss G: 1.6286 (1.2934) Acc G: 17.286%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.0768 (0.0933) Acc D Real: 99.228%
Loss D Fake: 0.3150 (0.3969) Acc D Fake: 82.727%
Loss D: 0.392
Loss G: 1.6453 (1.2970) Acc G: 17.280%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.0762 (0.0931) Acc D Real: 99.235%
Loss D Fake: 0.3086 (0.3960) Acc D Fake: 82.733%
Loss D: 0.385
Loss G: 1.6628 (1.3007) Acc G: 17.274%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.0770 (0.0929) Acc D Real: 99.243%
Loss D Fake: 0.3024 (0.3951) Acc D Fake: 82.739%
Loss D: 0.379
Loss G: 1.6798 (1.3044) Acc G: 17.268%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.0756 (0.0928) Acc D Real: 99.250%
Loss D Fake: 0.2968 (0.3941) Acc D Fake: 82.745%
Loss D: 0.372
Loss G: 1.6958 (1.3082) Acc G: 17.248%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.1303 (0.0931) Acc D Real: 99.232%
Loss D Fake: 0.2919 (0.3931) Acc D Fake: 82.767%
Loss D: 0.422
Loss G: 1.7099 (1.3121) Acc G: 17.226%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.0816 (0.0930) Acc D Real: 99.239%
Loss D Fake: 0.2880 (0.3921) Acc D Fake: 82.788%
Loss D: 0.370
Loss G: 1.7225 (1.3161) Acc G: 17.205%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.1406 (0.0935) Acc D Real: 99.221%
Loss D Fake: 0.2851 (0.3911) Acc D Fake: 82.810%
Loss D: 0.426
Loss G: 1.7320 (1.3201) Acc G: 17.184%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.1822 (0.0943) Acc D Real: 99.181%
Loss D Fake: 0.2847 (0.3901) Acc D Fake: 82.830%
Loss D: 0.467
Loss G: 1.7334 (1.3240) Acc G: 17.163%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.0823 (0.0942) Acc D Real: 99.189%
Loss D Fake: 0.2880 (0.3891) Acc D Fake: 82.842%
Loss D: 0.370
Loss G: 1.7318 (1.3278) Acc G: 17.158%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.0775 (0.0940) Acc D Real: 99.196%
Loss D Fake: 0.2915 (0.3882) Acc D Fake: 82.846%
Loss D: 0.369
Loss G: 1.7313 (1.3315) Acc G: 17.154%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.0800 (0.0939) Acc D Real: 99.203%
Loss D Fake: 0.2944 (0.3873) Acc D Fake: 82.851%
Loss D: 0.374
Loss G: 1.7315 (1.3352) Acc G: 17.149%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.0810 (0.0938) Acc D Real: 99.211%
Loss D Fake: 0.2970 (0.3865) Acc D Fake: 82.855%
Loss D: 0.378
Loss G: 1.7338 (1.3388) Acc G: 17.145%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.0748 (0.0936) Acc D Real: 99.218%
Loss D Fake: 0.2978 (0.3857) Acc D Fake: 82.859%
Loss D: 0.373
Loss G: 1.7411 (1.3424) Acc G: 17.141%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.0777 (0.0935) Acc D Real: 99.225%
Loss D Fake: 0.2959 (0.3849) Acc D Fake: 82.864%
Loss D: 0.374
Loss G: 1.7527 (1.3461) Acc G: 17.136%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.0782 (0.0934) Acc D Real: 99.232%
Loss D Fake: 0.2922 (0.3841) Acc D Fake: 82.868%
Loss D: 0.370
Loss G: 1.7670 (1.3498) Acc G: 17.132%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.1810 (0.0941) Acc D Real: 99.192%
Loss D Fake: 0.2880 (0.3833) Acc D Fake: 82.872%
Loss D: 0.469
Loss G: 1.7802 (1.3536) Acc G: 17.128%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.1319 (0.0945) Acc D Real: 99.176%
Loss D Fake: 0.2843 (0.3824) Acc D Fake: 82.876%
Loss D: 0.416
Loss G: 1.7926 (1.3574) Acc G: 17.124%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.1336 (0.0948) Acc D Real: 99.161%
Loss D Fake: 0.2810 (0.3815) Acc D Fake: 82.880%
Loss D: 0.415
Loss G: 1.8026 (1.3612) Acc G: 17.120%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.0846 (0.0947) Acc D Real: 99.168%
Loss D Fake: 0.2796 (0.3807) Acc D Fake: 82.884%
Loss D: 0.364
Loss G: 1.8076 (1.3651) Acc G: 17.116%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.0817 (0.0946) Acc D Real: 99.175%
Loss D Fake: 0.2804 (0.3798) Acc D Fake: 82.888%
Loss D: 0.362
Loss G: 1.8120 (1.3688) Acc G: 17.112%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.1293 (0.0949) Acc D Real: 99.162%
Loss D Fake: 0.2824 (0.3790) Acc D Fake: 82.891%
Loss D: 0.412
Loss G: 1.8070 (1.3725) Acc G: 17.109%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.1332 (0.0952) Acc D Real: 99.147%
Loss D Fake: 0.2893 (0.3782) Acc D Fake: 82.881%
Loss D: 0.423
Loss G: 1.8002 (1.3761) Acc G: 17.119%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.0766 (0.0950) Acc D Real: 99.154%
Loss D Fake: 0.2942 (0.3775) Acc D Fake: 82.871%
Loss D: 0.371
Loss G: 1.8009 (1.3796) Acc G: 17.129%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.0781 (0.0949) Acc D Real: 99.161%
Loss D Fake: 0.2941 (0.3769) Acc D Fake: 82.861%
Loss D: 0.372
Loss G: 1.8119 (1.3831) Acc G: 17.139%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.1331 (0.0952) Acc D Real: 99.146%
Loss D Fake: 0.2893 (0.3761) Acc D Fake: 82.851%
Loss D: 0.422
Loss G: 1.8288 (1.3868) Acc G: 17.135%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.0845 (0.0951) Acc D Real: 99.153%
Loss D Fake: 0.2831 (0.3754) Acc D Fake: 82.855%
Loss D: 0.368
Loss G: 1.8459 (1.3905) Acc G: 17.131%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.0857 (0.0951) Acc D Real: 99.160%
Loss D Fake: 0.2779 (0.3746) Acc D Fake: 82.859%
Loss D: 0.364
Loss G: 1.8602 (1.3942) Acc G: 17.128%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.0798 (0.0949) Acc D Real: 99.166%
Loss D Fake: 0.2741 (0.3738) Acc D Fake: 82.863%
Loss D: 0.354
Loss G: 1.8734 (1.3980) Acc G: 17.124%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.0845 (0.0949) Acc D Real: 99.173%
Loss D Fake: 0.2709 (0.3730) Acc D Fake: 82.867%
Loss D: 0.355
Loss G: 1.8846 (1.4019) Acc G: 17.120%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.0874 (0.0948) Acc D Real: 99.179%
Loss D Fake: 0.2692 (0.3722) Acc D Fake: 82.870%
Loss D: 0.357
Loss G: 1.8929 (1.4057) Acc G: 17.117%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.2053 (0.0957) Acc D Real: 99.144%
Loss D Fake: 0.2712 (0.3714) Acc D Fake: 82.874%
Loss D: 0.476
Loss G: 1.8835 (1.4094) Acc G: 17.113%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.2395 (0.0968) Acc D Real: 99.092%
Loss D Fake: 0.2933 (0.3708) Acc D Fake: 82.865%
Loss D: 0.533
Loss G: 1.7086 (1.4117) Acc G: 17.187%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.1373 (0.0971) Acc D Real: 99.078%
Loss D Fake: 4.4182 (0.4017) Acc D Fake: 82.232%
Loss D: 4.556
Loss G: 0.1117 (1.4018) Acc G: 17.819%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.1338 (0.0973) Acc D Real: 99.065%
Loss D Fake: 4.3043 (0.4313) Acc D Fake: 81.609%
Loss D: 4.438
Loss G: 1.8273 (1.4050) Acc G: 17.835%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.0901 (0.0973) Acc D Real: 99.072%
Loss D Fake: 0.2762 (0.4301) Acc D Fake: 81.622%
Loss D: 0.366
Loss G: 1.9217 (1.4089) Acc G: 17.814%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.6196 (0.1012) Acc D Real: 98.894%
Loss D Fake: 0.2733 (0.4289) Acc D Fake: 81.635%
Loss D: 0.893
Loss G: 0.1295 (1.3993) Acc G: 18.427%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.1454 (0.1015) Acc D Real: 98.882%
Loss D Fake: 4.3188 (0.4578) Acc D Fake: 81.030%
Loss D: 4.464
Loss G: 0.0872 (1.3896) Acc G: 19.032%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.0839 (0.1014) Acc D Real: 98.891%
Loss D Fake: 4.3654 (0.4865) Acc D Fake: 80.434%
Loss D: 4.449
Loss G: 0.0806 (1.3800) Acc G: 19.627%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.0799 (0.1012) Acc D Real: 98.899%
Loss D Fake: 4.3119 (0.5144) Acc D Fake: 79.847%
Loss D: 4.392
Loss G: 0.0787 (1.3705) Acc G: 20.214%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.0818 (0.1011) Acc D Real: 98.906%
Loss D Fake: 4.2169 (0.5412) Acc D Fake: 79.269%
Loss D: 4.299
Loss G: 0.0788 (1.3611) Acc G: 20.792%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.0791 (0.1009) Acc D Real: 98.914%
Loss D Fake: 4.0977 (0.5668) Acc D Fake: 78.698%
Loss D: 4.177
Loss G: 0.0802 (1.3519) Acc G: 21.362%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.0813 (0.1008) Acc D Real: 98.922%
Loss D Fake: 3.9616 (0.5911) Acc D Fake: 78.136%
Loss D: 4.043
Loss G: 0.0825 (1.3429) Acc G: 21.923%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.0847 (0.1007) Acc D Real: 98.929%
Loss D Fake: 3.8131 (0.6139) Acc D Fake: 77.582%
Loss D: 3.898
Loss G: 0.0856 (1.3339) Acc G: 22.477%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.0886 (0.1006) Acc D Real: 98.937%
Loss D Fake: 3.6550 (0.6353) Acc D Fake: 77.036%
Loss D: 3.744
Loss G: 0.0896 (1.3252) Acc G: 23.023%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.0929 (0.1005) Acc D Real: 98.944%
Loss D Fake: 3.4902 (0.6553) Acc D Fake: 76.497%
Loss D: 3.583
Loss G: 0.0945 (1.3166) Acc G: 23.561%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.0970 (0.1005) Acc D Real: 98.951%
Loss D Fake: 3.3221 (0.6738) Acc D Fake: 75.966%
Loss D: 3.419
Loss G: 0.1002 (1.3081) Acc G: 24.092%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.1031 (0.1005) Acc D Real: 98.959%
Loss D Fake: 3.1545 (0.6909) Acc D Fake: 75.442%
Loss D: 3.258
Loss G: 0.1069 (1.2998) Acc G: 24.616%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.1094 (0.1006) Acc D Real: 98.966%
Loss D Fake: 2.9910 (0.7067) Acc D Fake: 74.925%
Loss D: 3.100
Loss G: 0.1146 (1.2917) Acc G: 25.132%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.1156 (0.1007) Acc D Real: 98.973%
Loss D Fake: 2.8337 (0.7212) Acc D Fake: 74.415%
Loss D: 2.949
Loss G: 0.1232 (1.2838) Acc G: 25.641%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.1274 (0.1009) Acc D Real: 98.980%
Loss D Fake: 2.6832 (0.7344) Acc D Fake: 73.913%
Loss D: 2.811
Loss G: 0.1328 (1.2760) Acc G: 26.144%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.1431 (0.1012) Acc D Real: 98.985%
Loss D Fake: 2.5398 (0.7465) Acc D Fake: 73.417%
Loss D: 2.683
Loss G: 0.1434 (1.2684) Acc G: 26.639%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.1483 (0.1015) Acc D Real: 98.990%
Loss D Fake: 2.4028 (0.7576) Acc D Fake: 72.927%
Loss D: 2.551
Loss G: 0.1551 (1.2610) Acc G: 27.128%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.1615 (0.1019) Acc D Real: 98.995%
Loss D Fake: 2.2718 (0.7676) Acc D Fake: 72.444%
Loss D: 2.433
Loss G: 0.1680 (1.2537) Acc G: 27.611%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.1752 (0.1024) Acc D Real: 98.995%
Loss D Fake: 2.1469 (0.7767) Acc D Fake: 71.968%
Loss D: 2.322
Loss G: 0.1821 (1.2467) Acc G: 28.087%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.1866 (0.1029) Acc D Real: 98.995%
Loss D Fake: 2.0286 (0.7849) Acc D Fake: 71.497%
Loss D: 2.215
Loss G: 0.1972 (1.2398) Acc G: 28.557%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.2038 (0.1036) Acc D Real: 98.986%
Loss D Fake: 1.9178 (0.7922) Acc D Fake: 71.033%
Loss D: 2.122
Loss G: 0.2133 (1.2332) Acc G: 29.010%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.2181 (0.1043) Acc D Real: 98.978%
Loss D Fake: 1.8152 (0.7988) Acc D Fake: 70.585%
Loss D: 2.033
Loss G: 0.2301 (1.2267) Acc G: 29.447%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.2389 (0.1052) Acc D Real: 98.959%
Loss D Fake: 1.7211 (0.8047) Acc D Fake: 70.154%
Loss D: 1.960
Loss G: 0.2473 (1.2204) Acc G: 29.878%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.2543 (0.1061) Acc D Real: 98.934%
Loss D Fake: 1.6352 (0.8100) Acc D Fake: 69.729%
Loss D: 1.889
Loss G: 0.2648 (1.2143) Acc G: 30.293%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.2696 (0.1071) Acc D Real: 98.907%
Loss D Fake: 1.5572 (0.8147) Acc D Fake: 69.319%
Loss D: 1.827
Loss G: 0.2824 (1.2084) Acc G: 30.702%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.2935 (0.1083) Acc D Real: 98.871%
Loss D Fake: 1.4866 (0.8190) Acc D Fake: 68.914%
Loss D: 1.780
Loss G: 0.2998 (1.2027) Acc G: 31.107%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.3053 (0.1095) Acc D Real: 98.840%
Loss D Fake: 1.4231 (0.8227) Acc D Fake: 68.515%
Loss D: 1.728
Loss G: 0.3168 (1.1972) Acc G: 31.506%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.3256 (0.1109) Acc D Real: 98.805%
Loss D Fake: 1.3662 (0.8261) Acc D Fake: 68.120%
Loss D: 1.692
Loss G: 0.3332 (1.1918) Acc G: 31.900%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.3394 (0.1123) Acc D Real: 98.770%
Loss D Fake: 1.3155 (0.8291) Acc D Fake: 67.731%
Loss D: 1.655
Loss G: 0.3490 (1.1866) Acc G: 32.290%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.3549 (0.1138) Acc D Real: 98.736%
Loss D Fake: 1.2705 (0.8318) Acc D Fake: 67.346%
Loss D: 1.625
Loss G: 0.3638 (1.1816) Acc G: 32.664%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.3719 (0.1154) Acc D Real: 98.698%
Loss D Fake: 1.2307 (0.8343) Acc D Fake: 66.976%
Loss D: 1.603
Loss G: 0.3776 (1.1767) Acc G: 33.034%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3821 (0.1170) Acc D Real: 98.663%
Loss D Fake: 1.1959 (0.8365) Acc D Fake: 66.610%
Loss D: 1.578
Loss G: 0.3903 (1.1719) Acc G: 33.400%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.3966 (0.1187) Acc D Real: 98.624%
Loss D Fake: 1.1655 (0.8385) Acc D Fake: 66.249%
Loss D: 1.562
Loss G: 0.4019 (1.1672) Acc G: 33.761%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4092 (0.1204) Acc D Real: 98.585%
Loss D Fake: 1.1392 (0.8403) Acc D Fake: 65.893%
Loss D: 1.548
Loss G: 0.4122 (1.1627) Acc G: 34.107%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4180 (0.1222) Acc D Real: 98.547%
Loss D Fake: 1.1166 (0.8419) Acc D Fake: 65.550%
Loss D: 1.535
Loss G: 0.4213 (1.1583) Acc G: 34.450%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4253 (0.1240) Acc D Real: 98.510%
Loss D Fake: 1.0975 (0.8434) Acc D Fake: 65.211%
Loss D: 1.523
Loss G: 0.4292 (1.1540) Acc G: 34.789%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4331 (0.1258) Acc D Real: 98.473%
Loss D Fake: 1.0813 (0.8448) Acc D Fake: 64.877%
Loss D: 1.514
Loss G: 0.4360 (1.1498) Acc G: 35.123%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4413 (0.1276) Acc D Real: 98.434%
Loss D Fake: 1.0679 (0.8461) Acc D Fake: 64.546%
Loss D: 1.509
Loss G: 0.4416 (1.1456) Acc G: 35.454%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4446 (0.1295) Acc D Real: 98.397%
Loss D Fake: 1.0569 (0.8473) Acc D Fake: 64.219%
Loss D: 1.502
Loss G: 0.4463 (1.1416) Acc G: 35.781%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4518 (0.1313) Acc D Real: 98.359%
Loss D Fake: 1.0481 (0.8485) Acc D Fake: 63.896%
Loss D: 1.500
Loss G: 0.4500 (1.1376) Acc G: 36.104%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4541 (0.1332) Acc D Real: 98.323%
Loss D Fake: 1.0411 (0.8496) Acc D Fake: 63.577%
Loss D: 1.495
Loss G: 0.4528 (1.1336) Acc G: 36.423%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4530 (0.1350) Acc D Real: 98.290%
Loss D Fake: 1.0357 (0.8507) Acc D Fake: 63.261%
Loss D: 1.489
Loss G: 0.4550 (1.1298) Acc G: 36.739%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4577 (0.1369) Acc D Real: 98.256%
Loss D Fake: 1.0316 (0.8517) Acc D Fake: 62.949%
Loss D: 1.489
Loss G: 0.4565 (1.1259) Acc G: 37.051%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4569 (0.1387) Acc D Real: 98.223%
Loss D Fake: 1.0288 (0.8527) Acc D Fake: 62.641%
Loss D: 1.486
Loss G: 0.4575 (1.1222) Acc G: 37.359%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4619 (0.1405) Acc D Real: 98.188%
Loss D Fake: 1.0269 (0.8537) Acc D Fake: 62.336%
Loss D: 1.489
Loss G: 0.4580 (1.1184) Acc G: 37.664%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4621 (0.1423) Acc D Real: 98.156%
Loss D Fake: 1.0258 (0.8546) Acc D Fake: 62.034%
Loss D: 1.488
Loss G: 0.4581 (1.1147) Acc G: 37.966%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4628 (0.1441) Acc D Real: 98.122%
Loss D Fake: 1.0255 (0.8556) Acc D Fake: 61.736%
Loss D: 1.488
Loss G: 0.4579 (1.1111) Acc G: 38.274%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4574 (0.1458) Acc D Real: 98.094%
Loss D Fake: 1.0257 (0.8565) Acc D Fake: 61.431%
Loss D: 1.483
Loss G: 0.4574 (1.1075) Acc G: 38.578%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4575 (0.1475) Acc D Real: 98.065%
Loss D Fake: 1.0263 (0.8575) Acc D Fake: 61.130%
Loss D: 1.484
Loss G: 0.4568 (1.1039) Acc G: 38.879%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4583 (0.1492) Acc D Real: 98.036%
Loss D Fake: 1.0272 (0.8584) Acc D Fake: 60.824%
Loss D: 1.485
Loss G: 0.4560 (1.1004) Acc G: 39.185%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4581 (0.1509) Acc D Real: 98.008%
Loss D Fake: 1.0285 (0.8593) Acc D Fake: 60.521%
Loss D: 1.487
Loss G: 0.4551 (1.0969) Acc G: 39.489%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4541 (0.1525) Acc D Real: 97.982%
Loss D Fake: 1.0300 (0.8602) Acc D Fake: 60.220%
Loss D: 1.484
Loss G: 0.4540 (1.0934) Acc G: 39.789%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4541 (0.1541) Acc D Real: 97.956%
Loss D Fake: 1.0316 (0.8612) Acc D Fake: 59.924%
Loss D: 1.486
Loss G: 0.4529 (1.0899) Acc G: 40.086%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4511 (0.1557) Acc D Real: 97.932%
Loss D Fake: 1.0334 (0.8621) Acc D Fake: 59.630%
Loss D: 1.484
Loss G: 0.4518 (1.0865) Acc G: 40.379%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4525 (0.1573) Acc D Real: 97.907%
Loss D Fake: 1.0352 (0.8630) Acc D Fake: 59.339%
Loss D: 1.488
Loss G: 0.4507 (1.0831) Acc G: 40.670%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4502 (0.1589) Acc D Real: 97.882%
Loss D Fake: 1.0370 (0.8639) Acc D Fake: 59.052%
Loss D: 1.487
Loss G: 0.4496 (1.0798) Acc G: 40.957%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4498 (0.1604) Acc D Real: 97.857%
Loss D Fake: 1.0388 (0.8648) Acc D Fake: 58.767%
Loss D: 1.489
Loss G: 0.4485 (1.0765) Acc G: 41.242%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4487 (0.1619) Acc D Real: 97.834%
Loss D Fake: 1.0405 (0.8658) Acc D Fake: 58.486%
Loss D: 1.489
Loss G: 0.4475 (1.0732) Acc G: 41.523%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4503 (0.1634) Acc D Real: 97.809%
Loss D Fake: 1.0421 (0.8667) Acc D Fake: 58.207%
Loss D: 1.492
Loss G: 0.4466 (1.0699) Acc G: 41.802%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4447 (0.1649) Acc D Real: 97.788%
Loss D Fake: 1.0436 (0.8676) Acc D Fake: 57.932%
Loss D: 1.488
Loss G: 0.4456 (1.0667) Acc G: 42.077%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4446 (0.1663) Acc D Real: 97.766%
Loss D Fake: 1.0451 (0.8685) Acc D Fake: 57.659%
Loss D: 1.490
Loss G: 0.4448 (1.0635) Acc G: 42.350%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4444 (0.1677) Acc D Real: 97.744%
Loss D Fake: 1.0466 (0.8694) Acc D Fake: 57.389%
Loss D: 1.491
Loss G: 0.4439 (1.0603) Acc G: 42.620%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4394 (0.1691) Acc D Real: 97.726%
Loss D Fake: 1.0479 (0.8703) Acc D Fake: 57.121%
Loss D: 1.487
Loss G: 0.4432 (1.0571) Acc G: 42.887%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4382 (0.1705) Acc D Real: 97.708%
Loss D Fake: 1.0490 (0.8712) Acc D Fake: 56.857%
Loss D: 1.487
Loss G: 0.4425 (1.0540) Acc G: 43.152%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4395 (0.1718) Acc D Real: 97.690%
Loss D Fake: 1.0501 (0.8721) Acc D Fake: 56.595%
Loss D: 1.490
Loss G: 0.4419 (1.0509) Acc G: 43.414%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4407 (0.1732) Acc D Real: 97.671%
Loss D Fake: 1.0512 (0.8730) Acc D Fake: 56.336%
Loss D: 1.492
Loss G: 0.4412 (1.0479) Acc G: 43.673%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4372 (0.1745) Acc D Real: 97.654%
Loss D Fake: 1.0522 (0.8739) Acc D Fake: 56.079%
Loss D: 1.489
Loss G: 0.4407 (1.0448) Acc G: 43.930%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4363 (0.1758) Acc D Real: 97.637%
Loss D Fake: 1.0532 (0.8748) Acc D Fake: 55.825%
Loss D: 1.489
Loss G: 0.4401 (1.0418) Acc G: 44.184%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4360 (0.1771) Acc D Real: 97.620%
Loss D Fake: 1.0543 (0.8757) Acc D Fake: 55.573%
Loss D: 1.490
Loss G: 0.4394 (1.0388) Acc G: 44.435%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4335 (0.1784) Acc D Real: 97.603%
Loss D Fake: 1.0559 (0.8766) Acc D Fake: 55.324%
Loss D: 1.489
Loss G: 0.4388 (1.0359) Acc G: 44.684%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4388 (0.1796) Acc D Real: 97.585%
Loss D Fake: 1.0572 (0.8775) Acc D Fake: 55.077%
Loss D: 1.496
Loss G: 0.4384 (1.0330) Acc G: 44.931%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4287 (0.1808) Acc D Real: 97.570%
Loss D Fake: 1.0577 (0.8784) Acc D Fake: 54.833%
Loss D: 1.486
Loss G: 0.4382 (1.0301) Acc G: 45.175%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4272 (0.1820) Acc D Real: 97.557%
Loss D Fake: 1.0583 (0.8792) Acc D Fake: 54.591%
Loss D: 1.486
Loss G: 0.4380 (1.0272) Acc G: 45.417%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4310 (0.1832) Acc D Real: 97.542%
Loss D Fake: 1.0585 (0.8801) Acc D Fake: 54.344%
Loss D: 1.490
Loss G: 0.4383 (1.0243) Acc G: 45.665%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4247 (0.1844) Acc D Real: 97.529%
Loss D Fake: 1.0574 (0.8810) Acc D Fake: 54.098%
Loss D: 1.482
Loss G: 0.4383 (1.0215) Acc G: 45.910%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4247 (0.1856) Acc D Real: 97.515%
Loss D Fake: 1.0583 (0.8818) Acc D Fake: 53.855%
Loss D: 1.483
Loss G: 0.4378 (1.0187) Acc G: 46.153%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4275 (0.1867) Acc D Real: 97.501%
Loss D Fake: 1.0598 (0.8827) Acc D Fake: 53.615%
Loss D: 1.487
Loss G: 0.4377 (1.0160) Acc G: 46.393%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4209 (0.1878) Acc D Real: 97.491%
Loss D Fake: 1.0604 (0.8835) Acc D Fake: 53.377%
Loss D: 1.481
Loss G: 0.4374 (1.0132) Acc G: 46.632%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4262 (0.1889) Acc D Real: 97.478%
Loss D Fake: 1.0612 (0.8843) Acc D Fake: 53.140%
Loss D: 1.487
Loss G: 0.4380 (1.0105) Acc G: 46.868%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4249 (0.1901) Acc D Real: 97.466%
Loss D Fake: 1.0572 (0.8852) Acc D Fake: 52.907%
Loss D: 1.482
Loss G: 0.4393 (1.0078) Acc G: 47.101%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4331 (0.1912) Acc D Real: 97.452%
Loss D Fake: 1.0547 (0.8859) Acc D Fake: 52.675%
Loss D: 1.488
Loss G: 0.4398 (1.0052) Acc G: 47.333%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4286 (0.1923) Acc D Real: 97.439%
Loss D Fake: 1.0545 (0.8867) Acc D Fake: 52.445%
Loss D: 1.483
Loss G: 0.4405 (1.0025) Acc G: 47.562%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4250 (0.1934) Acc D Real: 97.428%
Loss D Fake: 1.0522 (0.8875) Acc D Fake: 52.218%
Loss D: 1.477
Loss G: 0.4414 (0.9999) Acc G: 47.790%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4315 (0.1945) Acc D Real: 97.416%
Loss D Fake: 1.0510 (0.8882) Acc D Fake: 51.993%
Loss D: 1.483
Loss G: 0.4417 (0.9974) Acc G: 48.015%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4258 (0.1955) Acc D Real: 97.406%
Loss D Fake: 1.0513 (0.8890) Acc D Fake: 51.770%
Loss D: 1.477
Loss G: 0.4428 (0.9948) Acc G: 48.238%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4282 (0.1966) Acc D Real: 97.397%
Loss D Fake: 1.0471 (0.8897) Acc D Fake: 51.548%
Loss D: 1.475
Loss G: 0.4441 (0.9923) Acc G: 48.459%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4299 (0.1977) Acc D Real: 97.386%
Loss D Fake: 1.0450 (0.8904) Acc D Fake: 51.329%
Loss D: 1.475
Loss G: 0.4447 (0.9898) Acc G: 48.679%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4379 (0.1987) Acc D Real: 97.375%
Loss D Fake: 1.0454 (0.8911) Acc D Fake: 51.112%
Loss D: 1.483
Loss G: 0.4454 (0.9874) Acc G: 48.896%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4293 (0.1998) Acc D Real: 97.367%
Loss D Fake: 1.0430 (0.8918) Acc D Fake: 50.897%
Loss D: 1.472
Loss G: 0.4461 (0.9849) Acc G: 49.111%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4347 (0.2008) Acc D Real: 97.358%
Loss D Fake: 1.0402 (0.8925) Acc D Fake: 50.684%
Loss D: 1.475
Loss G: 0.4477 (0.9825) Acc G: 49.324%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4369 (0.2019) Acc D Real: 97.348%
Loss D Fake: 1.0353 (0.8931) Acc D Fake: 50.472%
Loss D: 1.472
Loss G: 0.4484 (0.9801) Acc G: 49.535%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4385 (0.2029) Acc D Real: 97.338%
Loss D Fake: 1.0367 (0.8938) Acc D Fake: 50.263%
Loss D: 1.475
Loss G: 0.4476 (0.9778) Acc G: 49.745%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4434 (0.2040) Acc D Real: 97.337%
Loss D Fake: 1.0388 (0.8944) Acc D Fake: 50.211%
Loss D: 1.482
Loss G: 0.4486 (0.9754) Acc G: 49.797%
LR: 2.000e-04
Epoch: 7/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4325 (0.4366) Acc D Real: 95.443%
Loss D Fake: 1.0394 (1.0366) Acc D Fake: 3.333%
Loss D: 1.472
Loss G: 0.4473 (0.4479) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4386 (0.4373) Acc D Real: 95.469%
Loss D Fake: 1.0379 (1.0370) Acc D Fake: 3.333%
Loss D: 1.476
Loss G: 0.4488 (0.4482) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4408 (0.4382) Acc D Real: 95.534%
Loss D Fake: 1.0320 (1.0358) Acc D Fake: 3.333%
Loss D: 1.473
Loss G: 0.4490 (0.4484) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4446 (0.4395) Acc D Real: 95.562%
Loss D Fake: 1.0352 (1.0357) Acc D Fake: 3.333%
Loss D: 1.480
Loss G: 0.4470 (0.4481) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4326 (0.4383) Acc D Real: 95.668%
Loss D Fake: 1.0437 (1.0370) Acc D Fake: 3.333%
Loss D: 1.476
Loss G: 0.4477 (0.4480) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4364 (0.4380) Acc D Real: 95.759%
Loss D Fake: 1.0347 (1.0367) Acc D Fake: 3.333%
Loss D: 1.471
Loss G: 0.4466 (0.4478) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4394 (0.4382) Acc D Real: 95.853%
Loss D Fake: 1.0442 (1.0376) Acc D Fake: 3.333%
Loss D: 1.484
Loss G: 0.4473 (0.4478) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4424 (0.4387) Acc D Real: 95.903%
Loss D Fake: 1.0322 (1.0370) Acc D Fake: 3.333%
Loss D: 1.475
Loss G: 0.4488 (0.4479) Acc G: 96.667%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4438 (0.4392) Acc D Real: 95.995%
Loss D Fake: 1.0316 (1.0365) Acc D Fake: 3.333%
Loss D: 1.475
Loss G: 0.4479 (0.4479) Acc G: 96.833%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4431 (0.4395) Acc D Real: 96.117%
Loss D Fake: 1.0371 (1.0365) Acc D Fake: 3.182%
Loss D: 1.480
Loss G: 0.4442 (0.4475) Acc G: 96.970%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4441 (0.4399) Acc D Real: 96.198%
Loss D Fake: 1.0510 (1.0377) Acc D Fake: 3.056%
Loss D: 1.495
Loss G: 0.4470 (0.4475) Acc G: 97.083%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4443 (0.4403) Acc D Real: 96.278%
Loss D Fake: 1.0293 (1.0371) Acc D Fake: 2.821%
Loss D: 1.474
Loss G: 0.4500 (0.4477) Acc G: 97.308%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4534 (0.4412) Acc D Real: 96.369%
Loss D Fake: 1.0267 (1.0363) Acc D Fake: 2.619%
Loss D: 1.480
Loss G: 0.4502 (0.4479) Acc G: 97.500%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4492 (0.4417) Acc D Real: 96.458%
Loss D Fake: 1.0272 (1.0357) Acc D Fake: 2.444%
Loss D: 1.476
Loss G: 0.4494 (0.4480) Acc G: 97.667%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4475 (0.4421) Acc D Real: 96.559%
Loss D Fake: 1.0292 (1.0353) Acc D Fake: 2.292%
Loss D: 1.477
Loss G: 0.4480 (0.4480) Acc G: 97.812%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4539 (0.4428) Acc D Real: 96.605%
Loss D Fake: 1.0322 (1.0351) Acc D Fake: 2.157%
Loss D: 1.486
Loss G: 0.4463 (0.4479) Acc G: 97.941%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4471 (0.4430) Acc D Real: 96.684%
Loss D Fake: 1.0356 (1.0352) Acc D Fake: 2.037%
Loss D: 1.483
Loss G: 0.4442 (0.4477) Acc G: 98.056%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4471 (0.4432) Acc D Real: 96.752%
Loss D Fake: 1.0408 (1.0355) Acc D Fake: 1.930%
Loss D: 1.488
Loss G: 0.4408 (0.4473) Acc G: 98.158%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4384 (0.4430) Acc D Real: 96.820%
Loss D Fake: 1.0529 (1.0363) Acc D Fake: 1.833%
Loss D: 1.491
Loss G: 0.4328 (0.4466) Acc G: 98.250%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4322 (0.4425) Acc D Real: 96.873%
Loss D Fake: 1.1012 (1.0394) Acc D Fake: 1.746%
Loss D: 1.533
Loss G: 0.4404 (0.4463) Acc G: 98.333%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4445 (0.4426) Acc D Real: 96.932%
Loss D Fake: 1.0393 (1.0394) Acc D Fake: 1.667%
Loss D: 1.484
Loss G: 0.4439 (0.4462) Acc G: 98.409%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4474 (0.4428) Acc D Real: 96.986%
Loss D Fake: 1.0370 (1.0393) Acc D Fake: 1.594%
Loss D: 1.484
Loss G: 0.4441 (0.4461) Acc G: 98.478%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4479 (0.4430) Acc D Real: 97.033%
Loss D Fake: 1.0376 (1.0392) Acc D Fake: 1.528%
Loss D: 1.485
Loss G: 0.4434 (0.4460) Acc G: 98.542%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4460 (0.4431) Acc D Real: 97.096%
Loss D Fake: 1.0392 (1.0392) Acc D Fake: 1.467%
Loss D: 1.485
Loss G: 0.4423 (0.4458) Acc G: 98.600%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4461 (0.4432) Acc D Real: 97.151%
Loss D Fake: 1.0412 (1.0393) Acc D Fake: 1.410%
Loss D: 1.487
Loss G: 0.4412 (0.4456) Acc G: 98.654%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4445 (0.4433) Acc D Real: 97.209%
Loss D Fake: 1.0434 (1.0395) Acc D Fake: 1.358%
Loss D: 1.488
Loss G: 0.4399 (0.4454) Acc G: 98.704%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4435 (0.4433) Acc D Real: 97.262%
Loss D Fake: 1.0457 (1.0397) Acc D Fake: 1.310%
Loss D: 1.489
Loss G: 0.4387 (0.4452) Acc G: 98.750%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4424 (0.4433) Acc D Real: 97.302%
Loss D Fake: 1.0479 (1.0400) Acc D Fake: 1.264%
Loss D: 1.490
Loss G: 0.4375 (0.4449) Acc G: 98.793%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4411 (0.4432) Acc D Real: 97.342%
Loss D Fake: 1.0501 (1.0403) Acc D Fake: 1.222%
Loss D: 1.491
Loss G: 0.4364 (0.4447) Acc G: 98.833%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4401 (0.4431) Acc D Real: 97.387%
Loss D Fake: 1.0521 (1.0407) Acc D Fake: 1.183%
Loss D: 1.492
Loss G: 0.4354 (0.4444) Acc G: 98.871%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4385 (0.4429) Acc D Real: 97.438%
Loss D Fake: 1.0539 (1.0411) Acc D Fake: 1.146%
Loss D: 1.492
Loss G: 0.4344 (0.4440) Acc G: 98.906%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4380 (0.4428) Acc D Real: 97.479%
Loss D Fake: 1.0557 (1.0415) Acc D Fake: 1.111%
Loss D: 1.494
Loss G: 0.4336 (0.4437) Acc G: 98.939%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4376 (0.4426) Acc D Real: 97.517%
Loss D Fake: 1.0572 (1.0420) Acc D Fake: 1.078%
Loss D: 1.495
Loss G: 0.4328 (0.4434) Acc G: 98.971%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4361 (0.4424) Acc D Real: 97.561%
Loss D Fake: 1.0586 (1.0425) Acc D Fake: 1.048%
Loss D: 1.495
Loss G: 0.4321 (0.4431) Acc G: 99.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4354 (0.4423) Acc D Real: 97.609%
Loss D Fake: 1.0598 (1.0430) Acc D Fake: 1.019%
Loss D: 1.495
Loss G: 0.4314 (0.4428) Acc G: 99.028%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4353 (0.4421) Acc D Real: 97.642%
Loss D Fake: 1.0609 (1.0434) Acc D Fake: 0.991%
Loss D: 1.496
Loss G: 0.4309 (0.4424) Acc G: 99.054%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4341 (0.4419) Acc D Real: 97.693%
Loss D Fake: 1.0619 (1.0439) Acc D Fake: 0.965%
Loss D: 1.496
Loss G: 0.4304 (0.4421) Acc G: 99.079%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4341 (0.4417) Acc D Real: 97.742%
Loss D Fake: 1.0627 (1.0444) Acc D Fake: 0.940%
Loss D: 1.497
Loss G: 0.4300 (0.4418) Acc G: 99.103%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4329 (0.4414) Acc D Real: 97.790%
Loss D Fake: 1.0634 (1.0449) Acc D Fake: 0.917%
Loss D: 1.496
Loss G: 0.4296 (0.4415) Acc G: 99.125%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4321 (0.4412) Acc D Real: 97.842%
Loss D Fake: 1.0640 (1.0454) Acc D Fake: 0.894%
Loss D: 1.496
Loss G: 0.4293 (0.4412) Acc G: 99.146%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4320 (0.4410) Acc D Real: 97.888%
Loss D Fake: 1.0644 (1.0458) Acc D Fake: 0.873%
Loss D: 1.496
Loss G: 0.4291 (0.4409) Acc G: 99.167%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4315 (0.4408) Acc D Real: 97.934%
Loss D Fake: 1.0649 (1.0462) Acc D Fake: 0.853%
Loss D: 1.496
Loss G: 0.4288 (0.4406) Acc G: 99.186%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4315 (0.4406) Acc D Real: 97.979%
Loss D Fake: 1.0652 (1.0467) Acc D Fake: 0.833%
Loss D: 1.497
Loss G: 0.4286 (0.4404) Acc G: 99.205%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4311 (0.4403) Acc D Real: 98.024%
Loss D Fake: 1.0655 (1.0471) Acc D Fake: 0.815%
Loss D: 1.497
Loss G: 0.4285 (0.4401) Acc G: 99.222%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4309 (0.4401) Acc D Real: 98.067%
Loss D Fake: 1.0657 (1.0475) Acc D Fake: 0.797%
Loss D: 1.497
Loss G: 0.4284 (0.4398) Acc G: 99.239%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4306 (0.4399) Acc D Real: 98.108%
Loss D Fake: 1.0659 (1.0479) Acc D Fake: 0.780%
Loss D: 1.496
Loss G: 0.4283 (0.4396) Acc G: 99.255%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4316 (0.4398) Acc D Real: 98.143%
Loss D Fake: 1.0660 (1.0483) Acc D Fake: 0.764%
Loss D: 1.498
Loss G: 0.4282 (0.4394) Acc G: 99.271%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4299 (0.4396) Acc D Real: 98.181%
Loss D Fake: 1.0661 (1.0486) Acc D Fake: 0.748%
Loss D: 1.496
Loss G: 0.4281 (0.4391) Acc G: 99.286%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4306 (0.4394) Acc D Real: 98.217%
Loss D Fake: 1.0661 (1.0490) Acc D Fake: 0.733%
Loss D: 1.497
Loss G: 0.4281 (0.4389) Acc G: 99.300%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4305 (0.4392) Acc D Real: 98.252%
Loss D Fake: 1.0662 (1.0493) Acc D Fake: 0.719%
Loss D: 1.497
Loss G: 0.4280 (0.4387) Acc G: 99.314%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4305 (0.4390) Acc D Real: 98.284%
Loss D Fake: 1.0662 (1.0496) Acc D Fake: 0.705%
Loss D: 1.497
Loss G: 0.4280 (0.4385) Acc G: 99.327%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4299 (0.4389) Acc D Real: 98.317%
Loss D Fake: 1.0662 (1.0500) Acc D Fake: 0.692%
Loss D: 1.496
Loss G: 0.4279 (0.4383) Acc G: 99.340%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4302 (0.4387) Acc D Real: 98.348%
Loss D Fake: 1.0662 (1.0503) Acc D Fake: 0.679%
Loss D: 1.496
Loss G: 0.4279 (0.4381) Acc G: 99.352%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4304 (0.4386) Acc D Real: 98.378%
Loss D Fake: 1.0662 (1.0505) Acc D Fake: 0.667%
Loss D: 1.497
Loss G: 0.4279 (0.4379) Acc G: 99.364%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4300 (0.4384) Acc D Real: 98.407%
Loss D Fake: 1.0662 (1.0508) Acc D Fake: 0.655%
Loss D: 1.496
Loss G: 0.4279 (0.4377) Acc G: 99.375%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4295 (0.4383) Acc D Real: 98.435%
Loss D Fake: 1.0661 (1.0511) Acc D Fake: 0.643%
Loss D: 1.496
Loss G: 0.4279 (0.4376) Acc G: 99.386%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4302 (0.4381) Acc D Real: 98.462%
Loss D Fake: 1.0661 (1.0514) Acc D Fake: 0.632%
Loss D: 1.496
Loss G: 0.4278 (0.4374) Acc G: 99.397%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4303 (0.4380) Acc D Real: 98.488%
Loss D Fake: 1.0661 (1.0516) Acc D Fake: 0.621%
Loss D: 1.496
Loss G: 0.4278 (0.4372) Acc G: 99.407%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4292 (0.4378) Acc D Real: 98.513%
Loss D Fake: 1.0661 (1.0518) Acc D Fake: 0.611%
Loss D: 1.495
Loss G: 0.4278 (0.4371) Acc G: 99.417%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4296 (0.4377) Acc D Real: 98.537%
Loss D Fake: 1.0661 (1.0521) Acc D Fake: 0.601%
Loss D: 1.496
Loss G: 0.4278 (0.4369) Acc G: 99.426%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4294 (0.4376) Acc D Real: 98.561%
Loss D Fake: 1.0661 (1.0523) Acc D Fake: 0.591%
Loss D: 1.496
Loss G: 0.4277 (0.4368) Acc G: 99.435%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4290 (0.4374) Acc D Real: 98.584%
Loss D Fake: 1.0661 (1.0525) Acc D Fake: 0.582%
Loss D: 1.495
Loss G: 0.4277 (0.4366) Acc G: 99.444%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4294 (0.4373) Acc D Real: 98.606%
Loss D Fake: 1.0661 (1.0527) Acc D Fake: 0.573%
Loss D: 1.496
Loss G: 0.4277 (0.4365) Acc G: 99.453%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4289 (0.4372) Acc D Real: 98.627%
Loss D Fake: 1.0661 (1.0529) Acc D Fake: 0.564%
Loss D: 1.495
Loss G: 0.4276 (0.4364) Acc G: 99.462%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4293 (0.4371) Acc D Real: 98.648%
Loss D Fake: 1.0662 (1.0531) Acc D Fake: 0.556%
Loss D: 1.496
Loss G: 0.4276 (0.4362) Acc G: 99.470%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4291 (0.4369) Acc D Real: 98.668%
Loss D Fake: 1.0662 (1.0533) Acc D Fake: 0.547%
Loss D: 1.495
Loss G: 0.4275 (0.4361) Acc G: 99.478%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4288 (0.4368) Acc D Real: 98.686%
Loss D Fake: 1.0663 (1.0535) Acc D Fake: 0.539%
Loss D: 1.495
Loss G: 0.4275 (0.4360) Acc G: 99.485%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4293 (0.4367) Acc D Real: 98.705%
Loss D Fake: 1.0663 (1.0537) Acc D Fake: 0.531%
Loss D: 1.496
Loss G: 0.4274 (0.4358) Acc G: 99.493%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4289 (0.4366) Acc D Real: 98.724%
Loss D Fake: 1.0664 (1.0539) Acc D Fake: 0.524%
Loss D: 1.495
Loss G: 0.4274 (0.4357) Acc G: 99.500%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4286 (0.4365) Acc D Real: 98.742%
Loss D Fake: 1.0665 (1.0541) Acc D Fake: 0.516%
Loss D: 1.495
Loss G: 0.4273 (0.4356) Acc G: 99.507%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4283 (0.4364) Acc D Real: 98.759%
Loss D Fake: 1.0666 (1.0542) Acc D Fake: 0.509%
Loss D: 1.495
Loss G: 0.4272 (0.4355) Acc G: 99.514%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4283 (0.4363) Acc D Real: 98.776%
Loss D Fake: 1.0667 (1.0544) Acc D Fake: 0.502%
Loss D: 1.495
Loss G: 0.4272 (0.4354) Acc G: 99.521%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4280 (0.4362) Acc D Real: 98.793%
Loss D Fake: 1.0668 (1.0546) Acc D Fake: 0.495%
Loss D: 1.495
Loss G: 0.4271 (0.4353) Acc G: 99.527%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4281 (0.4360) Acc D Real: 98.809%
Loss D Fake: 1.0669 (1.0547) Acc D Fake: 0.489%
Loss D: 1.495
Loss G: 0.4270 (0.4351) Acc G: 99.533%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4277 (0.4359) Acc D Real: 98.825%
Loss D Fake: 1.0670 (1.0549) Acc D Fake: 0.482%
Loss D: 1.495
Loss G: 0.4269 (0.4350) Acc G: 99.539%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4276 (0.4358) Acc D Real: 98.840%
Loss D Fake: 1.0671 (1.0551) Acc D Fake: 0.476%
Loss D: 1.495
Loss G: 0.4269 (0.4349) Acc G: 99.545%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4276 (0.4357) Acc D Real: 98.855%
Loss D Fake: 1.0672 (1.0552) Acc D Fake: 0.470%
Loss D: 1.495
Loss G: 0.4268 (0.4348) Acc G: 99.551%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4275 (0.4356) Acc D Real: 98.869%
Loss D Fake: 1.0673 (1.0554) Acc D Fake: 0.464%
Loss D: 1.495
Loss G: 0.4267 (0.4347) Acc G: 99.557%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4273 (0.4355) Acc D Real: 98.883%
Loss D Fake: 1.0674 (1.0555) Acc D Fake: 0.458%
Loss D: 1.495
Loss G: 0.4266 (0.4346) Acc G: 99.562%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4272 (0.4354) Acc D Real: 98.897%
Loss D Fake: 1.0676 (1.0557) Acc D Fake: 0.453%
Loss D: 1.495
Loss G: 0.4265 (0.4345) Acc G: 99.568%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4270 (0.4353) Acc D Real: 98.911%
Loss D Fake: 1.0677 (1.0558) Acc D Fake: 0.447%
Loss D: 1.495
Loss G: 0.4264 (0.4344) Acc G: 99.573%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4268 (0.4352) Acc D Real: 98.924%
Loss D Fake: 1.0679 (1.0560) Acc D Fake: 0.442%
Loss D: 1.495
Loss G: 0.4263 (0.4343) Acc G: 99.578%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4266 (0.4351) Acc D Real: 98.937%
Loss D Fake: 1.0681 (1.0561) Acc D Fake: 0.437%
Loss D: 1.495
Loss G: 0.4262 (0.4342) Acc G: 99.583%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4266 (0.4350) Acc D Real: 98.949%
Loss D Fake: 1.0683 (1.0563) Acc D Fake: 0.431%
Loss D: 1.495
Loss G: 0.4261 (0.4341) Acc G: 99.588%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4263 (0.4349) Acc D Real: 98.961%
Loss D Fake: 1.0685 (1.0564) Acc D Fake: 0.426%
Loss D: 1.495
Loss G: 0.4260 (0.4340) Acc G: 99.593%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4260 (0.4348) Acc D Real: 98.973%
Loss D Fake: 1.0687 (1.0565) Acc D Fake: 0.421%
Loss D: 1.495
Loss G: 0.4258 (0.4339) Acc G: 99.598%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4261 (0.4347) Acc D Real: 98.985%
Loss D Fake: 1.0689 (1.0567) Acc D Fake: 0.417%
Loss D: 1.495
Loss G: 0.4257 (0.4339) Acc G: 99.602%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4257 (0.4346) Acc D Real: 98.996%
Loss D Fake: 1.0692 (1.0568) Acc D Fake: 0.412%
Loss D: 1.495
Loss G: 0.4256 (0.4338) Acc G: 99.607%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4251 (0.4345) Acc D Real: 99.008%
Loss D Fake: 1.0694 (1.0570) Acc D Fake: 0.407%
Loss D: 1.495
Loss G: 0.4254 (0.4337) Acc G: 99.611%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4252 (0.4344) Acc D Real: 99.018%
Loss D Fake: 1.0697 (1.0571) Acc D Fake: 0.403%
Loss D: 1.495
Loss G: 0.4252 (0.4336) Acc G: 99.615%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4248 (0.4343) Acc D Real: 99.029%
Loss D Fake: 1.0700 (1.0572) Acc D Fake: 0.399%
Loss D: 1.495
Loss G: 0.4251 (0.4335) Acc G: 99.620%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4240 (0.4342) Acc D Real: 99.040%
Loss D Fake: 1.0704 (1.0574) Acc D Fake: 0.394%
Loss D: 1.494
Loss G: 0.4249 (0.4334) Acc G: 99.624%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4244 (0.4341) Acc D Real: 99.050%
Loss D Fake: 1.0708 (1.0575) Acc D Fake: 0.390%
Loss D: 1.495
Loss G: 0.4246 (0.4333) Acc G: 99.628%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4239 (0.4340) Acc D Real: 99.060%
Loss D Fake: 1.0712 (1.0577) Acc D Fake: 0.386%
Loss D: 1.495
Loss G: 0.4244 (0.4332) Acc G: 99.632%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4231 (0.4339) Acc D Real: 99.070%
Loss D Fake: 1.0717 (1.0578) Acc D Fake: 0.382%
Loss D: 1.495
Loss G: 0.4241 (0.4331) Acc G: 99.635%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4232 (0.4337) Acc D Real: 99.079%
Loss D Fake: 1.0722 (1.0580) Acc D Fake: 0.378%
Loss D: 1.495
Loss G: 0.4239 (0.4330) Acc G: 99.639%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4224 (0.4336) Acc D Real: 99.089%
Loss D Fake: 1.0728 (1.0581) Acc D Fake: 0.374%
Loss D: 1.495
Loss G: 0.4236 (0.4329) Acc G: 99.643%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4221 (0.4335) Acc D Real: 99.098%
Loss D Fake: 1.0734 (1.0583) Acc D Fake: 0.370%
Loss D: 1.495
Loss G: 0.4233 (0.4328) Acc G: 99.646%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4225 (0.4334) Acc D Real: 99.107%
Loss D Fake: 1.0740 (1.0584) Acc D Fake: 0.367%
Loss D: 1.496
Loss G: 0.4230 (0.4327) Acc G: 99.650%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4209 (0.4333) Acc D Real: 99.116%
Loss D Fake: 1.0745 (1.0586) Acc D Fake: 0.363%
Loss D: 1.495
Loss G: 0.4228 (0.4326) Acc G: 99.653%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4212 (0.4332) Acc D Real: 99.124%
Loss D Fake: 1.0750 (1.0587) Acc D Fake: 0.359%
Loss D: 1.496
Loss G: 0.4225 (0.4325) Acc G: 99.657%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4206 (0.4330) Acc D Real: 99.133%
Loss D Fake: 1.0754 (1.0589) Acc D Fake: 0.356%
Loss D: 1.496
Loss G: 0.4223 (0.4324) Acc G: 99.660%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4215 (0.4329) Acc D Real: 99.141%
Loss D Fake: 1.0757 (1.0591) Acc D Fake: 0.353%
Loss D: 1.497
Loss G: 0.4222 (0.4323) Acc G: 99.663%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4193 (0.4328) Acc D Real: 99.149%
Loss D Fake: 1.0759 (1.0592) Acc D Fake: 0.349%
Loss D: 1.495
Loss G: 0.4221 (0.4322) Acc G: 99.667%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4199 (0.4327) Acc D Real: 99.157%
Loss D Fake: 1.0760 (1.0594) Acc D Fake: 0.346%
Loss D: 1.496
Loss G: 0.4221 (0.4321) Acc G: 99.670%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4195 (0.4326) Acc D Real: 99.165%
Loss D Fake: 1.0760 (1.0595) Acc D Fake: 0.343%
Loss D: 1.496
Loss G: 0.4222 (0.4320) Acc G: 99.673%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4198 (0.4324) Acc D Real: 99.173%
Loss D Fake: 1.0758 (1.0597) Acc D Fake: 0.340%
Loss D: 1.496
Loss G: 0.4223 (0.4320) Acc G: 99.676%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4189 (0.4323) Acc D Real: 99.181%
Loss D Fake: 1.0755 (1.0598) Acc D Fake: 0.336%
Loss D: 1.494
Loss G: 0.4225 (0.4319) Acc G: 99.679%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4202 (0.4322) Acc D Real: 99.188%
Loss D Fake: 1.0751 (1.0600) Acc D Fake: 0.333%
Loss D: 1.495
Loss G: 0.4227 (0.4318) Acc G: 99.682%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4204 (0.4321) Acc D Real: 99.195%
Loss D Fake: 1.0745 (1.0601) Acc D Fake: 0.330%
Loss D: 1.495
Loss G: 0.4231 (0.4317) Acc G: 99.685%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4203 (0.4320) Acc D Real: 99.202%
Loss D Fake: 1.0737 (1.0602) Acc D Fake: 0.327%
Loss D: 1.494
Loss G: 0.4235 (0.4316) Acc G: 99.688%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4192 (0.4319) Acc D Real: 99.210%
Loss D Fake: 1.0728 (1.0603) Acc D Fake: 0.324%
Loss D: 1.492
Loss G: 0.4239 (0.4316) Acc G: 99.690%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4208 (0.4318) Acc D Real: 99.216%
Loss D Fake: 1.0720 (1.0604) Acc D Fake: 0.322%
Loss D: 1.493
Loss G: 0.4243 (0.4315) Acc G: 99.693%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4235 (0.4317) Acc D Real: 99.223%
Loss D Fake: 1.0711 (1.0605) Acc D Fake: 0.319%
Loss D: 1.495
Loss G: 0.4248 (0.4314) Acc G: 99.696%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4219 (0.4316) Acc D Real: 99.230%
Loss D Fake: 1.0700 (1.0606) Acc D Fake: 0.316%
Loss D: 1.492
Loss G: 0.4254 (0.4314) Acc G: 99.698%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4226 (0.4315) Acc D Real: 99.237%
Loss D Fake: 1.0687 (1.0607) Acc D Fake: 0.313%
Loss D: 1.491
Loss G: 0.4261 (0.4313) Acc G: 99.701%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4233 (0.4315) Acc D Real: 99.243%
Loss D Fake: 1.0674 (1.0607) Acc D Fake: 0.311%
Loss D: 1.491
Loss G: 0.4267 (0.4313) Acc G: 99.703%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4240 (0.4314) Acc D Real: 99.249%
Loss D Fake: 1.0662 (1.0608) Acc D Fake: 0.308%
Loss D: 1.490
Loss G: 0.4272 (0.4313) Acc G: 99.706%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4230 (0.4313) Acc D Real: 99.256%
Loss D Fake: 1.0652 (1.0608) Acc D Fake: 0.306%
Loss D: 1.488
Loss G: 0.4276 (0.4312) Acc G: 99.708%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4222 (0.4313) Acc D Real: 99.262%
Loss D Fake: 1.0647 (1.0609) Acc D Fake: 0.303%
Loss D: 1.487
Loss G: 0.4278 (0.4312) Acc G: 99.711%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4257 (0.4312) Acc D Real: 99.268%
Loss D Fake: 1.0646 (1.0609) Acc D Fake: 0.301%
Loss D: 1.490
Loss G: 0.4278 (0.4312) Acc G: 99.713%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4262 (0.4312) Acc D Real: 99.274%
Loss D Fake: 1.0643 (1.0609) Acc D Fake: 0.298%
Loss D: 1.491
Loss G: 0.4281 (0.4312) Acc G: 99.715%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4234 (0.4311) Acc D Real: 99.280%
Loss D Fake: 1.0637 (1.0609) Acc D Fake: 0.296%
Loss D: 1.487
Loss G: 0.4283 (0.4311) Acc G: 99.718%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4228 (0.4310) Acc D Real: 99.285%
Loss D Fake: 1.0634 (1.0610) Acc D Fake: 0.293%
Loss D: 1.486
Loss G: 0.4283 (0.4311) Acc G: 99.720%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4233 (0.4310) Acc D Real: 99.291%
Loss D Fake: 1.0637 (1.0610) Acc D Fake: 0.291%
Loss D: 1.487
Loss G: 0.4281 (0.4311) Acc G: 99.722%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4255 (0.4309) Acc D Real: 99.297%
Loss D Fake: 1.0641 (1.0610) Acc D Fake: 0.289%
Loss D: 1.490
Loss G: 0.4281 (0.4311) Acc G: 99.724%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4251 (0.4309) Acc D Real: 99.302%
Loss D Fake: 1.0640 (1.0610) Acc D Fake: 0.286%
Loss D: 1.489
Loss G: 0.4282 (0.4310) Acc G: 99.727%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4246 (0.4308) Acc D Real: 99.308%
Loss D Fake: 1.0636 (1.0610) Acc D Fake: 0.284%
Loss D: 1.488
Loss G: 0.4284 (0.4310) Acc G: 99.729%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4246 (0.4308) Acc D Real: 99.313%
Loss D Fake: 1.0631 (1.0611) Acc D Fake: 0.282%
Loss D: 1.488
Loss G: 0.4287 (0.4310) Acc G: 99.731%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4240 (0.4307) Acc D Real: 99.318%
Loss D Fake: 1.0624 (1.0611) Acc D Fake: 0.280%
Loss D: 1.486
Loss G: 0.4291 (0.4310) Acc G: 99.733%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4254 (0.4307) Acc D Real: 99.323%
Loss D Fake: 1.0618 (1.0611) Acc D Fake: 0.278%
Loss D: 1.487
Loss G: 0.4293 (0.4310) Acc G: 99.735%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4248 (0.4307) Acc D Real: 99.328%
Loss D Fake: 1.0615 (1.0611) Acc D Fake: 0.276%
Loss D: 1.486
Loss G: 0.4294 (0.4310) Acc G: 99.737%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4246 (0.4306) Acc D Real: 99.333%
Loss D Fake: 1.0615 (1.0611) Acc D Fake: 0.274%
Loss D: 1.486
Loss G: 0.4292 (0.4310) Acc G: 99.739%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4244 (0.4306) Acc D Real: 99.338%
Loss D Fake: 1.0621 (1.0611) Acc D Fake: 0.272%
Loss D: 1.487
Loss G: 0.4289 (0.4309) Acc G: 99.741%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4249 (0.4305) Acc D Real: 99.343%
Loss D Fake: 1.0629 (1.0611) Acc D Fake: 0.270%
Loss D: 1.488
Loss G: 0.4286 (0.4309) Acc G: 99.743%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4246 (0.4305) Acc D Real: 99.348%
Loss D Fake: 1.0634 (1.0611) Acc D Fake: 0.268%
Loss D: 1.488
Loss G: 0.4284 (0.4309) Acc G: 99.745%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4230 (0.4304) Acc D Real: 99.353%
Loss D Fake: 1.0638 (1.0611) Acc D Fake: 0.266%
Loss D: 1.487
Loss G: 0.4282 (0.4309) Acc G: 99.746%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4234 (0.4304) Acc D Real: 99.357%
Loss D Fake: 1.0642 (1.0612) Acc D Fake: 0.264%
Loss D: 1.488
Loss G: 0.4283 (0.4309) Acc G: 99.748%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4232 (0.4303) Acc D Real: 99.362%
Loss D Fake: 1.0637 (1.0612) Acc D Fake: 0.262%
Loss D: 1.487
Loss G: 0.4286 (0.4308) Acc G: 99.750%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4217 (0.4303) Acc D Real: 99.367%
Loss D Fake: 1.0631 (1.0612) Acc D Fake: 0.260%
Loss D: 1.485
Loss G: 0.4287 (0.4308) Acc G: 99.752%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4245 (0.4302) Acc D Real: 99.371%
Loss D Fake: 1.0629 (1.0612) Acc D Fake: 0.258%
Loss D: 1.487
Loss G: 0.4289 (0.4308) Acc G: 99.754%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4190 (0.4302) Acc D Real: 99.375%
Loss D Fake: 1.0631 (1.0612) Acc D Fake: 0.256%
Loss D: 1.482
Loss G: 0.4283 (0.4308) Acc G: 99.755%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4254 (0.4301) Acc D Real: 99.380%
Loss D Fake: 1.0646 (1.0612) Acc D Fake: 0.255%
Loss D: 1.490
Loss G: 0.4282 (0.4308) Acc G: 99.757%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4208 (0.4301) Acc D Real: 99.384%
Loss D Fake: 1.0644 (1.0613) Acc D Fake: 0.253%
Loss D: 1.485
Loss G: 0.4283 (0.4308) Acc G: 99.759%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4244 (0.4300) Acc D Real: 99.388%
Loss D Fake: 1.0639 (1.0613) Acc D Fake: 0.251%
Loss D: 1.488
Loss G: 0.4288 (0.4308) Acc G: 99.760%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4241 (0.4300) Acc D Real: 99.392%
Loss D Fake: 1.0624 (1.0613) Acc D Fake: 0.249%
Loss D: 1.486
Loss G: 0.4296 (0.4307) Acc G: 99.762%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4244 (0.4299) Acc D Real: 99.396%
Loss D Fake: 1.0604 (1.0613) Acc D Fake: 0.248%
Loss D: 1.485
Loss G: 0.4305 (0.4307) Acc G: 99.764%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4287 (0.4299) Acc D Real: 99.401%
Loss D Fake: 1.0581 (1.0613) Acc D Fake: 0.246%
Loss D: 1.487
Loss G: 0.4315 (0.4307) Acc G: 99.765%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4250 (0.4299) Acc D Real: 99.405%
Loss D Fake: 1.0567 (1.0612) Acc D Fake: 0.244%
Loss D: 1.482
Loss G: 0.4314 (0.4308) Acc G: 99.767%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4275 (0.4299) Acc D Real: 99.408%
Loss D Fake: 1.0577 (1.0612) Acc D Fake: 0.243%
Loss D: 1.485
Loss G: 0.4309 (0.4308) Acc G: 99.768%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4266 (0.4299) Acc D Real: 99.412%
Loss D Fake: 1.0588 (1.0612) Acc D Fake: 0.241%
Loss D: 1.485
Loss G: 0.4305 (0.4308) Acc G: 99.770%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4261 (0.4298) Acc D Real: 99.416%
Loss D Fake: 1.0597 (1.0612) Acc D Fake: 0.240%
Loss D: 1.486
Loss G: 0.4300 (0.4307) Acc G: 99.771%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4270 (0.4298) Acc D Real: 99.420%
Loss D Fake: 1.0605 (1.0612) Acc D Fake: 0.238%
Loss D: 1.488
Loss G: 0.4299 (0.4307) Acc G: 99.773%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4230 (0.4298) Acc D Real: 99.424%
Loss D Fake: 1.0612 (1.0612) Acc D Fake: 0.237%
Loss D: 1.484
Loss G: 0.4291 (0.4307) Acc G: 99.774%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4216 (0.4297) Acc D Real: 99.427%
Loss D Fake: 1.0637 (1.0612) Acc D Fake: 0.235%
Loss D: 1.485
Loss G: 0.4280 (0.4307) Acc G: 99.776%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4242 (0.4297) Acc D Real: 99.431%
Loss D Fake: 1.0655 (1.0612) Acc D Fake: 0.234%
Loss D: 1.490
Loss G: 0.4280 (0.4307) Acc G: 99.777%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4176 (0.4296) Acc D Real: 99.435%
Loss D Fake: 1.0654 (1.0612) Acc D Fake: 0.232%
Loss D: 1.483
Loss G: 0.4275 (0.4307) Acc G: 99.778%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4217 (0.4296) Acc D Real: 99.438%
Loss D Fake: 1.0668 (1.0613) Acc D Fake: 0.231%
Loss D: 1.488
Loss G: 0.4275 (0.4307) Acc G: 99.780%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4237 (0.4295) Acc D Real: 99.442%
Loss D Fake: 1.0652 (1.0613) Acc D Fake: 0.229%
Loss D: 1.489
Loss G: 0.4286 (0.4306) Acc G: 99.781%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4219 (0.4295) Acc D Real: 99.445%
Loss D Fake: 1.0622 (1.0613) Acc D Fake: 0.228%
Loss D: 1.484
Loss G: 0.4294 (0.4306) Acc G: 99.783%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4204 (0.4294) Acc D Real: 99.449%
Loss D Fake: 1.0616 (1.0613) Acc D Fake: 0.226%
Loss D: 1.482
Loss G: 0.4291 (0.4306) Acc G: 99.784%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4230 (0.4294) Acc D Real: 99.452%
Loss D Fake: 1.0631 (1.0613) Acc D Fake: 0.225%
Loss D: 1.486
Loss G: 0.4287 (0.4306) Acc G: 99.785%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4248 (0.4294) Acc D Real: 99.455%
Loss D Fake: 1.0628 (1.0613) Acc D Fake: 0.224%
Loss D: 1.488
Loss G: 0.4295 (0.4306) Acc G: 99.787%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4250 (0.4293) Acc D Real: 99.459%
Loss D Fake: 1.0603 (1.0613) Acc D Fake: 0.222%
Loss D: 1.485
Loss G: 0.4302 (0.4306) Acc G: 99.788%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4252 (0.4293) Acc D Real: 99.462%
Loss D Fake: 1.0592 (1.0613) Acc D Fake: 0.221%
Loss D: 1.484
Loss G: 0.4303 (0.4306) Acc G: 99.789%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4241 (0.4293) Acc D Real: 99.465%
Loss D Fake: 1.0602 (1.0613) Acc D Fake: 0.220%
Loss D: 1.484
Loss G: 0.4292 (0.4306) Acc G: 99.790%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4235 (0.4292) Acc D Real: 99.468%
Loss D Fake: 1.0637 (1.0613) Acc D Fake: 0.218%
Loss D: 1.487
Loss G: 0.4281 (0.4306) Acc G: 99.792%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4219 (0.4292) Acc D Real: 99.471%
Loss D Fake: 1.0657 (1.0614) Acc D Fake: 0.217%
Loss D: 1.488
Loss G: 0.4279 (0.4306) Acc G: 99.793%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4167 (0.4291) Acc D Real: 99.475%
Loss D Fake: 1.0653 (1.0614) Acc D Fake: 0.216%
Loss D: 1.482
Loss G: 0.4281 (0.4305) Acc G: 99.794%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4199 (0.4291) Acc D Real: 99.478%
Loss D Fake: 1.0641 (1.0614) Acc D Fake: 0.214%
Loss D: 1.484
Loss G: 0.4289 (0.4305) Acc G: 99.795%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4216 (0.4290) Acc D Real: 99.481%
Loss D Fake: 1.0614 (1.0614) Acc D Fake: 0.213%
Loss D: 1.483
Loss G: 0.4298 (0.4305) Acc G: 99.797%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4258 (0.4290) Acc D Real: 99.484%
Loss D Fake: 1.0594 (1.0614) Acc D Fake: 0.212%
Loss D: 1.485
Loss G: 0.4304 (0.4305) Acc G: 99.798%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4240 (0.4290) Acc D Real: 99.487%
Loss D Fake: 1.0586 (1.0614) Acc D Fake: 0.211%
Loss D: 1.483
Loss G: 0.4304 (0.4305) Acc G: 99.799%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4237 (0.4289) Acc D Real: 99.490%
Loss D Fake: 1.0597 (1.0614) Acc D Fake: 0.210%
Loss D: 1.483
Loss G: 0.4296 (0.4305) Acc G: 99.800%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4267 (0.4289) Acc D Real: 99.492%
Loss D Fake: 1.0619 (1.0614) Acc D Fake: 0.208%
Loss D: 1.489
Loss G: 0.4289 (0.4305) Acc G: 99.801%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4195 (0.4289) Acc D Real: 99.495%
Loss D Fake: 1.0636 (1.0614) Acc D Fake: 0.207%
Loss D: 1.483
Loss G: 0.4280 (0.4305) Acc G: 99.802%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4261 (0.4289) Acc D Real: 99.498%
Loss D Fake: 1.0647 (1.0614) Acc D Fake: 0.206%
Loss D: 1.491
Loss G: 0.4288 (0.4305) Acc G: 99.803%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4217 (0.4288) Acc D Real: 99.501%
Loss D Fake: 1.0619 (1.0614) Acc D Fake: 0.205%
Loss D: 1.484
Loss G: 0.4287 (0.4305) Acc G: 99.804%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4216 (0.4288) Acc D Real: 99.504%
Loss D Fake: 1.0648 (1.0614) Acc D Fake: 0.204%
Loss D: 1.486
Loss G: 0.4272 (0.4305) Acc G: 99.806%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4125 (0.4287) Acc D Real: 99.507%
Loss D Fake: 1.0683 (1.0614) Acc D Fake: 0.203%
Loss D: 1.481
Loss G: 0.4278 (0.4305) Acc G: 99.807%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4213 (0.4287) Acc D Real: 99.509%
Loss D Fake: 1.0619 (1.0614) Acc D Fake: 0.201%
Loss D: 1.483
Loss G: 0.4299 (0.4304) Acc G: 99.808%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4224 (0.4286) Acc D Real: 99.512%
Loss D Fake: 1.0588 (1.0614) Acc D Fake: 0.200%
Loss D: 1.481
Loss G: 0.4301 (0.4304) Acc G: 99.809%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4203 (0.4286) Acc D Real: 99.515%
Loss D Fake: 1.0600 (1.0614) Acc D Fake: 0.199%
Loss D: 1.480
Loss G: 0.4294 (0.4304) Acc G: 99.810%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4235 (0.4285) Acc D Real: 99.517%
Loss D Fake: 1.0620 (1.0614) Acc D Fake: 0.198%
Loss D: 1.486
Loss G: 0.4287 (0.4304) Acc G: 99.811%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4202 (0.4285) Acc D Real: 99.520%
Loss D Fake: 1.0638 (1.0614) Acc D Fake: 0.197%
Loss D: 1.484
Loss G: 0.4280 (0.4304) Acc G: 99.812%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4229 (0.4285) Acc D Real: 99.522%
Loss D Fake: 1.0646 (1.0615) Acc D Fake: 0.196%
Loss D: 1.488
Loss G: 0.4285 (0.4304) Acc G: 99.813%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4247 (0.4284) Acc D Real: 99.525%
Loss D Fake: 1.0613 (1.0615) Acc D Fake: 0.195%
Loss D: 1.486
Loss G: 0.4297 (0.4304) Acc G: 99.814%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4249 (0.4284) Acc D Real: 99.527%
Loss D Fake: 1.0593 (1.0614) Acc D Fake: 0.194%
Loss D: 1.484
Loss G: 0.4299 (0.4304) Acc G: 99.815%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4216 (0.4284) Acc D Real: 99.530%
Loss D Fake: 1.0605 (1.0614) Acc D Fake: 0.193%
Loss D: 1.482
Loss G: 0.4287 (0.4304) Acc G: 99.816%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4189 (0.4283) Acc D Real: 99.532%
Loss D Fake: 1.0655 (1.0615) Acc D Fake: 0.192%
Loss D: 1.484
Loss G: 0.4267 (0.4304) Acc G: 99.817%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4197 (0.4283) Acc D Real: 99.535%
Loss D Fake: 1.0675 (1.0615) Acc D Fake: 0.191%
Loss D: 1.487
Loss G: 0.4285 (0.4304) Acc G: 99.818%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4136 (0.4282) Acc D Real: 99.537%
Loss D Fake: 1.0613 (1.0615) Acc D Fake: 0.190%
Loss D: 1.475
Loss G: 0.4286 (0.4304) Acc G: 99.819%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4215 (0.4282) Acc D Real: 99.540%
Loss D Fake: 1.0641 (1.0615) Acc D Fake: 0.189%
Loss D: 1.486
Loss G: 0.4276 (0.4303) Acc G: 99.820%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4149 (0.4281) Acc D Real: 99.542%
Loss D Fake: 1.0696 (1.0615) Acc D Fake: 0.188%
Loss D: 1.484
Loss G: 0.4261 (0.4303) Acc G: 99.821%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4180 (0.4281) Acc D Real: 99.544%
Loss D Fake: 1.0683 (1.0616) Acc D Fake: 0.187%
Loss D: 1.486
Loss G: 0.4287 (0.4303) Acc G: 99.821%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4242 (0.4280) Acc D Real: 99.547%
Loss D Fake: 1.0583 (1.0616) Acc D Fake: 0.186%
Loss D: 1.483
Loss G: 0.4314 (0.4303) Acc G: 99.822%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4225 (0.4280) Acc D Real: 99.549%
Loss D Fake: 1.0550 (1.0615) Acc D Fake: 0.185%
Loss D: 1.478
Loss G: 0.4318 (0.4303) Acc G: 99.823%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4280 (0.4280) Acc D Real: 99.551%
Loss D Fake: 1.0549 (1.0615) Acc D Fake: 0.184%
Loss D: 1.483
Loss G: 0.4317 (0.4303) Acc G: 99.824%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4271 (0.4280) Acc D Real: 99.553%
Loss D Fake: 1.0554 (1.0615) Acc D Fake: 0.183%
Loss D: 1.482
Loss G: 0.4313 (0.4303) Acc G: 99.825%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4263 (0.4280) Acc D Real: 99.556%
Loss D Fake: 1.0571 (1.0614) Acc D Fake: 0.182%
Loss D: 1.483
Loss G: 0.4298 (0.4303) Acc G: 99.826%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4173 (0.4280) Acc D Real: 99.558%
Loss D Fake: 1.0630 (1.0615) Acc D Fake: 0.182%
Loss D: 1.480
Loss G: 0.4256 (0.4303) Acc G: 99.827%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4205 (0.4279) Acc D Real: 99.560%
Loss D Fake: 1.0809 (1.0616) Acc D Fake: 0.181%
Loss D: 1.501
Loss G: 0.4302 (0.4303) Acc G: 99.828%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4221 (0.4279) Acc D Real: 99.562%
Loss D Fake: 1.0546 (1.0615) Acc D Fake: 0.180%
Loss D: 1.477
Loss G: 0.4323 (0.4303) Acc G: 99.828%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4280 (0.4279) Acc D Real: 99.564%
Loss D Fake: 1.0535 (1.0615) Acc D Fake: 0.179%
Loss D: 1.481
Loss G: 0.4321 (0.4303) Acc G: 99.829%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4278 (0.4279) Acc D Real: 99.566%
Loss D Fake: 1.0542 (1.0614) Acc D Fake: 0.178%
Loss D: 1.482
Loss G: 0.4316 (0.4303) Acc G: 99.830%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4272 (0.4279) Acc D Real: 99.568%
Loss D Fake: 1.0554 (1.0614) Acc D Fake: 0.177%
Loss D: 1.483
Loss G: 0.4309 (0.4303) Acc G: 99.831%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4261 (0.4279) Acc D Real: 99.571%
Loss D Fake: 1.0567 (1.0614) Acc D Fake: 0.176%
Loss D: 1.483
Loss G: 0.4301 (0.4303) Acc G: 99.832%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4259 (0.4279) Acc D Real: 99.573%
Loss D Fake: 1.0581 (1.0614) Acc D Fake: 0.175%
Loss D: 1.484
Loss G: 0.4294 (0.4303) Acc G: 99.833%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4249 (0.4279) Acc D Real: 99.575%
Loss D Fake: 1.0595 (1.0614) Acc D Fake: 0.175%
Loss D: 1.484
Loss G: 0.4287 (0.4303) Acc G: 99.833%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4243 (0.4278) Acc D Real: 99.577%
Loss D Fake: 1.0608 (1.0614) Acc D Fake: 0.174%
Loss D: 1.485
Loss G: 0.4280 (0.4303) Acc G: 99.834%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4234 (0.4278) Acc D Real: 99.579%
Loss D Fake: 1.0621 (1.0614) Acc D Fake: 0.173%
Loss D: 1.485
Loss G: 0.4274 (0.4303) Acc G: 99.835%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4230 (0.4278) Acc D Real: 99.581%
Loss D Fake: 1.0632 (1.0614) Acc D Fake: 0.172%
Loss D: 1.486
Loss G: 0.4268 (0.4303) Acc G: 99.836%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4221 (0.4278) Acc D Real: 99.583%
Loss D Fake: 1.0643 (1.0614) Acc D Fake: 0.171%
Loss D: 1.486
Loss G: 0.4263 (0.4303) Acc G: 99.836%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4216 (0.4277) Acc D Real: 99.585%
Loss D Fake: 1.0653 (1.0614) Acc D Fake: 0.171%
Loss D: 1.487
Loss G: 0.4258 (0.4302) Acc G: 99.837%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4212 (0.4277) Acc D Real: 99.586%
Loss D Fake: 1.0661 (1.0614) Acc D Fake: 0.170%
Loss D: 1.487
Loss G: 0.4254 (0.4302) Acc G: 99.838%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4203 (0.4277) Acc D Real: 99.588%
Loss D Fake: 1.0669 (1.0615) Acc D Fake: 0.169%
Loss D: 1.487
Loss G: 0.4250 (0.4302) Acc G: 99.839%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4201 (0.4276) Acc D Real: 99.590%
Loss D Fake: 1.0676 (1.0615) Acc D Fake: 0.168%
Loss D: 1.488
Loss G: 0.4246 (0.4302) Acc G: 99.839%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4198 (0.4276) Acc D Real: 99.592%
Loss D Fake: 1.0682 (1.0615) Acc D Fake: 0.167%
Loss D: 1.488
Loss G: 0.4243 (0.4301) Acc G: 99.840%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4193 (0.4276) Acc D Real: 99.594%
Loss D Fake: 1.0687 (1.0615) Acc D Fake: 0.167%
Loss D: 1.488
Loss G: 0.4241 (0.4301) Acc G: 99.841%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4190 (0.4275) Acc D Real: 99.596%
Loss D Fake: 1.0692 (1.0616) Acc D Fake: 0.166%
Loss D: 1.488
Loss G: 0.4239 (0.4301) Acc G: 99.842%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4188 (0.4275) Acc D Real: 99.598%
Loss D Fake: 1.0696 (1.0616) Acc D Fake: 0.165%
Loss D: 1.488
Loss G: 0.4237 (0.4301) Acc G: 99.842%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4186 (0.4274) Acc D Real: 99.599%
Loss D Fake: 1.0699 (1.0617) Acc D Fake: 0.164%
Loss D: 1.488
Loss G: 0.4235 (0.4300) Acc G: 99.843%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4181 (0.4274) Acc D Real: 99.601%
Loss D Fake: 1.0701 (1.0617) Acc D Fake: 0.164%
Loss D: 1.488
Loss G: 0.4234 (0.4300) Acc G: 99.844%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4179 (0.4274) Acc D Real: 99.603%
Loss D Fake: 1.0703 (1.0617) Acc D Fake: 0.163%
Loss D: 1.488
Loss G: 0.4233 (0.4300) Acc G: 99.844%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4177 (0.4273) Acc D Real: 99.603%
Loss D Fake: 1.0705 (1.0618) Acc D Fake: 0.163%
Loss D: 1.488
Loss G: 0.4233 (0.4299) Acc G: 99.845%
LR: 2.000e-04
Epoch: 8/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4178 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0707) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4231 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4177 (0.4177) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0707) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4231 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4172 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0707) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4231 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4174 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0708) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4172 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0708) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4172 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0708) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4173 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4172 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4173 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4171 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4163 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4170 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4168 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4167 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4166 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4168 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0709) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4164 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4166 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4163 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4163 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4162 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4163 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4162 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4164 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4161 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4156 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4159 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4155 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4156 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4158 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4155 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4152 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4155 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4157 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4147 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4158 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0709) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4150 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4149 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4152 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4151 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4145 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4230 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4147 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4150 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4147 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0709) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4153 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0708) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4142 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0707 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4146 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0706 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4149 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0706 (1.0708) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4231 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4142 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0706 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4232 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4134 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0705 (1.0708) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4232 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4145 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0705 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4232 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4142 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0704 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4233 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4146 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0703 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4233 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4145 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0702 (1.0708) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4234 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4143 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0701 (1.0708) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4235 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4139 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0699 (1.0708) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4235 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4141 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0698 (1.0707) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4236 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4146 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0696 (1.0707) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4237 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4144 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0695 (1.0707) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4238 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4142 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0693 (1.0707) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4239 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4143 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0692 (1.0707) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4239 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4140 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.0706) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4240 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4139 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0689 (1.0706) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4241 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4138 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0688 (1.0706) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4242 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4142 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0686 (1.0705) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4243 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4144 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0685 (1.0705) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4243 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4144 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0684 (1.0705) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4244 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4137 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0682 (1.0704) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4245 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4128 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0681 (1.0704) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4246 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4134 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0679 (1.0704) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4247 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4127 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0677 (1.0703) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4248 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4139 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0675 (1.0703) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4250 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4141 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0703) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4251 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4140 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0670 (1.0702) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4252 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4143 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0669 (1.0702) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4253 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4134 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0701) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4254 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4136 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0665 (1.0701) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4255 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4146 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0663 (1.0700) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4256 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4146 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0700) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4257 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4138 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0699) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4257 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4140 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0699) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4257 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4151 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0663 (1.0699) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4257 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4140 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0665 (1.0698) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4256 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4134 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0698) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4255 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4137 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0697) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4256 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4119 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0697) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4257 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4114 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0665 (1.0697) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4259 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4144 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0696) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4260 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4142 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0661 (1.0696) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4261 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4136 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0661 (1.0696) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4261 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4134 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0661 (1.0695) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4261 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4148 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0695) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4260 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4149 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0665 (1.0694) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4259 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4129 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0694) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4258 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4136 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0670 (1.0694) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4257 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4138 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0673 (1.0694) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4257 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4115 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0674 (1.0694) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4257 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4148 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0693) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4258 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4122 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0693) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4260 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4119 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0670 (1.0693) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4261 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4147 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0669 (1.0693) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4261 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4153 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0670 (1.0692) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4261 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4181 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0692) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4260 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4135 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0675 (1.0692) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4260 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4134 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0675 (1.0692) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4260 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4146 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0677 (1.0692) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4258 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4131 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0683 (1.0692) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4255 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4115 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0688 (1.0692) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4255 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4144 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0688 (1.0692) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4255 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4137 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.0692) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4255 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4117 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0689 (1.0692) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4258 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4165 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0681 (1.0691) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4262 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4170 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0673 (1.0691) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4267 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4181 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0663 (1.0691) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4273 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4147 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0649 (1.0691) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4280 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4187 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0636 (1.0690) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4286 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4195 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0628 (1.0690) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4288 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4187 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0627 (1.0689) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4289 (0.4244) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4182 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0689) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4291 (0.4244) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4214 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0621 (1.0688) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4290 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4197 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0688) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4288 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4200 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0631 (1.0687) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4283 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4189 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0643 (1.0687) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4277 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4188 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0657 (1.0686) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4268 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4209 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0674 (1.0686) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4263 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4208 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0679 (1.0686) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4263 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4224 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0686) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4269 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4255 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0654 (1.0686) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4279 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4226 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0631 (1.0686) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4287 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4259 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0618 (1.0685) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4292 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4246 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0607 (1.0684) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4296 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4250 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0600 (1.0684) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4296 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4218 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0607 (1.0683) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4288 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4254 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0683) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4281 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4243 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0634 (1.0682) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4276 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4228 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0642 (1.0682) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4272 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4206 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0652 (1.0682) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4265 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4207 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0668 (1.0682) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4256 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4245 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0682 (1.0682) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4252 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4230 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0684 (1.0682) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4252 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4229 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0681 (1.0682) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4254 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4232 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0672 (1.0682) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4260 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4227 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0658 (1.0682) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4265 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4254 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0646 (1.0681) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4272 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4255 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0632 (1.0681) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4278 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4251 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0620 (1.0681) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4282 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4267 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0613 (1.0680) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4285 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4261 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0608 (1.0680) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4286 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4268 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0607 (1.0679) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4285 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4269 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0609 (1.0679) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4284 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4258 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0611 (1.0678) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4281 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4262 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0616 (1.0678) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4278 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4265 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0620 (1.0677) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4276 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4246 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0677) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4273 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4262 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0630 (1.0677) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4271 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4245 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0634 (1.0677) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4268 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4247 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0638 (1.0676) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4266 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4244 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0641 (1.0676) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4264 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4247 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0645 (1.0676) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4262 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4244 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0648 (1.0676) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4260 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4246 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0651 (1.0676) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4258 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4234 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0654 (1.0675) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4256 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4236 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0658 (1.0675) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4254 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4234 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0662 (1.0675) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4251 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4227 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0675) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4248 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4222 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0673 (1.0675) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4245 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4219 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0678 (1.0675) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4242 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4208 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0684 (1.0675) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4239 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4211 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.0675) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4235 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4203 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0696 (1.0675) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4232 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4196 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0702 (1.0676) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4229 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4194 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0708 (1.0676) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4226 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4196 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0713 (1.0676) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4223 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4179 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0719 (1.0676) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4221 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4192 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0724 (1.0677) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4218 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4187 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0729 (1.0677) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4215 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4179 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0734 (1.0677) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4213 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4170 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0738 (1.0677) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4211 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4174 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0742 (1.0678) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4209 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4169 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0745 (1.0678) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4207 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4165 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0749 (1.0679) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4205 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4167 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0751 (1.0679) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4204 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4157 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0754 (1.0679) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4203 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4163 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.0680) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4202 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4161 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0758 (1.0680) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4201 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4160 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0760 (1.0681) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4200 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4151 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.0681) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4199 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4149 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0763 (1.0682) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4152 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0764 (1.0682) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4198 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4143 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0764 (1.0682) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4147 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0683) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4144 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0683) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4149 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0684) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4118 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0684) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4198 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4115 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0764 (1.0684) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4198 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4118 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0763 (1.0685) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4199 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4114 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0761 (1.0685) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4200 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4048 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0761 (1.0686) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4200 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.3977 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0766 (1.0686) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4193 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.3840 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.0687) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4132 (0.4244) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.3719 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.1720 (1.0692) Acc D Fake: 0.000%
Loss D: 1.544
Loss G: 0.3734 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.3635 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.1803 (1.0697) Acc D Fake: 0.000%
Loss D: 1.544
Loss G: 0.3717 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.3602 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.1784 (1.0703) Acc D Fake: 0.000%
Loss D: 1.539
Loss G: 0.3752 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.3743 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.1692 (1.0707) Acc D Fake: 0.000%
Loss D: 1.543
Loss G: 0.3806 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.3692 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.1515 (1.0711) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4256 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3782 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0572 (1.0711) Acc D Fake: 0.000%
Loss D: 1.435
Loss G: 0.4323 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4025 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0496 (1.0710) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4351 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4047 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0453 (1.0708) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4370 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.3997 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0424 (1.0707) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4381 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.3944 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0418 (1.0706) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4370 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3839 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0586 (1.0705) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4177 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.3840 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.1289 (1.0708) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4370 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.3804 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0358 (1.0706) Acc D Fake: 0.000%
Loss D: 1.416
Loss G: 0.4438 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.3946 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0288 (1.0704) Acc D Fake: 0.000%
Loss D: 1.423
Loss G: 0.4462 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4084 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0258 (1.0702) Acc D Fake: 0.000%
Loss D: 1.434
Loss G: 0.4471 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4149 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0260 (1.0700) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4456 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4119 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0362 (1.0699) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4333 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.3907 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.1226 (1.0701) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4421 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.3921 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.0270 (1.0699) Acc D Fake: 0.000%
Loss D: 1.419
Loss G: 0.4487 (0.4244) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.3972 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0209 (1.0697) Acc D Fake: 0.000%
Loss D: 1.418
Loss G: 0.4504 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4088 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0192 (1.0695) Acc D Fake: 0.000%
Loss D: 1.428
Loss G: 0.4508 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4010 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0199 (1.0692) Acc D Fake: 0.000%
Loss D: 1.421
Loss G: 0.4492 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.3980 (0.4143) Acc D Real: 100.000%
Loss D Fake: 1.0271 (1.0690) Acc D Fake: 0.000%
Loss D: 1.425
Loss G: 0.4449 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.3910 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0418 (1.0689) Acc D Fake: 0.000%
Loss D: 1.433
Loss G: 0.4509 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4197 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0172 (1.0687) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4506 (0.4251) Acc G: 100.000%
LR: 2.000e-04
Epoch: 9/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.3854 (0.3937) Acc D Real: 100.000%
Loss D Fake: 1.0603 (1.0434) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4554 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4210 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.0104 (1.0324) Acc D Fake: 0.000%
Loss D: 1.431
Loss G: 0.4544 (0.4511) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4442 (0.4132) Acc D Real: 100.000%
Loss D Fake: 1.0143 (1.0279) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4515 (0.4512) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4459 (0.4197) Acc D Real: 100.000%
Loss D Fake: 1.0199 (1.0263) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4482 (0.4506) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4426 (0.4235) Acc D Real: 100.000%
Loss D Fake: 1.0260 (1.0262) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4447 (0.4496) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4396 (0.4258) Acc D Real: 100.000%
Loss D Fake: 1.0323 (1.0271) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4413 (0.4484) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4367 (0.4272) Acc D Real: 100.000%
Loss D Fake: 1.0385 (1.0285) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4380 (0.4471) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4328 (0.4278) Acc D Real: 100.000%
Loss D Fake: 1.0444 (1.0303) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4350 (0.4458) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4298 (0.4280) Acc D Real: 100.000%
Loss D Fake: 1.0499 (1.0322) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4322 (0.4444) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4269 (0.4279) Acc D Real: 100.000%
Loss D Fake: 1.0551 (1.0343) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4296 (0.4431) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4249 (0.4277) Acc D Real: 100.000%
Loss D Fake: 1.0599 (1.0364) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4272 (0.4418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4232 (0.4273) Acc D Real: 100.000%
Loss D Fake: 1.0641 (1.0386) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4252 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4198 (0.4268) Acc D Real: 100.000%
Loss D Fake: 1.0677 (1.0406) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4234 (0.4393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4175 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.0711 (1.0427) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4218 (0.4381) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4180 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.0740 (1.0446) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4205 (0.4370) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4159 (0.4251) Acc D Real: 100.000%
Loss D Fake: 1.0763 (1.0465) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4195 (0.4360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4149 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.0780 (1.0482) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4187 (0.4350) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4138 (0.4239) Acc D Real: 100.000%
Loss D Fake: 1.0794 (1.0499) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4181 (0.4341) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4135 (0.4234) Acc D Real: 100.000%
Loss D Fake: 1.0804 (1.0514) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4176 (0.4333) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4130 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.0814 (1.0528) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4172 (0.4325) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4122 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.0821 (1.0542) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4169 (0.4318) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4116 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.0826 (1.0554) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4167 (0.4312) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4114 (0.4215) Acc D Real: 100.000%
Loss D Fake: 1.0830 (1.0566) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4164 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4110 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.0834 (1.0576) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4162 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4109 (0.4207) Acc D Real: 100.000%
Loss D Fake: 1.0837 (1.0586) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4162 (0.4294) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4113 (0.4204) Acc D Real: 100.000%
Loss D Fake: 1.0838 (1.0596) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4161 (0.4290) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4121 (0.4201) Acc D Real: 100.000%
Loss D Fake: 1.0838 (1.0604) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4162 (0.4285) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4112 (0.4198) Acc D Real: 100.000%
Loss D Fake: 1.0835 (1.0612) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4164 (0.4281) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4111 (0.4195) Acc D Real: 100.000%
Loss D Fake: 1.0832 (1.0620) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4165 (0.4277) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4113 (0.4192) Acc D Real: 100.000%
Loss D Fake: 1.0830 (1.0626) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4165 (0.4273) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4114 (0.4190) Acc D Real: 100.000%
Loss D Fake: 1.0829 (1.0633) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4166 (0.4270) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4117 (0.4187) Acc D Real: 100.000%
Loss D Fake: 1.0826 (1.0639) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4168 (0.4267) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4130 (0.4186) Acc D Real: 100.000%
Loss D Fake: 1.0823 (1.0644) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4170 (0.4264) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4127 (0.4184) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.0649) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4172 (0.4261) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4129 (0.4183) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0654) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4174 (0.4259) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4126 (0.4181) Acc D Real: 100.000%
Loss D Fake: 1.0808 (1.0658) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4177 (0.4257) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4126 (0.4180) Acc D Real: 100.000%
Loss D Fake: 1.0804 (1.0662) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4178 (0.4255) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4131 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0801 (1.0665) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4180 (0.4253) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4131 (0.4177) Acc D Real: 100.000%
Loss D Fake: 1.0799 (1.0668) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4181 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4125 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0797 (1.0672) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4181 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4129 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0797 (1.0675) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4181 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4132 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0796 (1.0677) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4181 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4132 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0795 (1.0680) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4182 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4138 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0794 (1.0683) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4183 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4143 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0791 (1.0685) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4185 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4136 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0786 (1.0687) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4187 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4148 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0782 (1.0689) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4189 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4144 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0778 (1.0691) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4191 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4142 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0773 (1.0693) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4193 (0.4238) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4136 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0769 (1.0694) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4195 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4147 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0695) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4197 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4145 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.0697) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4198 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4151 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0760 (1.0698) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4199 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4150 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0758 (1.0699) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4200 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4148 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.0700) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4200 (0.4234) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4148 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0755 (1.0701) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4201 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4146 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0755 (1.0702) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4201 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4149 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0755 (1.0703) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4200 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4142 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0755 (1.0704) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4200 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4142 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.0704) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4200 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4144 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.0705) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4199 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4145 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0758 (1.0706) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4198 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4145 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0759 (1.0707) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4198 (0.4229) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4136 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0761 (1.0708) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4197 (0.4229) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4143 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.0709) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4196 (0.4228) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4148 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0764 (1.0709) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4195 (0.4228) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4139 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0765 (1.0710) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4194 (0.4227) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4141 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0767 (1.0711) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4193 (0.4227) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4138 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0769 (1.0712) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4192 (0.4226) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4125 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0770 (1.0713) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4192 (0.4226) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4132 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0771 (1.0714) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4191 (0.4225) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4132 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0773 (1.0714) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4190 (0.4225) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4134 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0774 (1.0715) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4190 (0.4224) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4134 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0775 (1.0716) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4189 (0.4224) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4133 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0776 (1.0717) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4188 (0.4223) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4128 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0778 (1.0718) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4187 (0.4223) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4132 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0779 (1.0718) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4187 (0.4223) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4129 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0781 (1.0719) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4186 (0.4222) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4120 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0783 (1.0720) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4185 (0.4222) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4120 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0784 (1.0721) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4184 (0.4221) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4123 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0786 (1.0722) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4183 (0.4221) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4112 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0787 (1.0722) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4183 (0.4220) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4124 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0788 (1.0723) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4182 (0.4220) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4126 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0789 (1.0724) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4182 (0.4219) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4117 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0790 (1.0725) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4181 (0.4219) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4114 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0791 (1.0725) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4180 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4116 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0792 (1.0726) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4180 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4119 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0793 (1.0727) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4179 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4120 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0794 (1.0728) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4179 (0.4217) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4103 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0795 (1.0728) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4178 (0.4217) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4109 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0796 (1.0729) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4178 (0.4216) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4105 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0797 (1.0730) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4178 (0.4216) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4094 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0797 (1.0731) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4177 (0.4215) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4107 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0798 (1.0731) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4177 (0.4215) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4119 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0798 (1.0732) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4177 (0.4215) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4110 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0799 (1.0733) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4177 (0.4214) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4109 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0799 (1.0733) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4176 (0.4214) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4102 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0800 (1.0734) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4176 (0.4214) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4108 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0801 (1.0735) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4176 (0.4213) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4096 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0801 (1.0735) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4175 (0.4213) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4104 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0802 (1.0736) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4175 (0.4212) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4116 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0802 (1.0737) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4175 (0.4212) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4106 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0803 (1.0737) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4174 (0.4212) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4086 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0804 (1.0738) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4174 (0.4211) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4103 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.0804 (1.0739) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4174 (0.4211) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4111 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.0805 (1.0739) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4174 (0.4211) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4109 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.0805 (1.0740) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4173 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4091 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.0806 (1.0740) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4173 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4103 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.0741) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4173 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4101 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.0742) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4172 (0.4209) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4081 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0808 (1.0742) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4172 (0.4209) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4090 (0.4143) Acc D Real: 100.000%
Loss D Fake: 1.0808 (1.0743) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4172 (0.4209) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4093 (0.4143) Acc D Real: 100.000%
Loss D Fake: 1.0808 (1.0743) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4172 (0.4208) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4097 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0809 (1.0744) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4172 (0.4208) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4095 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0809 (1.0744) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4171 (0.4208) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4089 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0810 (1.0745) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4171 (0.4207) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4098 (0.4141) Acc D Real: 100.000%
Loss D Fake: 1.0810 (1.0746) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4171 (0.4207) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4063 (0.4141) Acc D Real: 100.000%
Loss D Fake: 1.0810 (1.0746) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4171 (0.4207) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4093 (0.4140) Acc D Real: 100.000%
Loss D Fake: 1.0810 (1.0747) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4171 (0.4206) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4077 (0.4140) Acc D Real: 100.000%
Loss D Fake: 1.0811 (1.0747) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4171 (0.4206) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4084 (0.4139) Acc D Real: 100.000%
Loss D Fake: 1.0811 (1.0748) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4171 (0.4206) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4097 (0.4139) Acc D Real: 100.000%
Loss D Fake: 1.0811 (1.0748) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4171 (0.4206) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4097 (0.4139) Acc D Real: 100.000%
Loss D Fake: 1.0812 (1.0749) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4171 (0.4205) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4083 (0.4138) Acc D Real: 100.000%
Loss D Fake: 1.0812 (1.0749) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4170 (0.4205) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4066 (0.4138) Acc D Real: 100.000%
Loss D Fake: 1.0812 (1.0750) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4170 (0.4205) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4056 (0.4137) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0750) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4170 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4074 (0.4136) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0751) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4170 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4087 (0.4136) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0751) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4170 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4070 (0.4136) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0752) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4170 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4081 (0.4135) Acc D Real: 100.000%
Loss D Fake: 1.0813 (1.0752) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4170 (0.4203) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4085 (0.4135) Acc D Real: 100.000%
Loss D Fake: 1.0814 (1.0753) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4170 (0.4203) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4063 (0.4134) Acc D Real: 100.000%
Loss D Fake: 1.0814 (1.0753) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4170 (0.4203) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4078 (0.4134) Acc D Real: 100.000%
Loss D Fake: 1.0815 (1.0754) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4170 (0.4203) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4097 (0.4133) Acc D Real: 100.000%
Loss D Fake: 1.0815 (1.0754) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4169 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4069 (0.4133) Acc D Real: 100.000%
Loss D Fake: 1.0816 (1.0754) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4169 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4070 (0.4133) Acc D Real: 100.000%
Loss D Fake: 1.0817 (1.0755) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4169 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4061 (0.4132) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.0755) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4168 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4057 (0.4131) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.0756) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4168 (0.4201) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4062 (0.4131) Acc D Real: 100.000%
Loss D Fake: 1.0819 (1.0756) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4168 (0.4201) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4063 (0.4131) Acc D Real: 100.000%
Loss D Fake: 1.0820 (1.0757) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4168 (0.4201) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4061 (0.4130) Acc D Real: 100.000%
Loss D Fake: 1.0821 (1.0757) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4167 (0.4201) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4072 (0.4130) Acc D Real: 100.000%
Loss D Fake: 1.0822 (1.0758) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4167 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4050 (0.4129) Acc D Real: 100.000%
Loss D Fake: 1.0823 (1.0758) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4167 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4058 (0.4129) Acc D Real: 100.000%
Loss D Fake: 1.0824 (1.0759) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4166 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4055 (0.4128) Acc D Real: 100.000%
Loss D Fake: 1.0825 (1.0759) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4166 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4050 (0.4128) Acc D Real: 100.000%
Loss D Fake: 1.0827 (1.0759) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4165 (0.4200) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4051 (0.4127) Acc D Real: 100.000%
Loss D Fake: 1.0828 (1.0760) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4165 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4041 (0.4126) Acc D Real: 100.000%
Loss D Fake: 1.0830 (1.0760) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4164 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4062 (0.4126) Acc D Real: 100.000%
Loss D Fake: 1.0831 (1.0761) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4163 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4047 (0.4125) Acc D Real: 100.000%
Loss D Fake: 1.0833 (1.0761) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4163 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4040 (0.4125) Acc D Real: 100.000%
Loss D Fake: 1.0835 (1.0762) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4162 (0.4198) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4041 (0.4124) Acc D Real: 100.000%
Loss D Fake: 1.0838 (1.0762) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4161 (0.4198) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4012 (0.4124) Acc D Real: 100.000%
Loss D Fake: 1.0840 (1.0763) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4160 (0.4198) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4019 (0.4123) Acc D Real: 100.000%
Loss D Fake: 1.0843 (1.0763) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4159 (0.4198) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4003 (0.4122) Acc D Real: 100.000%
Loss D Fake: 1.0847 (1.0764) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4157 (0.4197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4024 (0.4122) Acc D Real: 100.000%
Loss D Fake: 1.0851 (1.0764) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4156 (0.4197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4009 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0856 (1.0765) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4154 (0.4197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4022 (0.4120) Acc D Real: 100.000%
Loss D Fake: 1.0862 (1.0766) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4151 (0.4197) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.3958 (0.4119) Acc D Real: 100.000%
Loss D Fake: 1.0868 (1.0766) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4149 (0.4196) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4006 (0.4119) Acc D Real: 100.000%
Loss D Fake: 1.0876 (1.0767) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4145 (0.4196) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4020 (0.4118) Acc D Real: 100.000%
Loss D Fake: 1.0885 (1.0768) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4142 (0.4196) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4000 (0.4117) Acc D Real: 100.000%
Loss D Fake: 1.0894 (1.0768) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4138 (0.4195) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.3957 (0.4116) Acc D Real: 100.000%
Loss D Fake: 1.0907 (1.0769) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4131 (0.4195) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3973 (0.4115) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.0770) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4124 (0.4194) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.3925 (0.4114) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.0771) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4112 (0.4194) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.3907 (0.4113) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.0773) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4096 (0.4193) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.3874 (0.4112) Acc D Real: 100.000%
Loss D Fake: 1.1032 (1.0774) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4070 (0.4193) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.3757 (0.4109) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.0776) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4028 (0.4192) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.3652 (0.4107) Acc D Real: 100.000%
Loss D Fake: 1.1270 (1.0779) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.3961 (0.4190) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.3522 (0.4103) Acc D Real: 100.000%
Loss D Fake: 1.1568 (1.0784) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.3872 (0.4188) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.3458 (0.4100) Acc D Real: 100.000%
Loss D Fake: 1.1756 (1.0789) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3907 (0.4187) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.3502 (0.4096) Acc D Real: 100.000%
Loss D Fake: 1.1399 (1.0793) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.3982 (0.4186) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.3595 (0.4093) Acc D Real: 100.000%
Loss D Fake: 1.1305 (1.0796) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.3991 (0.4184) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.3458 (0.4090) Acc D Real: 100.000%
Loss D Fake: 1.1385 (1.0799) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.3968 (0.4183) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.3417 (0.4086) Acc D Real: 100.000%
Loss D Fake: 1.1446 (1.0803) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4015 (0.4182) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.3497 (0.4082) Acc D Real: 100.000%
Loss D Fake: 1.1190 (1.0805) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4095 (0.4182) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.3538 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.0806) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4133 (0.4181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.3554 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1026 (1.0808) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4134 (0.4181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.3403 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.1099 (1.0809) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4127 (0.4181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.3314 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1049 (1.0811) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4207 (0.4181) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.3489 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.0790 (1.0810) Acc D Fake: 0.000%
Loss D: 1.428
Loss G: 0.4287 (0.4182) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.3220 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.0694 (1.0810) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.4297 (0.4182) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.3093 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.0848 (1.0810) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.4195 (0.4182) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.3115 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.1457 (1.0813) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4323 (0.4183) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.3055 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.0408 (1.0811) Acc D Fake: 0.000%
Loss D: 1.346
Loss G: 0.4501 (0.4185) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.3331 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.0231 (1.0808) Acc D Fake: 0.000%
Loss D: 1.356
Loss G: 0.4512 (0.4187) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.3568 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.0331 (1.0806) Acc D Fake: 0.000%
Loss D: 1.390
Loss G: 0.4423 (0.4188) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.3323 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.0711 (1.0805) Acc D Fake: 0.000%
Loss D: 1.403
Loss G: 0.4106 (0.4187) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.2692 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.3217 (1.0818) Acc D Fake: 0.000%
Loss D: 1.591
Loss G: 0.4616 (0.4190) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.3594 (0.4026) Acc D Real: 100.000%
Loss D Fake: 0.9606 (1.0811) Acc D Fake: 0.000%
Loss D: 1.320
Loss G: 0.4996 (0.4194) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4663 (0.4029) Acc D Real: 100.000%
Loss D Fake: 0.9231 (1.0803) Acc D Fake: 0.000%
Loss D: 1.389
Loss G: 0.5149 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4852 (0.4033) Acc D Real: 100.000%
Loss D Fake: 0.9054 (1.0794) Acc D Fake: 0.000%
Loss D: 1.391
Loss G: 0.5233 (0.4204) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.5053 (0.4038) Acc D Real: 100.000%
Loss D Fake: 0.8956 (1.0785) Acc D Fake: 0.000%
Loss D: 1.401
Loss G: 0.5280 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.5119 (0.4044) Acc D Real: 100.000%
Loss D Fake: 0.8907 (1.0775) Acc D Fake: 0.000%
Loss D: 1.403
Loss G: 0.5301 (0.4215) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.5137 (0.4050) Acc D Real: 100.000%
Loss D Fake: 0.8892 (1.0765) Acc D Fake: 0.000%
Loss D: 1.403
Loss G: 0.5301 (0.4221) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.5110 (0.4055) Acc D Real: 100.000%
Loss D Fake: 0.8902 (1.0756) Acc D Fake: 0.000%
Loss D: 1.401
Loss G: 0.5287 (0.4226) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.5139 (0.4060) Acc D Real: 100.000%
Loss D Fake: 0.8932 (1.0747) Acc D Fake: 0.000%
Loss D: 1.407
Loss G: 0.5262 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.5115 (0.4066) Acc D Real: 100.000%
Loss D Fake: 0.8976 (1.0738) Acc D Fake: 0.000%
Loss D: 1.409
Loss G: 0.5227 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.5081 (0.4071) Acc D Real: 100.000%
Loss D Fake: 0.9033 (1.0729) Acc D Fake: 0.000%
Loss D: 1.411
Loss G: 0.5186 (0.4241) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4989 (0.4075) Acc D Real: 100.000%
Loss D Fake: 0.9097 (1.0721) Acc D Fake: 0.000%
Loss D: 1.409
Loss G: 0.5141 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.5032 (0.4080) Acc D Real: 100.000%
Loss D Fake: 0.9168 (1.0714) Acc D Fake: 0.000%
Loss D: 1.420
Loss G: 0.5093 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4954 (0.4084) Acc D Real: 100.000%
Loss D Fake: 0.9243 (1.0706) Acc D Fake: 0.000%
Loss D: 1.420
Loss G: 0.5044 (0.4254) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4919 (0.4088) Acc D Real: 100.000%
Loss D Fake: 0.9321 (1.0700) Acc D Fake: 0.000%
Loss D: 1.424
Loss G: 0.4993 (0.4257) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4706 (0.4092) Acc D Real: 100.000%
Loss D Fake: 0.9400 (1.0693) Acc D Fake: 0.000%
Loss D: 1.411
Loss G: 0.4944 (0.4261) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4819 (0.4095) Acc D Real: 100.000%
Loss D Fake: 0.9477 (1.0687) Acc D Fake: 0.000%
Loss D: 1.430
Loss G: 0.4896 (0.4264) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4743 (0.4098) Acc D Real: 100.000%
Loss D Fake: 0.9554 (1.0682) Acc D Fake: 0.000%
Loss D: 1.430
Loss G: 0.4849 (0.4267) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4714 (0.4101) Acc D Real: 100.000%
Loss D Fake: 0.9630 (1.0677) Acc D Fake: 0.000%
Loss D: 1.434
Loss G: 0.4804 (0.4269) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4680 (0.4104) Acc D Real: 100.000%
Loss D Fake: 0.9704 (1.0672) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4760 (0.4272) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4641 (0.4106) Acc D Real: 100.000%
Loss D Fake: 0.9776 (1.0668) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4718 (0.4274) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4601 (0.4109) Acc D Real: 100.000%
Loss D Fake: 0.9845 (1.0664) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4679 (0.4276) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4518 (0.4111) Acc D Real: 100.000%
Loss D Fake: 0.9910 (1.0660) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4642 (0.4277) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4502 (0.4113) Acc D Real: 100.000%
Loss D Fake: 0.9973 (1.0657) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4607 (0.4279) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4450 (0.4114) Acc D Real: 100.000%
Loss D Fake: 1.0032 (1.0654) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4574 (0.4280) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4434 (0.4116) Acc D Real: 100.000%
Loss D Fake: 1.0087 (1.0652) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4544 (0.4282) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4372 (0.4117) Acc D Real: 100.000%
Loss D Fake: 1.0138 (1.0649) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4517 (0.4283) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4318 (0.4118) Acc D Real: 100.000%
Loss D Fake: 1.0186 (1.0647) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4491 (0.4284) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4372 (0.4119) Acc D Real: 100.000%
Loss D Fake: 1.0230 (1.0645) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4468 (0.4284) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4310 (0.4120) Acc D Real: 100.000%
Loss D Fake: 1.0271 (1.0643) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4446 (0.4285) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4291 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0308 (1.0642) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4427 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4183 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0342 (1.0641) Acc D Fake: 0.000%
Loss D: 1.453
Loss G: 0.4409 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4116 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0372 (1.0639) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4395 (0.4287) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4268 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0397 (1.0638) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4381 (0.4287) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4226 (0.4122) Acc D Real: 100.000%
Loss D Fake: 1.0421 (1.0637) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4369 (0.4288) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4217 (0.4122) Acc D Real: 100.000%
Loss D Fake: 1.0442 (1.0636) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4358 (0.4288) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4157 (0.4123) Acc D Real: 100.000%
Loss D Fake: 1.0463 (1.0636) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4347 (0.4288) Acc G: 100.000%
LR: 2.000e-04
Epoch: 10/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4151 (0.4107) Acc D Real: 100.000%
Loss D Fake: 1.0494 (1.0487) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4332 (0.4335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4145 (0.4120) Acc D Real: 100.000%
Loss D Fake: 1.0507 (1.0494) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4325 (0.4332) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4005 (0.4091) Acc D Real: 100.000%
Loss D Fake: 1.0519 (1.0500) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4320 (0.4329) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4142 (0.4101) Acc D Real: 100.000%
Loss D Fake: 1.0527 (1.0505) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4315 (0.4326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4159 (0.4111) Acc D Real: 100.000%
Loss D Fake: 1.0535 (1.0510) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4311 (0.4324) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4154 (0.4117) Acc D Real: 100.000%
Loss D Fake: 1.0543 (1.0515) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4306 (0.4321) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.3918 (0.4092) Acc D Real: 100.000%
Loss D Fake: 1.0550 (1.0519) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4304 (0.4319) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4083 (0.4091) Acc D Real: 100.000%
Loss D Fake: 1.0553 (1.0523) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4302 (0.4317) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4109 (0.4093) Acc D Real: 100.000%
Loss D Fake: 1.0556 (1.0526) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4300 (0.4315) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4131 (0.4096) Acc D Real: 100.000%
Loss D Fake: 1.0560 (1.0530) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4297 (0.4314) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4123 (0.4099) Acc D Real: 100.000%
Loss D Fake: 1.0564 (1.0532) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4295 (0.4312) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.3997 (0.4091) Acc D Real: 100.000%
Loss D Fake: 1.0568 (1.0535) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4293 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4060 (0.4089) Acc D Real: 100.000%
Loss D Fake: 1.0570 (1.0538) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4292 (0.4309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4014 (0.4084) Acc D Real: 100.000%
Loss D Fake: 1.0571 (1.0540) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4291 (0.4308) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4104 (0.4085) Acc D Real: 100.000%
Loss D Fake: 1.0573 (1.0542) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4289 (0.4307) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4056 (0.4083) Acc D Real: 100.000%
Loss D Fake: 1.0575 (1.0544) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4288 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4011 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.0577 (1.0546) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4287 (0.4305) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4034 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.0578 (1.0547) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4286 (0.4304) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.3909 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.0579 (1.0549) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4285 (0.4303) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.3890 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.0579 (1.0550) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4286 (0.4302) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.3628 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.0575 (1.0552) Acc D Fake: 0.000%
Loss D: 1.420
Loss G: 0.4289 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.3871 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.0566 (1.0552) Acc D Fake: 0.000%
Loss D: 1.444
Loss G: 0.4293 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4070 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.0558 (1.0552) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4296 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.3390 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0553 (1.0552) Acc D Fake: 0.000%
Loss D: 1.394
Loss G: 0.4298 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.3420 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.0546 (1.0552) Acc D Fake: 0.000%
Loss D: 1.397
Loss G: 0.4303 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.3185 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.0531 (1.0551) Acc D Fake: 0.000%
Loss D: 1.372
Loss G: 0.4314 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.2819 (0.3916) Acc D Real: 100.000%
Loss D Fake: 1.0503 (1.0550) Acc D Fake: 0.000%
Loss D: 1.332
Loss G: 0.4333 (0.4302) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.2781 (0.3877) Acc D Real: 100.000%
Loss D Fake: 1.0466 (1.0547) Acc D Fake: 0.000%
Loss D: 1.325
Loss G: 0.4355 (0.4304) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.2903 (0.3844) Acc D Real: 100.000%
Loss D Fake: 1.0426 (1.0543) Acc D Fake: 0.000%
Loss D: 1.333
Loss G: 0.4380 (0.4307) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.2423 (0.3798) Acc D Real: 100.000%
Loss D Fake: 1.0381 (1.0538) Acc D Fake: 0.000%
Loss D: 1.280
Loss G: 0.4411 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.2392 (0.3754) Acc D Real: 100.000%
Loss D Fake: 1.0330 (1.0531) Acc D Fake: 0.000%
Loss D: 1.272
Loss G: 0.4447 (0.4314) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.1613 (0.3689) Acc D Real: 100.000%
Loss D Fake: 1.0268 (1.0523) Acc D Fake: 0.000%
Loss D: 1.188
Loss G: 0.4499 (0.4320) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.1697 (0.3631) Acc D Real: 100.000%
Loss D Fake: 1.0186 (1.0513) Acc D Fake: 0.000%
Loss D: 1.188
Loss G: 0.4554 (0.4327) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.1677 (0.3575) Acc D Real: 100.000%
Loss D Fake: 1.0136 (1.0502) Acc D Fake: 0.000%
Loss D: 1.181
Loss G: 0.4594 (0.4335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.1412 (0.3515) Acc D Real: 100.000%
Loss D Fake: 1.0166 (1.0493) Acc D Fake: 0.000%
Loss D: 1.158
Loss G: 0.4620 (0.4342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.1502 (0.3460) Acc D Real: 100.000%
Loss D Fake: 1.0288 (1.0488) Acc D Fake: 0.000%
Loss D: 1.179
Loss G: 0.4625 (0.4350) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.1558 (0.3410) Acc D Real: 100.000%
Loss D Fake: 1.0677 (1.0493) Acc D Fake: 0.000%
Loss D: 1.223
Loss G: 0.4654 (0.4358) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.1384 (0.3358) Acc D Real: 100.000%
Loss D Fake: 1.0467 (1.0492) Acc D Fake: 0.000%
Loss D: 1.185
Loss G: 0.4926 (0.4373) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.1395 (0.3309) Acc D Real: 100.000%
Loss D Fake: 0.9543 (1.0468) Acc D Fake: 0.000%
Loss D: 1.094
Loss G: 0.5225 (0.4394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.1805 (0.3273) Acc D Real: 100.000%
Loss D Fake: 0.9018 (1.0433) Acc D Fake: 0.000%
Loss D: 1.082
Loss G: 0.5476 (0.4420) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.2026 (0.3243) Acc D Real: 100.000%
Loss D Fake: 0.8639 (1.0390) Acc D Fake: 0.000%
Loss D: 1.066
Loss G: 0.5706 (0.4451) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.1740 (0.3208) Acc D Real: 100.000%
Loss D Fake: 0.8323 (1.0342) Acc D Fake: 0.000%
Loss D: 1.006
Loss G: 0.5928 (0.4485) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.1909 (0.3178) Acc D Real: 100.000%
Loss D Fake: 0.8041 (1.0290) Acc D Fake: 0.000%
Loss D: 0.995
Loss G: 0.6145 (0.4523) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.2447 (0.3162) Acc D Real: 99.998%
Loss D Fake: 0.7790 (1.0234) Acc D Fake: 0.000%
Loss D: 1.024
Loss G: 0.6353 (0.4564) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.3212 (0.3163) Acc D Real: 99.995%
Loss D Fake: 0.7569 (1.0176) Acc D Fake: 0.000%
Loss D: 1.078
Loss G: 0.6539 (0.4607) Acc G: 98.659%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.3457 (0.3170) Acc D Real: 99.813%
Loss D Fake: 0.7385 (1.0117) Acc D Fake: 1.702%
Loss D: 1.084
Loss G: 0.6697 (0.4651) Acc G: 96.986%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.2986 (0.3166) Acc D Real: 99.243%
Loss D Fake: 0.7234 (1.0057) Acc D Fake: 3.333%
Loss D: 1.022
Loss G: 0.6837 (0.4697) Acc G: 95.347%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.2114 (0.3144) Acc D Real: 98.909%
Loss D Fake: 0.7096 (0.9996) Acc D Fake: 4.932%
Loss D: 0.921
Loss G: 0.6980 (0.4743) Acc G: 93.776%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.3841 (0.3158) Acc D Real: 98.135%
Loss D Fake: 0.6967 (0.9936) Acc D Fake: 6.467%
Loss D: 1.081
Loss G: 0.7099 (0.4790) Acc G: 92.267%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.2934 (0.3154) Acc D Real: 97.630%
Loss D Fake: 0.6867 (0.9876) Acc D Fake: 7.941%
Loss D: 0.980
Loss G: 0.7203 (0.4838) Acc G: 90.817%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.3510 (0.3161) Acc D Real: 97.013%
Loss D Fake: 0.6780 (0.9816) Acc D Fake: 9.359%
Loss D: 1.029
Loss G: 0.7289 (0.4885) Acc G: 89.397%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4032 (0.3177) Acc D Real: 96.305%
Loss D Fake: 0.6718 (0.9758) Acc D Fake: 10.723%
Loss D: 1.075
Loss G: 0.7344 (0.4931) Acc G: 88.056%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.3866 (0.3190) Acc D Real: 95.669%
Loss D Fake: 0.6731 (0.9702) Acc D Fake: 12.037%
Loss D: 1.060
Loss G: 0.7278 (0.4975) Acc G: 86.796%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.2906 (0.3185) Acc D Real: 95.277%
Loss D Fake: 0.7089 (0.9654) Acc D Fake: 13.212%
Loss D: 0.999
Loss G: 0.0969 (0.4902) Acc G: 87.036%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.1825 (0.3160) Acc D Real: 95.135%
Loss D Fake: 2.9979 (1.0017) Acc D Fake: 12.976%
Loss D: 3.180
Loss G: 0.0908 (0.4831) Acc G: 87.267%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.1053 (0.3123) Acc D Real: 95.174%
Loss D Fake: 2.9340 (1.0356) Acc D Fake: 12.749%
Loss D: 3.039
Loss G: 0.0897 (0.4762) Acc G: 87.491%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.1047 (0.3088) Acc D Real: 95.216%
Loss D Fake: 2.8621 (1.0671) Acc D Fake: 12.529%
Loss D: 2.967
Loss G: 0.0909 (0.4695) Acc G: 87.707%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.0865 (0.3050) Acc D Real: 95.297%
Loss D Fake: 2.7916 (1.0963) Acc D Fake: 12.316%
Loss D: 2.878
Loss G: 0.0934 (0.4631) Acc G: 87.915%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.0889 (0.3014) Acc D Real: 95.375%
Loss D Fake: 2.7197 (1.1234) Acc D Fake: 12.111%
Loss D: 2.809
Loss G: 0.0968 (0.4570) Acc G: 88.116%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.0930 (0.2980) Acc D Real: 95.451%
Loss D Fake: 2.6466 (1.1483) Acc D Fake: 11.913%
Loss D: 2.740
Loss G: 0.1009 (0.4512) Acc G: 88.311%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.0970 (0.2947) Acc D Real: 95.524%
Loss D Fake: 2.5732 (1.1713) Acc D Fake: 11.720%
Loss D: 2.670
Loss G: 0.1056 (0.4456) Acc G: 88.500%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.1028 (0.2917) Acc D Real: 95.595%
Loss D Fake: 2.5004 (1.1924) Acc D Fake: 11.534%
Loss D: 2.603
Loss G: 0.1109 (0.4403) Acc G: 88.682%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.1080 (0.2888) Acc D Real: 95.664%
Loss D Fake: 2.4290 (1.2117) Acc D Fake: 11.354%
Loss D: 2.537
Loss G: 0.1165 (0.4352) Acc G: 88.859%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.1131 (0.2861) Acc D Real: 95.731%
Loss D Fake: 2.3599 (1.2294) Acc D Fake: 11.179%
Loss D: 2.473
Loss G: 0.1226 (0.4304) Acc G: 89.030%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.1203 (0.2836) Acc D Real: 95.795%
Loss D Fake: 2.2935 (1.2455) Acc D Fake: 11.010%
Loss D: 2.414
Loss G: 0.1288 (0.4259) Acc G: 89.197%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.1262 (0.2813) Acc D Real: 95.858%
Loss D Fake: 2.2304 (1.2602) Acc D Fake: 10.846%
Loss D: 2.357
Loss G: 0.1353 (0.4215) Acc G: 89.358%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.1332 (0.2791) Acc D Real: 95.919%
Loss D Fake: 2.1706 (1.2736) Acc D Fake: 10.686%
Loss D: 2.304
Loss G: 0.1419 (0.4174) Acc G: 89.514%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.1398 (0.2771) Acc D Real: 95.978%
Loss D Fake: 2.1144 (1.2858) Acc D Fake: 10.531%
Loss D: 2.254
Loss G: 0.1485 (0.4135) Acc G: 89.666%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.1461 (0.2752) Acc D Real: 96.036%
Loss D Fake: 2.0618 (1.2969) Acc D Fake: 10.381%
Loss D: 2.208
Loss G: 0.1552 (0.4098) Acc G: 89.814%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.1529 (0.2735) Acc D Real: 96.092%
Loss D Fake: 2.0127 (1.3070) Acc D Fake: 10.235%
Loss D: 2.166
Loss G: 0.1618 (0.4063) Acc G: 89.957%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.1599 (0.2719) Acc D Real: 96.146%
Loss D Fake: 1.9670 (1.3161) Acc D Fake: 10.093%
Loss D: 2.127
Loss G: 0.1683 (0.4030) Acc G: 90.097%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.1664 (0.2704) Acc D Real: 96.199%
Loss D Fake: 1.9244 (1.3245) Acc D Fake: 9.954%
Loss D: 2.091
Loss G: 0.1747 (0.3999) Acc G: 90.233%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.1724 (0.2691) Acc D Real: 96.250%
Loss D Fake: 1.8849 (1.3320) Acc D Fake: 9.820%
Loss D: 2.057
Loss G: 0.1809 (0.3969) Acc G: 90.365%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.1787 (0.2679) Acc D Real: 96.300%
Loss D Fake: 1.8483 (1.3389) Acc D Fake: 9.689%
Loss D: 2.027
Loss G: 0.1869 (0.3941) Acc G: 90.493%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.1850 (0.2668) Acc D Real: 96.349%
Loss D Fake: 1.8143 (1.3452) Acc D Fake: 9.561%
Loss D: 1.999
Loss G: 0.1928 (0.3915) Acc G: 90.618%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.1910 (0.2658) Acc D Real: 96.396%
Loss D Fake: 1.7827 (1.3509) Acc D Fake: 9.437%
Loss D: 1.974
Loss G: 0.1985 (0.3890) Acc G: 90.740%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.1968 (0.2650) Acc D Real: 96.442%
Loss D Fake: 1.7534 (1.3560) Acc D Fake: 9.316%
Loss D: 1.950
Loss G: 0.2040 (0.3866) Acc G: 90.859%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.2022 (0.2642) Acc D Real: 96.487%
Loss D Fake: 1.7261 (1.3607) Acc D Fake: 9.198%
Loss D: 1.928
Loss G: 0.2093 (0.3844) Acc G: 90.974%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.2075 (0.2635) Acc D Real: 96.531%
Loss D Fake: 1.7008 (1.3650) Acc D Fake: 9.083%
Loss D: 1.908
Loss G: 0.2144 (0.3822) Acc G: 91.087%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.2126 (0.2628) Acc D Real: 96.574%
Loss D Fake: 1.6771 (1.3688) Acc D Fake: 8.971%
Loss D: 1.890
Loss G: 0.2193 (0.3802) Acc G: 91.197%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.2175 (0.2623) Acc D Real: 96.616%
Loss D Fake: 1.6551 (1.3723) Acc D Fake: 8.862%
Loss D: 1.873
Loss G: 0.2240 (0.3783) Acc G: 91.305%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.2221 (0.2618) Acc D Real: 96.657%
Loss D Fake: 1.6344 (1.3755) Acc D Fake: 8.755%
Loss D: 1.857
Loss G: 0.2286 (0.3765) Acc G: 91.409%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.2270 (0.2614) Acc D Real: 96.696%
Loss D Fake: 1.6152 (1.3783) Acc D Fake: 8.651%
Loss D: 1.842
Loss G: 0.2329 (0.3748) Acc G: 91.512%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.2311 (0.2610) Acc D Real: 96.735%
Loss D Fake: 1.5971 (1.3809) Acc D Fake: 8.549%
Loss D: 1.828
Loss G: 0.2371 (0.3732) Acc G: 91.612%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.2352 (0.2607) Acc D Real: 96.773%
Loss D Fake: 1.5801 (1.3832) Acc D Fake: 8.450%
Loss D: 1.815
Loss G: 0.2411 (0.3717) Acc G: 91.709%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.2393 (0.2605) Acc D Real: 96.810%
Loss D Fake: 1.5641 (1.3853) Acc D Fake: 8.352%
Loss D: 1.803
Loss G: 0.2450 (0.3702) Acc G: 91.804%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.2432 (0.2603) Acc D Real: 96.847%
Loss D Fake: 1.5490 (1.3872) Acc D Fake: 8.258%
Loss D: 1.792
Loss G: 0.2488 (0.3688) Acc G: 91.897%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.2468 (0.2601) Acc D Real: 96.882%
Loss D Fake: 1.5348 (1.3888) Acc D Fake: 8.165%
Loss D: 1.782
Loss G: 0.2524 (0.3675) Acc G: 91.989%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.2503 (0.2600) Acc D Real: 96.917%
Loss D Fake: 1.5214 (1.3903) Acc D Fake: 8.074%
Loss D: 1.772
Loss G: 0.2558 (0.3663) Acc G: 92.078%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.2540 (0.2599) Acc D Real: 96.951%
Loss D Fake: 1.5087 (1.3916) Acc D Fake: 7.985%
Loss D: 1.763
Loss G: 0.2592 (0.3651) Acc G: 92.165%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.2572 (0.2599) Acc D Real: 96.984%
Loss D Fake: 1.4966 (1.3927) Acc D Fake: 7.899%
Loss D: 1.754
Loss G: 0.2624 (0.3640) Acc G: 92.250%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.2604 (0.2599) Acc D Real: 97.016%
Loss D Fake: 1.4852 (1.3937) Acc D Fake: 7.814%
Loss D: 1.746
Loss G: 0.2655 (0.3629) Acc G: 92.333%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.2634 (0.2600) Acc D Real: 97.048%
Loss D Fake: 1.4743 (1.3946) Acc D Fake: 7.730%
Loss D: 1.738
Loss G: 0.2685 (0.3619) Acc G: 92.415%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.2665 (0.2600) Acc D Real: 97.079%
Loss D Fake: 1.4639 (1.3953) Acc D Fake: 7.649%
Loss D: 1.730
Loss G: 0.2714 (0.3610) Acc G: 92.495%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.2695 (0.2601) Acc D Real: 97.109%
Loss D Fake: 1.4540 (1.3959) Acc D Fake: 7.569%
Loss D: 1.724
Loss G: 0.2742 (0.3601) Acc G: 92.573%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.2721 (0.2603) Acc D Real: 97.139%
Loss D Fake: 1.4446 (1.3964) Acc D Fake: 7.491%
Loss D: 1.717
Loss G: 0.2769 (0.3592) Acc G: 92.649%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.2747 (0.2604) Acc D Real: 97.168%
Loss D Fake: 1.4356 (1.3968) Acc D Fake: 7.415%
Loss D: 1.710
Loss G: 0.2796 (0.3584) Acc G: 92.724%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.2773 (0.2606) Acc D Real: 97.197%
Loss D Fake: 1.4269 (1.3971) Acc D Fake: 7.340%
Loss D: 1.704
Loss G: 0.2821 (0.3576) Acc G: 92.798%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.2798 (0.2608) Acc D Real: 97.225%
Loss D Fake: 1.4187 (1.3973) Acc D Fake: 7.267%
Loss D: 1.698
Loss G: 0.2846 (0.3569) Acc G: 92.870%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.2824 (0.2610) Acc D Real: 97.252%
Loss D Fake: 1.4107 (1.3975) Acc D Fake: 7.195%
Loss D: 1.693
Loss G: 0.2870 (0.3562) Acc G: 92.940%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.2848 (0.2612) Acc D Real: 97.279%
Loss D Fake: 1.4031 (1.3975) Acc D Fake: 7.124%
Loss D: 1.688
Loss G: 0.2893 (0.3555) Acc G: 93.010%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.2873 (0.2615) Acc D Real: 97.306%
Loss D Fake: 1.3958 (1.3975) Acc D Fake: 7.055%
Loss D: 1.683
Loss G: 0.2916 (0.3549) Acc G: 93.077%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.2894 (0.2617) Acc D Real: 97.332%
Loss D Fake: 1.3887 (1.3974) Acc D Fake: 6.987%
Loss D: 1.678
Loss G: 0.2938 (0.3543) Acc G: 93.144%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.2916 (0.2620) Acc D Real: 97.357%
Loss D Fake: 1.3819 (1.3973) Acc D Fake: 6.921%
Loss D: 1.674
Loss G: 0.2960 (0.3538) Acc G: 93.209%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.2935 (0.2623) Acc D Real: 97.382%
Loss D Fake: 1.3754 (1.3971) Acc D Fake: 6.855%
Loss D: 1.669
Loss G: 0.2981 (0.3533) Acc G: 93.273%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.2956 (0.2626) Acc D Real: 97.407%
Loss D Fake: 1.3691 (1.3968) Acc D Fake: 6.791%
Loss D: 1.665
Loss G: 0.3001 (0.3528) Acc G: 93.336%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.2975 (0.2629) Acc D Real: 97.431%
Loss D Fake: 1.3630 (1.3965) Acc D Fake: 6.728%
Loss D: 1.661
Loss G: 0.3021 (0.3523) Acc G: 93.398%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.2996 (0.2633) Acc D Real: 97.454%
Loss D Fake: 1.3571 (1.3961) Acc D Fake: 6.667%
Loss D: 1.657
Loss G: 0.3040 (0.3518) Acc G: 93.459%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.3010 (0.2636) Acc D Real: 97.477%
Loss D Fake: 1.3514 (1.3957) Acc D Fake: 6.606%
Loss D: 1.652
Loss G: 0.3059 (0.3514) Acc G: 93.518%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.3034 (0.2640) Acc D Real: 97.500%
Loss D Fake: 1.3459 (1.3953) Acc D Fake: 6.547%
Loss D: 1.649
Loss G: 0.3077 (0.3510) Acc G: 93.576%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.3050 (0.2644) Acc D Real: 97.522%
Loss D Fake: 1.3406 (1.3948) Acc D Fake: 6.488%
Loss D: 1.646
Loss G: 0.3095 (0.3507) Acc G: 93.634%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.3070 (0.2647) Acc D Real: 97.544%
Loss D Fake: 1.3354 (1.3943) Acc D Fake: 6.431%
Loss D: 1.642
Loss G: 0.3113 (0.3503) Acc G: 93.690%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.3087 (0.2651) Acc D Real: 97.566%
Loss D Fake: 1.3304 (1.3937) Acc D Fake: 6.374%
Loss D: 1.639
Loss G: 0.3130 (0.3500) Acc G: 93.745%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.3103 (0.2655) Acc D Real: 97.587%
Loss D Fake: 1.3255 (1.3931) Acc D Fake: 6.319%
Loss D: 1.636
Loss G: 0.3147 (0.3497) Acc G: 93.800%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.3117 (0.2659) Acc D Real: 97.608%
Loss D Fake: 1.3208 (1.3925) Acc D Fake: 6.264%
Loss D: 1.633
Loss G: 0.3163 (0.3494) Acc G: 93.853%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.3138 (0.2663) Acc D Real: 97.628%
Loss D Fake: 1.3162 (1.3918) Acc D Fake: 6.211%
Loss D: 1.630
Loss G: 0.3179 (0.3491) Acc G: 93.906%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.3148 (0.2667) Acc D Real: 97.648%
Loss D Fake: 1.3118 (1.3912) Acc D Fake: 6.158%
Loss D: 1.627
Loss G: 0.3195 (0.3489) Acc G: 93.957%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.3167 (0.2671) Acc D Real: 97.668%
Loss D Fake: 1.3075 (1.3905) Acc D Fake: 6.106%
Loss D: 1.624
Loss G: 0.3210 (0.3486) Acc G: 94.008%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.3178 (0.2676) Acc D Real: 97.688%
Loss D Fake: 1.3033 (1.3897) Acc D Fake: 6.056%
Loss D: 1.621
Loss G: 0.3225 (0.3484) Acc G: 94.058%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.3197 (0.2680) Acc D Real: 97.707%
Loss D Fake: 1.2992 (1.3890) Acc D Fake: 6.006%
Loss D: 1.619
Loss G: 0.3240 (0.3482) Acc G: 94.107%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.3783 (0.3003) Acc D Real: 98.562%
Loss D Fake: 1.1569 (1.3221) Acc D Fake: 3.765%
Loss D: 1.535
Loss G: 0.3810 (0.3522) Acc G: 96.306%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.3780 (0.3007) Acc D Real: 98.570%
Loss D Fake: 1.1560 (1.3212) Acc D Fake: 3.746%
Loss D: 1.534
Loss G: 0.3814 (0.3523) Acc G: 96.325%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.3784 (0.3011) Acc D Real: 98.577%
Loss D Fake: 1.1552 (1.3204) Acc D Fake: 3.726%
Loss D: 1.534
Loss G: 0.3818 (0.3525) Acc G: 96.343%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.3789 (0.3015) Acc D Real: 98.584%
Loss D Fake: 1.1544 (1.3195) Acc D Fake: 3.707%
Loss D: 1.533
Loss G: 0.3821 (0.3526) Acc G: 96.362%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.3794 (0.3019) Acc D Real: 98.591%
Loss D Fake: 1.1536 (1.3187) Acc D Fake: 3.689%
Loss D: 1.533
Loss G: 0.3825 (0.3528) Acc G: 96.381%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.3795 (0.3023) Acc D Real: 98.598%
Loss D Fake: 1.1528 (1.3179) Acc D Fake: 3.670%
Loss D: 1.532
Loss G: 0.3829 (0.3529) Acc G: 96.399%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.3793 (0.3027) Acc D Real: 98.606%
Loss D Fake: 1.1520 (1.3170) Acc D Fake: 3.652%
Loss D: 1.531
Loss G: 0.3832 (0.3531) Acc G: 96.417%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.3804 (0.3031) Acc D Real: 98.612%
Loss D Fake: 1.1512 (1.3162) Acc D Fake: 3.633%
Loss D: 1.532
Loss G: 0.3836 (0.3532) Acc G: 96.435%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.3800 (0.3035) Acc D Real: 98.619%
Loss D Fake: 1.1504 (1.3154) Acc D Fake: 3.615%
Loss D: 1.530
Loss G: 0.3839 (0.3534) Acc G: 96.453%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.3812 (0.3039) Acc D Real: 98.626%
Loss D Fake: 1.1497 (1.3146) Acc D Fake: 3.597%
Loss D: 1.531
Loss G: 0.3843 (0.3536) Acc G: 96.470%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.3820 (0.3043) Acc D Real: 98.633%
Loss D Fake: 1.1489 (1.3137) Acc D Fake: 3.580%
Loss D: 1.531
Loss G: 0.3846 (0.3537) Acc G: 96.488%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.3811 (0.3046) Acc D Real: 98.640%
Loss D Fake: 1.1482 (1.3129) Acc D Fake: 3.562%
Loss D: 1.529
Loss G: 0.3849 (0.3539) Acc G: 96.505%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.3819 (0.3050) Acc D Real: 98.646%
Loss D Fake: 1.1475 (1.3121) Acc D Fake: 3.545%
Loss D: 1.529
Loss G: 0.3852 (0.3540) Acc G: 96.522%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.3842 (0.3054) Acc D Real: 98.653%
Loss D Fake: 1.1468 (1.3113) Acc D Fake: 3.528%
Loss D: 1.531
Loss G: 0.3856 (0.3542) Acc G: 96.539%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3829 (0.3058) Acc D Real: 98.659%
Loss D Fake: 1.1461 (1.3105) Acc D Fake: 3.510%
Loss D: 1.529
Loss G: 0.3859 (0.3543) Acc G: 96.555%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.3835 (0.3061) Acc D Real: 98.666%
Loss D Fake: 1.1455 (1.3097) Acc D Fake: 3.494%
Loss D: 1.529
Loss G: 0.3862 (0.3545) Acc G: 96.572%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.3837 (0.3065) Acc D Real: 98.672%
Loss D Fake: 1.1448 (1.3089) Acc D Fake: 3.477%
Loss D: 1.528
Loss G: 0.3864 (0.3546) Acc G: 96.588%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.3844 (0.3069) Acc D Real: 98.679%
Loss D Fake: 1.1442 (1.3082) Acc D Fake: 3.460%
Loss D: 1.529
Loss G: 0.3867 (0.3548) Acc G: 96.605%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.3848 (0.3073) Acc D Real: 98.685%
Loss D Fake: 1.1435 (1.3074) Acc D Fake: 3.444%
Loss D: 1.528
Loss G: 0.3870 (0.3549) Acc G: 96.621%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3852 (0.3076) Acc D Real: 98.691%
Loss D Fake: 1.1429 (1.3066) Acc D Fake: 3.428%
Loss D: 1.528
Loss G: 0.3873 (0.3551) Acc G: 96.637%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.3847 (0.3080) Acc D Real: 98.697%
Loss D Fake: 1.1423 (1.3058) Acc D Fake: 3.412%
Loss D: 1.527
Loss G: 0.3876 (0.3552) Acc G: 96.652%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.3854 (0.3083) Acc D Real: 98.703%
Loss D Fake: 1.1418 (1.3051) Acc D Fake: 3.396%
Loss D: 1.527
Loss G: 0.3878 (0.3554) Acc G: 96.668%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.3848 (0.3087) Acc D Real: 98.709%
Loss D Fake: 1.1412 (1.3043) Acc D Fake: 3.380%
Loss D: 1.526
Loss G: 0.3881 (0.3555) Acc G: 96.684%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.3854 (0.3091) Acc D Real: 98.715%
Loss D Fake: 1.1406 (1.3035) Acc D Fake: 3.364%
Loss D: 1.526
Loss G: 0.3884 (0.3557) Acc G: 96.699%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.3863 (0.3094) Acc D Real: 98.721%
Loss D Fake: 1.1400 (1.3028) Acc D Fake: 3.349%
Loss D: 1.526
Loss G: 0.3886 (0.3558) Acc G: 96.714%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.3859 (0.3098) Acc D Real: 98.727%
Loss D Fake: 1.1395 (1.3020) Acc D Fake: 3.333%
Loss D: 1.525
Loss G: 0.3889 (0.3560) Acc G: 96.729%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.3882 (0.3101) Acc D Real: 98.733%
Loss D Fake: 1.1389 (1.3013) Acc D Fake: 3.318%
Loss D: 1.527
Loss G: 0.3891 (0.3561) Acc G: 96.744%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.3862 (0.3105) Acc D Real: 98.739%
Loss D Fake: 1.1384 (1.3006) Acc D Fake: 3.303%
Loss D: 1.525
Loss G: 0.3894 (0.3563) Acc G: 96.759%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.3874 (0.3108) Acc D Real: 98.744%
Loss D Fake: 1.1379 (1.2998) Acc D Fake: 3.288%
Loss D: 1.525
Loss G: 0.3896 (0.3564) Acc G: 96.774%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.3891 (0.3112) Acc D Real: 98.750%
Loss D Fake: 1.1374 (1.2991) Acc D Fake: 3.273%
Loss D: 1.526
Loss G: 0.3898 (0.3566) Acc G: 96.788%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.3884 (0.3115) Acc D Real: 98.756%
Loss D Fake: 1.1369 (1.2984) Acc D Fake: 3.259%
Loss D: 1.525
Loss G: 0.3901 (0.3567) Acc G: 96.803%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.3879 (0.3119) Acc D Real: 98.761%
Loss D Fake: 1.1364 (1.2976) Acc D Fake: 3.244%
Loss D: 1.524
Loss G: 0.3903 (0.3569) Acc G: 96.817%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.3880 (0.3122) Acc D Real: 98.767%
Loss D Fake: 1.1359 (1.2969) Acc D Fake: 3.230%
Loss D: 1.524
Loss G: 0.3905 (0.3570) Acc G: 96.831%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.3905 (0.3125) Acc D Real: 98.768%
Loss D Fake: 1.1355 (1.2962) Acc D Fake: 3.226%
Loss D: 1.526
Loss G: 0.3907 (0.3572) Acc G: 96.835%
LR: 2.000e-04
Epoch: 11/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.3896 (0.3887) Acc D Real: 100.000%
Loss D Fake: 1.1346 (1.1348) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3911 (0.3910) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.3884 (0.3886) Acc D Real: 100.000%
Loss D Fake: 1.1341 (1.1346) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3913 (0.3911) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.3898 (0.3889) Acc D Real: 100.000%
Loss D Fake: 1.1337 (1.1343) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3915 (0.3912) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.3904 (0.3892) Acc D Real: 100.000%
Loss D Fake: 1.1332 (1.1341) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3917 (0.3913) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.3903 (0.3894) Acc D Real: 100.000%
Loss D Fake: 1.1328 (1.1339) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3919 (0.3914) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.3898 (0.3894) Acc D Real: 100.000%
Loss D Fake: 1.1324 (1.1337) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3921 (0.3915) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.3920 (0.3898) Acc D Real: 100.000%
Loss D Fake: 1.1320 (1.1335) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3923 (0.3916) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.3933 (0.3902) Acc D Real: 100.000%
Loss D Fake: 1.1316 (1.1333) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3925 (0.3917) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.3925 (0.3904) Acc D Real: 100.000%
Loss D Fake: 1.1313 (1.1331) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3926 (0.3918) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.3903 (0.3904) Acc D Real: 100.000%
Loss D Fake: 1.1309 (1.1329) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3928 (0.3919) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.3929 (0.3906) Acc D Real: 100.000%
Loss D Fake: 1.1306 (1.1327) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3930 (0.3920) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.3917 (0.3907) Acc D Real: 100.000%
Loss D Fake: 1.1302 (1.1325) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3931 (0.3921) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.3916 (0.3907) Acc D Real: 100.000%
Loss D Fake: 1.1299 (1.1323) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3933 (0.3922) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.3918 (0.3908) Acc D Real: 100.000%
Loss D Fake: 1.1295 (1.1321) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3935 (0.3923) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.3929 (0.3909) Acc D Real: 100.000%
Loss D Fake: 1.1292 (1.1319) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3936 (0.3923) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.3926 (0.3910) Acc D Real: 100.000%
Loss D Fake: 1.1288 (1.1318) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3938 (0.3924) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.3927 (0.3911) Acc D Real: 100.000%
Loss D Fake: 1.1285 (1.1316) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3939 (0.3925) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.3929 (0.3912) Acc D Real: 100.000%
Loss D Fake: 1.1282 (1.1314) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3941 (0.3926) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.3934 (0.3913) Acc D Real: 100.000%
Loss D Fake: 1.1279 (1.1312) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3942 (0.3927) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.3941 (0.3915) Acc D Real: 100.000%
Loss D Fake: 1.1276 (1.1310) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3944 (0.3928) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.3930 (0.3915) Acc D Real: 100.000%
Loss D Fake: 1.1273 (1.1309) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3945 (0.3928) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.3953 (0.3917) Acc D Real: 100.000%
Loss D Fake: 1.1270 (1.1307) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3947 (0.3929) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.3939 (0.3918) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.1305) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3948 (0.3930) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.3933 (0.3919) Acc D Real: 100.000%
Loss D Fake: 1.1264 (1.1304) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3949 (0.3931) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.3947 (0.3920) Acc D Real: 100.000%
Loss D Fake: 1.1261 (1.1302) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3951 (0.3931) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.3965 (0.3921) Acc D Real: 100.000%
Loss D Fake: 1.1258 (1.1300) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3952 (0.3932) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.3943 (0.3922) Acc D Real: 100.000%
Loss D Fake: 1.1256 (1.1299) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3953 (0.3933) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.3959 (0.3923) Acc D Real: 100.000%
Loss D Fake: 1.1253 (1.1297) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3954 (0.3934) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.3959 (0.3925) Acc D Real: 100.000%
Loss D Fake: 1.1251 (1.1296) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3955 (0.3934) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.3946 (0.3925) Acc D Real: 100.000%
Loss D Fake: 1.1248 (1.1294) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3956 (0.3935) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.3947 (0.3926) Acc D Real: 100.000%
Loss D Fake: 1.1246 (1.1293) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3957 (0.3936) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.3954 (0.3927) Acc D Real: 100.000%
Loss D Fake: 1.1244 (1.1291) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3959 (0.3937) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.3943 (0.3927) Acc D Real: 100.000%
Loss D Fake: 1.1241 (1.1290) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3960 (0.3937) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.3969 (0.3928) Acc D Real: 100.000%
Loss D Fake: 1.1239 (1.1288) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3961 (0.3938) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.3959 (0.3929) Acc D Real: 100.000%
Loss D Fake: 1.1236 (1.1287) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3962 (0.3939) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.3959 (0.3930) Acc D Real: 100.000%
Loss D Fake: 1.1234 (1.1285) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3963 (0.3939) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.3967 (0.3931) Acc D Real: 100.000%
Loss D Fake: 1.1232 (1.1284) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3964 (0.3940) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.3980 (0.3932) Acc D Real: 100.000%
Loss D Fake: 1.1230 (1.1283) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3965 (0.3941) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.3974 (0.3933) Acc D Real: 100.000%
Loss D Fake: 1.1228 (1.1281) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3966 (0.3941) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.3977 (0.3934) Acc D Real: 100.000%
Loss D Fake: 1.1226 (1.1280) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3967 (0.3942) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.3973 (0.3935) Acc D Real: 100.000%
Loss D Fake: 1.1224 (1.1278) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3968 (0.3942) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.3982 (0.3936) Acc D Real: 100.000%
Loss D Fake: 1.1222 (1.1277) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3969 (0.3943) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.3965 (0.3937) Acc D Real: 100.000%
Loss D Fake: 1.1220 (1.1276) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3969 (0.3944) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.3995 (0.3938) Acc D Real: 100.000%
Loss D Fake: 1.1218 (1.1275) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3970 (0.3944) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.3972 (0.3939) Acc D Real: 100.000%
Loss D Fake: 1.1217 (1.1273) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3971 (0.3945) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.3979 (0.3940) Acc D Real: 100.000%
Loss D Fake: 1.1215 (1.1272) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3972 (0.3945) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.3989 (0.3941) Acc D Real: 100.000%
Loss D Fake: 1.1214 (1.1271) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3973 (0.3946) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.3983 (0.3942) Acc D Real: 100.000%
Loss D Fake: 1.1212 (1.1270) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3973 (0.3946) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.3995 (0.3943) Acc D Real: 100.000%
Loss D Fake: 1.1211 (1.1269) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3974 (0.3947) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.3986 (0.3944) Acc D Real: 100.000%
Loss D Fake: 1.1209 (1.1267) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3975 (0.3948) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.3982 (0.3944) Acc D Real: 100.000%
Loss D Fake: 1.1208 (1.1266) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3975 (0.3948) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4001 (0.3946) Acc D Real: 100.000%
Loss D Fake: 1.1206 (1.1265) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3976 (0.3949) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.3986 (0.3946) Acc D Real: 100.000%
Loss D Fake: 1.1205 (1.1264) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3976 (0.3949) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.3984 (0.3947) Acc D Real: 100.000%
Loss D Fake: 1.1204 (1.1263) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3977 (0.3950) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.3998 (0.3948) Acc D Real: 100.000%
Loss D Fake: 1.1203 (1.1262) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3978 (0.3950) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.3991 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1201 (1.1261) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3978 (0.3951) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.3993 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1200 (1.1260) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3979 (0.3951) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4004 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1199 (1.1259) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3979 (0.3952) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4002 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1198 (1.1258) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3980 (0.3952) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4007 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1197 (1.1257) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3980 (0.3953) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.3986 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1196 (1.1256) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3981 (0.3953) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.3994 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1195 (1.1255) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3981 (0.3953) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4015 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1194 (1.1254) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3982 (0.3954) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4004 (0.3955) Acc D Real: 100.000%
Loss D Fake: 1.1193 (1.1253) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3982 (0.3954) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.3995 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1192 (1.1252) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3983 (0.3955) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4013 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1191 (1.1251) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3983 (0.3955) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4003 (0.3957) Acc D Real: 100.000%
Loss D Fake: 1.1190 (1.1250) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3983 (0.3956) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.3991 (0.3958) Acc D Real: 100.000%
Loss D Fake: 1.1189 (1.1249) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3984 (0.3956) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4015 (0.3958) Acc D Real: 100.000%
Loss D Fake: 1.1188 (1.1248) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3984 (0.3956) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4012 (0.3959) Acc D Real: 100.000%
Loss D Fake: 1.1187 (1.1247) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3985 (0.3957) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4014 (0.3960) Acc D Real: 100.000%
Loss D Fake: 1.1186 (1.1247) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3985 (0.3957) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4021 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.1186 (1.1246) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3985 (0.3958) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4020 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.1185 (1.1245) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3986 (0.3958) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4010 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.1185 (1.1244) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3986 (0.3958) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4009 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1184 (1.1243) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3986 (0.3959) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4016 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1183 (1.1243) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3986 (0.3959) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4015 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1183 (1.1242) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3987 (0.3959) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4019 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1182 (1.1241) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3987 (0.3960) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4017 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1182 (1.1240) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3987 (0.3960) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4010 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1181 (1.1240) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3987 (0.3960) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4013 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1181 (1.1239) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3988 (0.3961) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4016 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1180 (1.1238) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3961) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4018 (0.3968) Acc D Real: 100.000%
Loss D Fake: 1.1180 (1.1237) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3961) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4022 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1179 (1.1237) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3962) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4029 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1179 (1.1236) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3962) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4023 (0.3970) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1235) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3989 (0.3962) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4013 (0.3970) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1235) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3963) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4032 (0.3971) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1234) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3963) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4029 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1233) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3963) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4016 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1233) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3964) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4026 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1232) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3989 (0.3964) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4038 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1232) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3964) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4014 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1231) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3964) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4020 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1230) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3990 (0.3965) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4015 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1230) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3965) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4031 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1229) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3965) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4034 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1229) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3965) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4019 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1228) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3966) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4019 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1228) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3966) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4029 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1227) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3990 (0.3966) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4019 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1227) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3966) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4033 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1226) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4029 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1226) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4026 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1225) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4032 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1225) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4028 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1224) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3967) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4036 (0.3981) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1224) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3968) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4033 (0.3981) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1223) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3968) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4020 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1223) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3991 (0.3968) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4019 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1222) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3991 (0.3968) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4038 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1222) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3969) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4033 (0.3983) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1221) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3969) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4029 (0.3983) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1221) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3969) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4035 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1221) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3969) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4036 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1220) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3969) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4026 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1220) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4020 (0.3985) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1219) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4031 (0.3985) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1219) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4037 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1218) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4030 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1218) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4038 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1218) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3970) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4041 (0.3987) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1217) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4033 (0.3987) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1217) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4031 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1217) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4041 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1216) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4022 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1216) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4030 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1216) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3971) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4044 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1215) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4043 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1215) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3992 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4029 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1214) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3992 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4045 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1214) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4036 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1214) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4041 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1213) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4031 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1213) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3972) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4031 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1213) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4041 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1213) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4025 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1212) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4039 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1212) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4038 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1212) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4031 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1211) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4037 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1211) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3973) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4037 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1211) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4034 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1211) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4034 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1210) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4041 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1210) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4044 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1210) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4042 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1210) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4039 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1209) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4037 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1209) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3991 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4034 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1209) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3974) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4042 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1209) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4046 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1208) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4031 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1208) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4040 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1208) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4047 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1208) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4038 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1207) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4039 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1207) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3990 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4037 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1207) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4034 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1207) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4028 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1207) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3989 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4035 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1206) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3975) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4040 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1206) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4036 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1206) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4037 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1206) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4039 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1206) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4041 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1205) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4037 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1205) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3989 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4031 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1205) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4037 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1205) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4038 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1205) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4036 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1205) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4040 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1204) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4030 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4030 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3976) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4033 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4028 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4028 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4030 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1204) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4027 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1203) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4029 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1203) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4026 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1203) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4025 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1178 (1.1203) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4025 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1203) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4034 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1203) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4035 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1203) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4025 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4022 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4028 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4025 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4025 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4031 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4031 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3977) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4024 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1177 (1.1202) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4022 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4027 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4027 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4030 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4030 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4023 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4023 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4027 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1201) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4023 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4028 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4024 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4022 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4016 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4025 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4024 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4024 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1200) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4018 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4022 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3988 (0.3978) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4019 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3988 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4021 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4018 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4014 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4012 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4012 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4016 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1174 (1.1199) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4015 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4014 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3989 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4014 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1173 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4017 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4015 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4013 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.1198) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3990 (0.3979) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4014 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1198) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.3979) Acc G: 100.000%
LR: 2.000e-04
Epoch: 12/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4012 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1171) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3990 (0.3990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4011 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.1171) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4008 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1170 (1.1171) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4008 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1170 (1.1171) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4007 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1169 (1.1170) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4008 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1169 (1.1170) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4008 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1169 (1.1170) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3991 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4007 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1168 (1.1170) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4007 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1168 (1.1170) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4005 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1167 (1.1169) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4005 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1167 (1.1169) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4004 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1167 (1.1169) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4003 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1166 (1.1169) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4001 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1166 (1.1169) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3993 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4001 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1165 (1.1168) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3993 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4000 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1165 (1.1168) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3993 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.3998 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1165 (1.1168) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3993 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.3999 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1168) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3994 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.3997 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1168) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3994 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.3996 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1167) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3994 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.3996 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1167) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3994 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.3995 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1167) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3995 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.3994 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1167) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3995 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.3994 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1166) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3995 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.3992 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1166) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3995 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.3991 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1159 (1.1166) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3996 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.3990 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1159 (1.1166) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3996 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.3990 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.1165) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3996 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.3989 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1157 (1.1165) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3997 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.3988 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.1165) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3997 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.3989 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.1165) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3998 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.3986 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1155 (1.1164) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3998 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.3985 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1164) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3998 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.3982 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1164) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3999 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.3985 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1163) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.3999 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.3983 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1163) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.3999 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.3982 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1163) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4000 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.3982 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1162) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4000 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.3982 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1149 (1.1162) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4000 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.3984 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.1162) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4001 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.3979 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.1161) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4001 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.3980 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1147 (1.1161) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4002 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.3978 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.1161) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4002 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.3976 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.1160) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4003 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.3978 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1144 (1.1160) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4003 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.3973 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1143 (1.1160) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4003 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.3977 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1142 (1.1159) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4004 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.3974 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.1159) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4004 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.3973 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.1159) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4005 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.3974 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1140 (1.1158) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4005 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.3969 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1139 (1.1158) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4005 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.3968 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1138 (1.1157) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4006 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.3969 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1137 (1.1157) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4006 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.3970 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1136 (1.1157) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4007 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.3970 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1156) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4007 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.3965 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1156) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4007 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.3968 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1134 (1.1156) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4008 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.3960 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1133 (1.1155) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4008 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.3963 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1132 (1.1155) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4009 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.3960 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.1154) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4009 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.3957 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.1154) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4009 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.3960 (0.3987) Acc D Real: 100.000%
Loss D Fake: 1.1130 (1.1154) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4010 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.3958 (0.3987) Acc D Real: 100.000%
Loss D Fake: 1.1129 (1.1153) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4010 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.3964 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1128 (1.1153) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4010 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.3956 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1128 (1.1152) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4011 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.3958 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1127 (1.1152) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4011 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.3949 (0.3985) Acc D Real: 100.000%
Loss D Fake: 1.1126 (1.1152) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4011 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.3952 (0.3985) Acc D Real: 100.000%
Loss D Fake: 1.1126 (1.1151) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4012 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.3950 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1125 (1.1151) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4012 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.3951 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1151) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4012 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.3952 (0.3983) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1150) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4013 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.3950 (0.3983) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1150) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4013 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.3956 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1149) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4013 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.3948 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1149) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4013 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.3958 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1149) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4014 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.3943 (0.3981) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1148) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4014 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.3949 (0.3981) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1148) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4014 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.3946 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1148) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4014 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.3948 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1147) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4015 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.3940 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1147) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4015 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.3941 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1147) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4015 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.3943 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1146) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4015 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.3939 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1146) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.3942 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1146) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.3933 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1145) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4016 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.3941 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1145) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.3937 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1145) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4016 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.3936 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1144) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.3931 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1144) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.3937 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1144) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.3932 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1143) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.3934 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1143) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.3938 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1143) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.3941 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1142) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.3939 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1142) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.3934 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1142) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.3944 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1141) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4018 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.3934 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1141) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.3924 (0.3971) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1141) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.3919 (0.3971) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1141) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4018 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.3923 (0.3970) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1140) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4018 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.3929 (0.3970) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1140) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.3925 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1140) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.3932 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1140) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.3932 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1139) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.3934 (0.3968) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1139) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.3924 (0.3968) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1139) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.3930 (0.3968) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1138) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.3930 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1138) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.3928 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1138) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.3937 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1138) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.3928 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1137) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.3917 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1137) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.3931 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1137) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.3918 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1137) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.3936 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1137) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.3925 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1136) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.3911 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1136) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.3913 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1136) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.3903 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1136) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.3929 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1135) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.3931 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1135) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.3924 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1135) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.3920 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1135) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.3923 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1135) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.3910 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.3907 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.3946 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.3919 (0.3960) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.3927 (0.3960) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.3935 (0.3960) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1134) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.3937 (0.3960) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.3914 (0.3959) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.3933 (0.3959) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.3904 (0.3959) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.3920 (0.3959) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.3908 (0.3958) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1133) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.3908 (0.3958) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1132) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.3917 (0.3958) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1132) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.3921 (0.3957) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1132) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.3916 (0.3957) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1132) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.3915 (0.3957) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1132) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.3916 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1132) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.3926 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.3934 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.3925 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.3913 (0.3956) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.3939 (0.3955) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.3918 (0.3955) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.3923 (0.3955) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1131) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.3909 (0.3955) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1131) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4019 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.3920 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.3922 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4019 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.3899 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.3944 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.3931 (0.3954) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.3902 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1130) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.3926 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1130) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.3935 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1130) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.3934 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1130) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.3912 (0.3953) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1129) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.3918 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1129) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.3926 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1129) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3937 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.3915 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.3943 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.3924 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.3941 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.3925 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.3931 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4018 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.3904 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1129) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4017 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.3923 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.3940 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1128) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.3920 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1128) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.3923 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.3924 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.3957 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.3927 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.3943 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.3927 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.3926 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.3938 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.3940 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1128) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.3922 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1128) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.3946 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.3924 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.3940 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.3960 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.3952 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.3947 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.3941 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.3970 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.3953 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.3930 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.3925 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4017 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.3931 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.3954 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1127) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.3932 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.3939 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.3959 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.3940 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.3961 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.3944 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1127) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.3977 (0.3949) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.3964 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3986 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.3983 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.3980 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.3971 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.3983 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3964 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.3954 (0.3950) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.3996 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.3975 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.3967 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.3977 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.3968 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.3966 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.3963 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.3980 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.3962 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.3946 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1126) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.3969 (0.3951) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4013 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4016 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.3993 (0.3952) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1126) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4015 (0.4012) Acc G: 100.000%
LR: 2.000e-04
Epoch: 13/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.3983 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1118) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.3961 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4016 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.3992 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4001 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.3991 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4005 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1119) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.3999 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.3982 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4014 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.3987 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4015 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4003 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.3997 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1119) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.3988 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1119) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.3989 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1120) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4010 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1120) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4017 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1120) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4016 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1120) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4017 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1120) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.3996 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1120) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4014 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4009 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1120) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4013 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4024 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1120) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4037 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1120) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4003 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1121) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4020 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1121) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4023 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1121) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4027 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4043 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4028 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4037 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4022 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4041 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4049 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4039 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1121) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4040 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1122) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4057 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1122) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4059 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1122) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4061 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1122) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4034 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1122) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4044 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4044 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4043 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4054 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4070 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4071 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1122) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4069 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1122) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4013 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4074 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1122) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4014 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4078 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1122) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4014 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4067 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1122) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4014 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4086 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1122) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4014 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4103 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1122) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4015 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4085 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1122) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4015 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4076 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1122) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4016 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4058 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1122) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4016 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4082 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1122) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4016 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4081 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1121) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4017 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4084 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1121) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4017 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4102 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1121) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4017 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4113 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1121) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4018 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4123 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1121) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4019 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4109 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1121) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4019 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4106 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.1121) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4020 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4113 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1107 (1.1120) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4021 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4109 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.1120) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4022 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4116 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1103 (1.1120) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4022 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4112 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1102 (1.1120) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4023 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4103 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1100 (1.1119) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4024 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4113 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.1119) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4025 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4126 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1096 (1.1119) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4026 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4112 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.1094 (1.1118) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4027 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4124 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.1118) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4028 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4132 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.1089 (1.1118) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4029 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4113 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.1087 (1.1117) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4030 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4125 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.1085 (1.1117) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4031 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4122 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.1082 (1.1116) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4032 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4132 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.1116) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4034 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4162 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.1077 (1.1115) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4035 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4149 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.1074 (1.1115) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4036 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4128 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.1071 (1.1114) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4038 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4139 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.1068 (1.1114) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4039 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4176 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.1065 (1.1113) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4041 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4150 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.1112) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4042 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4152 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.1112) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4044 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4168 (0.4063) Acc D Real: 100.000%
Loss D Fake: 1.1054 (1.1111) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4046 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4156 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.1110) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4048 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4165 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.1047 (1.1110) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4050 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4142 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.1043 (1.1109) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4052 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4171 (0.4067) Acc D Real: 100.000%
Loss D Fake: 1.1039 (1.1108) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4054 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4165 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.1107) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4055 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4179 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1030 (1.1106) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4058 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4166 (0.4070) Acc D Real: 100.000%
Loss D Fake: 1.1026 (1.1106) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4060 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4174 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.1105) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4062 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4166 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.1017 (1.1104) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4064 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4173 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.1013 (1.1103) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4066 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4183 (0.4075) Acc D Real: 100.000%
Loss D Fake: 1.1008 (1.1102) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4068 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4171 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1004 (1.1101) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4070 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4183 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.0999 (1.1100) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4073 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4210 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.0995 (1.1099) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4075 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4196 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.1098) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4077 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4208 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.1097) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4080 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4187 (0.4081) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.1095) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4083 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4209 (0.4083) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1094) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4085 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4194 (0.4084) Acc D Real: 100.000%
Loss D Fake: 1.0968 (1.1093) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4088 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4201 (0.4085) Acc D Real: 100.000%
Loss D Fake: 1.0963 (1.1092) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4090 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4198 (0.4086) Acc D Real: 100.000%
Loss D Fake: 1.0958 (1.1090) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4093 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4209 (0.4087) Acc D Real: 100.000%
Loss D Fake: 1.0952 (1.1089) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4096 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4201 (0.4088) Acc D Real: 100.000%
Loss D Fake: 1.0947 (1.1088) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4098 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4218 (0.4089) Acc D Real: 100.000%
Loss D Fake: 1.0941 (1.1087) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4101 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4201 (0.4090) Acc D Real: 100.000%
Loss D Fake: 1.0936 (1.1085) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4104 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4213 (0.4091) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.1084) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4106 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4217 (0.4093) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.1082) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4109 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4214 (0.4094) Acc D Real: 100.000%
Loss D Fake: 1.0920 (1.1081) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4112 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4218 (0.4095) Acc D Real: 100.000%
Loss D Fake: 1.0914 (1.1079) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4114 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4209 (0.4096) Acc D Real: 100.000%
Loss D Fake: 1.0909 (1.1078) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4117 (0.4035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4229 (0.4097) Acc D Real: 100.000%
Loss D Fake: 1.0903 (1.1076) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4120 (0.4036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4218 (0.4098) Acc D Real: 100.000%
Loss D Fake: 1.0898 (1.1075) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4122 (0.4036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4234 (0.4099) Acc D Real: 100.000%
Loss D Fake: 1.0892 (1.1073) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4125 (0.4037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4232 (0.4100) Acc D Real: 100.000%
Loss D Fake: 1.0887 (1.1072) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4128 (0.4038) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4228 (0.4101) Acc D Real: 100.000%
Loss D Fake: 1.0881 (1.1070) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4131 (0.4039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4238 (0.4102) Acc D Real: 100.000%
Loss D Fake: 1.0875 (1.1069) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4134 (0.4039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4237 (0.4103) Acc D Real: 100.000%
Loss D Fake: 1.0870 (1.1067) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4136 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4239 (0.4105) Acc D Real: 100.000%
Loss D Fake: 1.0864 (1.1065) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4139 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4223 (0.4106) Acc D Real: 100.000%
Loss D Fake: 1.0858 (1.1064) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4142 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4238 (0.4107) Acc D Real: 100.000%
Loss D Fake: 1.0853 (1.1062) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4145 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4244 (0.4108) Acc D Real: 100.000%
Loss D Fake: 1.0847 (1.1060) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4148 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4253 (0.4109) Acc D Real: 100.000%
Loss D Fake: 1.0841 (1.1059) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4150 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4253 (0.4110) Acc D Real: 100.000%
Loss D Fake: 1.0836 (1.1057) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4153 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4249 (0.4111) Acc D Real: 100.000%
Loss D Fake: 1.0830 (1.1055) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4156 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4237 (0.4112) Acc D Real: 100.000%
Loss D Fake: 1.0824 (1.1053) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4159 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4246 (0.4113) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.1051) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4162 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4251 (0.4114) Acc D Real: 100.000%
Loss D Fake: 1.0812 (1.1050) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4165 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4255 (0.4115) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.1048) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4168 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4255 (0.4116) Acc D Real: 100.000%
Loss D Fake: 1.0801 (1.1046) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4171 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4267 (0.4117) Acc D Real: 100.000%
Loss D Fake: 1.0796 (1.1044) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4174 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4252 (0.4118) Acc D Real: 100.000%
Loss D Fake: 1.0790 (1.1042) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4176 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4250 (0.4119) Acc D Real: 100.000%
Loss D Fake: 1.0784 (1.1040) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4179 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4257 (0.4120) Acc D Real: 100.000%
Loss D Fake: 1.0779 (1.1038) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4182 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4268 (0.4121) Acc D Real: 100.000%
Loss D Fake: 1.0773 (1.1037) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4185 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4269 (0.4122) Acc D Real: 100.000%
Loss D Fake: 1.0768 (1.1035) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4188 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4259 (0.4123) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.1033) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4190 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4260 (0.4124) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.1031) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4193 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4269 (0.4125) Acc D Real: 100.000%
Loss D Fake: 1.0751 (1.1029) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4196 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4265 (0.4126) Acc D Real: 100.000%
Loss D Fake: 1.0746 (1.1027) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4199 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4262 (0.4127) Acc D Real: 100.000%
Loss D Fake: 1.0740 (1.1025) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4201 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4271 (0.4128) Acc D Real: 100.000%
Loss D Fake: 1.0735 (1.1023) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4204 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4262 (0.4129) Acc D Real: 100.000%
Loss D Fake: 1.0730 (1.1021) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4207 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4268 (0.4130) Acc D Real: 100.000%
Loss D Fake: 1.0725 (1.1019) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4209 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4271 (0.4131) Acc D Real: 100.000%
Loss D Fake: 1.0720 (1.1017) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4212 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4274 (0.4132) Acc D Real: 100.000%
Loss D Fake: 1.0715 (1.1015) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4214 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4274 (0.4133) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.1013) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4217 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4271 (0.4134) Acc D Real: 100.000%
Loss D Fake: 1.0705 (1.1011) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4219 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4279 (0.4135) Acc D Real: 100.000%
Loss D Fake: 1.0700 (1.1009) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4222 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4271 (0.4136) Acc D Real: 100.000%
Loss D Fake: 1.0695 (1.1007) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4224 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4276 (0.4137) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.1005) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4227 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4277 (0.4137) Acc D Real: 100.000%
Loss D Fake: 1.0685 (1.1003) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4229 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4280 (0.4138) Acc D Real: 100.000%
Loss D Fake: 1.0681 (1.1001) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4232 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4280 (0.4139) Acc D Real: 100.000%
Loss D Fake: 1.0676 (1.0999) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4234 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4282 (0.4140) Acc D Real: 100.000%
Loss D Fake: 1.0671 (1.0996) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4237 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4286 (0.4141) Acc D Real: 100.000%
Loss D Fake: 1.0666 (1.0994) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4239 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4283 (0.4142) Acc D Real: 100.000%
Loss D Fake: 1.0661 (1.0992) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4242 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4283 (0.4143) Acc D Real: 100.000%
Loss D Fake: 1.0656 (1.0990) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4244 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4286 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.0652 (1.0988) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4247 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4284 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.0647 (1.0986) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4249 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4284 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.0642 (1.0984) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4252 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4286 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.0638 (1.0982) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4254 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4288 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.0633 (1.0980) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4256 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4286 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.0629 (1.0978) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4259 (0.4084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4292 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0976) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4261 (0.4085) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4293 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0620 (1.0974) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4263 (0.4086) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4294 (0.4150) Acc D Real: 100.000%
Loss D Fake: 1.0615 (1.0971) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4266 (0.4087) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4293 (0.4151) Acc D Real: 100.000%
Loss D Fake: 1.0610 (1.0969) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4268 (0.4088) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4290 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.0605 (1.0967) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4271 (0.4089) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4291 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.0601 (1.0965) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4273 (0.4091) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4295 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0597 (1.0963) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4275 (0.4092) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4295 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.0592 (1.0961) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4278 (0.4093) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4297 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.0588 (1.0959) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4280 (0.4094) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4295 (0.4156) Acc D Real: 100.000%
Loss D Fake: 1.0583 (1.0957) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4283 (0.4095) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4295 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.0578 (1.0955) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4285 (0.4096) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4297 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0574 (1.0953) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4287 (0.4097) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4299 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.0569 (1.0950) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4290 (0.4098) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4297 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.0565 (1.0948) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4292 (0.4099) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4298 (0.4160) Acc D Real: 100.000%
Loss D Fake: 1.0560 (1.0946) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4294 (0.4100) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4299 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0556 (1.0944) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4297 (0.4101) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4299 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.0551 (1.0942) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4299 (0.4102) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4301 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.0547 (1.0940) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4302 (0.4103) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4301 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.0542 (1.0938) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4304 (0.4104) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4300 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0538 (1.0936) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4306 (0.4105) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4301 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.0534 (1.0933) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4309 (0.4107) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4301 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.0529 (1.0931) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4311 (0.4108) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4303 (0.4166) Acc D Real: 100.000%
Loss D Fake: 1.0525 (1.0929) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4313 (0.4109) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4304 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0521 (1.0927) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4315 (0.4110) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4304 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0517 (1.0925) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4317 (0.4111) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4303 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0513 (1.0923) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4319 (0.4112) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4303 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0509 (1.0921) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4321 (0.4113) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4302 (0.4169) Acc D Real: 100.000%
Loss D Fake: 1.0505 (1.0919) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4324 (0.4114) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4303 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0501 (1.0916) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4326 (0.4115) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4303 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0497 (1.0914) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4328 (0.4116) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4306 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0492 (1.0912) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4330 (0.4117) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4304 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0488 (1.0910) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4333 (0.4118) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4307 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0484 (1.0908) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4335 (0.4119) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4305 (0.4173) Acc D Real: 100.000%
Loss D Fake: 1.0480 (1.0906) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4337 (0.4121) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4308 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0476 (1.0904) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4339 (0.4122) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4306 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0472 (1.0902) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4341 (0.4123) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4310 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0468 (1.0899) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4343 (0.4124) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4304 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0465 (1.0897) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4345 (0.4125) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4309 (0.4177) Acc D Real: 100.000%
Loss D Fake: 1.0461 (1.0895) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4347 (0.4126) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4304 (0.4177) Acc D Real: 100.000%
Loss D Fake: 1.0457 (1.0893) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4349 (0.4127) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4312 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0453 (1.0891) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4351 (0.4128) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4306 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0450 (1.0889) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4353 (0.4129) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4306 (0.4179) Acc D Real: 100.000%
Loss D Fake: 1.0446 (1.0887) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4355 (0.4130) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4310 (0.4180) Acc D Real: 100.000%
Loss D Fake: 1.0443 (1.0885) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4357 (0.4131) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4311 (0.4180) Acc D Real: 100.000%
Loss D Fake: 1.0439 (1.0883) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4359 (0.4132) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4307 (0.4181) Acc D Real: 100.000%
Loss D Fake: 1.0436 (1.0881) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4361 (0.4133) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4309 (0.4181) Acc D Real: 100.000%
Loss D Fake: 1.0432 (1.0878) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4363 (0.4134) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4302 (0.4182) Acc D Real: 100.000%
Loss D Fake: 1.0429 (1.0876) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4365 (0.4136) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4313 (0.4183) Acc D Real: 100.000%
Loss D Fake: 1.0425 (1.0874) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4366 (0.4137) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4312 (0.4183) Acc D Real: 100.000%
Loss D Fake: 1.0422 (1.0872) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4368 (0.4138) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4316 (0.4184) Acc D Real: 100.000%
Loss D Fake: 1.0419 (1.0870) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4370 (0.4139) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4312 (0.4184) Acc D Real: 100.000%
Loss D Fake: 1.0416 (1.0868) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4372 (0.4140) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4312 (0.4185) Acc D Real: 100.000%
Loss D Fake: 1.0413 (1.0866) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4373 (0.4141) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4309 (0.4186) Acc D Real: 100.000%
Loss D Fake: 1.0410 (1.0864) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4375 (0.4142) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4308 (0.4186) Acc D Real: 100.000%
Loss D Fake: 1.0407 (1.0862) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4376 (0.4143) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4317 (0.4187) Acc D Real: 100.000%
Loss D Fake: 1.0404 (1.0860) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4378 (0.4144) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4304 (0.4187) Acc D Real: 100.000%
Loss D Fake: 1.0401 (1.0858) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4379 (0.4145) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4316 (0.4188) Acc D Real: 100.000%
Loss D Fake: 1.0398 (1.0856) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4381 (0.4146) Acc G: 100.000%
LR: 2.000e-04
Epoch: 14/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4306 (0.4309) Acc D Real: 100.000%
Loss D Fake: 1.0393 (1.0394) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4384 (0.4383) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4305 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0390 (1.0393) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4385 (0.4384) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4307 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0387 (1.0391) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4387 (0.4385) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4303 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0384 (1.0390) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4389 (0.4386) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4310 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0381 (1.0389) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4390 (0.4386) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4304 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0378 (1.0387) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4392 (0.4387) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4300 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0375 (1.0386) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4394 (0.4388) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4306 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0372 (1.0384) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4395 (0.4389) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4305 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0369 (1.0383) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4397 (0.4390) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4303 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0366 (1.0381) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4399 (0.4390) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4305 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0363 (1.0380) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4400 (0.4391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4309 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0360 (1.0378) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4402 (0.4392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4307 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0357 (1.0377) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4404 (0.4393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4310 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0354 (1.0375) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4405 (0.4394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4301 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0352 (1.0374) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4407 (0.4395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4303 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0349 (1.0372) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4408 (0.4395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4300 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0346 (1.0371) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4410 (0.4396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4305 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0343 (1.0369) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4411 (0.4397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4311 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0341 (1.0368) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4413 (0.4398) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4302 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0338 (1.0366) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4414 (0.4399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4313 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0335 (1.0365) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4416 (0.4399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4302 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0333 (1.0364) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4417 (0.4400) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4301 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0331 (1.0362) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4418 (0.4401) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4293 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0328 (1.0361) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4420 (0.4402) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4297 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0326 (1.0360) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4421 (0.4402) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4308 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0323 (1.0358) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4423 (0.4403) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4315 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0321 (1.0357) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4424 (0.4404) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4314 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0319 (1.0356) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4425 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4295 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0317 (1.0354) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4426 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4300 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0315 (1.0353) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4427 (0.4406) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4292 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0312 (1.0352) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4429 (0.4407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4301 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0310 (1.0350) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4430 (0.4407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4300 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0308 (1.0349) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4431 (0.4408) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4299 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0306 (1.0348) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4432 (0.4409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4303 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0304 (1.0347) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4433 (0.4409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4321 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0302 (1.0346) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4434 (0.4410) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4317 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0301 (1.0344) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4435 (0.4411) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4299 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0300 (1.0343) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4436 (0.4411) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4308 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0298 (1.0342) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4436 (0.4412) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4287 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0297 (1.0341) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4437 (0.4413) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4277 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0296 (1.0340) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4438 (0.4413) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4299 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0294 (1.0339) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4439 (0.4414) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4302 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0293 (1.0338) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4440 (0.4414) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4292 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0292 (1.0337) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4440 (0.4415) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4310 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0290 (1.0336) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4441 (0.4416) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4298 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0289 (1.0335) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4442 (0.4416) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4285 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0288 (1.0334) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4442 (0.4417) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4288 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0287 (1.0333) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4443 (0.4417) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4285 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0286 (1.0332) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4444 (0.4418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4292 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0285 (1.0331) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4444 (0.4418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4290 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0284 (1.0330) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4445 (0.4419) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4284 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0283 (1.0329) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4445 (0.4419) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4288 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0282 (1.0328) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4446 (0.4420) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4278 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0281 (1.0328) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4447 (0.4420) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4292 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0280 (1.0327) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4447 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4291 (0.4300) Acc D Real: 100.000%
Loss D Fake: 1.0279 (1.0326) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4447 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4295 (0.4300) Acc D Real: 100.000%
Loss D Fake: 1.0279 (1.0325) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4448 (0.4422) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4278 (0.4300) Acc D Real: 100.000%
Loss D Fake: 1.0279 (1.0324) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4448 (0.4422) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4264 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.0278 (1.0323) Acc D Fake: 0.000%
Loss D: 1.454
Loss G: 0.4448 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4297 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0323) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4449 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4277 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0322) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4449 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4295 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0321) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4449 (0.4424) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4291 (0.4299) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0321) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4449 (0.4424) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4269 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0320) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4449 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4277 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.0277 (1.0319) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4449 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4280 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.0278 (1.0319) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4449 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4287 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.0278 (1.0318) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4449 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4280 (0.4297) Acc D Real: 100.000%
Loss D Fake: 1.0279 (1.0317) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4448 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4289 (0.4297) Acc D Real: 100.000%
Loss D Fake: 1.0280 (1.0317) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4448 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4279 (0.4297) Acc D Real: 100.000%
Loss D Fake: 1.0281 (1.0316) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4447 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4277 (0.4297) Acc D Real: 100.000%
Loss D Fake: 1.0282 (1.0316) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4447 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4281 (0.4296) Acc D Real: 100.000%
Loss D Fake: 1.0283 (1.0315) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4446 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4273 (0.4296) Acc D Real: 100.000%
Loss D Fake: 1.0285 (1.0315) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4445 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4287 (0.4296) Acc D Real: 100.000%
Loss D Fake: 1.0286 (1.0315) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4444 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4264 (0.4296) Acc D Real: 100.000%
Loss D Fake: 1.0288 (1.0314) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4443 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4280 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.0290 (1.0314) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4442 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4286 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.0292 (1.0314) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4441 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4283 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.0295 (1.0314) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4439 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4258 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.0297 (1.0313) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4438 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4288 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.0300 (1.0313) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4437 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4253 (0.4294) Acc D Real: 100.000%
Loss D Fake: 1.0303 (1.0313) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4435 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4285 (0.4294) Acc D Real: 100.000%
Loss D Fake: 1.0306 (1.0313) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4433 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4266 (0.4294) Acc D Real: 100.000%
Loss D Fake: 1.0310 (1.0313) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4431 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4268 (0.4293) Acc D Real: 100.000%
Loss D Fake: 1.0313 (1.0313) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4430 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4251 (0.4293) Acc D Real: 100.000%
Loss D Fake: 1.0317 (1.0313) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4428 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4260 (0.4292) Acc D Real: 100.000%
Loss D Fake: 1.0320 (1.0313) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4426 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4257 (0.4292) Acc D Real: 100.000%
Loss D Fake: 1.0324 (1.0313) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4424 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4271 (0.4292) Acc D Real: 100.000%
Loss D Fake: 1.0328 (1.0313) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4421 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4255 (0.4291) Acc D Real: 100.000%
Loss D Fake: 1.0332 (1.0314) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4419 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4260 (0.4291) Acc D Real: 100.000%
Loss D Fake: 1.0337 (1.0314) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4417 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4252 (0.4291) Acc D Real: 100.000%
Loss D Fake: 1.0341 (1.0314) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4414 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4264 (0.4290) Acc D Real: 100.000%
Loss D Fake: 1.0346 (1.0314) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4412 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4257 (0.4290) Acc D Real: 100.000%
Loss D Fake: 1.0351 (1.0315) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4409 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4246 (0.4290) Acc D Real: 100.000%
Loss D Fake: 1.0356 (1.0315) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4406 (0.4428) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4252 (0.4289) Acc D Real: 100.000%
Loss D Fake: 1.0362 (1.0316) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4403 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4267 (0.4289) Acc D Real: 100.000%
Loss D Fake: 1.0367 (1.0316) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4400 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4255 (0.4289) Acc D Real: 100.000%
Loss D Fake: 1.0373 (1.0317) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4397 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4250 (0.4288) Acc D Real: 100.000%
Loss D Fake: 1.0379 (1.0317) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4393 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4244 (0.4288) Acc D Real: 100.000%
Loss D Fake: 1.0386 (1.0318) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4390 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4257 (0.4287) Acc D Real: 100.000%
Loss D Fake: 1.0392 (1.0319) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4386 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4245 (0.4287) Acc D Real: 100.000%
Loss D Fake: 1.0399 (1.0320) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4383 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4269 (0.4287) Acc D Real: 100.000%
Loss D Fake: 1.0406 (1.0320) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4379 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4248 (0.4286) Acc D Real: 100.000%
Loss D Fake: 1.0413 (1.0321) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4375 (0.4424) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4263 (0.4286) Acc D Real: 100.000%
Loss D Fake: 1.0421 (1.0322) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4371 (0.4424) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4226 (0.4286) Acc D Real: 100.000%
Loss D Fake: 1.0429 (1.0323) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4367 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4234 (0.4285) Acc D Real: 100.000%
Loss D Fake: 1.0436 (1.0324) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4362 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4246 (0.4285) Acc D Real: 100.000%
Loss D Fake: 1.0444 (1.0325) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4358 (0.4422) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4251 (0.4285) Acc D Real: 100.000%
Loss D Fake: 1.0452 (1.0327) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4354 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4255 (0.4284) Acc D Real: 100.000%
Loss D Fake: 1.0461 (1.0328) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4349 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4234 (0.4284) Acc D Real: 100.000%
Loss D Fake: 1.0469 (1.0329) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4344 (0.4420) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4263 (0.4284) Acc D Real: 100.000%
Loss D Fake: 1.0478 (1.0330) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4340 (0.4419) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4222 (0.4283) Acc D Real: 100.000%
Loss D Fake: 1.0487 (1.0332) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4335 (0.4419) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4231 (0.4283) Acc D Real: 100.000%
Loss D Fake: 1.0496 (1.0333) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4330 (0.4418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4203 (0.4282) Acc D Real: 100.000%
Loss D Fake: 1.0505 (1.0335) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4326 (0.4417) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4225 (0.4281) Acc D Real: 100.000%
Loss D Fake: 1.0513 (1.0336) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4321 (0.4416) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4211 (0.4281) Acc D Real: 100.000%
Loss D Fake: 1.0522 (1.0338) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4316 (0.4415) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4217 (0.4280) Acc D Real: 100.000%
Loss D Fake: 1.0531 (1.0340) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4312 (0.4414) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4235 (0.4280) Acc D Real: 100.000%
Loss D Fake: 1.0540 (1.0341) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4307 (0.4414) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4202 (0.4279) Acc D Real: 100.000%
Loss D Fake: 1.0549 (1.0343) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4302 (0.4413) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4228 (0.4279) Acc D Real: 100.000%
Loss D Fake: 1.0557 (1.0345) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4298 (0.4412) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4218 (0.4278) Acc D Real: 100.000%
Loss D Fake: 1.0566 (1.0347) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4293 (0.4411) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4221 (0.4278) Acc D Real: 100.000%
Loss D Fake: 1.0575 (1.0348) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4288 (0.4410) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4218 (0.4277) Acc D Real: 100.000%
Loss D Fake: 1.0585 (1.0350) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4283 (0.4409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4219 (0.4277) Acc D Real: 100.000%
Loss D Fake: 1.0594 (1.0352) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4278 (0.4408) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4198 (0.4276) Acc D Real: 100.000%
Loss D Fake: 1.0603 (1.0354) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4273 (0.4407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4225 (0.4276) Acc D Real: 100.000%
Loss D Fake: 1.0612 (1.0356) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4269 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4213 (0.4275) Acc D Real: 100.000%
Loss D Fake: 1.0621 (1.0358) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4264 (0.4404) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4206 (0.4275) Acc D Real: 100.000%
Loss D Fake: 1.0631 (1.0360) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4259 (0.4403) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4203 (0.4274) Acc D Real: 100.000%
Loss D Fake: 1.0640 (1.0363) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4254 (0.4402) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4217 (0.4274) Acc D Real: 100.000%
Loss D Fake: 1.0649 (1.0365) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4249 (0.4401) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4176 (0.4273) Acc D Real: 100.000%
Loss D Fake: 1.0658 (1.0367) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4245 (0.4400) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4199 (0.4273) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0369) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4240 (0.4399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4204 (0.4272) Acc D Real: 100.000%
Loss D Fake: 1.0676 (1.0372) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4235 (0.4397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4238 (0.4272) Acc D Real: 100.000%
Loss D Fake: 1.0685 (1.0374) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4230 (0.4396) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4190 (0.4271) Acc D Real: 100.000%
Loss D Fake: 1.0694 (1.0376) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4226 (0.4395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4203 (0.4271) Acc D Real: 100.000%
Loss D Fake: 1.0703 (1.0379) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4221 (0.4394) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4184 (0.4270) Acc D Real: 100.000%
Loss D Fake: 1.0712 (1.0381) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4216 (0.4392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4202 (0.4270) Acc D Real: 100.000%
Loss D Fake: 1.0721 (1.0383) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4212 (0.4391) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4189 (0.4269) Acc D Real: 100.000%
Loss D Fake: 1.0730 (1.0386) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4207 (0.4390) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4197 (0.4268) Acc D Real: 100.000%
Loss D Fake: 1.0739 (1.0388) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4203 (0.4388) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4204 (0.4268) Acc D Real: 100.000%
Loss D Fake: 1.0747 (1.0391) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4198 (0.4387) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4178 (0.4267) Acc D Real: 100.000%
Loss D Fake: 1.0756 (1.0394) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4194 (0.4386) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4186 (0.4267) Acc D Real: 100.000%
Loss D Fake: 1.0764 (1.0396) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4190 (0.4384) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4169 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0773 (1.0399) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4185 (0.4383) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4208 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0781 (1.0401) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4181 (0.4382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4176 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0789 (1.0404) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4177 (0.4380) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4202 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0798 (1.0407) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4173 (0.4379) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4161 (0.4264) Acc D Real: 100.000%
Loss D Fake: 1.0806 (1.0409) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4168 (0.4377) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4159 (0.4263) Acc D Real: 100.000%
Loss D Fake: 1.0814 (1.0412) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4164 (0.4376) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4182 (0.4263) Acc D Real: 100.000%
Loss D Fake: 1.0821 (1.0415) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4161 (0.4374) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4183 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.0829 (1.0417) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4157 (0.4373) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4191 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.0837 (1.0420) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4153 (0.4372) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4198 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.0844 (1.0423) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4149 (0.4370) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4182 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.0852 (1.0426) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4145 (0.4369) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4182 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.0860 (1.0429) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4141 (0.4367) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4167 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.0868 (1.0431) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4137 (0.4366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4152 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.0875 (1.0434) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4133 (0.4364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4182 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.0882 (1.0437) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4130 (0.4363) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4169 (0.4258) Acc D Real: 100.000%
Loss D Fake: 1.0889 (1.0440) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4126 (0.4361) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4154 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.0896 (1.0443) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4123 (0.4360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4185 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.0903 (1.0445) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4119 (0.4358) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4152 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.0910 (1.0448) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4116 (0.4357) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4172 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.0451) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4112 (0.4355) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4166 (0.4255) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.0454) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4109 (0.4354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4149 (0.4255) Acc D Real: 100.000%
Loss D Fake: 1.0930 (1.0457) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4106 (0.4352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4151 (0.4254) Acc D Real: 100.000%
Loss D Fake: 1.0937 (1.0460) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4103 (0.4351) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4163 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.0943 (1.0463) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4099 (0.4349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4135 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.0949 (1.0466) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4096 (0.4348) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4145 (0.4252) Acc D Real: 100.000%
Loss D Fake: 1.0955 (1.0468) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4093 (0.4346) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4136 (0.4251) Acc D Real: 100.000%
Loss D Fake: 1.0961 (1.0471) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4091 (0.4345) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4136 (0.4251) Acc D Real: 100.000%
Loss D Fake: 1.0966 (1.0474) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4088 (0.4343) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4130 (0.4250) Acc D Real: 100.000%
Loss D Fake: 1.0972 (1.0477) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4085 (0.4342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4125 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.0480) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4083 (0.4340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4136 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.0982 (1.0483) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4080 (0.4339) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4121 (0.4248) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.0486) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4078 (0.4337) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4129 (0.4247) Acc D Real: 100.000%
Loss D Fake: 1.0991 (1.0488) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4076 (0.4336) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4163 (0.4247) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.0491) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4073 (0.4335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4114 (0.4246) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.0494) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4071 (0.4333) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4147 (0.4246) Acc D Real: 100.000%
Loss D Fake: 1.1005 (1.0497) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4069 (0.4332) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4131 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.1010 (1.0500) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4066 (0.4330) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4116 (0.4244) Acc D Real: 100.000%
Loss D Fake: 1.1014 (1.0503) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4064 (0.4329) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4133 (0.4244) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.0505) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4062 (0.4327) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4123 (0.4243) Acc D Real: 100.000%
Loss D Fake: 1.1023 (1.0508) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4060 (0.4326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4125 (0.4242) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.0511) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4058 (0.4324) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4127 (0.4242) Acc D Real: 100.000%
Loss D Fake: 1.1031 (1.0514) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4056 (0.4323) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4145 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.0517) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4054 (0.4321) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4123 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.1039 (1.0519) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4052 (0.4320) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4107 (0.4240) Acc D Real: 100.000%
Loss D Fake: 1.1043 (1.0522) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4050 (0.4319) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4136 (0.4239) Acc D Real: 100.000%
Loss D Fake: 1.1047 (1.0525) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4048 (0.4317) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4140 (0.4239) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.0528) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4046 (0.4316) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4109 (0.4238) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.0531) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4044 (0.4314) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4122 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.1059 (1.0533) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4042 (0.4313) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4131 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.0536) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4041 (0.4312) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4126 (0.4236) Acc D Real: 100.000%
Loss D Fake: 1.1066 (1.0539) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4039 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4109 (0.4236) Acc D Real: 100.000%
Loss D Fake: 1.1070 (1.0541) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4037 (0.4309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4099 (0.4235) Acc D Real: 100.000%
Loss D Fake: 1.1073 (1.0544) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4035 (0.4307) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4138 (0.4235) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.0547) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4034 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4125 (0.4234) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.0549) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4032 (0.4305) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4101 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.1083 (1.0552) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4031 (0.4303) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4128 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.1086 (1.0555) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4029 (0.4302) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4089 (0.4232) Acc D Real: 100.000%
Loss D Fake: 1.1089 (1.0557) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4028 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4114 (0.4232) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.0560) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4026 (0.4299) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4138 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.1095 (1.0563) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4025 (0.4298) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4123 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.0565) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4023 (0.4296) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4108 (0.4230) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.0568) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4022 (0.4295) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4081 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.1104 (1.0570) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4020 (0.4294) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4090 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.1106 (1.0573) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4019 (0.4292) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4114 (0.4228) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.0576) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4018 (0.4291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4093 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.0578) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4017 (0.4290) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4096 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.0581) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4016 (0.4289) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4093 (0.4226) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.0583) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4015 (0.4287) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4077 (0.4225) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.0586) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4014 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4078 (0.4225) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.0588) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4013 (0.4285) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4096 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.0591) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4012 (0.4283) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4133 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.0593) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4011 (0.4282) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4106 (0.4223) Acc D Real: 100.000%
Loss D Fake: 1.1125 (1.0596) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4010 (0.4281) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4072 (0.4222) Acc D Real: 100.000%
Loss D Fake: 1.1127 (1.0598) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4009 (0.4280) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4090 (0.4222) Acc D Real: 100.000%
Loss D Fake: 1.1129 (1.0601) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4008 (0.4278) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4091 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.0603) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4008 (0.4277) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4099 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.1132 (1.0605) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4007 (0.4276) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4104 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.1134 (1.0608) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4006 (0.4275) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4081 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.1136 (1.0610) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4005 (0.4274) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4114 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.1137 (1.0612) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4004 (0.4272) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4103 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.1139 (1.0615) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4003 (0.4271) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4094 (0.4218) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.0617) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4003 (0.4270) Acc G: 100.000%
LR: 2.000e-04
Epoch: 15/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4073 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.1144 (1.1143) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4001 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4091 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.1144) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4001 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4082 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.1144) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4000 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4085 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1147 (1.1145) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3999 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4089 (0.4082) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.1145) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3999 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4091 (0.4083) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1146) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3998 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4087 (0.4084) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1147) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3998 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4092 (0.4085) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1147) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3997 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4078 (0.4084) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1148) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3997 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4070 (0.4083) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1148) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3996 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4059 (0.4081) Acc D Real: 100.000%
Loss D Fake: 1.1155 (1.1149) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3996 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4075 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.1149) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3996 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4084 (0.4081) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.1150) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3995 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4075 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1157 (1.1150) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3995 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4061 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1157 (1.1151) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3995 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4081 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.1151) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3994 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4088 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.1152) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3994 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4079 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1159 (1.1152) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3994 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4090 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1152) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3993 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4075 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1153) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3993 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4068 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1153) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3993 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4076 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1153) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3993 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4059 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1154) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4069 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1154) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4075 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1154) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4079 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1155) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4079 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1155) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4073 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1155) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3992 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4060 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1156) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4060 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1156) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4076 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1156) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3992 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4059 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1156) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4071 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4073 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4065 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4069 (0.4075) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4057 (0.4075) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4057 (0.4074) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.1157) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3991 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4053 (0.4074) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4058 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4055 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.1163 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4057 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4054 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.1162 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3992 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4061 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3993 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4056 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.1161 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3993 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4065 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1158) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3993 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4055 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3993 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4057 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.1159 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3994 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4057 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.1159 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3994 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4054 (0.4070) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3994 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4044 (0.4070) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.1158) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3994 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4055 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1157 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3995 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4058 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3995 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4060 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1155 (1.1158) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3995 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4045 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.1155 (1.1158) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3996 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4055 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3996 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4061 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3996 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4048 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1158) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3997 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4053 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1158) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3997 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4046 (0.4067) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1158) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3997 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4039 (0.4067) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1158) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3998 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4058 (0.4067) Acc D Real: 100.000%
Loss D Fake: 1.1149 (1.1157) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3998 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4052 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.1149 (1.1157) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3999 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4046 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.1157) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3999 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4040 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.1147 (1.1157) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4000 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4048 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.1157) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4000 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4043 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.1157) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4001 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4053 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.1144 (1.1156) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4001 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4046 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.1143 (1.1156) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4002 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4046 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.1142 (1.1156) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4002 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4042 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.1156) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4003 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4046 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.1140 (1.1156) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4003 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4038 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.1138 (1.1155) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4004 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4041 (0.4063) Acc D Real: 100.000%
Loss D Fake: 1.1137 (1.1155) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4004 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4042 (0.4063) Acc D Real: 100.000%
Loss D Fake: 1.1136 (1.1155) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4005 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4045 (0.4063) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1155) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4005 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4040 (0.4062) Acc D Real: 100.000%
Loss D Fake: 1.1134 (1.1154) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4006 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4038 (0.4062) Acc D Real: 100.000%
Loss D Fake: 1.1133 (1.1154) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4006 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4036 (0.4062) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.1154) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4007 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4040 (0.4062) Acc D Real: 100.000%
Loss D Fake: 1.1130 (1.1154) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4008 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4037 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.1129 (1.1153) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4008 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4039 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.1127 (1.1153) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4009 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4036 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.1126 (1.1153) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4010 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4036 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.1125 (1.1152) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4010 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4036 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1152) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4011 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4034 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.1122 (1.1152) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4012 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4028 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1151) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4012 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4034 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1151) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4013 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4030 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1150) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4014 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4037 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1150) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4014 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4037 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1150) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4015 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4034 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1149) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4016 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4029 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1149) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4017 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4033 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1149) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4017 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4028 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.1148) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4018 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4032 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.1107 (1.1148) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4019 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4029 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.1147) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4019 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4031 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.1104 (1.1147) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4020 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4030 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.1102 (1.1146) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4021 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4029 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.1146) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4022 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4028 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.1099 (1.1145) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4022 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4026 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.1145) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4023 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4026 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.1096 (1.1145) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4024 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4026 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.1095 (1.1144) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4025 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4024 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.1093 (1.1144) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4025 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4024 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.1143) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4026 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4024 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.1090 (1.1143) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4027 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4023 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.1089 (1.1142) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4028 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4023 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.1087 (1.1142) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4028 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4023 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.1085 (1.1141) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4029 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4022 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.1084 (1.1141) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4030 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4021 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.1082 (1.1140) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4031 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4021 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.1140) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4032 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4021 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.1079 (1.1139) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4032 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4020 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.1077 (1.1138) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4033 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4017 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.1075 (1.1138) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4034 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4016 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.1074 (1.1137) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4035 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4017 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.1072 (1.1137) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4036 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4016 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.1070 (1.1136) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4036 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4015 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.1069 (1.1136) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4037 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4015 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.1067 (1.1135) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4038 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4014 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.1066 (1.1135) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4039 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4016 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.1064 (1.1134) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4040 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4012 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.1133) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4040 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4015 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.1061 (1.1133) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4041 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4016 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.1059 (1.1132) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4042 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4010 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.1132) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4043 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4011 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.1056 (1.1131) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4044 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4013 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.1054 (1.1131) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4044 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4009 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.1053 (1.1130) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4045 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4010 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.1129) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4046 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4008 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.1049 (1.1129) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4047 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4006 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.1128) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4048 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4008 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1046 (1.1128) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4048 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4007 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.1127) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4049 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4005 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1043 (1.1126) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4050 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4012 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1041 (1.1126) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4051 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4009 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1040 (1.1125) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4051 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4005 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1038 (1.1124) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4052 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4009 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1037 (1.1124) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4053 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.3996 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.1123) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4054 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4007 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1033 (1.1123) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4055 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4004 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1032 (1.1122) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4055 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.3999 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1030 (1.1121) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4056 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4005 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1029 (1.1121) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4057 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.3997 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1028 (1.1120) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4057 (0.4013) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4005 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1026 (1.1119) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4058 (0.4013) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4001 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1025 (1.1119) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4059 (0.4013) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4005 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1023 (1.1118) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4060 (0.4013) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.3995 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.1118) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4060 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.3997 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1020 (1.1117) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4061 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.3997 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.1116) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4062 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4000 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1017 (1.1116) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4062 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.3988 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1016 (1.1115) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4063 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.3994 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1015 (1.1114) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4064 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4005 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1013 (1.1114) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4064 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4000 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1012 (1.1113) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4065 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4007 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1011 (1.1112) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4066 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4001 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1009 (1.1112) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4066 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.3998 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1008 (1.1111) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4067 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4009 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1007 (1.1110) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4068 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.3997 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1006 (1.1110) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4068 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.3985 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1004 (1.1109) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4069 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3990 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.1109) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4069 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.3992 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1002 (1.1108) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4070 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.3990 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.1107) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4071 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.3988 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.1000 (1.1107) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4071 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.3998 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.0999 (1.1106) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4072 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.3996 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.1105) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4072 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.3987 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.0997 (1.1105) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4073 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.3986 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.1104) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4073 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.3997 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.0995 (1.1103) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4074 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.3990 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.0994 (1.1103) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4074 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.3988 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.1102) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4075 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.3986 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.0992 (1.1102) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4075 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.3996 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.0991 (1.1101) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4076 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.3994 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.1100) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4076 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.3982 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.0989 (1.1100) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4076 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.3973 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.0988 (1.1099) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4077 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.3991 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.1098) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4077 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.3977 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.1098) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4078 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.3981 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.0986 (1.1097) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4078 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.3997 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.1097) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4078 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.3980 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.1096) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4079 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.3984 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.1095) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4079 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.3981 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.1095) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4079 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.3968 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.0982 (1.1094) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4080 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.3985 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.0982 (1.1094) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4080 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.3978 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.1093) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4080 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.3974 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.1092) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4081 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.3986 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.1092) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4081 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.3961 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.1091) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4081 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.3971 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.1091) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4081 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.3975 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1090) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4082 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.3977 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1090) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4082 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.3984 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1089) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4082 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.3966 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.1088) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4082 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.3979 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.1088) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4082 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.3976 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.1087) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.3957 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.1087) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4083 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.3979 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.1086) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.3972 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.1086) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.3980 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1085) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4083 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.3962 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1085) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4083 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.3979 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1084) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3967 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1083) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4083 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.3971 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1083) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4084 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.3962 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1082) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4084 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.3969 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1082) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4084 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.3963 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1081) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4084 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3982 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1081) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4084 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.3972 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1080) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4084 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.3992 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1080) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4084 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.3976 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1079) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4084 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.3976 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1079) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4084 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.3958 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1078) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4084 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.3998 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1078) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4084 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.3964 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1077) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4084 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.3964 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1077) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4084 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.3955 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.0974 (1.1077) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4084 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.3987 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1076) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4084 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.3956 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1076) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4084 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.3954 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1075) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4083 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.3976 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1075) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.3974 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1074) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4035) Acc G: 100.000%
LR: 2.000e-04
Epoch: 16/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.3956 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.0976) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4083 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.3977 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.0976) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4083 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.3965 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.0976) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4083 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.3949 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.0976) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4082 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.3977 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.0977) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4082 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.3983 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.0977) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4082 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.3937 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.0977) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4082 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.3959 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.0977) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4082 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.3990 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.0977) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4081 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.3955 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.0978) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4081 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.3978 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.0978) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4081 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.3950 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.0978) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4081 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.3947 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.0978) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4080 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.3960 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0982 (1.0979) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4080 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.3951 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.0979) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4080 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.3956 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.0979) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4080 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.3949 (0.3961) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.0979) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4079 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.3977 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.0980) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4079 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.3976 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.0980) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4079 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.3971 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0986 (1.0980) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4078 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.3981 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.0981) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4078 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.3962 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0988 (1.0981) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4077 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.3933 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0989 (1.0981) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4077 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.3967 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.0982) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4076 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.3954 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.0991 (1.0982) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4076 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.3961 (0.3962) Acc D Real: 100.000%
Loss D Fake: 1.0992 (1.0982) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4075 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.3980 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.0983) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4075 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.3981 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0994 (1.0983) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4074 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.3980 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0995 (1.0983) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4074 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.3970 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.0984) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4073 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.3950 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0997 (1.0984) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4073 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.3949 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.0985) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4072 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.3991 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1000 (1.0985) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4072 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.3997 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.0986) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4071 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.3988 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1002 (1.0986) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4071 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.3947 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.0986) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4070 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.3941 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1004 (1.0987) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4069 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.3928 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1005 (1.0987) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4069 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.3959 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1007 (1.0988) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4068 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.3973 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1008 (1.0988) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4067 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.3965 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1010 (1.0989) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4067 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.3942 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1011 (1.0989) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4066 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.3957 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1012 (1.0990) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4065 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.3982 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1014 (1.0990) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4065 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.3970 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1015 (1.0991) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4064 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.3955 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1017 (1.0992) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4063 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.3941 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.0992) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4062 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.3966 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1020 (1.0993) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4062 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.3963 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.0993) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4061 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.3969 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1023 (1.0994) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4060 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.3953 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1025 (1.0994) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4059 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.3958 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.0995) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4059 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.3939 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1029 (1.0996) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4058 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.3963 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1030 (1.0996) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4057 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.3983 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1032 (1.0997) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4056 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.3986 (0.3963) Acc D Real: 100.000%
Loss D Fake: 1.1034 (1.0998) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4055 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.3982 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1036 (1.0998) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4054 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.3966 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1038 (1.0999) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4053 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.3962 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1040 (1.1000) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4052 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.3988 (0.3964) Acc D Real: 100.000%
Loss D Fake: 1.1042 (1.1000) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4051 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4002 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.1001) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4050 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.3999 (0.3965) Acc D Real: 100.000%
Loss D Fake: 1.1046 (1.1002) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4049 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4000 (0.3966) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.1002) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4049 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4023 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1049 (1.1003) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4048 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4016 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.1004) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4047 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.3964 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1053 (1.1005) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4046 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.3967 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.1005) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4045 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.3946 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.1006) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4044 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.3987 (0.3967) Acc D Real: 100.000%
Loss D Fake: 1.1059 (1.1007) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4043 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4026 (0.3968) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.1008) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4042 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4025 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1064 (1.1008) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4041 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.3997 (0.3969) Acc D Real: 100.000%
Loss D Fake: 1.1066 (1.1009) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4040 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4005 (0.3970) Acc D Real: 100.000%
Loss D Fake: 1.1068 (1.1010) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4039 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4042 (0.3971) Acc D Real: 100.000%
Loss D Fake: 1.1070 (1.1011) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4038 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.3999 (0.3971) Acc D Real: 100.000%
Loss D Fake: 1.1072 (1.1012) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4037 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4000 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1074 (1.1012) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4036 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.3976 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.1013) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4035 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4008 (0.3972) Acc D Real: 100.000%
Loss D Fake: 1.1078 (1.1014) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4034 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4018 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.1015) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4033 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.3981 (0.3973) Acc D Real: 100.000%
Loss D Fake: 1.1083 (1.1016) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4032 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4050 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1085 (1.1017) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4031 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4010 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1087 (1.1017) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4030 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4001 (0.3974) Acc D Real: 100.000%
Loss D Fake: 1.1089 (1.1018) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4029 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4019 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.1019) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4027 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.3983 (0.3975) Acc D Real: 100.000%
Loss D Fake: 1.1094 (1.1020) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4026 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4022 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1096 (1.1021) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4025 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4032 (0.3976) Acc D Real: 100.000%
Loss D Fake: 1.1099 (1.1022) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4024 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4010 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.1023) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4023 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4014 (0.3977) Acc D Real: 100.000%
Loss D Fake: 1.1104 (1.1024) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4022 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4029 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1106 (1.1024) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4020 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4012 (0.3978) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.1025) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4019 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4033 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1111 (1.1026) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4018 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4010 (0.3979) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1027) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4017 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4038 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1028) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4016 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4028 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1029) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4015 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4021 (0.3980) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.1030) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4013 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4051 (0.3981) Acc D Real: 100.000%
Loss D Fake: 1.1123 (1.1031) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4012 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4039 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1126 (1.1032) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4011 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4052 (0.3982) Acc D Real: 100.000%
Loss D Fake: 1.1128 (1.1033) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4010 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4083 (0.3983) Acc D Real: 100.000%
Loss D Fake: 1.1130 (1.1034) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4009 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4059 (0.3984) Acc D Real: 100.000%
Loss D Fake: 1.1132 (1.1035) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4008 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4047 (0.3985) Acc D Real: 100.000%
Loss D Fake: 1.1134 (1.1036) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4007 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4071 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1136 (1.1037) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4006 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4068 (0.3986) Acc D Real: 100.000%
Loss D Fake: 1.1138 (1.1038) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4005 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4068 (0.3987) Acc D Real: 100.000%
Loss D Fake: 1.1140 (1.1039) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4005 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4069 (0.3988) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.1040) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4004 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4060 (0.3989) Acc D Real: 100.000%
Loss D Fake: 1.1143 (1.1041) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4003 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4085 (0.3990) Acc D Real: 100.000%
Loss D Fake: 1.1144 (1.1042) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4002 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4104 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.1042) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4002 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4075 (0.3991) Acc D Real: 100.000%
Loss D Fake: 1.1147 (1.1043) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4001 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4081 (0.3992) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.1044) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4001 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4112 (0.3993) Acc D Real: 100.000%
Loss D Fake: 1.1149 (1.1045) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4000 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4075 (0.3994) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1046) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4000 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4105 (0.3995) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1047) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3999 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4076 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1048) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3999 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4094 (0.3996) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1049) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3999 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4061 (0.3997) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1050) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3998 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4117 (0.3998) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1051) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3998 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4091 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1052) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3998 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4081 (0.3999) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1052) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3998 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4121 (0.4000) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1053) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3998 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4071 (0.4001) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1054) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3998 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4105 (0.4002) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1055) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3998 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4119 (0.4003) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1056) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3998 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4112 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1153 (1.1056) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3998 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4107 (0.4004) Acc D Real: 100.000%
Loss D Fake: 1.1152 (1.1057) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3999 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4098 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1151 (1.1058) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3999 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4136 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1059) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3999 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4145 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1149 (1.1059) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4000 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4140 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1147 (1.1060) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4001 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4129 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.1061) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4002 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4149 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1143 (1.1061) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4003 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4151 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1141 (1.1062) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4004 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4136 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1138 (1.1062) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4005 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4174 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1063) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.4007 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4131 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.1063) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4009 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4165 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1128 (1.1064) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4010 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4154 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1064) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4012 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4134 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1065) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4014 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4126 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1065) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4016 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4205 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1065) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.4018 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4142 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.1107 (1.1066) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4020 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4185 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.1102 (1.1066) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4022 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4187 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1097 (1.1066) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4025 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4179 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.1066) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4027 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4190 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1086 (1.1066) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.4030 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4184 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.1067) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4033 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4200 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1074 (1.1067) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4036 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4180 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.1068 (1.1067) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4039 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4207 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.1061 (1.1067) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4042 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4199 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.1066) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4045 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4210 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.1066) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4048 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4180 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.1041 (1.1066) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4052 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4205 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.1034 (1.1066) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4055 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4191 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.1066) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4058 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4188 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.1020 (1.1065) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4062 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4193 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.1013 (1.1065) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4065 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4204 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.1006 (1.1065) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4068 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4202 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.0999 (1.1064) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4072 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4205 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.0992 (1.1064) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4075 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4205 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.1063) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4078 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4223 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1063) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4082 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4233 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.0971 (1.1062) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4085 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4228 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.0963 (1.1062) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4089 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4234 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.0956 (1.1061) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4093 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4244 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.1060) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4097 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4229 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.0940 (1.1060) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4101 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4240 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.0932 (1.1059) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4105 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4233 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1058) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4109 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4233 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.0915 (1.1057) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4113 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4217 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.0907 (1.1056) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4117 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4251 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.0899 (1.1056) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4121 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4267 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.0891 (1.1055) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4125 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4245 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.0883 (1.1054) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4129 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4241 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.0874 (1.1053) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4133 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4245 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.0866 (1.1052) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4137 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4239 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.0858 (1.1050) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4141 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4239 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.0850 (1.1049) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4145 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4254 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.0842 (1.1048) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4149 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4256 (0.4061) Acc D Real: 100.000%
Loss D Fake: 1.0834 (1.1047) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4153 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4259 (0.4063) Acc D Real: 100.000%
Loss D Fake: 1.0826 (1.1046) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4157 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4250 (0.4064) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.1045) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4161 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4261 (0.4065) Acc D Real: 100.000%
Loss D Fake: 1.0810 (1.1043) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4165 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4259 (0.4066) Acc D Real: 100.000%
Loss D Fake: 1.0802 (1.1042) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4169 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4259 (0.4067) Acc D Real: 100.000%
Loss D Fake: 1.0795 (1.1041) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4173 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4273 (0.4068) Acc D Real: 100.000%
Loss D Fake: 1.0787 (1.1039) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4177 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4273 (0.4069) Acc D Real: 100.000%
Loss D Fake: 1.0778 (1.1038) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4181 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4265 (0.4070) Acc D Real: 100.000%
Loss D Fake: 1.0770 (1.1036) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4185 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4268 (0.4071) Acc D Real: 100.000%
Loss D Fake: 1.0762 (1.1035) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4189 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4272 (0.4072) Acc D Real: 100.000%
Loss D Fake: 1.0754 (1.1034) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4193 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4268 (0.4073) Acc D Real: 100.000%
Loss D Fake: 1.0746 (1.1032) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4197 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4269 (0.4074) Acc D Real: 100.000%
Loss D Fake: 1.0738 (1.1031) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4201 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4277 (0.4075) Acc D Real: 100.000%
Loss D Fake: 1.0730 (1.1029) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4206 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4280 (0.4076) Acc D Real: 100.000%
Loss D Fake: 1.0721 (1.1027) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4210 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4266 (0.4077) Acc D Real: 100.000%
Loss D Fake: 1.0713 (1.1026) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4214 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4260 (0.4078) Acc D Real: 100.000%
Loss D Fake: 1.0705 (1.1024) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4218 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4282 (0.4079) Acc D Real: 100.000%
Loss D Fake: 1.0698 (1.1023) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4222 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4284 (0.4080) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.1021) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4226 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4278 (0.4081) Acc D Real: 100.000%
Loss D Fake: 1.0682 (1.1019) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4230 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4282 (0.4082) Acc D Real: 100.000%
Loss D Fake: 1.0674 (1.1017) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4234 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4282 (0.4083) Acc D Real: 100.000%
Loss D Fake: 1.0666 (1.1016) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4238 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4277 (0.4084) Acc D Real: 100.000%
Loss D Fake: 1.0659 (1.1014) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4242 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4289 (0.4085) Acc D Real: 100.000%
Loss D Fake: 1.0651 (1.1012) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4246 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4290 (0.4086) Acc D Real: 100.000%
Loss D Fake: 1.0643 (1.1010) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4250 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4281 (0.4087) Acc D Real: 100.000%
Loss D Fake: 1.0635 (1.1009) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4254 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4285 (0.4088) Acc D Real: 100.000%
Loss D Fake: 1.0627 (1.1007) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4258 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4282 (0.4089) Acc D Real: 100.000%
Loss D Fake: 1.0619 (1.1005) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4262 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4286 (0.4090) Acc D Real: 100.000%
Loss D Fake: 1.0611 (1.1003) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4266 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4290 (0.4091) Acc D Real: 100.000%
Loss D Fake: 1.0604 (1.1001) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4270 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4284 (0.4092) Acc D Real: 100.000%
Loss D Fake: 1.0596 (1.0999) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4274 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4284 (0.4093) Acc D Real: 100.000%
Loss D Fake: 1.0589 (1.0997) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4278 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4294 (0.4094) Acc D Real: 100.000%
Loss D Fake: 1.0582 (1.0995) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4282 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4289 (0.4094) Acc D Real: 100.000%
Loss D Fake: 1.0574 (1.0993) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4286 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4291 (0.4095) Acc D Real: 100.000%
Loss D Fake: 1.0567 (1.0991) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4289 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4291 (0.4096) Acc D Real: 100.000%
Loss D Fake: 1.0559 (1.0989) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4293 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4294 (0.4097) Acc D Real: 100.000%
Loss D Fake: 1.0552 (1.0987) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4297 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4292 (0.4098) Acc D Real: 100.000%
Loss D Fake: 1.0545 (1.0985) Acc D Fake: 0.000%
Loss D: 1.484
Loss G: 0.4301 (0.4080) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4293 (0.4099) Acc D Real: 100.000%
Loss D Fake: 1.0537 (1.0983) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4305 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4295 (0.4100) Acc D Real: 100.000%
Loss D Fake: 1.0530 (1.0981) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4309 (0.4082) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4295 (0.4101) Acc D Real: 100.000%
Loss D Fake: 1.0522 (1.0979) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4313 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4295 (0.4102) Acc D Real: 100.000%
Loss D Fake: 1.0515 (1.0977) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4317 (0.4084) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4297 (0.4103) Acc D Real: 100.000%
Loss D Fake: 1.0508 (1.0975) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4321 (0.4085) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4297 (0.4103) Acc D Real: 100.000%
Loss D Fake: 1.0500 (1.0973) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4325 (0.4086) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4297 (0.4104) Acc D Real: 100.000%
Loss D Fake: 1.0493 (1.0971) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4329 (0.4087) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4298 (0.4105) Acc D Real: 100.000%
Loss D Fake: 1.0485 (1.0968) Acc D Fake: 0.000%
Loss D: 1.478
Loss G: 0.4333 (0.4088) Acc G: 100.000%
LR: 2.000e-04
Epoch: 17/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4301 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0471 (1.0474) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4340 (0.4338) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4300 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0463 (1.0471) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4344 (0.4340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4301 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0456 (1.0467) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4348 (0.4342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4302 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0449 (1.0463) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4352 (0.4344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4302 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0442 (1.0460) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4356 (0.4346) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4301 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0435 (1.0456) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4359 (0.4348) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4300 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0428 (1.0453) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4363 (0.4350) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4300 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0420 (1.0449) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4367 (0.4352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4305 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0413 (1.0446) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4371 (0.4354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4303 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0405 (1.0442) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4376 (0.4356) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4305 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0398 (1.0438) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4380 (0.4358) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4306 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0390 (1.0434) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4384 (0.4360) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4307 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0382 (1.0431) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4388 (0.4362) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4306 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0375 (1.0427) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4392 (0.4364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4309 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0367 (1.0423) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4396 (0.4366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4308 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0360 (1.0420) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4400 (0.4368) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4307 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0352 (1.0416) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4404 (0.4370) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4312 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0345 (1.0412) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4409 (0.4372) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4309 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0337 (1.0408) Acc D Fake: 0.000%
Loss D: 1.465
Loss G: 0.4413 (0.4374) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4312 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0330 (1.0405) Acc D Fake: 0.000%
Loss D: 1.464
Loss G: 0.4417 (0.4376) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4312 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0323 (1.0401) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4421 (0.4378) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4301 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0315 (1.0397) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4425 (0.4380) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4306 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0307 (1.0393) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4429 (0.4382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4316 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0299 (1.0390) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4434 (0.4384) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4305 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0292 (1.0386) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4438 (0.4386) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4314 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0284 (1.0382) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4442 (0.4388) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4318 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0276 (1.0378) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4447 (0.4390) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4323 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0269 (1.0374) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4451 (0.4393) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4321 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0261 (1.0371) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4455 (0.4395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4323 (0.4308) Acc D Real: 100.000%
Loss D Fake: 1.0254 (1.0367) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4459 (0.4397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4321 (0.4308) Acc D Real: 100.000%
Loss D Fake: 1.0248 (1.0363) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4462 (0.4399) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4310 (0.4308) Acc D Real: 100.000%
Loss D Fake: 1.0241 (1.0360) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4466 (0.4401) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4322 (0.4308) Acc D Real: 100.000%
Loss D Fake: 1.0234 (1.0356) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4470 (0.4403) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4328 (0.4309) Acc D Real: 100.000%
Loss D Fake: 1.0227 (1.0352) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4474 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4323 (0.4309) Acc D Real: 100.000%
Loss D Fake: 1.0220 (1.0348) Acc D Fake: 0.000%
Loss D: 1.454
Loss G: 0.4478 (0.4407) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4318 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0214 (1.0345) Acc D Fake: 0.000%
Loss D: 1.453
Loss G: 0.4482 (0.4409) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4303 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0207 (1.0341) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4486 (0.4411) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4320 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0200 (1.0338) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4490 (0.4413) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4314 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0192 (1.0334) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4494 (0.4415) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4329 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0185 (1.0330) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4498 (0.4417) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4324 (0.4311) Acc D Real: 100.000%
Loss D Fake: 1.0178 (1.0327) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4502 (0.4419) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4316 (0.4311) Acc D Real: 100.000%
Loss D Fake: 1.0172 (1.0323) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4506 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4315 (0.4311) Acc D Real: 100.000%
Loss D Fake: 1.0165 (1.0319) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4510 (0.4423) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4319 (0.4311) Acc D Real: 100.000%
Loss D Fake: 1.0157 (1.0316) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4514 (0.4425) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4344 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0151 (1.0312) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4518 (0.4427) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4308 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0144 (1.0309) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4522 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4319 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0137 (1.0305) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4526 (0.4431) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4315 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0130 (1.0302) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4530 (0.4433) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4337 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0123 (1.0298) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4533 (0.4435) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4337 (0.4313) Acc D Real: 100.000%
Loss D Fake: 1.0117 (1.0294) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4537 (0.4437) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4324 (0.4313) Acc D Real: 100.000%
Loss D Fake: 1.0111 (1.0291) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4541 (0.4439) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4323 (0.4313) Acc D Real: 100.000%
Loss D Fake: 1.0105 (1.0287) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4544 (0.4441) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4325 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.0099 (1.0284) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4548 (0.4443) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4330 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.0093 (1.0280) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4551 (0.4445) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4348 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.0088 (1.0277) Acc D Fake: 0.000%
Loss D: 1.444
Loss G: 0.4554 (0.4447) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4334 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0083 (1.0274) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4557 (0.4449) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4311 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0078 (1.0270) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4560 (0.4451) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4341 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0072 (1.0267) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4563 (0.4453) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4317 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0068 (1.0264) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4566 (0.4455) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4339 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0063 (1.0260) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4569 (0.4456) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4328 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0058 (1.0257) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4572 (0.4458) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4316 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0054 (1.0254) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4574 (0.4460) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4320 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0050 (1.0251) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4577 (0.4462) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4333 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0045 (1.0247) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4580 (0.4464) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4334 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0041 (1.0244) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4582 (0.4466) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4342 (0.4317) Acc D Real: 100.000%
Loss D Fake: 1.0038 (1.0241) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4584 (0.4467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4353 (0.4317) Acc D Real: 100.000%
Loss D Fake: 1.0035 (1.0238) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4585 (0.4469) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4342 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.0033 (1.0235) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4586 (0.4471) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4324 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.0032 (1.0232) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4587 (0.4472) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4353 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.0031 (1.0229) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4588 (0.4474) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4351 (0.4319) Acc D Real: 100.000%
Loss D Fake: 1.0030 (1.0227) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4588 (0.4476) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4359 (0.4319) Acc D Real: 100.000%
Loss D Fake: 1.0031 (1.0224) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4588 (0.4477) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4345 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0032 (1.0221) Acc D Fake: 0.000%
Loss D: 1.438
Loss G: 0.4587 (0.4479) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4341 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0034 (1.0219) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4586 (0.4480) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4332 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0037 (1.0217) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4585 (0.4481) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4373 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0039 (1.0214) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4583 (0.4483) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4343 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0044 (1.0212) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4581 (0.4484) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4350 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0048 (1.0210) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4578 (0.4485) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4308 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0053 (1.0208) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4575 (0.4486) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4302 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0058 (1.0206) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4573 (0.4487) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4331 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0063 (1.0204) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4570 (0.4488) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4342 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0069 (1.0203) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4567 (0.4489) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4337 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0076 (1.0201) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4563 (0.4490) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4324 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0083 (1.0200) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4558 (0.4491) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4317 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0091 (1.0199) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4554 (0.4492) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4350 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0100 (1.0198) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4549 (0.4492) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4360 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0110 (1.0197) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4543 (0.4493) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4306 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0121 (1.0196) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4537 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4316 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0132 (1.0195) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4530 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4306 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0144 (1.0194) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4524 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4321 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0156 (1.0194) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4517 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4311 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0169 (1.0194) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4510 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4299 (0.4322) Acc D Real: 100.000%
Loss D Fake: 1.0182 (1.0194) Acc D Fake: 0.000%
Loss D: 1.448
Loss G: 0.4502 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4296 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0195 (1.0194) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4495 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4304 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0209 (1.0194) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4487 (0.4495) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4315 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0224 (1.0194) Acc D Fake: 0.000%
Loss D: 1.454
Loss G: 0.4479 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4318 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0239 (1.0195) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4470 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4291 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0255 (1.0195) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4461 (0.4494) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4315 (0.4321) Acc D Real: 100.000%
Loss D Fake: 1.0272 (1.0196) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4451 (0.4493) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4309 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0289 (1.0197) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4441 (0.4493) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4297 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0308 (1.0198) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4431 (0.4492) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4340 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0326 (1.0199) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4420 (0.4492) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4283 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0346 (1.0201) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4409 (0.4491) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4297 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0367 (1.0202) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4398 (0.4490) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4336 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0387 (1.0204) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4387 (0.4489) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4277 (0.4320) Acc D Real: 100.000%
Loss D Fake: 1.0409 (1.0206) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4375 (0.4488) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4297 (0.4319) Acc D Real: 100.000%
Loss D Fake: 1.0430 (1.0208) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4363 (0.4487) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4247 (0.4319) Acc D Real: 100.000%
Loss D Fake: 1.0452 (1.0210) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4351 (0.4486) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4298 (0.4319) Acc D Real: 100.000%
Loss D Fake: 1.0473 (1.0213) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4340 (0.4484) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4251 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.0495 (1.0215) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4328 (0.4483) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4291 (0.4318) Acc D Real: 100.000%
Loss D Fake: 1.0516 (1.0218) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4317 (0.4481) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4273 (0.4317) Acc D Real: 100.000%
Loss D Fake: 1.0538 (1.0221) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4305 (0.4480) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4260 (0.4317) Acc D Real: 100.000%
Loss D Fake: 1.0560 (1.0224) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4294 (0.4478) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4272 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0581 (1.0227) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4282 (0.4476) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4245 (0.4316) Acc D Real: 100.000%
Loss D Fake: 1.0603 (1.0230) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4270 (0.4475) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4260 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0624 (1.0233) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4259 (0.4473) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4249 (0.4315) Acc D Real: 100.000%
Loss D Fake: 1.0646 (1.0237) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4248 (0.4471) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4218 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.0667 (1.0240) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4237 (0.4469) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4261 (0.4314) Acc D Real: 100.000%
Loss D Fake: 1.0688 (1.0244) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4226 (0.4467) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4250 (0.4313) Acc D Real: 100.000%
Loss D Fake: 1.0709 (1.0248) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4215 (0.4465) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4233 (0.4312) Acc D Real: 100.000%
Loss D Fake: 1.0730 (1.0252) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4204 (0.4463) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4177 (0.4311) Acc D Real: 100.000%
Loss D Fake: 1.0750 (1.0256) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4194 (0.4461) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4210 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0769 (1.0260) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4184 (0.4458) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4216 (0.4310) Acc D Real: 100.000%
Loss D Fake: 1.0788 (1.0264) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4174 (0.4456) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4238 (0.4309) Acc D Real: 100.000%
Loss D Fake: 1.0807 (1.0269) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4165 (0.4454) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4200 (0.4308) Acc D Real: 100.000%
Loss D Fake: 1.0826 (1.0273) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4155 (0.4451) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4174 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0844 (1.0277) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4146 (0.4449) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4221 (0.4307) Acc D Real: 100.000%
Loss D Fake: 1.0862 (1.0282) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4137 (0.4447) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4201 (0.4306) Acc D Real: 100.000%
Loss D Fake: 1.0880 (1.0287) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4128 (0.4444) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4172 (0.4305) Acc D Real: 100.000%
Loss D Fake: 1.0897 (1.0291) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4119 (0.4442) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4203 (0.4304) Acc D Real: 100.000%
Loss D Fake: 1.0914 (1.0296) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4110 (0.4439) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4169 (0.4303) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.0301) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4102 (0.4437) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4151 (0.4302) Acc D Real: 100.000%
Loss D Fake: 1.0947 (1.0306) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4094 (0.4434) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4179 (0.4301) Acc D Real: 100.000%
Loss D Fake: 1.0963 (1.0310) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4086 (0.4431) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4153 (0.4300) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.0315) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4079 (0.4429) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4122 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.0992 (1.0320) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4072 (0.4426) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4172 (0.4298) Acc D Real: 100.000%
Loss D Fake: 1.1006 (1.0325) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4065 (0.4424) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4134 (0.4296) Acc D Real: 100.000%
Loss D Fake: 1.1020 (1.0330) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4059 (0.4421) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4155 (0.4295) Acc D Real: 100.000%
Loss D Fake: 1.1032 (1.0335) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4052 (0.4418) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4119 (0.4294) Acc D Real: 100.000%
Loss D Fake: 1.1045 (1.0340) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4046 (0.4416) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4161 (0.4293) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0345) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4040 (0.4413) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4123 (0.4292) Acc D Real: 100.000%
Loss D Fake: 1.1069 (1.0350) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4035 (0.4410) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4130 (0.4291) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.0356) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4029 (0.4408) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4123 (0.4290) Acc D Real: 100.000%
Loss D Fake: 1.1091 (1.0361) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4024 (0.4405) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4120 (0.4289) Acc D Real: 100.000%
Loss D Fake: 1.1102 (1.0366) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4019 (0.4402) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4094 (0.4287) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.0371) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4014 (0.4400) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4118 (0.4286) Acc D Real: 100.000%
Loss D Fake: 1.1121 (1.0376) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4009 (0.4397) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4097 (0.4285) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.0381) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4005 (0.4395) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4117 (0.4284) Acc D Real: 100.000%
Loss D Fake: 1.1139 (1.0386) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4001 (0.4392) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4090 (0.4282) Acc D Real: 100.000%
Loss D Fake: 1.1148 (1.0391) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3997 (0.4389) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4121 (0.4281) Acc D Real: 100.000%
Loss D Fake: 1.1156 (1.0396) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3993 (0.4387) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4100 (0.4280) Acc D Real: 100.000%
Loss D Fake: 1.1164 (1.0401) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3989 (0.4384) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4089 (0.4279) Acc D Real: 100.000%
Loss D Fake: 1.1171 (1.0406) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3985 (0.4382) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4097 (0.4278) Acc D Real: 100.000%
Loss D Fake: 1.1179 (1.0411) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3982 (0.4379) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4093 (0.4277) Acc D Real: 100.000%
Loss D Fake: 1.1186 (1.0416) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3979 (0.4376) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4105 (0.4275) Acc D Real: 100.000%
Loss D Fake: 1.1192 (1.0421) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3976 (0.4374) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4035 (0.4274) Acc D Real: 100.000%
Loss D Fake: 1.1199 (1.0426) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3973 (0.4371) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4060 (0.4273) Acc D Real: 100.000%
Loss D Fake: 1.1204 (1.0431) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3970 (0.4369) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4094 (0.4272) Acc D Real: 100.000%
Loss D Fake: 1.1209 (1.0436) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3968 (0.4366) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4108 (0.4270) Acc D Real: 100.000%
Loss D Fake: 1.1214 (1.0440) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3965 (0.4364) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4049 (0.4269) Acc D Real: 100.000%
Loss D Fake: 1.1219 (1.0445) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3963 (0.4361) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4071 (0.4268) Acc D Real: 100.000%
Loss D Fake: 1.1223 (1.0450) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3961 (0.4359) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4087 (0.4267) Acc D Real: 100.000%
Loss D Fake: 1.1228 (1.0455) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3959 (0.4356) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4087 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.1232 (1.0459) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3957 (0.4354) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4083 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.1236 (1.0464) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3955 (0.4352) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4078 (0.4263) Acc D Real: 100.000%
Loss D Fake: 1.1240 (1.0469) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3953 (0.4349) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4060 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.1244 (1.0473) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3951 (0.4347) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4042 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.1248 (1.0478) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3950 (0.4344) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4068 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.1251 (1.0483) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3948 (0.4342) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4048 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.1253 (1.0487) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3947 (0.4340) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4045 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.1256 (1.0492) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3946 (0.4338) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4052 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.1258 (1.0496) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3945 (0.4335) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4058 (0.4255) Acc D Real: 100.000%
Loss D Fake: 1.1260 (1.0500) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3944 (0.4333) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4043 (0.4254) Acc D Real: 100.000%
Loss D Fake: 1.1261 (1.0505) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3943 (0.4331) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4048 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.1263 (1.0509) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3943 (0.4329) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4036 (0.4251) Acc D Real: 100.000%
Loss D Fake: 1.1264 (1.0513) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3942 (0.4326) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4046 (0.4250) Acc D Real: 100.000%
Loss D Fake: 1.1265 (1.0517) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3942 (0.4324) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4052 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.1266 (1.0522) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3941 (0.4322) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4048 (0.4248) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0526) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3941 (0.4320) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4024 (0.4247) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0530) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3941 (0.4318) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4042 (0.4246) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0534) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3941 (0.4316) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4024 (0.4244) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0538) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3941 (0.4314) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4042 (0.4243) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0542) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3941 (0.4312) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4027 (0.4242) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0546) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3941 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4050 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0550) Acc D Fake: 0.000%
Loss D: 1.532
Loss G: 0.3941 (0.4308) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4028 (0.4240) Acc D Real: 100.000%
Loss D Fake: 1.1266 (1.0554) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3942 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4026 (0.4239) Acc D Real: 100.000%
Loss D Fake: 1.1265 (1.0557) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3942 (0.4304) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4025 (0.4238) Acc D Real: 100.000%
Loss D Fake: 1.1264 (1.0561) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3942 (0.4302) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4027 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.1263 (1.0565) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3943 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4028 (0.4236) Acc D Real: 100.000%
Loss D Fake: 1.1262 (1.0568) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3944 (0.4298) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4029 (0.4234) Acc D Real: 100.000%
Loss D Fake: 1.1261 (1.0572) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3944 (0.4296) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4018 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.1259 (1.0576) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3945 (0.4295) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4023 (0.4232) Acc D Real: 100.000%
Loss D Fake: 1.1258 (1.0579) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3946 (0.4293) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4035 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.1256 (1.0583) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3947 (0.4291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4019 (0.4230) Acc D Real: 100.000%
Loss D Fake: 1.1254 (1.0586) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3947 (0.4289) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4025 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.1252 (1.0589) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3948 (0.4287) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4008 (0.4228) Acc D Real: 100.000%
Loss D Fake: 1.1250 (1.0593) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3949 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4005 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.1248 (1.0596) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3951 (0.4284) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4027 (0.4226) Acc D Real: 100.000%
Loss D Fake: 1.1246 (1.0599) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3952 (0.4282) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4020 (0.4225) Acc D Real: 100.000%
Loss D Fake: 1.1243 (1.0602) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3953 (0.4281) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4028 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.1241 (1.0606) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3954 (0.4279) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4022 (0.4223) Acc D Real: 100.000%
Loss D Fake: 1.1238 (1.0609) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3955 (0.4278) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4016 (0.4222) Acc D Real: 100.000%
Loss D Fake: 1.1236 (1.0612) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3956 (0.4276) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4014 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.1233 (1.0615) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3958 (0.4274) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4026 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.1230 (1.0618) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3959 (0.4273) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4014 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.1228 (1.0621) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3960 (0.4271) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4014 (0.4218) Acc D Real: 100.000%
Loss D Fake: 1.1225 (1.0624) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3962 (0.4270) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4022 (0.4217) Acc D Real: 100.000%
Loss D Fake: 1.1222 (1.0627) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3963 (0.4268) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4023 (0.4216) Acc D Real: 100.000%
Loss D Fake: 1.1219 (1.0629) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3965 (0.4267) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4015 (0.4215) Acc D Real: 100.000%
Loss D Fake: 1.1216 (1.0632) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3966 (0.4266) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4016 (0.4214) Acc D Real: 100.000%
Loss D Fake: 1.1212 (1.0635) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3968 (0.4264) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4018 (0.4213) Acc D Real: 100.000%
Loss D Fake: 1.1209 (1.0638) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3969 (0.4263) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4034 (0.4212) Acc D Real: 100.000%
Loss D Fake: 1.1206 (1.0640) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.3971 (0.4261) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4015 (0.4212) Acc D Real: 100.000%
Loss D Fake: 1.1203 (1.0643) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3972 (0.4260) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4018 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.1200 (1.0645) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3974 (0.4259) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4022 (0.4210) Acc D Real: 100.000%
Loss D Fake: 1.1197 (1.0648) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3975 (0.4257) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4017 (0.4209) Acc D Real: 100.000%
Loss D Fake: 1.1193 (1.0650) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3977 (0.4256) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4015 (0.4208) Acc D Real: 100.000%
Loss D Fake: 1.1190 (1.0653) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3978 (0.4255) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4010 (0.4207) Acc D Real: 100.000%
Loss D Fake: 1.1186 (1.0655) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3980 (0.4254) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4013 (0.4206) Acc D Real: 100.000%
Loss D Fake: 1.1183 (1.0658) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3982 (0.4252) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4021 (0.4205) Acc D Real: 100.000%
Loss D Fake: 1.1179 (1.0660) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3983 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4013 (0.4205) Acc D Real: 100.000%
Loss D Fake: 1.1176 (1.0662) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3985 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4008 (0.4204) Acc D Real: 100.000%
Loss D Fake: 1.1172 (1.0665) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3987 (0.4249) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4014 (0.4203) Acc D Real: 100.000%
Loss D Fake: 1.1168 (1.0667) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3989 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4021 (0.4202) Acc D Real: 100.000%
Loss D Fake: 1.1165 (1.0669) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3990 (0.4247) Acc G: 100.000%
LR: 2.000e-04
Epoch: 18/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4015 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1157 (1.1159) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3994 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4018 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1154 (1.1157) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3996 (0.3994) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4018 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1156) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3998 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4012 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1146 (1.1154) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3999 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4017 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1143 (1.1152) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4001 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4011 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1139 (1.1150) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4003 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1148) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4005 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.1146) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4007 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1128 (1.1144) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4008 (0.4000) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1124 (1.1143) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4010 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1141) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4012 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4014 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1139) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4014 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4017 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1137) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4016 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.1135) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4017 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.1133) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4019 (0.4006) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.1131) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4021 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4014 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1097 (1.1129) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4023 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1094 (1.1128) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4025 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1090 (1.1126) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4026 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1086 (1.1124) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4028 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1083 (1.1122) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4030 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4017 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1079 (1.1120) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4032 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4019 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.1118) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4033 (0.4013) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4018 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1072 (1.1116) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4035 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4018 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1069 (1.1115) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4037 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1065 (1.1113) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4039 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4017 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.1111) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4040 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4020 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.1109) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4042 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.1107) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4044 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.1105) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4045 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4020 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.1104) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4047 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4014 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.1102) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4049 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4018 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1041 (1.1100) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4050 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4019 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1038 (1.1098) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4052 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4012 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.1096) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4053 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4021 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1031 (1.1095) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4055 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4019 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1028 (1.1093) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4057 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4020 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1025 (1.1091) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4058 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.1090) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4060 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4021 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.1088) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4061 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4015 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1016 (1.1086) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4063 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4012 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1013 (1.1084) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4064 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4018 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1010 (1.1083) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4065 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1007 (1.1081) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4067 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4013 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1004 (1.1079) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4068 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.1078) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4070 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4007 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.1076) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4071 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4019 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.1074) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4072 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.1073) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4074 (0.4035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4017 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.1071) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4075 (0.4036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4014 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0988 (1.1070) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4076 (0.4037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4011 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.1068) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4078 (0.4037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4006 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.1066) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4079 (0.4038) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4012 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.1065) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4080 (0.4039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1063) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4081 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4014 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1062) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4083 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4008 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0973 (1.1060) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4084 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0970 (1.1059) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4085 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0968 (1.1057) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4086 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4012 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0966 (1.1056) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4087 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4007 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0964 (1.1054) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4088 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4010 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0962 (1.1053) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4089 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4024 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0960 (1.1051) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4090 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4011 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0958 (1.1050) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4091 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.3996 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0956 (1.1048) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4092 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4003 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0954 (1.1047) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4093 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4018 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0952 (1.1046) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4094 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4008 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0950 (1.1044) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4095 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4011 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.1043) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4096 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4013 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0946 (1.1041) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4097 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4025 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0944 (1.1040) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4098 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4019 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0943 (1.1039) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4099 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4005 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0941 (1.1037) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4099 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4005 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0939 (1.1036) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4100 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4008 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0938 (1.1035) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4101 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.3997 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0937 (1.1034) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4102 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.3987 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0935 (1.1032) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4102 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4017 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0934 (1.1031) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4103 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4001 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0932 (1.1030) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4104 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4000 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.1029) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4104 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4016 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0930 (1.1027) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4105 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4014 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0929 (1.1026) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4105 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.3997 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0928 (1.1025) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4106 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4016 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0927 (1.1024) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4106 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4007 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0926 (1.1023) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4107 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.3993 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.1022) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4107 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4003 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1020) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4108 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4014 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1019) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4108 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4008 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1018) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4109 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.3998 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1017) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4109 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4012 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0921 (1.1016) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4109 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.3993 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0921 (1.1015) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4109 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.3997 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0920 (1.1014) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4110 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.3997 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0920 (1.1013) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4110 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4009 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0919 (1.1012) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4110 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.3977 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0919 (1.1011) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4110 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4000 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.1010) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.3999 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.1009) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4009 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.1008) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4111 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4018 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1008) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4111 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4009 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1007) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4111 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.3980 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1006) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4111 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.3991 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1005) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4111 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.3994 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1004) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4111 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4002 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1003) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4008 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1002) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4111 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.3991 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0917 (1.1002) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4111 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.3980 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.1001) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4111 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4006 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.1000) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4004 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0918 (1.0999) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.3997 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0919 (1.0999) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4111 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4005 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0919 (1.0998) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4110 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4011 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0919 (1.0997) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4110 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.3985 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0920 (1.0997) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4110 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.3994 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0921 (1.0996) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4110 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.3996 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0921 (1.0995) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4109 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4003 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.0995) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4109 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.3988 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.0994) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4109 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.3976 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.0994) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4108 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4000 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.0993) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4108 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.3995 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.0992) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4107 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4021 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0926 (1.0992) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4107 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.3986 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0927 (1.0991) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4106 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4012 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0928 (1.0991) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4106 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.3992 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0929 (1.0990) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4105 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.3986 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.0990) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4105 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4004 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0932 (1.0989) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4104 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4006 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0933 (1.0989) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4103 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.3994 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0934 (1.0989) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4103 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.3983 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0936 (1.0988) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4102 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4025 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0937 (1.0988) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4101 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4017 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0939 (1.0987) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4101 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4015 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0940 (1.0987) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4100 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4012 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0942 (1.0987) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4099 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.3993 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0943 (1.0986) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4098 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.3981 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0945 (1.0986) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4098 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.3988 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0946 (1.0986) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4097 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4010 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.0986) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4096 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4000 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0950 (1.0985) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4095 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.3983 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0952 (1.0985) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4094 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4000 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0954 (1.0985) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4093 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4000 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0956 (1.0985) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4092 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.3981 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0958 (1.0984) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4091 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4010 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0960 (1.0984) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4090 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4005 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0962 (1.0984) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4089 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4008 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0964 (1.0984) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4088 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.3996 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0966 (1.0984) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4087 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4027 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0969 (1.0984) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4086 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4001 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0971 (1.0984) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4085 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.3981 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0973 (1.0984) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4084 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4014 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0976 (1.0984) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4083 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.3996 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.0983) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4081 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.3988 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0980 (1.0983) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4080 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4010 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.0983) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4079 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.3997 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.0983) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4078 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4001 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0988 (1.0984) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4077 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4009 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.0984) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4075 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.3998 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.0984) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4074 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4059 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.0995 (1.0984) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4073 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4015 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.0984) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4072 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4010 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.0984) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4070 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4031 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.0984) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4069 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4021 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1006 (1.0984) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4068 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.3997 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1009 (1.0984) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4067 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4029 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1011 (1.0984) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4065 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4021 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1014 (1.0985) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4064 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4028 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1017 (1.0985) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4063 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4002 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1020 (1.0985) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4061 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4012 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1023 (1.0985) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4060 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4033 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1025 (1.0985) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4058 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4034 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1028 (1.0986) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4057 (0.4078) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4041 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1031 (1.0986) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4056 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4020 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1034 (1.0986) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4054 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4062 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1037 (1.0987) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4053 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4010 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1040 (1.0987) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4051 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4054 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1043 (1.0987) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4050 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4055 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1046 (1.0987) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4049 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4051 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.0988) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4047 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4049 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.0988) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4046 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4011 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1054 (1.0989) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4045 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4050 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0989) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4043 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4060 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.1059 (1.0989) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4042 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4048 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.0990) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4041 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4082 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1065 (1.0990) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4039 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4025 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1068 (1.0991) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4038 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4050 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1070 (1.0991) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4037 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4053 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.1073 (1.0991) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4035 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4063 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.0992) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4034 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4064 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1078 (1.0992) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4033 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4076 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.1081 (1.0993) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4032 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4079 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1083 (1.0993) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4030 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4045 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1086 (1.0994) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4029 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4059 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1088 (1.0994) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4028 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4047 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1090 (1.0995) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4027 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4052 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.1093 (1.0995) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4026 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4102 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.1095 (1.0996) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4025 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4052 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.0996) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4023 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4077 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.1100 (1.0997) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4022 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4088 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1102 (1.0997) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4021 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4104 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.1104 (1.0998) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4021 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4082 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.0998) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4020 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4041 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1107 (1.0999) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4019 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4083 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.0999) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4018 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4113 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1000) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4017 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4081 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1000) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4017 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4064 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1113 (1.1001) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4016 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4095 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1002) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4016 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4095 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1002) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4015 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4124 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1003) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4015 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4065 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1003) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4014 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4100 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1004) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4014 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4135 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1004) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4014 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4062 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1005) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4014 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4090 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1005) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4013 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4130 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.1119 (1.1006) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4013 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4124 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1006) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4013 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4101 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1007) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4014 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4070 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1118 (1.1007) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4014 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4122 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1117 (1.1008) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4014 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4130 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.1008) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4014 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4154 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1009) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.4015 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4106 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1114 (1.1009) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4016 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4130 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1112 (1.1010) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4016 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4115 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1010) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4017 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4120 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1109 (1.1011) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4018 (0.4066) Acc G: 100.000%
LR: 2.000e-04
Epoch: 19/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4188 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.1104 (1.1105) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.4020 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4133 (0.4146) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.1104) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4022 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4137 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.1098 (1.1103) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4023 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4162 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.1095 (1.1101) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4025 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4130 (0.4144) Acc D Real: 100.000%
Loss D Fake: 1.1092 (1.1099) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4026 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4152 (0.4145) Acc D Real: 100.000%
Loss D Fake: 1.1088 (1.1098) Acc D Fake: 0.000%
Loss D: 1.524
Loss G: 0.4028 (0.4023) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4171 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.1084 (1.1096) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4030 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4150 (0.4149) Acc D Real: 100.000%
Loss D Fake: 1.1080 (1.1094) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4032 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4132 (0.4147) Acc D Real: 100.000%
Loss D Fake: 1.1076 (1.1092) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4034 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4161 (0.4148) Acc D Real: 100.000%
Loss D Fake: 1.1071 (1.1090) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4036 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4192 (0.4152) Acc D Real: 100.000%
Loss D Fake: 1.1067 (1.1088) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.4038 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4165 (0.4153) Acc D Real: 100.000%
Loss D Fake: 1.1062 (1.1086) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4040 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4165 (0.4154) Acc D Real: 100.000%
Loss D Fake: 1.1056 (1.1084) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4043 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4165 (0.4155) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.1082) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4046 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4187 (0.4157) Acc D Real: 100.000%
Loss D Fake: 1.1045 (1.1080) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4048 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4176 (0.4158) Acc D Real: 100.000%
Loss D Fake: 1.1040 (1.1077) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4051 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4177 (0.4159) Acc D Real: 100.000%
Loss D Fake: 1.1034 (1.1075) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4054 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4193 (0.4161) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.1072) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4057 (0.4035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4187 (0.4162) Acc D Real: 100.000%
Loss D Fake: 1.1021 (1.1070) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4060 (0.4037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4176 (0.4163) Acc D Real: 100.000%
Loss D Fake: 1.1014 (1.1067) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4063 (0.4038) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4189 (0.4164) Acc D Real: 100.000%
Loss D Fake: 1.1008 (1.1065) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4066 (0.4039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4192 (0.4165) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.1062) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4070 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4202 (0.4167) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.1059) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4073 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4205 (0.4168) Acc D Real: 100.000%
Loss D Fake: 1.0986 (1.1056) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4077 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4207 (0.4170) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1053) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4081 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4201 (0.4171) Acc D Real: 100.000%
Loss D Fake: 1.0971 (1.1050) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4084 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4195 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0963 (1.1047) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4088 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4196 (0.4172) Acc D Real: 100.000%
Loss D Fake: 1.0955 (1.1044) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4092 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4208 (0.4174) Acc D Real: 100.000%
Loss D Fake: 1.0947 (1.1040) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4096 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4219 (0.4175) Acc D Real: 100.000%
Loss D Fake: 1.0939 (1.1037) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4100 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4202 (0.4176) Acc D Real: 100.000%
Loss D Fake: 1.0930 (1.1034) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4104 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4209 (0.4177) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1030) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4108 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4203 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0913 (1.1027) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4112 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4197 (0.4178) Acc D Real: 100.000%
Loss D Fake: 1.0905 (1.1023) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4117 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4205 (0.4179) Acc D Real: 100.000%
Loss D Fake: 1.0897 (1.1020) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4121 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4213 (0.4180) Acc D Real: 100.000%
Loss D Fake: 1.0888 (1.1016) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4125 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4222 (0.4181) Acc D Real: 100.000%
Loss D Fake: 1.0880 (1.1013) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4129 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4199 (0.4181) Acc D Real: 100.000%
Loss D Fake: 1.0871 (1.1009) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4133 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4198 (0.4182) Acc D Real: 100.000%
Loss D Fake: 1.0863 (1.1006) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4137 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4226 (0.4183) Acc D Real: 100.000%
Loss D Fake: 1.0854 (1.1002) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4142 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4221 (0.4184) Acc D Real: 100.000%
Loss D Fake: 1.0846 (1.0998) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4146 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4229 (0.4185) Acc D Real: 100.000%
Loss D Fake: 1.0837 (1.0994) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4150 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4237 (0.4186) Acc D Real: 100.000%
Loss D Fake: 1.0828 (1.0991) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4155 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4228 (0.4187) Acc D Real: 100.000%
Loss D Fake: 1.0818 (1.0987) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4160 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4245 (0.4188) Acc D Real: 100.000%
Loss D Fake: 1.0809 (1.0983) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4165 (0.4079) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4218 (0.4189) Acc D Real: 100.000%
Loss D Fake: 1.0799 (1.0979) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4170 (0.4081) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4227 (0.4190) Acc D Real: 100.000%
Loss D Fake: 1.0789 (1.0975) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4175 (0.4083) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4232 (0.4191) Acc D Real: 100.000%
Loss D Fake: 1.0779 (1.0971) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4180 (0.4085) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4235 (0.4191) Acc D Real: 100.000%
Loss D Fake: 1.0769 (1.0967) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4185 (0.4087) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4226 (0.4192) Acc D Real: 100.000%
Loss D Fake: 1.0759 (1.0963) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4190 (0.4089) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4222 (0.4193) Acc D Real: 100.000%
Loss D Fake: 1.0749 (1.0959) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4195 (0.4091) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4232 (0.4193) Acc D Real: 100.000%
Loss D Fake: 1.0740 (1.0955) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4199 (0.4093) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4237 (0.4194) Acc D Real: 100.000%
Loss D Fake: 1.0730 (1.0950) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4204 (0.4095) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4239 (0.4195) Acc D Real: 100.000%
Loss D Fake: 1.0720 (1.0946) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4209 (0.4097) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4231 (0.4196) Acc D Real: 100.000%
Loss D Fake: 1.0710 (1.0942) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4214 (0.4099) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4237 (0.4196) Acc D Real: 100.000%
Loss D Fake: 1.0700 (1.0938) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4220 (0.4101) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4248 (0.4197) Acc D Real: 100.000%
Loss D Fake: 1.0690 (1.0934) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4225 (0.4103) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4244 (0.4198) Acc D Real: 100.000%
Loss D Fake: 1.0680 (1.0929) Acc D Fake: 0.000%
Loss D: 1.492
Loss G: 0.4230 (0.4105) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4240 (0.4199) Acc D Real: 100.000%
Loss D Fake: 1.0669 (1.0925) Acc D Fake: 0.000%
Loss D: 1.491
Loss G: 0.4236 (0.4108) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4244 (0.4200) Acc D Real: 100.000%
Loss D Fake: 1.0659 (1.0921) Acc D Fake: 0.000%
Loss D: 1.490
Loss G: 0.4241 (0.4110) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4242 (0.4200) Acc D Real: 100.000%
Loss D Fake: 1.0648 (1.0916) Acc D Fake: 0.000%
Loss D: 1.489
Loss G: 0.4247 (0.4112) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4236 (0.4201) Acc D Real: 100.000%
Loss D Fake: 1.0637 (1.0912) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4252 (0.4114) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4242 (0.4201) Acc D Real: 100.000%
Loss D Fake: 1.0627 (1.0907) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4257 (0.4116) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4251 (0.4202) Acc D Real: 100.000%
Loss D Fake: 1.0617 (1.0903) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4263 (0.4119) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4246 (0.4203) Acc D Real: 100.000%
Loss D Fake: 1.0607 (1.0898) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4268 (0.4121) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4249 (0.4204) Acc D Real: 100.000%
Loss D Fake: 1.0596 (1.0894) Acc D Fake: 0.000%
Loss D: 1.485
Loss G: 0.4273 (0.4123) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4248 (0.4204) Acc D Real: 100.000%
Loss D Fake: 1.0586 (1.0889) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4279 (0.4126) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4251 (0.4205) Acc D Real: 100.000%
Loss D Fake: 1.0575 (1.0885) Acc D Fake: 0.000%
Loss D: 1.483
Loss G: 0.4285 (0.4128) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4249 (0.4206) Acc D Real: 100.000%
Loss D Fake: 1.0564 (1.0880) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4290 (0.4130) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4251 (0.4206) Acc D Real: 100.000%
Loss D Fake: 1.0554 (1.0876) Acc D Fake: 0.000%
Loss D: 1.481
Loss G: 0.4296 (0.4133) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4254 (0.4207) Acc D Real: 100.000%
Loss D Fake: 1.0543 (1.0871) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4302 (0.4135) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4255 (0.4208) Acc D Real: 100.000%
Loss D Fake: 1.0532 (1.0866) Acc D Fake: 0.000%
Loss D: 1.479
Loss G: 0.4308 (0.4137) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4254 (0.4208) Acc D Real: 100.000%
Loss D Fake: 1.0520 (1.0862) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4314 (0.4140) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4256 (0.4209) Acc D Real: 100.000%
Loss D Fake: 1.0509 (1.0857) Acc D Fake: 0.000%
Loss D: 1.477
Loss G: 0.4320 (0.4142) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4255 (0.4209) Acc D Real: 100.000%
Loss D Fake: 1.0498 (1.0852) Acc D Fake: 0.000%
Loss D: 1.475
Loss G: 0.4326 (0.4144) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4256 (0.4210) Acc D Real: 100.000%
Loss D Fake: 1.0486 (1.0847) Acc D Fake: 0.000%
Loss D: 1.474
Loss G: 0.4332 (0.4147) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4259 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.0475 (1.0843) Acc D Fake: 0.000%
Loss D: 1.473
Loss G: 0.4338 (0.4149) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4261 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.0463 (1.0838) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4344 (0.4152) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4261 (0.4212) Acc D Real: 100.000%
Loss D Fake: 1.0451 (1.0833) Acc D Fake: 0.000%
Loss D: 1.471
Loss G: 0.4351 (0.4154) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4264 (0.4213) Acc D Real: 100.000%
Loss D Fake: 1.0439 (1.0828) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4357 (0.4157) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4262 (0.4213) Acc D Real: 100.000%
Loss D Fake: 1.0428 (1.0823) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4364 (0.4159) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4268 (0.4214) Acc D Real: 100.000%
Loss D Fake: 1.0416 (1.0818) Acc D Fake: 0.000%
Loss D: 1.468
Loss G: 0.4370 (0.4162) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4268 (0.4214) Acc D Real: 100.000%
Loss D Fake: 1.0404 (1.0813) Acc D Fake: 0.000%
Loss D: 1.467
Loss G: 0.4376 (0.4164) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4272 (0.4215) Acc D Real: 100.000%
Loss D Fake: 1.0392 (1.0808) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4383 (0.4167) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4278 (0.4216) Acc D Real: 100.000%
Loss D Fake: 1.0381 (1.0804) Acc D Fake: 0.000%
Loss D: 1.466
Loss G: 0.4389 (0.4170) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4264 (0.4216) Acc D Real: 100.000%
Loss D Fake: 1.0369 (1.0799) Acc D Fake: 0.000%
Loss D: 1.463
Loss G: 0.4395 (0.4172) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4259 (0.4217) Acc D Real: 100.000%
Loss D Fake: 1.0357 (1.0794) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4402 (0.4175) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4272 (0.4217) Acc D Real: 100.000%
Loss D Fake: 1.0344 (1.0788) Acc D Fake: 0.000%
Loss D: 1.462
Loss G: 0.4409 (0.4177) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4278 (0.4218) Acc D Real: 100.000%
Loss D Fake: 1.0332 (1.0783) Acc D Fake: 0.000%
Loss D: 1.461
Loss G: 0.4416 (0.4180) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4279 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.0319 (1.0778) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4423 (0.4183) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4278 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.0307 (1.0773) Acc D Fake: 0.000%
Loss D: 1.459
Loss G: 0.4430 (0.4185) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4282 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.0294 (1.0768) Acc D Fake: 0.000%
Loss D: 1.458
Loss G: 0.4437 (0.4188) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4270 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.0282 (1.0763) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4444 (0.4191) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4285 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.0269 (1.0758) Acc D Fake: 0.000%
Loss D: 1.455
Loss G: 0.4451 (0.4194) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4306 (0.4222) Acc D Real: 100.000%
Loss D Fake: 1.0256 (1.0752) Acc D Fake: 0.000%
Loss D: 1.456
Loss G: 0.4458 (0.4196) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4285 (0.4223) Acc D Real: 100.000%
Loss D Fake: 1.0244 (1.0747) Acc D Fake: 0.000%
Loss D: 1.453
Loss G: 0.4465 (0.4199) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4280 (0.4223) Acc D Real: 100.000%
Loss D Fake: 1.0232 (1.0742) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4472 (0.4202) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4300 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.0219 (1.0737) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4479 (0.4205) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4299 (0.4225) Acc D Real: 100.000%
Loss D Fake: 1.0207 (1.0731) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4486 (0.4207) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4309 (0.4226) Acc D Real: 100.000%
Loss D Fake: 1.0196 (1.0726) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4492 (0.4210) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4307 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.0184 (1.0721) Acc D Fake: 0.000%
Loss D: 1.449
Loss G: 0.4499 (0.4213) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4292 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.0173 (1.0715) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4505 (0.4216) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.4312 (0.4228) Acc D Real: 100.000%
Loss D Fake: 1.0162 (1.0710) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4512 (0.4219) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4308 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.0151 (1.0705) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4518 (0.4222) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4323 (0.4230) Acc D Real: 100.000%
Loss D Fake: 1.0141 (1.0699) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4524 (0.4225) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4317 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.0131 (1.0694) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4530 (0.4227) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4305 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.0121 (1.0689) Acc D Fake: 0.000%
Loss D: 1.443
Loss G: 0.4536 (0.4230) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4311 (0.4232) Acc D Real: 100.000%
Loss D Fake: 1.0111 (1.0684) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4542 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4304 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.0101 (1.0678) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4548 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4307 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.0090 (1.0673) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4554 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4340 (0.4234) Acc D Real: 100.000%
Loss D Fake: 1.0080 (1.0668) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4560 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4323 (0.4235) Acc D Real: 100.000%
Loss D Fake: 1.0071 (1.0662) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4565 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4329 (0.4236) Acc D Real: 100.000%
Loss D Fake: 1.0062 (1.0657) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4571 (0.4247) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4362 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.0054 (1.0652) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4575 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4322 (0.4238) Acc D Real: 100.000%
Loss D Fake: 1.0047 (1.0647) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4579 (0.4253) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4376 (0.4239) Acc D Real: 100.000%
Loss D Fake: 1.0041 (1.0641) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4582 (0.4256) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4357 (0.4240) Acc D Real: 100.000%
Loss D Fake: 1.0037 (1.0636) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4585 (0.4259) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4372 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.0034 (1.0631) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4586 (0.4261) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4356 (0.4242) Acc D Real: 100.000%
Loss D Fake: 1.0033 (1.0626) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4587 (0.4264) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4340 (0.4243) Acc D Real: 100.000%
Loss D Fake: 1.0032 (1.0621) Acc D Fake: 0.000%
Loss D: 1.437
Loss G: 0.4588 (0.4267) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4357 (0.4244) Acc D Real: 100.000%
Loss D Fake: 1.0031 (1.0617) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4588 (0.4269) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4373 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.0032 (1.0612) Acc D Fake: 0.000%
Loss D: 1.440
Loss G: 0.4588 (0.4272) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.4327 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.0033 (1.0607) Acc D Fake: 0.000%
Loss D: 1.436
Loss G: 0.4587 (0.4275) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4355 (0.4246) Acc D Real: 100.000%
Loss D Fake: 1.0035 (1.0603) Acc D Fake: 0.000%
Loss D: 1.439
Loss G: 0.4587 (0.4277) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4370 (0.4247) Acc D Real: 100.000%
Loss D Fake: 1.0037 (1.0598) Acc D Fake: 0.000%
Loss D: 1.441
Loss G: 0.4585 (0.4280) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4382 (0.4248) Acc D Real: 100.000%
Loss D Fake: 1.0041 (1.0594) Acc D Fake: 0.000%
Loss D: 1.442
Loss G: 0.4582 (0.4282) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4390 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.0047 (1.0589) Acc D Fake: 0.000%
Loss D: 1.444
Loss G: 0.4578 (0.4284) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4390 (0.4250) Acc D Real: 100.000%
Loss D Fake: 1.0056 (1.0585) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4573 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4383 (0.4252) Acc D Real: 100.000%
Loss D Fake: 1.0066 (1.0581) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4567 (0.4289) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4376 (0.4252) Acc D Real: 100.000%
Loss D Fake: 1.0077 (1.0577) Acc D Fake: 0.000%
Loss D: 1.445
Loss G: 0.4560 (0.4291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4366 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.0090 (1.0574) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4553 (0.4293) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4362 (0.4254) Acc D Real: 100.000%
Loss D Fake: 1.0104 (1.0570) Acc D Fake: 0.000%
Loss D: 1.447
Loss G: 0.4545 (0.4295) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4346 (0.4255) Acc D Real: 100.000%
Loss D Fake: 1.0118 (1.0567) Acc D Fake: 0.000%
Loss D: 1.446
Loss G: 0.4537 (0.4296) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4371 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.0132 (1.0564) Acc D Fake: 0.000%
Loss D: 1.450
Loss G: 0.4529 (0.4298) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4369 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.0148 (1.0561) Acc D Fake: 0.000%
Loss D: 1.452
Loss G: 0.4520 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4404 (0.4258) Acc D Real: 100.000%
Loss D Fake: 1.0166 (1.0558) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4509 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4351 (0.4258) Acc D Real: 100.000%
Loss D Fake: 1.0186 (1.0555) Acc D Fake: 0.000%
Loss D: 1.454
Loss G: 0.4497 (0.4303) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4308 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.0207 (1.0552) Acc D Fake: 0.000%
Loss D: 1.451
Loss G: 0.4486 (0.4304) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4375 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.0226 (1.0550) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4475 (0.4305) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4323 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.0247 (1.0548) Acc D Fake: 0.000%
Loss D: 1.457
Loss G: 0.4463 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4328 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.0268 (1.0546) Acc D Fake: 0.000%
Loss D: 1.460
Loss G: 0.4451 (0.4307) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4407 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.0291 (1.0544) Acc D Fake: 0.000%
Loss D: 1.470
Loss G: 0.4438 (0.4308) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4378 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.0316 (1.0543) Acc D Fake: 0.000%
Loss D: 1.469
Loss G: 0.4423 (0.4309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4380 (0.4263) Acc D Real: 100.000%
Loss D Fake: 1.0344 (1.0541) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4407 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4342 (0.4264) Acc D Real: 100.000%
Loss D Fake: 1.0374 (1.0540) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4390 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4317 (0.4264) Acc D Real: 100.000%
Loss D Fake: 1.0404 (1.0539) Acc D Fake: 0.000%
Loss D: 1.472
Loss G: 0.4374 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4363 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0434 (1.0538) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4357 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4295 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0465 (1.0538) Acc D Fake: 0.000%
Loss D: 1.476
Loss G: 0.4341 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4302 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0495 (1.0538) Acc D Fake: 0.000%
Loss D: 1.480
Loss G: 0.4325 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4300 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0524 (1.0538) Acc D Fake: 0.000%
Loss D: 1.482
Loss G: 0.4309 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4317 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0554 (1.0538) Acc D Fake: 0.000%
Loss D: 1.487
Loss G: 0.4293 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4272 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0585 (1.0538) Acc D Fake: 0.000%
Loss D: 1.486
Loss G: 0.4277 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4269 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0614 (1.0539) Acc D Fake: 0.000%
Loss D: 1.488
Loss G: 0.4261 (0.4311) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4300 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0643 (1.0539) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4246 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4292 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0673 (1.0540) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4230 (0.4310) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4273 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0703 (1.0541) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4214 (0.4309) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4278 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0733 (1.0542) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4198 (0.4308) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4241 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0763 (1.0544) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4183 (0.4308) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4240 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0792 (1.0545) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4168 (0.4307) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4245 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0821 (1.0547) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4153 (0.4306) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4249 (0.4266) Acc D Real: 100.000%
Loss D Fake: 1.0849 (1.0549) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4139 (0.4305) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4198 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0878 (1.0551) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4125 (0.4304) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4224 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0904 (1.0553) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4111 (0.4303) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4271 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.0555) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4098 (0.4301) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4183 (0.4265) Acc D Real: 100.000%
Loss D Fake: 1.0958 (1.0558) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4084 (0.4300) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4132 (0.4264) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.0560) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4073 (0.4299) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4166 (0.4263) Acc D Real: 100.000%
Loss D Fake: 1.1006 (1.0563) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4062 (0.4297) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4140 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.1028 (1.0566) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4051 (0.4296) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4138 (0.4262) Acc D Real: 100.000%
Loss D Fake: 1.1047 (1.0568) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4042 (0.4294) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4141 (0.4261) Acc D Real: 100.000%
Loss D Fake: 1.1066 (1.0571) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.4033 (0.4293) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4141 (0.4260) Acc D Real: 100.000%
Loss D Fake: 1.1084 (1.0574) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4025 (0.4291) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4126 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.1100 (1.0577) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.4017 (0.4290) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4129 (0.4259) Acc D Real: 100.000%
Loss D Fake: 1.1116 (1.0581) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.4009 (0.4288) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4088 (0.4258) Acc D Real: 100.000%
Loss D Fake: 1.1131 (1.0584) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.4002 (0.4286) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4107 (0.4257) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.0587) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3996 (0.4285) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4100 (0.4256) Acc D Real: 100.000%
Loss D Fake: 1.1158 (1.0590) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3990 (0.4283) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4113 (0.4255) Acc D Real: 100.000%
Loss D Fake: 1.1170 (1.0593) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3984 (0.4281) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4075 (0.4254) Acc D Real: 100.000%
Loss D Fake: 1.1182 (1.0597) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3978 (0.4280) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4106 (0.4253) Acc D Real: 100.000%
Loss D Fake: 1.1192 (1.0600) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3973 (0.4278) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4062 (0.4252) Acc D Real: 100.000%
Loss D Fake: 1.1202 (1.0603) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3969 (0.4276) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4070 (0.4251) Acc D Real: 100.000%
Loss D Fake: 1.1211 (1.0607) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3965 (0.4275) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4075 (0.4250) Acc D Real: 100.000%
Loss D Fake: 1.1219 (1.0610) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3961 (0.4273) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4062 (0.4249) Acc D Real: 100.000%
Loss D Fake: 1.1227 (1.0613) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3957 (0.4271) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4055 (0.4248) Acc D Real: 100.000%
Loss D Fake: 1.1234 (1.0617) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3954 (0.4269) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4050 (0.4247) Acc D Real: 100.000%
Loss D Fake: 1.1240 (1.0620) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3952 (0.4268) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4042 (0.4246) Acc D Real: 100.000%
Loss D Fake: 1.1245 (1.0623) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3949 (0.4266) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4047 (0.4245) Acc D Real: 100.000%
Loss D Fake: 1.1250 (1.0627) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3947 (0.4264) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4032 (0.4244) Acc D Real: 100.000%
Loss D Fake: 1.1254 (1.0630) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3945 (0.4263) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4006 (0.4243) Acc D Real: 100.000%
Loss D Fake: 1.1257 (1.0633) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3944 (0.4261) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4035 (0.4242) Acc D Real: 100.000%
Loss D Fake: 1.1260 (1.0637) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3943 (0.4259) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4040 (0.4241) Acc D Real: 100.000%
Loss D Fake: 1.1262 (1.0640) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3942 (0.4258) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4044 (0.4240) Acc D Real: 100.000%
Loss D Fake: 1.1264 (1.0643) Acc D Fake: 0.000%
Loss D: 1.531
Loss G: 0.3941 (0.4256) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4030 (0.4238) Acc D Real: 100.000%
Loss D Fake: 1.1265 (1.0646) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3940 (0.4254) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4034 (0.4237) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0649) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3940 (0.4253) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4036 (0.4236) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0653) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3940 (0.4251) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4017 (0.4235) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0656) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3939 (0.4250) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4030 (0.4234) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0659) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3939 (0.4248) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4028 (0.4233) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0662) Acc D Fake: 0.000%
Loss D: 1.530
Loss G: 0.3939 (0.4246) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4007 (0.4232) Acc D Real: 100.000%
Loss D Fake: 1.1268 (1.0665) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3940 (0.4245) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4008 (0.4231) Acc D Real: 100.000%
Loss D Fake: 1.1267 (1.0668) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3940 (0.4243) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4012 (0.4230) Acc D Real: 100.000%
Loss D Fake: 1.1265 (1.0671) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3941 (0.4242) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4004 (0.4229) Acc D Real: 100.000%
Loss D Fake: 1.1264 (1.0674) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3942 (0.4240) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4024 (0.4228) Acc D Real: 100.000%
Loss D Fake: 1.1262 (1.0677) Acc D Fake: 0.000%
Loss D: 1.529
Loss G: 0.3943 (0.4239) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4007 (0.4227) Acc D Real: 100.000%
Loss D Fake: 1.1260 (1.0680) Acc D Fake: 0.000%
Loss D: 1.527
Loss G: 0.3944 (0.4237) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4021 (0.4226) Acc D Real: 100.000%
Loss D Fake: 1.1257 (1.0682) Acc D Fake: 0.000%
Loss D: 1.528
Loss G: 0.3945 (0.4236) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.3997 (0.4225) Acc D Real: 100.000%
Loss D Fake: 1.1255 (1.0685) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3946 (0.4235) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4005 (0.4224) Acc D Real: 100.000%
Loss D Fake: 1.1252 (1.0688) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3948 (0.4233) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4007 (0.4222) Acc D Real: 100.000%
Loss D Fake: 1.1249 (1.0691) Acc D Fake: 0.000%
Loss D: 1.526
Loss G: 0.3949 (0.4232) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4008 (0.4221) Acc D Real: 100.000%
Loss D Fake: 1.1246 (1.0693) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3951 (0.4231) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4006 (0.4220) Acc D Real: 100.000%
Loss D Fake: 1.1242 (1.0696) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3953 (0.4229) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.3995 (0.4219) Acc D Real: 100.000%
Loss D Fake: 1.1239 (1.0698) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3954 (0.4228) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4011 (0.4218) Acc D Real: 100.000%
Loss D Fake: 1.1235 (1.0701) Acc D Fake: 0.000%
Loss D: 1.525
Loss G: 0.3956 (0.4227) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.3996 (0.4217) Acc D Real: 100.000%
Loss D Fake: 1.1231 (1.0703) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3958 (0.4225) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4006 (0.4216) Acc D Real: 100.000%
Loss D Fake: 1.1227 (1.0706) Acc D Fake: 0.000%
Loss D: 1.523
Loss G: 0.3960 (0.4224) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4001 (0.4215) Acc D Real: 100.000%
Loss D Fake: 1.1222 (1.0708) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3962 (0.4223) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4000 (0.4214) Acc D Real: 100.000%
Loss D Fake: 1.1218 (1.0710) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3964 (0.4222) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4001 (0.4213) Acc D Real: 100.000%
Loss D Fake: 1.1213 (1.0713) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3967 (0.4221) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4000 (0.4212) Acc D Real: 100.000%
Loss D Fake: 1.1209 (1.0715) Acc D Fake: 0.000%
Loss D: 1.521
Loss G: 0.3969 (0.4219) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4013 (0.4212) Acc D Real: 100.000%
Loss D Fake: 1.1204 (1.0717) Acc D Fake: 0.000%
Loss D: 1.522
Loss G: 0.3971 (0.4218) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.3999 (0.4211) Acc D Real: 100.000%
Loss D Fake: 1.1200 (1.0719) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3973 (0.4217) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4003 (0.4210) Acc D Real: 100.000%
Loss D Fake: 1.1195 (1.0722) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.3975 (0.4216) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4000 (0.4209) Acc D Real: 100.000%
Loss D Fake: 1.1190 (1.0724) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3978 (0.4215) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.3998 (0.4208) Acc D Real: 100.000%
Loss D Fake: 1.1185 (1.0726) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3980 (0.4214) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.3997 (0.4207) Acc D Real: 100.000%
Loss D Fake: 1.1180 (1.0728) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.3983 (0.4213) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4011 (0.4206) Acc D Real: 100.000%
Loss D Fake: 1.1175 (1.0730) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.3985 (0.4212) Acc G: 100.000%
LR: 2.000e-04
Epoch: 20/20
TRAIN Iteration: [   2/226]
Loss D Real: 0.4002 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1165 (1.1168) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3990 (0.3989) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   3/226]
Loss D Real: 0.4010 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1160 (1.1165) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.3992 (0.3990) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   4/226]
Loss D Real: 0.4008 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1155 (1.1163) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.3995 (0.3991) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   5/226]
Loss D Real: 0.4003 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1150 (1.1160) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3997 (0.3992) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   6/226]
Loss D Real: 0.4004 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1145 (1.1158) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.3999 (0.3993) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   7/226]
Loss D Real: 0.4003 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1140 (1.1155) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4002 (0.3995) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   8/226]
Loss D Real: 0.4007 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1135 (1.1153) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4004 (0.3996) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [   9/226]
Loss D Real: 0.4003 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1130 (1.1150) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4007 (0.3997) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  10/226]
Loss D Real: 0.4004 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1125 (1.1148) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4009 (0.3998) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  11/226]
Loss D Real: 0.4004 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1120 (1.1145) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4011 (0.3999) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  12/226]
Loss D Real: 0.4005 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1115 (1.1143) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4014 (0.4001) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  13/226]
Loss D Real: 0.4005 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1110 (1.1140) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4016 (0.4002) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  14/226]
Loss D Real: 0.4007 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1105 (1.1138) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4018 (0.4003) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  15/226]
Loss D Real: 0.4006 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1101 (1.1135) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4021 (0.4004) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  16/226]
Loss D Real: 0.4008 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1096 (1.1133) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4023 (0.4005) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  17/226]
Loss D Real: 0.4006 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1091 (1.1130) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4025 (0.4007) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  18/226]
Loss D Real: 0.4007 (0.4005) Acc D Real: 100.000%
Loss D Fake: 1.1086 (1.1128) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4028 (0.4008) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  19/226]
Loss D Real: 0.4009 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1082 (1.1125) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4030 (0.4009) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  20/226]
Loss D Real: 0.4008 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1077 (1.1123) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4032 (0.4010) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  21/226]
Loss D Real: 0.4008 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1072 (1.1121) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4034 (0.4011) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  22/226]
Loss D Real: 0.4007 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1068 (1.1118) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4037 (0.4012) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  23/226]
Loss D Real: 0.4012 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1063 (1.1116) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4039 (0.4014) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  24/226]
Loss D Real: 0.4010 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1059 (1.1113) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4041 (0.4015) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  25/226]
Loss D Real: 0.4010 (0.4006) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.1111) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4043 (0.4016) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  26/226]
Loss D Real: 0.4009 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1050 (1.1109) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4045 (0.4017) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  27/226]
Loss D Real: 0.4012 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1046 (1.1106) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4047 (0.4018) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  28/226]
Loss D Real: 0.4016 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1042 (1.1104) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4049 (0.4019) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  29/226]
Loss D Real: 0.4015 (0.4007) Acc D Real: 100.000%
Loss D Fake: 1.1038 (1.1102) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4051 (0.4020) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  30/226]
Loss D Real: 0.4016 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1034 (1.1100) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4053 (0.4021) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  31/226]
Loss D Real: 0.4008 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1030 (1.1097) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4055 (0.4022) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  32/226]
Loss D Real: 0.4002 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1026 (1.1095) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4057 (0.4024) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  33/226]
Loss D Real: 0.4013 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.1093) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4059 (0.4025) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  34/226]
Loss D Real: 0.4016 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1018 (1.1091) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4061 (0.4026) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  35/226]
Loss D Real: 0.4013 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1014 (1.1088) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4063 (0.4027) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  36/226]
Loss D Real: 0.4013 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1011 (1.1086) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4065 (0.4028) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  37/226]
Loss D Real: 0.4013 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1007 (1.1084) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4066 (0.4029) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  38/226]
Loss D Real: 0.4011 (0.4008) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.1082) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4068 (0.4030) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  39/226]
Loss D Real: 0.4021 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.1000 (1.1080) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4070 (0.4031) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  40/226]
Loss D Real: 0.4017 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.1078) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4071 (0.4032) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  41/226]
Loss D Real: 0.4025 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0993 (1.1076) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4073 (0.4033) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  42/226]
Loss D Real: 0.4007 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0990 (1.1074) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4075 (0.4034) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  43/226]
Loss D Real: 0.4010 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.1072) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4076 (0.4035) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  44/226]
Loss D Real: 0.4014 (0.4009) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.1070) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4078 (0.4036) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  45/226]
Loss D Real: 0.4020 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.1068) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4079 (0.4037) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  46/226]
Loss D Real: 0.4023 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0978 (1.1066) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4081 (0.4038) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  47/226]
Loss D Real: 0.4023 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.1064) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4082 (0.4039) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  48/226]
Loss D Real: 0.4010 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0972 (1.1062) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4083 (0.4040) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  49/226]
Loss D Real: 0.4013 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0969 (1.1060) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4085 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  50/226]
Loss D Real: 0.4008 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0967 (1.1058) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4086 (0.4041) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  51/226]
Loss D Real: 0.4008 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0964 (1.1056) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4087 (0.4042) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  52/226]
Loss D Real: 0.4015 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0962 (1.1054) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4088 (0.4043) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  53/226]
Loss D Real: 0.4005 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0959 (1.1053) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4090 (0.4044) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  54/226]
Loss D Real: 0.4020 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0957 (1.1051) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4091 (0.4045) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  55/226]
Loss D Real: 0.4013 (0.4010) Acc D Real: 100.000%
Loss D Fake: 1.0954 (1.1049) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4092 (0.4046) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  56/226]
Loss D Real: 0.4030 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0952 (1.1047) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4093 (0.4047) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  57/226]
Loss D Real: 0.4024 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0950 (1.1046) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4094 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  58/226]
Loss D Real: 0.4005 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.1044) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4095 (0.4048) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  59/226]
Loss D Real: 0.4017 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0946 (1.1042) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4096 (0.4049) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  60/226]
Loss D Real: 0.4013 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0944 (1.1041) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4097 (0.4050) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  61/226]
Loss D Real: 0.4027 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0942 (1.1039) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4098 (0.4051) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  62/226]
Loss D Real: 0.4025 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0940 (1.1038) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4099 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  63/226]
Loss D Real: 0.4010 (0.4011) Acc D Real: 100.000%
Loss D Fake: 1.0939 (1.1036) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4100 (0.4052) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  64/226]
Loss D Real: 0.4019 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0937 (1.1034) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4100 (0.4053) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  65/226]
Loss D Real: 0.4015 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0936 (1.1033) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4101 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  66/226]
Loss D Real: 0.4027 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0934 (1.1031) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4102 (0.4054) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  67/226]
Loss D Real: 0.4008 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0933 (1.1030) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4102 (0.4055) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  68/226]
Loss D Real: 0.4024 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0932 (1.1028) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4103 (0.4056) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  69/226]
Loss D Real: 0.4036 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.1027) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4104 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  70/226]
Loss D Real: 0.4005 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0930 (1.1026) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4104 (0.4057) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  71/226]
Loss D Real: 0.4004 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0929 (1.1024) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4105 (0.4058) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  72/226]
Loss D Real: 0.4025 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0928 (1.1023) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4105 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  73/226]
Loss D Real: 0.4021 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0927 (1.1022) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4106 (0.4059) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  74/226]
Loss D Real: 0.4018 (0.4012) Acc D Real: 100.000%
Loss D Fake: 1.0926 (1.1020) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4106 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  75/226]
Loss D Real: 0.4033 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.1019) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4106 (0.4060) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  76/226]
Loss D Real: 0.4050 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1018) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4107 (0.4061) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  77/226]
Loss D Real: 0.4025 (0.4013) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1017) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4107 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  78/226]
Loss D Real: 0.4051 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1015) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4107 (0.4062) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  79/226]
Loss D Real: 0.4031 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1014) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4107 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  80/226]
Loss D Real: 0.4021 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1013) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4107 (0.4063) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  81/226]
Loss D Real: 0.4020 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1012) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4107 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  82/226]
Loss D Real: 0.4017 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1011) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4108 (0.4064) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  83/226]
Loss D Real: 0.4014 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1010) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4108 (0.4065) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  84/226]
Loss D Real: 0.4007 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1009) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4108 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  85/226]
Loss D Real: 0.4036 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1008) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4108 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  86/226]
Loss D Real: 0.4005 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1007) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4108 (0.4066) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  87/226]
Loss D Real: 0.4023 (0.4014) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1006) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4108 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  88/226]
Loss D Real: 0.4036 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1005) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4107 (0.4067) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  89/226]
Loss D Real: 0.4022 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1004) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4107 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  90/226]
Loss D Real: 0.4034 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0923 (1.1003) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4107 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  91/226]
Loss D Real: 0.4036 (0.4015) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1002) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4107 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  92/226]
Loss D Real: 0.4050 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0924 (1.1001) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4107 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  93/226]
Loss D Real: 0.4023 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0925 (1.1001) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4106 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  94/226]
Loss D Real: 0.4015 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0926 (1.1000) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4106 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  95/226]
Loss D Real: 0.4027 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0926 (1.0999) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4106 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  96/226]
Loss D Real: 0.4013 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0927 (1.0998) Acc D Fake: 0.000%
Loss D: 1.494
Loss G: 0.4105 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  97/226]
Loss D Real: 0.4029 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0928 (1.0997) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4105 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  98/226]
Loss D Real: 0.4024 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0929 (1.0997) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4104 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [  99/226]
Loss D Real: 0.4040 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0930 (1.0996) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4104 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 100/226]
Loss D Real: 0.4016 (0.4016) Acc D Real: 100.000%
Loss D Fake: 1.0931 (1.0995) Acc D Fake: 0.000%
Loss D: 1.495
Loss G: 0.4103 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 101/226]
Loss D Real: 0.4057 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0932 (1.0995) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4103 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 102/226]
Loss D Real: 0.4038 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0933 (1.0994) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4102 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 103/226]
Loss D Real: 0.4058 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0934 (1.0994) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4102 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 104/226]
Loss D Real: 0.3990 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0935 (1.0993) Acc D Fake: 0.000%
Loss D: 1.493
Loss G: 0.4101 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 105/226]
Loss D Real: 0.4032 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0936 (1.0993) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4101 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 106/226]
Loss D Real: 0.4023 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0938 (1.0992) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4100 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 107/226]
Loss D Real: 0.4023 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0939 (1.0992) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4099 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 108/226]
Loss D Real: 0.4028 (0.4017) Acc D Real: 100.000%
Loss D Fake: 1.0940 (1.0991) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4099 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 109/226]
Loss D Real: 0.4046 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.0942 (1.0991) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4098 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 110/226]
Loss D Real: 0.4023 (0.4018) Acc D Real: 100.000%
Loss D: 1.497
Loss G: 0.4097 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 111/226]
Loss D Real: 0.4046 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.0945 (1.0990) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4096 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 112/226]
Loss D Real: 0.4036 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.0946 (1.0989) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4096 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 113/226]
Loss D Real: 0.4047 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.0948 (1.0989) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4095 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 114/226]
Loss D Real: 0.4017 (0.4018) Acc D Real: 100.000%
Loss D Fake: 1.0949 (1.0989) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4094 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 115/226]
Loss D Real: 0.4084 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0951 (1.0988) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4093 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 116/226]
Loss D Real: 0.4009 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0953 (1.0988) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4093 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 117/226]
Loss D Real: 0.4016 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0954 (1.0988) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4092 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 118/226]
Loss D Real: 0.4029 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0956 (1.0987) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4091 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 119/226]
Loss D Real: 0.4050 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0958 (1.0987) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4090 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 120/226]
Loss D Real: 0.4019 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0960 (1.0987) Acc D Fake: 0.000%
Loss D: 1.498
Loss G: 0.4089 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 121/226]
Loss D Real: 0.4010 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0961 (1.0987) Acc D Fake: 0.000%
Loss D: 1.497
Loss G: 0.4088 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 122/226]
Loss D Real: 0.4058 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0963 (1.0987) Acc D Fake: 0.000%
Loss D: 1.502
Loss G: 0.4087 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 123/226]
Loss D Real: 0.4030 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0965 (1.0986) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4086 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 124/226]
Loss D Real: 0.3995 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0967 (1.0986) Acc D Fake: 0.000%
Loss D: 1.496
Loss G: 0.4086 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 125/226]
Loss D Real: 0.4038 (0.4019) Acc D Real: 100.000%
Loss D Fake: 1.0969 (1.0986) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4085 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 126/226]
Loss D Real: 0.4101 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.0971 (1.0986) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4084 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 127/226]
Loss D Real: 0.4017 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.0973 (1.0986) Acc D Fake: 0.000%
Loss D: 1.499
Loss G: 0.4083 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 128/226]
Loss D Real: 0.4039 (0.4020) Acc D Real: 100.000%
Loss D Fake: 1.0975 (1.0986) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4082 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 129/226]
Loss D Real: 0.4070 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0977 (1.0986) Acc D Fake: 0.000%
Loss D: 1.505
Loss G: 0.4081 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 130/226]
Loss D Real: 0.4053 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.0986) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4080 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 131/226]
Loss D Real: 0.4026 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0981 (1.0986) Acc D Fake: 0.000%
Loss D: 1.501
Loss G: 0.4079 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 132/226]
Loss D Real: 0.4020 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0983 (1.0986) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4078 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 133/226]
Loss D Real: 0.4049 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0985 (1.0986) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4077 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 134/226]
Loss D Real: 0.4039 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0987 (1.0986) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4076 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 135/226]
Loss D Real: 0.4014 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0989 (1.0986) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4074 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 136/226]
Loss D Real: 0.4047 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0992 (1.0986) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4073 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 137/226]
Loss D Real: 0.4007 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0994 (1.0986) Acc D Fake: 0.000%
Loss D: 1.500
Loss G: 0.4072 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 138/226]
Loss D Real: 0.4039 (0.4021) Acc D Real: 100.000%
Loss D Fake: 1.0996 (1.0986) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4071 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 139/226]
Loss D Real: 0.4076 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.0986) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4070 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 140/226]
Loss D Real: 0.4043 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1001 (1.0986) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4069 (0.4077) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 141/226]
Loss D Real: 0.4063 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.0986) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4068 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 142/226]
Loss D Real: 0.4029 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1005 (1.0986) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4067 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 143/226]
Loss D Real: 0.4030 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1008 (1.0986) Acc D Fake: 0.000%
Loss D: 1.504
Loss G: 0.4066 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 144/226]
Loss D Real: 0.4021 (0.4022) Acc D Real: 100.000%
Loss D Fake: 1.1010 (1.0987) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4064 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 145/226]
Loss D Real: 0.4068 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1012 (1.0987) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4063 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 146/226]
Loss D Real: 0.4055 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1015 (1.0987) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4062 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 147/226]
Loss D Real: 0.4069 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1017 (1.0987) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4061 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 148/226]
Loss D Real: 0.4061 (0.4023) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.0987) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4060 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 149/226]
Loss D Real: 0.4080 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1021 (1.0988) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4059 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 150/226]
Loss D Real: 0.4089 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1023 (1.0988) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4058 (0.4076) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 151/226]
Loss D Real: 0.4065 (0.4024) Acc D Real: 100.000%
Loss D Fake: 1.1025 (1.0988) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4057 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 152/226]
Loss D Real: 0.4065 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1027 (1.0988) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4056 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 153/226]
Loss D Real: 0.4030 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1029 (1.0989) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4055 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 154/226]
Loss D Real: 0.4064 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1031 (1.0989) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4054 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 155/226]
Loss D Real: 0.4060 (0.4025) Acc D Real: 100.000%
Loss D Fake: 1.1033 (1.0989) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4053 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 156/226]
Loss D Real: 0.4099 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.0989) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4052 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 157/226]
Loss D Real: 0.4091 (0.4026) Acc D Real: 100.000%
Loss D Fake: 1.1037 (1.0990) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4051 (0.4075) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 158/226]
Loss D Real: 0.4081 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1039 (1.0990) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4050 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 159/226]
Loss D Real: 0.4077 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1041 (1.0990) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4049 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 160/226]
Loss D Real: 0.4090 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1042 (1.0991) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4049 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 161/226]
Loss D Real: 0.4060 (0.4027) Acc D Real: 100.000%
Loss D Fake: 1.1044 (1.0991) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4048 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 162/226]
Loss D Real: 0.4099 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.1045 (1.0991) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4047 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 163/226]
Loss D Real: 0.4040 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.1047 (1.0992) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4046 (0.4074) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 164/226]
Loss D Real: 0.4083 (0.4028) Acc D Real: 100.000%
Loss D Fake: 1.1048 (1.0992) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4046 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 165/226]
Loss D Real: 0.4078 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.1050 (1.0992) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4045 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 166/226]
Loss D Real: 0.4079 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.1051 (1.0993) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4044 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 167/226]
Loss D Real: 0.4095 (0.4029) Acc D Real: 100.000%
Loss D Fake: 1.1052 (1.0993) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4044 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 168/226]
Loss D Real: 0.4099 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.1053 (1.0994) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4043 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 169/226]
Loss D Real: 0.4087 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.1054 (1.0994) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4043 (0.4073) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 170/226]
Loss D Real: 0.4097 (0.4030) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.0994) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4042 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 171/226]
Loss D Real: 0.4099 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.1056 (1.0995) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4042 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 172/226]
Loss D Real: 0.4084 (0.4031) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0995) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4041 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 173/226]
Loss D Real: 0.4108 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0995) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4041 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 174/226]
Loss D Real: 0.4115 (0.4032) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.0996) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4041 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 175/226]
Loss D Real: 0.4134 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.0996) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4041 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 176/226]
Loss D Real: 0.4111 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.0996) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4041 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 177/226]
Loss D Real: 0.4102 (0.4033) Acc D Real: 100.000%
Loss D Fake: 1.1058 (1.0997) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4041 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 178/226]
Loss D Real: 0.4095 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0997) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4041 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 179/226]
Loss D Real: 0.4136 (0.4034) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0997) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4041 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 180/226]
Loss D Real: 0.4091 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.1057 (1.0998) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4041 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 181/226]
Loss D Real: 0.4109 (0.4035) Acc D Real: 100.000%
Loss D Fake: 1.1056 (1.0998) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4042 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 182/226]
Loss D Real: 0.4113 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.1056 (1.0998) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4042 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 183/226]
Loss D Real: 0.4106 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.1055 (1.0999) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4042 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 184/226]
Loss D Real: 0.4110 (0.4036) Acc D Real: 100.000%
Loss D Fake: 1.1054 (1.0999) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4043 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 185/226]
Loss D Real: 0.4118 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.1053 (1.0999) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4043 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 186/226]
Loss D Real: 0.4121 (0.4037) Acc D Real: 100.000%
Loss D Fake: 1.1052 (1.1000) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4044 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 187/226]
Loss D Real: 0.4125 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1050 (1.1000) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4044 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 188/226]
Loss D Real: 0.4125 (0.4038) Acc D Real: 100.000%
Loss D Fake: 1.1049 (1.1000) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4045 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 189/226]
Loss D Real: 0.4135 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1047 (1.1000) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4046 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 190/226]
Loss D Real: 0.4150 (0.4039) Acc D Real: 100.000%
Loss D Fake: 1.1045 (1.1001) Acc D Fake: 0.000%
Loss D: 1.520
Loss G: 0.4047 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 191/226]
Loss D Real: 0.4127 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1043 (1.1001) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4048 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 192/226]
Loss D Real: 0.4143 (0.4040) Acc D Real: 100.000%
Loss D Fake: 1.1041 (1.1001) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4049 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 193/226]
Loss D Real: 0.4154 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1038 (1.1001) Acc D Fake: 0.000%
Loss D: 1.519
Loss G: 0.4050 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 194/226]
Loss D Real: 0.4149 (0.4041) Acc D Real: 100.000%
Loss D Fake: 1.1035 (1.1001) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4052 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 195/226]
Loss D Real: 0.4137 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1032 (1.1002) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4053 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 196/226]
Loss D Real: 0.4135 (0.4042) Acc D Real: 100.000%
Loss D Fake: 1.1029 (1.1002) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4055 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 197/226]
Loss D Real: 0.4147 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1026 (1.1002) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4056 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 198/226]
Loss D Real: 0.4146 (0.4043) Acc D Real: 100.000%
Loss D Fake: 1.1022 (1.1002) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4058 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 199/226]
Loss D Real: 0.4153 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1019 (1.1002) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4060 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 200/226]
Loss D Real: 0.4138 (0.4044) Acc D Real: 100.000%
Loss D Fake: 1.1015 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4061 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 201/226]
Loss D Real: 0.4139 (0.4045) Acc D Real: 100.000%
Loss D Fake: 1.1011 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4063 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 202/226]
Loss D Real: 0.4178 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1007 (1.1002) Acc D Fake: 0.000%
Loss D: 1.518
Loss G: 0.4065 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 203/226]
Loss D Real: 0.4141 (0.4046) Acc D Real: 100.000%
Loss D Fake: 1.1003 (1.1002) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4067 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 204/226]
Loss D Real: 0.4152 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.0998 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4069 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 205/226]
Loss D Real: 0.4160 (0.4047) Acc D Real: 100.000%
Loss D Fake: 1.0994 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4072 (0.4068) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 206/226]
Loss D Real: 0.4178 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.0989 (1.1002) Acc D Fake: 0.000%
Loss D: 1.517
Loss G: 0.4074 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 207/226]
Loss D Real: 0.4173 (0.4048) Acc D Real: 100.000%
Loss D Fake: 1.0984 (1.1002) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4076 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 208/226]
Loss D Real: 0.4167 (0.4049) Acc D Real: 100.000%
Loss D Fake: 1.0979 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4079 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 209/226]
Loss D Real: 0.4180 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.0973 (1.1002) Acc D Fake: 0.000%
Loss D: 1.515
Loss G: 0.4082 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 210/226]
Loss D Real: 0.4195 (0.4050) Acc D Real: 100.000%
Loss D Fake: 1.0968 (1.1001) Acc D Fake: 0.000%
Loss D: 1.516
Loss G: 0.4084 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 211/226]
Loss D Real: 0.4179 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.0962 (1.1001) Acc D Fake: 0.000%
Loss D: 1.514
Loss G: 0.4087 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 212/226]
Loss D Real: 0.4177 (0.4051) Acc D Real: 100.000%
Loss D Fake: 1.0955 (1.1001) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4091 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 213/226]
Loss D Real: 0.4180 (0.4052) Acc D Real: 100.000%
Loss D Fake: 1.0949 (1.1001) Acc D Fake: 0.000%
Loss D: 1.513
Loss G: 0.4094 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 214/226]
Loss D Real: 0.4182 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.0942 (1.1001) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4097 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 215/226]
Loss D Real: 0.4162 (0.4053) Acc D Real: 100.000%
Loss D Fake: 1.0935 (1.1000) Acc D Fake: 0.000%
Loss D: 1.510
Loss G: 0.4100 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 216/226]
Loss D Real: 0.4193 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.0929 (1.1000) Acc D Fake: 0.000%
Loss D: 1.512
Loss G: 0.4103 (0.4069) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 217/226]
Loss D Real: 0.4170 (0.4054) Acc D Real: 100.000%
Loss D Fake: 1.0922 (1.1000) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4107 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 218/226]
Loss D Real: 0.4191 (0.4055) Acc D Real: 100.000%
Loss D Fake: 1.0915 (1.0999) Acc D Fake: 0.000%
Loss D: 1.511
Loss G: 0.4110 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 219/226]
Loss D Real: 0.4186 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.0908 (1.0999) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4114 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 220/226]
Loss D Real: 0.4182 (0.4056) Acc D Real: 100.000%
Loss D Fake: 1.0901 (1.0998) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4117 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 221/226]
Loss D Real: 0.4199 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.0893 (1.0998) Acc D Fake: 0.000%
Loss D: 1.509
Loss G: 0.4121 (0.4070) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 222/226]
Loss D Real: 0.4192 (0.4057) Acc D Real: 100.000%
Loss D Fake: 1.0886 (1.0997) Acc D Fake: 0.000%
Loss D: 1.508
Loss G: 0.4125 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 223/226]
Loss D Real: 0.4191 (0.4058) Acc D Real: 100.000%
Loss D Fake: 1.0878 (1.0997) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4129 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 224/226]
Loss D Real: 0.4198 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.0870 (1.0996) Acc D Fake: 0.000%
Loss D: 1.507
Loss G: 0.4133 (0.4071) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 225/226]
Loss D Real: 0.4197 (0.4059) Acc D Real: 100.000%
Loss D Fake: 1.0862 (1.0996) Acc D Fake: 0.000%
Loss D: 1.506
Loss G: 0.4137 (0.4072) Acc G: 100.000%
LR: 2.000e-04
TRAIN Iteration: [ 226/226]
Loss D Real: 0.4173 (0.4060) Acc D Real: 100.000%
Loss D Fake: 1.0854 (1.0995) Acc D Fake: 0.000%
Loss D: 1.503
Loss G: 0.4141 (0.4072) Acc G: 100.000%
LR: 2.000e-04
Best Metric: At 5 Epoch Gen 0.677 Dis
MODEL TRAINING COMPLETED.
 BEST RESULT SAVED
 Batch: 1/121
121
Batch [1/121]: Anomaly Score: 388.667 label: 0.0
 Batch: 2/121
Batch [2/121]: Anomaly Score: 400.877 label: 0.0
 Batch: 3/121
Batch [3/121]: Anomaly Score: 396.713 label: 0.0
 Batch: 4/121
Batch [4/121]: Anomaly Score: 385.431 label: 0.0
 Batch: 5/121
Batch [5/121]: Anomaly Score: 396.282 label: 0.0
 Batch: 6/121
Batch [6/121]: Anomaly Score: 379.090 label: 0.0
 Batch: 7/121
Batch [7/121]: Anomaly Score: 381.965 label: 0.0
 Batch: 8/121
Batch [8/121]: Anomaly Score: 398.052 label: 0.0
 Batch: 9/121
Batch [9/121]: Anomaly Score: 388.418 label: 0.0
 Batch: 10/121
Batch [10/121]: Anomaly Score: 377.248 label: 0.0
 Batch: 11/121
Batch [11/121]: Anomaly Score: 378.082 label: 0.0
 Batch: 12/121
Batch [12/121]: Anomaly Score: 374.707 label: 0.0
 Batch: 13/121
Batch [13/121]: Anomaly Score: 396.279 label: 0.0
 Batch: 14/121
Batch [14/121]: Anomaly Score: 381.354 label: 0.0
 Batch: 15/121
Batch [15/121]: Anomaly Score: 389.618 label: 0.0
 Batch: 16/121
Batch [16/121]: Anomaly Score: 400.964 label: 0.0
 Batch: 17/121
Batch [17/121]: Anomaly Score: 388.848 label: 0.0
 Batch: 18/121
Batch [18/121]: Anomaly Score: 389.620 label: 0.0
 Batch: 19/121
Batch [19/121]: Anomaly Score: 395.936 label: 0.0
 Batch: 20/121
Batch [20/121]: Anomaly Score: 393.399 label: 0.0
 Batch: 21/121
Batch [21/121]: Anomaly Score: 402.836 label: 0.0
 Batch: 22/121
Batch [22/121]: Anomaly Score: 396.799 label: 0.0
 Batch: 23/121
Batch [23/121]: Anomaly Score: 397.740 label: 0.0
 Batch: 24/121
Batch [24/121]: Anomaly Score: 391.733 label: 0.0
 Batch: 25/121
Batch [25/121]: Anomaly Score: 383.337 label: 0.0
 Batch: 26/121
Batch [26/121]: Anomaly Score: 386.870 label: 0.0
 Batch: 27/121
Batch [27/121]: Anomaly Score: 379.714 label: 0.0
 Batch: 28/121
Batch [28/121]: Anomaly Score: 394.784 label: 0.0
 Batch: 29/121
Batch [29/121]: Anomaly Score: 389.525 label: 0.0
 Batch: 30/121
Batch [30/121]: Anomaly Score: 378.772 label: 0.0
 Batch: 31/121
Batch [31/121]: Anomaly Score: 359.174 label: 0.0
 Batch: 32/121
Batch [32/121]: Anomaly Score: 365.216 label: 0.0
 Batch: 33/121
Batch [33/121]: Anomaly Score: 358.041 label: 0.0
 Batch: 34/121
Batch [34/121]: Anomaly Score: 376.802 label: 0.0
 Batch: 35/121
Batch [35/121]: Anomaly Score: 373.927 label: 0.0
 Batch: 36/121
Batch [36/121]: Anomaly Score: 380.419 label: 0.0
 Batch: 37/121
Batch [37/121]: Anomaly Score: 379.265 label: 0.0
 Batch: 38/121
Batch [38/121]: Anomaly Score: 378.408 label: 0.0
 Batch: 39/121
Batch [39/121]: Anomaly Score: 367.943 label: 0.0
 Batch: 40/121
Batch [40/121]: Anomaly Score: 381.466 label: 0.0
 Batch: 41/121
Batch [41/121]: Anomaly Score: 374.863 label: 0.0
 Batch: 42/121
Batch [42/121]: Anomaly Score: 366.563 label: 0.0
 Batch: 43/121
Batch [43/121]: Anomaly Score: 364.983 label: 0.0
 Batch: 44/121
Batch [44/121]: Anomaly Score: 365.576 label: 0.0
 Batch: 45/121
Batch [45/121]: Anomaly Score: 366.813 label: 0.0
 Batch: 46/121
Batch [46/121]: Anomaly Score: 377.453 label: 0.0
 Batch: 47/121
Batch [47/121]: Anomaly Score: 370.067 label: 0.0
 Batch: 48/121
Batch [48/121]: Anomaly Score: 380.927 label: 0.0
 Batch: 49/121
Batch [49/121]: Anomaly Score: 380.440 label: 0.0
 Batch: 50/121
Batch [50/121]: Anomaly Score: 371.385 label: 0.0
 Batch: 51/121
Batch [51/121]: Anomaly Score: 369.314 label: 0.0
 Batch: 52/121
Batch [52/121]: Anomaly Score: 369.765 label: 0.0
 Batch: 53/121
Batch [53/121]: Anomaly Score: 354.884 label: 0.0
 Batch: 54/121
Batch [54/121]: Anomaly Score: 354.934 label: 0.0
 Batch: 55/121
Batch [55/121]: Anomaly Score: 368.114 label: 0.0
 Batch: 56/121
Batch [56/121]: Anomaly Score: 367.346 label: 0.0
 Batch: 57/121
Batch [57/121]: Anomaly Score: 365.519 label: 0.0
 Batch: 58/121
Batch [58/121]: Anomaly Score: 376.468 label: 0.0
 Batch: 59/121
Batch [59/121]: Anomaly Score: 364.806 label: 0.0
 Batch: 60/121
Batch [60/121]: Anomaly Score: 357.900 label: 1.0
 Batch: 61/121
Batch [61/121]: Anomaly Score: 359.582 label: 1.0
 Batch: 62/121
Batch [62/121]: Anomaly Score: 357.994 label: 1.0
 Batch: 63/121
Batch [63/121]: Anomaly Score: 28.346 label: 1.0
 Batch: 64/121
Batch [64/121]: Anomaly Score: 352.504 label: 1.0
 Batch: 65/121
Batch [65/121]: Anomaly Score: 364.573 label: 1.0
 Batch: 66/121
Batch [66/121]: Anomaly Score: 363.729 label: 1.0
 Batch: 67/121
Batch [67/121]: Anomaly Score: 358.867 label: 0.0
 Batch: 68/121
Batch [68/121]: Anomaly Score: 376.380 label: 0.0
 Batch: 69/121
Batch [69/121]: Anomaly Score: 370.170 label: 0.0
 Batch: 70/121
Batch [70/121]: Anomaly Score: 372.747 label: 0.0
 Batch: 71/121
Batch [71/121]: Anomaly Score: 353.838 label: 0.0
 Batch: 72/121
Batch [72/121]: Anomaly Score: 361.429 label: 0.0
 Batch: 73/121
Batch [73/121]: Anomaly Score: 371.973 label: 0.0
 Batch: 74/121
Batch [74/121]: Anomaly Score: 376.414 label: 0.0
 Batch: 75/121
Batch [75/121]: Anomaly Score: 372.977 label: 0.0
 Batch: 76/121
Batch [76/121]: Anomaly Score: 379.558 label: 0.0
 Batch: 77/121
Batch [77/121]: Anomaly Score: 381.431 label: 0.0
 Batch: 78/121
Batch [78/121]: Anomaly Score: 387.505 label: 0.0
 Batch: 79/121
Batch [79/121]: Anomaly Score: 378.472 label: 0.0
 Batch: 80/121
Batch [80/121]: Anomaly Score: 380.481 label: 0.0
 Batch: 81/121
Batch [81/121]: Anomaly Score: 378.576 label: 0.0
 Batch: 82/121
Batch [82/121]: Anomaly Score: 382.456 label: 0.0
 Batch: 83/121
Batch [83/121]: Anomaly Score: 378.782 label: 0.0
 Batch: 84/121
Batch [84/121]: Anomaly Score: 381.667 label: 0.0
 Batch: 85/121
Batch [85/121]: Anomaly Score: 397.662 label: 0.0
 Batch: 86/121
Batch [86/121]: Anomaly Score: 389.958 label: 0.0
 Batch: 87/121
Batch [87/121]: Anomaly Score: 381.424 label: 0.0
 Batch: 88/121
Batch [88/121]: Anomaly Score: 386.662 label: 0.0
 Batch: 89/121
Batch [89/121]: Anomaly Score: 376.319 label: 0.0
 Batch: 90/121
Batch [90/121]: Anomaly Score: 389.130 label: 0.0
 Batch: 91/121
Batch [91/121]: Anomaly Score: 396.279 label: 0.0
 Batch: 92/121
Batch [92/121]: Anomaly Score: 402.073 label: 0.0
 Batch: 93/121
Batch [93/121]: Anomaly Score: 405.135 label: 0.0
 Batch: 94/121
Batch [94/121]: Anomaly Score: 386.969 label: 0.0
 Batch: 95/121
Batch [95/121]: Anomaly Score: 395.516 label: 0.0
 Batch: 96/121
Batch [96/121]: Anomaly Score: 402.827 label: 0.0
 Batch: 97/121
Batch [97/121]: Anomaly Score: 394.921 label: 0.0
 Batch: 98/121
Batch [98/121]: Anomaly Score: 395.703 label: 0.0
 Batch: 99/121
Batch [99/121]: Anomaly Score: 395.790 label: 0.0
 Batch: 100/121
Batch [100/121]: Anomaly Score: 394.383 label: 1.0
 Batch: 101/121
Batch [101/121]: Anomaly Score: 402.796 label: 1.0
 Batch: 102/121
Batch [102/121]: Anomaly Score: 396.948 label: 1.0
 Batch: 103/121
Batch [103/121]: Anomaly Score: 404.478 label: 1.0
 Batch: 104/121
Batch [104/121]: Anomaly Score: 412.443 label: 1.0
 Batch: 105/121
Batch [105/121]: Anomaly Score: 400.065 label: 1.0
 Batch: 106/121
Batch [106/121]: Anomaly Score: 400.684 label: 1.0
 Batch: 107/121
Batch [107/121]: Anomaly Score: 407.361 label: 1.0
 Batch: 108/121
Batch [108/121]: Anomaly Score: 393.058 label: 0.0
 Batch: 109/121
Batch [109/121]: Anomaly Score: 400.934 label: 0.0
 Batch: 110/121
Batch [110/121]: Anomaly Score: 401.528 label: 0.0
 Batch: 111/121
Batch [111/121]: Anomaly Score: 402.821 label: 0.0
 Batch: 112/121
Batch [112/121]: Anomaly Score: 407.781 label: 0.0
 Batch: 113/121
Batch [113/121]: Anomaly Score: 404.220 label: 0.0
 Batch: 114/121
Batch [114/121]: Anomaly Score: 391.742 label: 0.0
 Batch: 115/121
Batch [115/121]: Anomaly Score: 405.971 label: 0.0
 Batch: 116/121
Batch [116/121]: Anomaly Score: 393.439 label: 0.0
 Batch: 117/121
Batch [117/121]: Anomaly Score: 397.403 label: 0.0
 Batch: 118/121
Batch [118/121]: Anomaly Score: 411.412 label: 0.0
 Batch: 119/121
Batch [119/121]: Anomaly Score: 397.374 label: 0.0
 Batch: 120/121
Batch [120/121]: Anomaly Score: 395.226 label: 0.0
 Batch: 121/121
Batch [121/121]: Anomaly Score: 403.745 label: 0.0